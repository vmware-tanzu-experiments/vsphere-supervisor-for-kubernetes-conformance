{"msg":"Test Suite starting","total":270,"completed":0,"skipped":0,"failed":0}
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1613965799 - Will randomize all specs
Will run 270 of 4992 specs

Feb 22 03:50:04.717: INFO: >>> kubeConfig: /root/.kube/config
Feb 22 03:50:04.720: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Feb 22 03:50:08.590: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Feb 22 03:50:09.786: INFO: 33 / 33 pods in namespace 'kube-system' are running and ready (1 seconds elapsed)
Feb 22 03:50:09.786: INFO: expected 3 pod replicas in namespace 'kube-system', 3 are Running and Ready.
Feb 22 03:50:09.786: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Feb 22 03:50:09.896: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Feb 22 03:50:09.896: INFO: e2e test version: v1.18.2
Feb 22 03:50:09.901: INFO: kube-apiserver version: v1.18.10+wcp.2
Feb 22 03:50:09.901: INFO: >>> kubeConfig: /root/.kube/config
Feb 22 03:50:09.944: INFO: Cluster IP family: ipv4
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 03:50:09.946: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename pods
Feb 22 03:50:10.534: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Feb 22 03:50:10.675: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-9876
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Feb 22 03:50:10.843: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 03:51:15.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9876" for this suite.

â€¢ [SLOW TEST:65.641 seconds]
[k8s.io] Pods
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Pods should be submitted and removed [NodeConformance] [Conformance]","total":270,"completed":1,"skipped":23,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 03:51:15.596: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-3182
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-3182
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-3182
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-3182
Feb 22 03:51:16.020: INFO: Found 0 stateful pods, waiting for 1
Feb 22 03:51:26.059: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
Feb 22 03:51:36.050: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
Feb 22 03:51:46.029: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
Feb 22 03:51:56.066: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
Feb 22 03:52:06.045: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Feb 22 03:52:06.076: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-3182 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb 22 03:52:06.869: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb 22 03:52:06.869: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb 22 03:52:06.869: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb 22 03:52:06.884: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Feb 22 03:52:16.893: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 22 03:52:16.893: INFO: Waiting for statefulset status.replicas updated to 0
Feb 22 03:52:16.938: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999344s
Feb 22 03:52:17.948: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.990892491s
Feb 22 03:52:18.955: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.981341171s
Feb 22 03:52:19.964: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.974049892s
Feb 22 03:52:20.971: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.965549797s
Feb 22 03:52:21.984: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.957881311s
Feb 22 03:52:22.992: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.944793561s
Feb 22 03:52:24.003: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.937200944s
Feb 22 03:52:25.010: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.925528577s
Feb 22 03:52:26.041: INFO: Verifying statefulset ss doesn't scale past 1 for another 918.425116ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-3182
Feb 22 03:52:27.050: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-3182 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 22 03:52:27.559: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Feb 22 03:52:27.559: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb 22 03:52:27.559: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Feb 22 03:52:27.566: INFO: Found 1 stateful pods, waiting for 3
Feb 22 03:52:37.580: INFO: Found 2 stateful pods, waiting for 3
Feb 22 03:52:47.586: INFO: Found 2 stateful pods, waiting for 3
Feb 22 03:52:57.582: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 22 03:52:57.582: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 22 03:52:57.582: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Pending - Ready=false
Feb 22 03:53:07.578: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 22 03:53:07.578: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 22 03:53:07.578: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Pending - Ready=false
Feb 22 03:53:17.588: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 22 03:53:17.588: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 22 03:53:17.588: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Pending - Ready=false
Feb 22 03:53:27.578: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 22 03:53:27.578: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 22 03:53:27.579: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Feb 22 03:53:27.625: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-3182 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb 22 03:53:28.326: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb 22 03:53:28.326: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb 22 03:53:28.326: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb 22 03:53:28.326: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-3182 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb 22 03:53:29.372: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb 22 03:53:29.372: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb 22 03:53:29.372: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb 22 03:53:29.372: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-3182 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb 22 03:53:29.987: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb 22 03:53:29.987: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb 22 03:53:29.987: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb 22 03:53:29.987: INFO: Waiting for statefulset status.replicas updated to 0
Feb 22 03:53:29.997: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Feb 22 03:53:40.023: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 22 03:53:40.023: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Feb 22 03:53:40.023: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Feb 22 03:53:40.066: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999361s
Feb 22 03:53:41.078: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.988995358s
Feb 22 03:53:42.091: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.976474293s
Feb 22 03:53:43.108: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.963436252s
Feb 22 03:53:44.119: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.946894143s
Feb 22 03:53:45.150: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.935357651s
Feb 22 03:53:46.183: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.904416103s
Feb 22 03:53:47.193: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.872039777s
Feb 22 03:53:48.207: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.861361866s
Feb 22 03:53:49.216: INFO: Verifying statefulset ss doesn't scale past 3 for another 847.801636ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-3182
Feb 22 03:53:50.229: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-3182 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 22 03:53:50.747: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Feb 22 03:53:50.747: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb 22 03:53:50.747: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Feb 22 03:53:50.747: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-3182 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 22 03:53:51.425: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Feb 22 03:53:51.425: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb 22 03:53:51.425: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Feb 22 03:53:51.425: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-3182 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 22 03:53:51.831: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Feb 22 03:53:51.831: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb 22 03:53:51.831: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Feb 22 03:53:51.831: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Feb 22 03:54:41.880: INFO: Deleting all statefulset in ns statefulset-3182
Feb 22 03:54:41.889: INFO: Scaling statefulset ss to 0
Feb 22 03:54:41.923: INFO: Waiting for statefulset status.replicas updated to 0
Feb 22 03:54:41.929: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 03:54:41.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3182" for this suite.

â€¢ [SLOW TEST:206.497 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]","total":270,"completed":2,"skipped":72,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 03:54:42.108: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3835
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-9f8cb7c3-efb7-4d7a-9a31-a8fd3e1db682
STEP: Creating a pod to test consume secrets
Feb 22 03:54:42.558: INFO: Waiting up to 5m0s for pod "pod-secrets-7124a6c3-b740-45ef-b606-8e33db7f9d14" in namespace "secrets-3835" to be "Succeeded or Failed"
Feb 22 03:54:42.598: INFO: Pod "pod-secrets-7124a6c3-b740-45ef-b606-8e33db7f9d14": Phase="Pending", Reason="", readiness=false. Elapsed: 39.562393ms
Feb 22 03:54:44.608: INFO: Pod "pod-secrets-7124a6c3-b740-45ef-b606-8e33db7f9d14": Phase="Pending", Reason="", readiness=false. Elapsed: 2.050333368s
Feb 22 03:54:46.625: INFO: Pod "pod-secrets-7124a6c3-b740-45ef-b606-8e33db7f9d14": Phase="Pending", Reason="", readiness=false. Elapsed: 4.067318096s
Feb 22 03:54:48.655: INFO: Pod "pod-secrets-7124a6c3-b740-45ef-b606-8e33db7f9d14": Phase="Pending", Reason="", readiness=false. Elapsed: 6.097232926s
Feb 22 03:54:50.663: INFO: Pod "pod-secrets-7124a6c3-b740-45ef-b606-8e33db7f9d14": Phase="Pending", Reason="", readiness=false. Elapsed: 8.104653048s
Feb 22 03:54:52.682: INFO: Pod "pod-secrets-7124a6c3-b740-45ef-b606-8e33db7f9d14": Phase="Pending", Reason="", readiness=false. Elapsed: 10.124013039s
Feb 22 03:54:54.694: INFO: Pod "pod-secrets-7124a6c3-b740-45ef-b606-8e33db7f9d14": Phase="Pending", Reason="", readiness=false. Elapsed: 12.136376322s
Feb 22 03:54:56.706: INFO: Pod "pod-secrets-7124a6c3-b740-45ef-b606-8e33db7f9d14": Phase="Pending", Reason="", readiness=false. Elapsed: 14.147793349s
Feb 22 03:54:58.715: INFO: Pod "pod-secrets-7124a6c3-b740-45ef-b606-8e33db7f9d14": Phase="Pending", Reason="", readiness=false. Elapsed: 16.157232576s
Feb 22 03:55:00.724: INFO: Pod "pod-secrets-7124a6c3-b740-45ef-b606-8e33db7f9d14": Phase="Pending", Reason="", readiness=false. Elapsed: 18.166276207s
Feb 22 03:55:02.762: INFO: Pod "pod-secrets-7124a6c3-b740-45ef-b606-8e33db7f9d14": Phase="Pending", Reason="", readiness=false. Elapsed: 20.203622905s
Feb 22 03:55:04.775: INFO: Pod "pod-secrets-7124a6c3-b740-45ef-b606-8e33db7f9d14": Phase="Pending", Reason="", readiness=false. Elapsed: 22.217256987s
Feb 22 03:55:06.790: INFO: Pod "pod-secrets-7124a6c3-b740-45ef-b606-8e33db7f9d14": Phase="Pending", Reason="", readiness=false. Elapsed: 24.23198451s
Feb 22 03:55:08.804: INFO: Pod "pod-secrets-7124a6c3-b740-45ef-b606-8e33db7f9d14": Phase="Pending", Reason="", readiness=false. Elapsed: 26.245638481s
Feb 22 03:55:10.812: INFO: Pod "pod-secrets-7124a6c3-b740-45ef-b606-8e33db7f9d14": Phase="Pending", Reason="", readiness=false. Elapsed: 28.253733253s
Feb 22 03:55:12.829: INFO: Pod "pod-secrets-7124a6c3-b740-45ef-b606-8e33db7f9d14": Phase="Pending", Reason="", readiness=false. Elapsed: 30.271385025s
Feb 22 03:55:14.841: INFO: Pod "pod-secrets-7124a6c3-b740-45ef-b606-8e33db7f9d14": Phase="Pending", Reason="", readiness=false. Elapsed: 32.282679656s
Feb 22 03:55:16.847: INFO: Pod "pod-secrets-7124a6c3-b740-45ef-b606-8e33db7f9d14": Phase="Pending", Reason="", readiness=false. Elapsed: 34.289379907s
Feb 22 03:55:18.856: INFO: Pod "pod-secrets-7124a6c3-b740-45ef-b606-8e33db7f9d14": Phase="Pending", Reason="", readiness=false. Elapsed: 36.298305195s
Feb 22 03:55:20.862: INFO: Pod "pod-secrets-7124a6c3-b740-45ef-b606-8e33db7f9d14": Phase="Pending", Reason="", readiness=false. Elapsed: 38.303674961s
Feb 22 03:55:22.869: INFO: Pod "pod-secrets-7124a6c3-b740-45ef-b606-8e33db7f9d14": Phase="Pending", Reason="", readiness=false. Elapsed: 40.310734473s
Feb 22 03:55:24.874: INFO: Pod "pod-secrets-7124a6c3-b740-45ef-b606-8e33db7f9d14": Phase="Pending", Reason="", readiness=false. Elapsed: 42.316187039s
Feb 22 03:55:26.881: INFO: Pod "pod-secrets-7124a6c3-b740-45ef-b606-8e33db7f9d14": Phase="Pending", Reason="", readiness=false. Elapsed: 44.323403719s
Feb 22 03:55:28.895: INFO: Pod "pod-secrets-7124a6c3-b740-45ef-b606-8e33db7f9d14": Phase="Pending", Reason="", readiness=false. Elapsed: 46.337403777s
Feb 22 03:55:30.908: INFO: Pod "pod-secrets-7124a6c3-b740-45ef-b606-8e33db7f9d14": Phase="Pending", Reason="", readiness=false. Elapsed: 48.349772225s
Feb 22 03:55:32.916: INFO: Pod "pod-secrets-7124a6c3-b740-45ef-b606-8e33db7f9d14": Phase="Pending", Reason="", readiness=false. Elapsed: 50.358394625s
Feb 22 03:55:34.937: INFO: Pod "pod-secrets-7124a6c3-b740-45ef-b606-8e33db7f9d14": Phase="Pending", Reason="", readiness=false. Elapsed: 52.379162122s
Feb 22 03:55:36.944: INFO: Pod "pod-secrets-7124a6c3-b740-45ef-b606-8e33db7f9d14": Phase="Pending", Reason="", readiness=false. Elapsed: 54.386022095s
Feb 22 03:55:38.991: INFO: Pod "pod-secrets-7124a6c3-b740-45ef-b606-8e33db7f9d14": Phase="Succeeded", Reason="", readiness=false. Elapsed: 56.433294459s
STEP: Saw pod success
Feb 22 03:55:38.991: INFO: Pod "pod-secrets-7124a6c3-b740-45ef-b606-8e33db7f9d14" satisfied condition "Succeeded or Failed"
Feb 22 03:55:39.021: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com pod pod-secrets-7124a6c3-b740-45ef-b606-8e33db7f9d14 container secret-volume-test: <nil>
STEP: delete the pod
Feb 22 03:55:39.151: INFO: Waiting for pod pod-secrets-7124a6c3-b740-45ef-b606-8e33db7f9d14 to disappear
Feb 22 03:55:39.174: INFO: Pod pod-secrets-7124a6c3-b740-45ef-b606-8e33db7f9d14 still exists
Feb 22 03:55:41.174: INFO: Waiting for pod pod-secrets-7124a6c3-b740-45ef-b606-8e33db7f9d14 to disappear
Feb 22 03:55:41.180: INFO: Pod pod-secrets-7124a6c3-b740-45ef-b606-8e33db7f9d14 still exists
Feb 22 03:55:43.174: INFO: Waiting for pod pod-secrets-7124a6c3-b740-45ef-b606-8e33db7f9d14 to disappear
Feb 22 03:55:43.182: INFO: Pod pod-secrets-7124a6c3-b740-45ef-b606-8e33db7f9d14 still exists
Feb 22 03:55:45.174: INFO: Waiting for pod pod-secrets-7124a6c3-b740-45ef-b606-8e33db7f9d14 to disappear
Feb 22 03:55:45.183: INFO: Pod pod-secrets-7124a6c3-b740-45ef-b606-8e33db7f9d14 still exists
Feb 22 03:55:47.174: INFO: Waiting for pod pod-secrets-7124a6c3-b740-45ef-b606-8e33db7f9d14 to disappear
Feb 22 03:55:47.181: INFO: Pod pod-secrets-7124a6c3-b740-45ef-b606-8e33db7f9d14 still exists
Feb 22 03:55:49.174: INFO: Waiting for pod pod-secrets-7124a6c3-b740-45ef-b606-8e33db7f9d14 to disappear
Feb 22 03:55:49.186: INFO: Pod pod-secrets-7124a6c3-b740-45ef-b606-8e33db7f9d14 still exists
Feb 22 03:55:51.174: INFO: Waiting for pod pod-secrets-7124a6c3-b740-45ef-b606-8e33db7f9d14 to disappear
Feb 22 03:55:51.183: INFO: Pod pod-secrets-7124a6c3-b740-45ef-b606-8e33db7f9d14 still exists
Feb 22 03:55:53.174: INFO: Waiting for pod pod-secrets-7124a6c3-b740-45ef-b606-8e33db7f9d14 to disappear
Feb 22 03:55:53.180: INFO: Pod pod-secrets-7124a6c3-b740-45ef-b606-8e33db7f9d14 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 03:55:53.181: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3835" for this suite.

â€¢ [SLOW TEST:71.274 seconds]
[sig-storage] Secrets
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:36
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":270,"completed":3,"skipped":119,"failed":0}
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 03:55:53.378: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-8270
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:91
Feb 22 03:55:53.650: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 22 03:55:53.684: INFO: Waiting for terminating namespaces to be deleted...
Feb 22 03:55:53.699: INFO: 
Logging pods the kubelet thinks is on node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com before test
Feb 22 03:55:53.733: INFO: wcp-sanity-busybox-7bf494fc58-tlpw6 from test-update-workload-ns started at 2021-02-22 03:28:50 +0000 UTC (1 container statuses recorded)
Feb 22 03:55:53.734: INFO: 	Container wcp-sanity-busybox-container ready: true, restart count 0
Feb 22 03:55:53.734: INFO: helloworld from test-telemetry started at 2021-02-22 03:31:02 +0000 UTC (1 container statuses recorded)
Feb 22 03:55:53.734: INFO: 	Container hello ready: true, restart count 0
Feb 22 03:55:53.734: INFO: nginx-private from test-image-pull-secrets-ns started at 2021-02-22 03:11:22 +0000 UTC (1 container statuses recorded)
Feb 22 03:55:53.734: INFO: 	Container nginx-private-container ready: true, restart count 0
Feb 22 03:55:53.734: INFO: helloworld from test-kube-events-ns started at 2021-02-22 03:14:06 +0000 UTC (1 container statuses recorded)
Feb 22 03:55:53.734: INFO: 	Container hello ready: true, restart count 0
Feb 22 03:55:53.734: INFO: schedext-test-node-selector-1 from test-node-selector started at 2021-02-22 03:16:36 +0000 UTC (1 container statuses recorded)
Feb 22 03:55:53.734: INFO: 	Container hello ready: true, restart count 0
Feb 22 03:55:53.734: INFO: schedext-test-affinity-3 from test-pod-affinity started at 2021-02-22 03:18:02 +0000 UTC (1 container statuses recorded)
Feb 22 03:55:53.734: INFO: 	Container hello ready: true, restart count 0
Feb 22 03:55:53.734: INFO: test-docker-registry from test-private-image-registry-ns started at 2021-02-22 03:23:54 +0000 UTC (1 container statuses recorded)
Feb 22 03:55:53.734: INFO: 	Container test-docker-registry ready: true, restart count 0
Feb 22 03:55:53.734: INFO: 
Logging pods the kubelet thinks is on node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com before test
Feb 22 03:55:53.771: INFO: hello-web-2-dcbfdb96d-zbpc8 from test-network-policy started at 2021-02-22 03:15:17 +0000 UTC (1 container statuses recorded)
Feb 22 03:55:53.772: INFO: 	Container hello-app ready: true, restart count 0
Feb 22 03:55:53.772: INFO: podwithpersistentvolume from storage-class-test-2 started at 2021-02-22 03:25:55 +0000 UTC (1 container statuses recorded)
Feb 22 03:55:53.772: INFO: 	Container hello ready: true, restart count 0
Feb 22 03:55:53.772: INFO: helloworld from test-update-workload-ns started at 2021-02-22 03:29:47 +0000 UTC (1 container statuses recorded)
Feb 22 03:55:53.772: INFO: 	Container hello ready: true, restart count 0
Feb 22 03:55:53.772: INFO: hello-web-5f76cbcd98-4j9qm from test-cluster-ip-service started at 2021-02-22 03:04:48 +0000 UTC (1 container statuses recorded)
Feb 22 03:55:53.772: INFO: 	Container hello-app ready: true, restart count 0
Feb 22 03:55:53.772: INFO: helloworld from test-exec-ns started at 2021-02-22 03:10:20 +0000 UTC (1 container statuses recorded)
Feb 22 03:55:53.772: INFO: 	Container hello ready: true, restart count 0
Feb 22 03:55:53.772: INFO: hello-web-1-5f76cbcd98-gzs8q from test-network-policy started at 2021-02-22 03:15:17 +0000 UTC (1 container statuses recorded)
Feb 22 03:55:53.772: INFO: 	Container hello-app ready: true, restart count 0
Feb 22 03:55:53.772: INFO: schedext-test-node-selector-2 from test-node-selector started at 2021-02-22 03:16:42 +0000 UTC (1 container statuses recorded)
Feb 22 03:55:53.772: INFO: 	Container hello ready: true, restart count 0
Feb 22 03:55:53.772: INFO: busybox-annotation from test-podvm-annotations started at 2021-02-22 03:20:40 +0000 UTC (1 container statuses recorded)
Feb 22 03:55:53.772: INFO: 	Container busybox-annotation ready: true, restart count 0
Feb 22 03:55:53.772: INFO: wcp-sanity-busybox-7bf494fc58-rlg2l from test-update-workload-ns started at 2021-02-22 03:28:51 +0000 UTC (1 container statuses recorded)
Feb 22 03:55:53.772: INFO: 	Container wcp-sanity-busybox-container ready: true, restart count 0
Feb 22 03:55:53.772: INFO: 
Logging pods the kubelet thinks is on node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com before test
Feb 22 03:55:53.792: INFO: busybox from test-pod-external-nw-access started at 2021-02-22 03:22:58 +0000 UTC (1 container statuses recorded)
Feb 22 03:55:53.792: INFO: 	Container busybox ready: true, restart count 0
Feb 22 03:55:53.792: INFO: curl-pod from test-cluster-ip-service started at 2021-02-22 03:04:01 +0000 UTC (1 container statuses recorded)
Feb 22 03:55:53.792: INFO: 	Container curl-container ready: true, restart count 0
Feb 22 03:55:53.792: INFO: curl-pod from test-network-policy started at 2021-02-22 03:15:49 +0000 UTC (1 container statuses recorded)
Feb 22 03:55:53.792: INFO: 	Container curl-container ready: true, restart count 0
Feb 22 03:55:53.792: INFO: schedext-test-affinity-1 from test-pod-affinity started at 2021-02-22 03:17:26 +0000 UTC (1 container statuses recorded)
Feb 22 03:55:53.792: INFO: 	Container hello ready: true, restart count 0
Feb 22 03:55:53.792: INFO: schedext-test-affinity-2 from test-pod-affinity started at 2021-02-22 03:17:50 +0000 UTC (1 container statuses recorded)
Feb 22 03:55:53.792: INFO: 	Container hello ready: true, restart count 0
Feb 22 03:55:53.792: INFO: wcp-sanity-busybox-7bf494fc58-7sn7q from test-dataprovider-podvms-ns started at 2021-02-22 03:08:43 +0000 UTC (1 container statuses recorded)
Feb 22 03:55:53.792: INFO: 	Container wcp-sanity-busybox-container ready: true, restart count 0
Feb 22 03:55:53.792: INFO: wcp-sanity-busybox-7bf494fc58-pln4w from test-dataprovider-podvms-ns started at 2021-02-22 03:08:42 +0000 UTC (1 container statuses recorded)
Feb 22 03:55:53.792: INFO: 	Container wcp-sanity-busybox-container ready: true, restart count 0
Feb 22 03:55:53.792: INFO: podwithpersistentvolume from storage-policy-test started at 2021-02-22 03:27:14 +0000 UTC (1 container statuses recorded)
Feb 22 03:55:53.792: INFO: 	Container hello ready: true, restart count 0
Feb 22 03:55:53.792: INFO: wcp-sanity-busybox-7bf494fc58-npc5m from test-update-workload-ns started at 2021-02-22 03:28:52 +0000 UTC (1 container statuses recorded)
Feb 22 03:55:53.792: INFO: 	Container wcp-sanity-busybox-container ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: verifying the node has the label node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com
STEP: verifying the node has the label node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com
STEP: verifying the node has the label node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com
Feb 22 03:55:54.144: INFO: Pod podwithpersistentvolume requesting resource cpu=0m on Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com
Feb 22 03:55:54.144: INFO: Pod podwithpersistentvolume requesting resource cpu=0m on Node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com
Feb 22 03:55:54.144: INFO: Pod curl-pod requesting resource cpu=0m on Node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com
Feb 22 03:55:54.144: INFO: Pod hello-web-5f76cbcd98-4j9qm requesting resource cpu=0m on Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com
Feb 22 03:55:54.145: INFO: Pod wcp-sanity-busybox-7bf494fc58-7sn7q requesting resource cpu=0m on Node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com
Feb 22 03:55:54.145: INFO: Pod wcp-sanity-busybox-7bf494fc58-pln4w requesting resource cpu=0m on Node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com
Feb 22 03:55:54.145: INFO: Pod helloworld requesting resource cpu=0m on Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com
Feb 22 03:55:54.145: INFO: Pod nginx-private requesting resource cpu=0m on Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com
Feb 22 03:55:54.146: INFO: Pod helloworld requesting resource cpu=0m on Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com
Feb 22 03:55:54.146: INFO: Pod curl-pod requesting resource cpu=0m on Node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com
Feb 22 03:55:54.146: INFO: Pod hello-web-1-5f76cbcd98-gzs8q requesting resource cpu=0m on Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com
Feb 22 03:55:54.146: INFO: Pod hello-web-2-dcbfdb96d-zbpc8 requesting resource cpu=0m on Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com
Feb 22 03:55:54.146: INFO: Pod schedext-test-node-selector-1 requesting resource cpu=0m on Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com
Feb 22 03:55:54.147: INFO: Pod schedext-test-node-selector-2 requesting resource cpu=0m on Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com
Feb 22 03:55:54.147: INFO: Pod schedext-test-affinity-1 requesting resource cpu=500m on Node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com
Feb 22 03:55:54.147: INFO: Pod schedext-test-affinity-2 requesting resource cpu=500m on Node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com
Feb 22 03:55:54.147: INFO: Pod schedext-test-affinity-3 requesting resource cpu=500m on Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com
Feb 22 03:55:54.147: INFO: Pod busybox requesting resource cpu=0m on Node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com
Feb 22 03:55:54.148: INFO: Pod busybox-annotation requesting resource cpu=0m on Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com
Feb 22 03:55:54.148: INFO: Pod test-docker-registry requesting resource cpu=0m on Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com
Feb 22 03:55:54.148: INFO: Pod helloworld requesting resource cpu=0m on Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com
Feb 22 03:55:54.148: INFO: Pod helloworld requesting resource cpu=0m on Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com
Feb 22 03:55:54.149: INFO: Pod wcp-sanity-busybox-7bf494fc58-npc5m requesting resource cpu=0m on Node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com
Feb 22 03:55:54.150: INFO: Pod wcp-sanity-busybox-7bf494fc58-rlg2l requesting resource cpu=0m on Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com
Feb 22 03:55:54.150: INFO: Pod wcp-sanity-busybox-7bf494fc58-tlpw6 requesting resource cpu=0m on Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com
STEP: Starting Pods to consume most of the cluster CPU.
Feb 22 03:55:54.154: INFO: Creating a pod which consumes cpu=6650m on Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com
Feb 22 03:55:54.185: INFO: Creating a pod which consumes cpu=7000m on Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com
Feb 22 03:55:54.209: INFO: Creating a pod which consumes cpu=5600m on Node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3f5134c0-abea-4413-b2ba-50eb933ea0e7.1613966164], Reason = [SuccessfulRealizeNSXResource], Message = [Successfully realized NSX resource for Pod]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3f5134c0-abea-4413-b2ba-50eb933ea0e7.1665f5aa71ba4353], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8270/filler-pod-3f5134c0-abea-4413-b2ba-50eb933ea0e7 to sc2-rdops-vm05-dhcp-179-105.eng.vmware.com]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3f5134c0-abea-4413-b2ba-50eb933ea0e7.1665f5af53c0430f], Reason = [Image], Message = [Image pause-54467452d21a00c28aa4cce37d0850173b528ca6-v42879 bound successfully]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3f5134c0-abea-4413-b2ba-50eb933ea0e7.1665f5b0ded01578], Reason = [Pulling], Message = [Waiting for Image sched-pred-8270/pause-54467452d21a00c28aa4cce37d0850173b528ca6-v42879]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3f5134c0-abea-4413-b2ba-50eb933ea0e7.1665f5b1e06235a0], Reason = [Pulled], Message = [Image sched-pred-8270/pause-54467452d21a00c28aa4cce37d0850173b528ca6-v42879 is ready]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3f5134c0-abea-4413-b2ba-50eb933ea0e7.1665f5b496575ca8], Reason = [SuccessfulMountVolume], Message = [Successfully mounted volume default-token-g42gj]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3f5134c0-abea-4413-b2ba-50eb933ea0e7.1665f5b496589140], Reason = [Created], Message = [Created container filler-pod-3f5134c0-abea-4413-b2ba-50eb933ea0e7]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3f5134c0-abea-4413-b2ba-50eb933ea0e7.1665f5b496592d80], Reason = [Started], Message = [Started container filler-pod-3f5134c0-abea-4413-b2ba-50eb933ea0e7]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-adeab647-2792-4008-b3bc-1816defceb3a.1613966163], Reason = [SuccessfulRealizeNSXResource], Message = [Successfully realized NSX resource for Pod]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-adeab647-2792-4008-b3bc-1816defceb3a.1665f5aa68dfc2c7], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8270/filler-pod-adeab647-2792-4008-b3bc-1816defceb3a to sc2-rdops-vm05-dhcp-174-51.eng.vmware.com]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-adeab647-2792-4008-b3bc-1816defceb3a.1665f5aaa581fe46], Reason = [Image], Message = [Image pause-54467452d21a00c28aa4cce37d0850173b528ca6-v19832 bound successfully]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-adeab647-2792-4008-b3bc-1816defceb3a.1665f5b13416f880], Reason = [Pulling], Message = [Waiting for Image sched-pred-8270/pause-54467452d21a00c28aa4cce37d0850173b528ca6-v19832]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-adeab647-2792-4008-b3bc-1816defceb3a.1665f5b1b7e4c6d8], Reason = [Pulled], Message = [Image sched-pred-8270/pause-54467452d21a00c28aa4cce37d0850173b528ca6-v19832 is ready]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-adeab647-2792-4008-b3bc-1816defceb3a.1665f5b4a3c50f70], Reason = [SuccessfulMountVolume], Message = [Successfully mounted volume default-token-g42gj]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-adeab647-2792-4008-b3bc-1816defceb3a.1665f5b4a3c68e40], Reason = [Created], Message = [Created container filler-pod-adeab647-2792-4008-b3bc-1816defceb3a]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-adeab647-2792-4008-b3bc-1816defceb3a.1665f5b4a3c7e9e8], Reason = [Started], Message = [Started container filler-pod-adeab647-2792-4008-b3bc-1816defceb3a]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e3607ece-8f7f-40aa-8da7-14253519dccc.1613966162], Reason = [SuccessfulRealizeNSXResource], Message = [Successfully realized NSX resource for Pod]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e3607ece-8f7f-40aa-8da7-14253519dccc.1665f5aa63d46ef7], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8270/filler-pod-e3607ece-8f7f-40aa-8da7-14253519dccc to sc2-rdops-vm05-dhcp-163-39.eng.vmware.com]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e3607ece-8f7f-40aa-8da7-14253519dccc.1665f5aa9e38667d], Reason = [Image], Message = [Image pause-54467452d21a00c28aa4cce37d0850173b528ca6-v42879 bound successfully]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e3607ece-8f7f-40aa-8da7-14253519dccc.1665f5afedd05430], Reason = [Pulling], Message = [Waiting for Image sched-pred-8270/pause-54467452d21a00c28aa4cce37d0850173b528ca6-v42879]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e3607ece-8f7f-40aa-8da7-14253519dccc.1665f5b1e0314648], Reason = [Pulled], Message = [Image sched-pred-8270/pause-54467452d21a00c28aa4cce37d0850173b528ca6-v42879 is ready]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e3607ece-8f7f-40aa-8da7-14253519dccc.1665f5b4534b3538], Reason = [SuccessfulMountVolume], Message = [Successfully mounted volume default-token-g42gj]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e3607ece-8f7f-40aa-8da7-14253519dccc.1665f5b4534c42c0], Reason = [Created], Message = [Created container filler-pod-e3607ece-8f7f-40aa-8da7-14253519dccc]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e3607ece-8f7f-40aa-8da7-14253519dccc.1665f5b4534ce2e8], Reason = [Started], Message = [Started container filler-pod-e3607ece-8f7f-40aa-8da7-14253519dccc]
STEP: Considering event: 
Type = [Normal], Name = [pause-54467452d21a00c28aa4cce37d0850173b528ca6-v19832.1665f5aae6298120], Reason = [Status], Message = [sc2-rdops-vm05-dhcp-163-39.eng.vmware.com: Image status changed to Resolving]
STEP: Considering event: 
Type = [Normal], Name = [pause-54467452d21a00c28aa4cce37d0850173b528ca6-v19832.1665f5acea7ac020], Reason = [Resolve], Message = [sc2-rdops-vm05-dhcp-163-39.eng.vmware.com: Image resolved to ChainID sha256:ba0dae6243cc9fa2890df40a625721fdbea5c94ca6da897acdd814d710149770]
STEP: Considering event: 
Type = [Warning], Name = [pause-54467452d21a00c28aa4cce37d0850173b528ca6-v19832.1665f5acfccda9dd], Reason = [Bind], Message = [Imagedisk bind failed: Operation cannot be fulfilled on images.imagecontroller.vmware.com "pause-54467452d21a00c28aa4cce37d0850173b528ca6-v19832": the object has been modified; please apply your changes to the latest version and try again]
STEP: Considering event: 
Type = [Normal], Name = [pause-54467452d21a00c28aa4cce37d0850173b528ca6-v19832.1665f5aeea45debd], Reason = [Bind], Message = [Imagedisk ba0dae6243cc9fa2890df40a625721fdbea5c94ca6da897acdd814d710149770-v32347619 successfully bound]
STEP: Considering event: 
Type = [Normal], Name = [pause-54467452d21a00c28aa4cce37d0850173b528ca6-v19832.1665f5af250eb5f1], Reason = [Status], Message = [Image status changed to Fetching]
STEP: Considering event: 
Type = [Normal], Name = [pause-54467452d21a00c28aa4cce37d0850173b528ca6-v19832.1665f5b1e3f28ca0], Reason = [Status], Message = [Image status changed to Ready]
STEP: Considering event: 
Type = [Normal], Name = [pause-54467452d21a00c28aa4cce37d0850173b528ca6-v42879.1665f5aafc80b650], Reason = [Status], Message = [sc2-rdops-vm05-dhcp-179-105.eng.vmware.com: Image status changed to Resolving]
STEP: Considering event: 
Type = [Normal], Name = [pause-54467452d21a00c28aa4cce37d0850173b528ca6-v42879.1665f5ad28e119b8], Reason = [Resolve], Message = [sc2-rdops-vm05-dhcp-179-105.eng.vmware.com: Image resolved to ChainID sha256:ba0dae6243cc9fa2890df40a625721fdbea5c94ca6da897acdd814d710149770]
STEP: Considering event: 
Type = [Normal], Name = [pause-54467452d21a00c28aa4cce37d0850173b528ca6-v42879.1665f5af1ae59876], Reason = [Bind], Message = [Imagedisk ba0dae6243cc9fa2890df40a625721fdbea5c94ca6da897acdd814d710149770-v32347619 successfully bound]
STEP: Considering event: 
Type = [Normal], Name = [pause-54467452d21a00c28aa4cce37d0850173b528ca6-v42879.1665f5af231cf5cf], Reason = [Status], Message = [Image status changed to Fetching]
STEP: Considering event: 
Type = [Normal], Name = [pause-54467452d21a00c28aa4cce37d0850173b528ca6-v42879.1665f5b1e1102f30], Reason = [Status], Message = [Image status changed to Ready]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.1665f5b51f6af1a8], Reason = [FailedScheduling], Message = [Insufficient resources.]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.1665f5b527cd2cff], Reason = [FailedScheduling], Message = [Insufficient resources.]
STEP: removing the label node off the node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 03:56:41.518: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-8270" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:82

â€¢ [SLOW TEST:48.320 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run  [Conformance]","total":270,"completed":4,"skipped":120,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 03:56:41.744: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in prestop-80
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:171
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating server pod server in namespace prestop-80
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-80
STEP: Deleting pre-stop pod
Feb 22 03:58:09.548: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 03:58:09.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-80" for this suite.

â€¢ [SLOW TEST:87.868 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] [sig-node] PreStop should call prestop when killing a pod  [Conformance]","total":270,"completed":5,"skipped":160,"failed":0}
SSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should patch a Namespace [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 03:58:09.612: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-1012
STEP: Waiting for a default service account to be provisioned in namespace
[It] should patch a Namespace [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a Namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nspatchtest-e6ea59f4-444b-4f00-aebf-9615c88b9f86-8969
STEP: patching the Namespace
STEP: get the Namespace and ensuring it has the label
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 03:58:10.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-1012" for this suite.
STEP: Destroying namespace "nspatchtest-e6ea59f4-444b-4f00-aebf-9615c88b9f86-8969" for this suite.
â€¢{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance]","total":270,"completed":6,"skipped":164,"failed":0}
SSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 03:58:10.212: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-5372
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 03:58:46.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-5372" for this suite.

â€¢ [SLOW TEST:36.678 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  when scheduling a read only busybox container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:188
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]","total":270,"completed":7,"skipped":175,"failed":0}
SSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 03:58:46.893: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-8239
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 04:02:01.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-8239" for this suite.

â€¢ [SLOW TEST:194.438 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  blackbox test
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:40
    when starting a container that exits
    /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:41
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]","total":270,"completed":8,"skipped":178,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 04:02:01.336: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1650
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: validating cluster-info
Feb 22 04:02:01.677: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config cluster-info'
Feb 22 04:02:02.072: INFO: stderr: ""
Feb 22 04:02:02.072: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://127.0.0.1:6443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://127.0.0.1:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 04:02:02.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1650" for this suite.
â€¢{"msg":"PASSED [sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes master services is included in cluster-info  [Conformance]","total":270,"completed":9,"skipped":190,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 04:02:02.173: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-604
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Feb 22 04:02:02.492: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9ab00252-405c-4a97-8086-021781f5918e" in namespace "downward-api-604" to be "Succeeded or Failed"
Feb 22 04:02:02.503: INFO: Pod "downwardapi-volume-9ab00252-405c-4a97-8086-021781f5918e": Phase="Pending", Reason="", readiness=false. Elapsed: 10.475936ms
Feb 22 04:02:04.510: INFO: Pod "downwardapi-volume-9ab00252-405c-4a97-8086-021781f5918e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017890697s
Feb 22 04:02:06.550: INFO: Pod "downwardapi-volume-9ab00252-405c-4a97-8086-021781f5918e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.057540831s
Feb 22 04:02:08.579: INFO: Pod "downwardapi-volume-9ab00252-405c-4a97-8086-021781f5918e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.08643721s
Feb 22 04:02:10.601: INFO: Pod "downwardapi-volume-9ab00252-405c-4a97-8086-021781f5918e": Phase="Pending", Reason="", readiness=false. Elapsed: 8.108611771s
Feb 22 04:02:12.607: INFO: Pod "downwardapi-volume-9ab00252-405c-4a97-8086-021781f5918e": Phase="Pending", Reason="", readiness=false. Elapsed: 10.114922005s
Feb 22 04:02:14.618: INFO: Pod "downwardapi-volume-9ab00252-405c-4a97-8086-021781f5918e": Phase="Pending", Reason="", readiness=false. Elapsed: 12.125417181s
Feb 22 04:02:16.859: INFO: Pod "downwardapi-volume-9ab00252-405c-4a97-8086-021781f5918e": Phase="Pending", Reason="", readiness=false. Elapsed: 14.366808293s
Feb 22 04:02:18.918: INFO: Pod "downwardapi-volume-9ab00252-405c-4a97-8086-021781f5918e": Phase="Pending", Reason="", readiness=false. Elapsed: 16.425128906s
Feb 22 04:02:20.934: INFO: Pod "downwardapi-volume-9ab00252-405c-4a97-8086-021781f5918e": Phase="Pending", Reason="", readiness=false. Elapsed: 18.441910946s
Feb 22 04:02:22.946: INFO: Pod "downwardapi-volume-9ab00252-405c-4a97-8086-021781f5918e": Phase="Pending", Reason="", readiness=false. Elapsed: 20.453276299s
Feb 22 04:02:24.962: INFO: Pod "downwardapi-volume-9ab00252-405c-4a97-8086-021781f5918e": Phase="Pending", Reason="", readiness=false. Elapsed: 22.46952231s
Feb 22 04:02:26.970: INFO: Pod "downwardapi-volume-9ab00252-405c-4a97-8086-021781f5918e": Phase="Pending", Reason="", readiness=false. Elapsed: 24.477995233s
Feb 22 04:02:28.985: INFO: Pod "downwardapi-volume-9ab00252-405c-4a97-8086-021781f5918e": Phase="Pending", Reason="", readiness=false. Elapsed: 26.492467042s
Feb 22 04:02:30.997: INFO: Pod "downwardapi-volume-9ab00252-405c-4a97-8086-021781f5918e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 28.504955544s
STEP: Saw pod success
Feb 22 04:02:30.998: INFO: Pod "downwardapi-volume-9ab00252-405c-4a97-8086-021781f5918e" satisfied condition "Succeeded or Failed"
Feb 22 04:02:31.019: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com pod downwardapi-volume-9ab00252-405c-4a97-8086-021781f5918e container client-container: <nil>
STEP: delete the pod
Feb 22 04:02:37.150: INFO: Waiting for pod downwardapi-volume-9ab00252-405c-4a97-8086-021781f5918e to disappear
Feb 22 04:02:37.168: INFO: Pod downwardapi-volume-9ab00252-405c-4a97-8086-021781f5918e still exists
Feb 22 04:02:39.169: INFO: Waiting for pod downwardapi-volume-9ab00252-405c-4a97-8086-021781f5918e to disappear
Feb 22 04:02:39.178: INFO: Pod downwardapi-volume-9ab00252-405c-4a97-8086-021781f5918e still exists
Feb 22 04:02:41.169: INFO: Waiting for pod downwardapi-volume-9ab00252-405c-4a97-8086-021781f5918e to disappear
Feb 22 04:02:41.193: INFO: Pod downwardapi-volume-9ab00252-405c-4a97-8086-021781f5918e no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 04:02:41.196: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-604" for this suite.

â€¢ [SLOW TEST:39.096 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:37
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]","total":270,"completed":10,"skipped":201,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 04:02:41.294: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-2413
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Feb 22 04:02:41.709: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Feb 22 04:02:41.764: INFO: Number of nodes with available pods: 0
Feb 22 04:02:41.764: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Feb 22 04:02:41.854: INFO: Number of nodes with available pods: 0
Feb 22 04:02:41.854: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 04:02:42.863: INFO: Number of nodes with available pods: 0
Feb 22 04:02:42.863: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 04:02:43.867: INFO: Number of nodes with available pods: 0
Feb 22 04:02:43.869: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 04:02:44.870: INFO: Number of nodes with available pods: 0
Feb 22 04:02:44.870: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 04:02:45.885: INFO: Number of nodes with available pods: 0
Feb 22 04:02:45.885: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 04:02:46.865: INFO: Number of nodes with available pods: 0
Feb 22 04:02:46.865: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 04:02:47.873: INFO: Number of nodes with available pods: 0
Feb 22 04:02:47.873: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 04:02:48.870: INFO: Number of nodes with available pods: 0
Feb 22 04:02:48.870: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 04:02:49.864: INFO: Number of nodes with available pods: 0
Feb 22 04:02:49.864: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 04:02:50.877: INFO: Number of nodes with available pods: 0
Feb 22 04:02:50.877: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 04:02:51.867: INFO: Number of nodes with available pods: 0
Feb 22 04:02:51.867: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 04:02:52.893: INFO: Number of nodes with available pods: 0
Feb 22 04:02:52.893: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 04:02:53.899: INFO: Number of nodes with available pods: 0
Feb 22 04:02:53.899: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 04:02:54.862: INFO: Number of nodes with available pods: 0
Feb 22 04:02:54.862: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 04:02:55.864: INFO: Number of nodes with available pods: 0
Feb 22 04:02:55.864: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 04:02:56.863: INFO: Number of nodes with available pods: 0
Feb 22 04:02:56.864: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 04:02:57.861: INFO: Number of nodes with available pods: 0
Feb 22 04:02:57.861: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 04:02:58.872: INFO: Number of nodes with available pods: 0
Feb 22 04:02:58.872: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 04:02:59.864: INFO: Number of nodes with available pods: 0
Feb 22 04:02:59.864: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 04:03:00.866: INFO: Number of nodes with available pods: 0
Feb 22 04:03:00.867: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 04:03:01.862: INFO: Number of nodes with available pods: 0
Feb 22 04:03:01.862: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 04:03:02.863: INFO: Number of nodes with available pods: 0
Feb 22 04:03:02.864: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 04:03:03.863: INFO: Number of nodes with available pods: 0
Feb 22 04:03:03.863: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 04:03:04.862: INFO: Number of nodes with available pods: 0
Feb 22 04:03:04.862: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 04:03:05.871: INFO: Number of nodes with available pods: 0
Feb 22 04:03:05.871: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 04:03:06.869: INFO: Number of nodes with available pods: 0
Feb 22 04:03:06.869: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 04:03:07.872: INFO: Number of nodes with available pods: 0
Feb 22 04:03:07.872: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 04:03:08.863: INFO: Number of nodes with available pods: 0
Feb 22 04:03:08.863: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 04:03:09.862: INFO: Number of nodes with available pods: 1
Feb 22 04:03:09.862: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Feb 22 04:03:09.920: INFO: Number of nodes with available pods: 1
Feb 22 04:03:09.920: INFO: Number of running nodes: 0, number of available pods: 1
Feb 22 04:03:10.930: INFO: Number of nodes with available pods: 0
Feb 22 04:03:10.930: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Feb 22 04:03:10.982: INFO: Number of nodes with available pods: 0
Feb 22 04:03:10.982: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 04:03:11.989: INFO: Number of nodes with available pods: 0
Feb 22 04:03:11.989: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 04:03:12.993: INFO: Number of nodes with available pods: 0
Feb 22 04:03:12.993: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 04:03:13.991: INFO: Number of nodes with available pods: 0
Feb 22 04:03:13.991: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 04:03:14.990: INFO: Number of nodes with available pods: 0
Feb 22 04:03:14.990: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 04:03:15.992: INFO: Number of nodes with available pods: 0
Feb 22 04:03:15.992: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 04:03:16.990: INFO: Number of nodes with available pods: 0
Feb 22 04:03:16.990: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 04:03:18.001: INFO: Number of nodes with available pods: 0
Feb 22 04:03:18.001: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 04:03:18.999: INFO: Number of nodes with available pods: 0
Feb 22 04:03:18.999: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 04:03:19.995: INFO: Number of nodes with available pods: 0
Feb 22 04:03:19.995: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 04:03:20.993: INFO: Number of nodes with available pods: 0
Feb 22 04:03:20.993: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 04:03:22.000: INFO: Number of nodes with available pods: 0
Feb 22 04:03:22.000: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 04:03:22.991: INFO: Number of nodes with available pods: 0
Feb 22 04:03:22.992: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 04:03:23.989: INFO: Number of nodes with available pods: 0
Feb 22 04:03:23.990: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 04:03:25.002: INFO: Number of nodes with available pods: 0
Feb 22 04:03:25.002: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 04:03:25.990: INFO: Number of nodes with available pods: 0
Feb 22 04:03:25.991: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 04:03:26.990: INFO: Number of nodes with available pods: 0
Feb 22 04:03:26.990: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 04:03:27.989: INFO: Number of nodes with available pods: 0
Feb 22 04:03:27.989: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 04:03:28.990: INFO: Number of nodes with available pods: 0
Feb 22 04:03:28.990: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 04:03:29.989: INFO: Number of nodes with available pods: 0
Feb 22 04:03:29.990: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 04:03:30.992: INFO: Number of nodes with available pods: 0
Feb 22 04:03:30.992: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 04:03:31.989: INFO: Number of nodes with available pods: 0
Feb 22 04:03:31.989: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 04:03:32.994: INFO: Number of nodes with available pods: 0
Feb 22 04:03:32.994: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 04:03:34.001: INFO: Number of nodes with available pods: 0
Feb 22 04:03:34.001: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 04:03:34.989: INFO: Number of nodes with available pods: 0
Feb 22 04:03:34.989: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 04:03:35.991: INFO: Number of nodes with available pods: 0
Feb 22 04:03:35.991: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 04:03:36.992: INFO: Number of nodes with available pods: 0
Feb 22 04:03:36.992: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 04:03:37.989: INFO: Number of nodes with available pods: 0
Feb 22 04:03:37.989: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 04:03:39.002: INFO: Number of nodes with available pods: 0
Feb 22 04:03:39.002: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 04:03:39.990: INFO: Number of nodes with available pods: 0
Feb 22 04:03:39.990: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 04:03:40.990: INFO: Number of nodes with available pods: 0
Feb 22 04:03:40.990: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 04:03:42.005: INFO: Number of nodes with available pods: 0
Feb 22 04:03:42.005: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 04:03:43.029: INFO: Number of nodes with available pods: 0
Feb 22 04:03:43.029: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 04:03:44.001: INFO: Number of nodes with available pods: 0
Feb 22 04:03:44.001: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 04:03:45.027: INFO: Number of nodes with available pods: 0
Feb 22 04:03:45.027: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 04:03:46.018: INFO: Number of nodes with available pods: 0
Feb 22 04:03:46.018: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 04:03:46.994: INFO: Number of nodes with available pods: 0
Feb 22 04:03:46.994: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 04:03:47.989: INFO: Number of nodes with available pods: 0
Feb 22 04:03:47.989: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 04:03:48.993: INFO: Number of nodes with available pods: 0
Feb 22 04:03:48.994: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 04:03:49.992: INFO: Number of nodes with available pods: 0
Feb 22 04:03:49.992: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 04:03:50.991: INFO: Number of nodes with available pods: 1
Feb 22 04:03:50.991: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2413, will wait for the garbage collector to delete the pods
Feb 22 04:03:51.118: INFO: Deleting DaemonSet.extensions daemon-set took: 35.650964ms
Feb 22 04:03:52.919: INFO: Terminating DaemonSet.extensions daemon-set pods took: 1.800697467s
Feb 22 04:04:05.527: INFO: Number of nodes with available pods: 0
Feb 22 04:04:05.528: INFO: Number of running nodes: 0, number of available pods: 0
Feb 22 04:04:05.561: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-2413/daemonsets","resourceVersion":"50691"},"items":null}

Feb 22 04:04:05.569: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-2413/pods","resourceVersion":"50692"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 04:04:05.685: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2413" for this suite.

â€¢ [SLOW TEST:84.465 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]","total":270,"completed":11,"skipped":242,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 04:04:05.763: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-6924
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Feb 22 04:04:06.889: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Feb 22 04:04:08.788: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 04:04:09.967: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-6924" for this suite.
â€¢{"msg":"PASSED [sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]","total":270,"completed":12,"skipped":253,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 04:04:10.305: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename crd-webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-webhook-1258
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Feb 22 04:04:11.627: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Feb 22 04:04:13.751: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563451, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563451, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563451, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563451, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-65c6cd5fdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:04:15.780: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563451, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563451, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563451, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563451, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-65c6cd5fdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:04:17.760: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563451, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563451, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563451, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563451, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-65c6cd5fdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:04:19.776: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563451, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563451, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563451, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563451, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-65c6cd5fdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:04:21.759: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563451, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563451, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563451, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563451, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-65c6cd5fdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:04:23.763: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563451, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563451, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563451, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563451, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-65c6cd5fdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:04:26.024: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563451, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563451, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563451, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563451, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-65c6cd5fdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:04:27.764: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563451, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563451, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563451, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563451, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-65c6cd5fdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:04:29.774: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563451, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563451, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563451, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563451, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-65c6cd5fdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:04:31.771: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563451, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563451, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563451, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563451, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-65c6cd5fdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:04:33.764: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563451, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563451, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563451, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563451, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-65c6cd5fdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:04:35.762: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563451, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563451, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563451, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563451, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-65c6cd5fdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:04:37.764: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563451, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563451, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563451, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563451, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-65c6cd5fdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:04:39.763: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563451, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563451, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563451, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563451, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-65c6cd5fdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:04:41.760: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563451, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563451, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563451, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563451, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-65c6cd5fdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:04:43.765: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563451, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563451, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563451, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563451, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-65c6cd5fdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:04:45.832: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563451, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563451, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563451, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563451, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-65c6cd5fdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 22 04:04:48.813: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Feb 22 04:04:48.916: INFO: >>> kubeConfig: /root/.kube/config
STEP: Creating a v1 custom resource
STEP: Create a v2 custom resource
STEP: List CRs in v1
STEP: List CRs in v2
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 04:04:55.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-1258" for this suite.
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

â€¢ [SLOW TEST:49.155 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]","total":270,"completed":13,"skipped":258,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 04:04:59.470: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6423
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name projected-secret-test-3aab7b2c-ec00-49e3-ba7f-185b62fdb308
STEP: Creating a pod to test consume secrets
Feb 22 04:05:00.182: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-9175fc20-3a77-412e-9b3c-bf3c21a811f3" in namespace "projected-6423" to be "Succeeded or Failed"
Feb 22 04:05:00.229: INFO: Pod "pod-projected-secrets-9175fc20-3a77-412e-9b3c-bf3c21a811f3": Phase="Pending", Reason="", readiness=false. Elapsed: 45.913587ms
Feb 22 04:05:02.892: INFO: Pod "pod-projected-secrets-9175fc20-3a77-412e-9b3c-bf3c21a811f3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.70888882s
Feb 22 04:05:04.923: INFO: Pod "pod-projected-secrets-9175fc20-3a77-412e-9b3c-bf3c21a811f3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.739886536s
Feb 22 04:05:07.029: INFO: Pod "pod-projected-secrets-9175fc20-3a77-412e-9b3c-bf3c21a811f3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.845847402s
Feb 22 04:05:09.050: INFO: Pod "pod-projected-secrets-9175fc20-3a77-412e-9b3c-bf3c21a811f3": Phase="Pending", Reason="", readiness=false. Elapsed: 8.866283478s
Feb 22 04:05:11.085: INFO: Pod "pod-projected-secrets-9175fc20-3a77-412e-9b3c-bf3c21a811f3": Phase="Pending", Reason="", readiness=false. Elapsed: 10.901326464s
Feb 22 04:05:13.112: INFO: Pod "pod-projected-secrets-9175fc20-3a77-412e-9b3c-bf3c21a811f3": Phase="Pending", Reason="", readiness=false. Elapsed: 12.929043239s
Feb 22 04:05:15.163: INFO: Pod "pod-projected-secrets-9175fc20-3a77-412e-9b3c-bf3c21a811f3": Phase="Pending", Reason="", readiness=false. Elapsed: 14.97945981s
Feb 22 04:05:17.177: INFO: Pod "pod-projected-secrets-9175fc20-3a77-412e-9b3c-bf3c21a811f3": Phase="Pending", Reason="", readiness=false. Elapsed: 16.993578364s
Feb 22 04:05:19.570: INFO: Pod "pod-projected-secrets-9175fc20-3a77-412e-9b3c-bf3c21a811f3": Phase="Pending", Reason="", readiness=false. Elapsed: 19.386620392s
Feb 22 04:05:23.517: INFO: Pod "pod-projected-secrets-9175fc20-3a77-412e-9b3c-bf3c21a811f3": Phase="Pending", Reason="", readiness=false. Elapsed: 23.334052196s
Feb 22 04:05:25.576: INFO: Pod "pod-projected-secrets-9175fc20-3a77-412e-9b3c-bf3c21a811f3": Phase="Pending", Reason="", readiness=false. Elapsed: 25.392170579s
Feb 22 04:05:27.587: INFO: Pod "pod-projected-secrets-9175fc20-3a77-412e-9b3c-bf3c21a811f3": Phase="Pending", Reason="", readiness=false. Elapsed: 27.403576548s
Feb 22 04:05:29.595: INFO: Pod "pod-projected-secrets-9175fc20-3a77-412e-9b3c-bf3c21a811f3": Phase="Pending", Reason="", readiness=false. Elapsed: 29.411212147s
Feb 22 04:05:31.636: INFO: Pod "pod-projected-secrets-9175fc20-3a77-412e-9b3c-bf3c21a811f3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 31.452630509s
STEP: Saw pod success
Feb 22 04:05:31.638: INFO: Pod "pod-projected-secrets-9175fc20-3a77-412e-9b3c-bf3c21a811f3" satisfied condition "Succeeded or Failed"
Feb 22 04:05:31.665: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com pod pod-projected-secrets-9175fc20-3a77-412e-9b3c-bf3c21a811f3 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 22 04:05:38.703: INFO: Waiting for pod pod-projected-secrets-9175fc20-3a77-412e-9b3c-bf3c21a811f3 to disappear
Feb 22 04:05:38.727: INFO: Pod pod-projected-secrets-9175fc20-3a77-412e-9b3c-bf3c21a811f3 still exists
Feb 22 04:05:40.727: INFO: Waiting for pod pod-projected-secrets-9175fc20-3a77-412e-9b3c-bf3c21a811f3 to disappear
Feb 22 04:05:40.753: INFO: Pod pod-projected-secrets-9175fc20-3a77-412e-9b3c-bf3c21a811f3 still exists
Feb 22 04:05:42.727: INFO: Waiting for pod pod-projected-secrets-9175fc20-3a77-412e-9b3c-bf3c21a811f3 to disappear
Feb 22 04:05:42.735: INFO: Pod pod-projected-secrets-9175fc20-3a77-412e-9b3c-bf3c21a811f3 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 04:05:42.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6423" for this suite.

â€¢ [SLOW TEST:43.315 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","total":270,"completed":14,"skipped":291,"failed":0}
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 04:05:42.793: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7536
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-bf8fc529-c957-48bd-9cfb-a577241ff49c
STEP: Creating a pod to test consume configMaps
Feb 22 04:05:43.281: INFO: Waiting up to 5m0s for pod "pod-configmaps-9827731e-76ea-45cb-8719-27a839b6a8f7" in namespace "configmap-7536" to be "Succeeded or Failed"
Feb 22 04:05:43.294: INFO: Pod "pod-configmaps-9827731e-76ea-45cb-8719-27a839b6a8f7": Phase="Pending", Reason="", readiness=false. Elapsed: 13.456991ms
Feb 22 04:05:45.305: INFO: Pod "pod-configmaps-9827731e-76ea-45cb-8719-27a839b6a8f7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024148342s
Feb 22 04:05:47.318: INFO: Pod "pod-configmaps-9827731e-76ea-45cb-8719-27a839b6a8f7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.036736297s
Feb 22 04:05:49.355: INFO: Pod "pod-configmaps-9827731e-76ea-45cb-8719-27a839b6a8f7": Phase="Pending", Reason="", readiness=false. Elapsed: 6.074138076s
Feb 22 04:05:51.387: INFO: Pod "pod-configmaps-9827731e-76ea-45cb-8719-27a839b6a8f7": Phase="Pending", Reason="", readiness=false. Elapsed: 8.10664897s
Feb 22 04:05:53.395: INFO: Pod "pod-configmaps-9827731e-76ea-45cb-8719-27a839b6a8f7": Phase="Pending", Reason="", readiness=false. Elapsed: 10.114561301s
Feb 22 04:05:55.405: INFO: Pod "pod-configmaps-9827731e-76ea-45cb-8719-27a839b6a8f7": Phase="Pending", Reason="", readiness=false. Elapsed: 12.124669642s
Feb 22 04:05:57.416: INFO: Pod "pod-configmaps-9827731e-76ea-45cb-8719-27a839b6a8f7": Phase="Pending", Reason="", readiness=false. Elapsed: 14.135175925s
Feb 22 04:05:59.426: INFO: Pod "pod-configmaps-9827731e-76ea-45cb-8719-27a839b6a8f7": Phase="Pending", Reason="", readiness=false. Elapsed: 16.14471493s
Feb 22 04:06:01.482: INFO: Pod "pod-configmaps-9827731e-76ea-45cb-8719-27a839b6a8f7": Phase="Pending", Reason="", readiness=false. Elapsed: 18.200826399s
Feb 22 04:06:03.494: INFO: Pod "pod-configmaps-9827731e-76ea-45cb-8719-27a839b6a8f7": Phase="Pending", Reason="", readiness=false. Elapsed: 20.212921538s
Feb 22 04:06:05.511: INFO: Pod "pod-configmaps-9827731e-76ea-45cb-8719-27a839b6a8f7": Phase="Pending", Reason="", readiness=false. Elapsed: 22.230296413s
Feb 22 04:06:07.522: INFO: Pod "pod-configmaps-9827731e-76ea-45cb-8719-27a839b6a8f7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.241226818s
STEP: Saw pod success
Feb 22 04:06:07.522: INFO: Pod "pod-configmaps-9827731e-76ea-45cb-8719-27a839b6a8f7" satisfied condition "Succeeded or Failed"
Feb 22 04:06:07.536: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com pod pod-configmaps-9827731e-76ea-45cb-8719-27a839b6a8f7 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 22 04:06:07.696: INFO: Waiting for pod pod-configmaps-9827731e-76ea-45cb-8719-27a839b6a8f7 to disappear
Feb 22 04:06:07.708: INFO: Pod pod-configmaps-9827731e-76ea-45cb-8719-27a839b6a8f7 still exists
Feb 22 04:06:09.708: INFO: Waiting for pod pod-configmaps-9827731e-76ea-45cb-8719-27a839b6a8f7 to disappear
Feb 22 04:06:09.718: INFO: Pod pod-configmaps-9827731e-76ea-45cb-8719-27a839b6a8f7 still exists
Feb 22 04:06:11.708: INFO: Waiting for pod pod-configmaps-9827731e-76ea-45cb-8719-27a839b6a8f7 to disappear
Feb 22 04:06:11.768: INFO: Pod pod-configmaps-9827731e-76ea-45cb-8719-27a839b6a8f7 still exists
Feb 22 04:06:13.708: INFO: Waiting for pod pod-configmaps-9827731e-76ea-45cb-8719-27a839b6a8f7 to disappear
Feb 22 04:06:13.717: INFO: Pod pod-configmaps-9827731e-76ea-45cb-8719-27a839b6a8f7 still exists
Feb 22 04:06:15.708: INFO: Waiting for pod pod-configmaps-9827731e-76ea-45cb-8719-27a839b6a8f7 to disappear
Feb 22 04:06:15.716: INFO: Pod pod-configmaps-9827731e-76ea-45cb-8719-27a839b6a8f7 still exists
Feb 22 04:06:17.708: INFO: Waiting for pod pod-configmaps-9827731e-76ea-45cb-8719-27a839b6a8f7 to disappear
Feb 22 04:06:17.717: INFO: Pod pod-configmaps-9827731e-76ea-45cb-8719-27a839b6a8f7 still exists
Feb 22 04:06:19.708: INFO: Waiting for pod pod-configmaps-9827731e-76ea-45cb-8719-27a839b6a8f7 to disappear
Feb 22 04:06:19.721: INFO: Pod pod-configmaps-9827731e-76ea-45cb-8719-27a839b6a8f7 still exists
Feb 22 04:06:21.708: INFO: Waiting for pod pod-configmaps-9827731e-76ea-45cb-8719-27a839b6a8f7 to disappear
Feb 22 04:06:21.720: INFO: Pod pod-configmaps-9827731e-76ea-45cb-8719-27a839b6a8f7 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 04:06:21.721: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7536" for this suite.

â€¢ [SLOW TEST:38.999 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:36
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","total":270,"completed":15,"skipped":296,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 04:06:21.794: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8528
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0777 on tmpfs
Feb 22 04:06:22.879: INFO: Waiting up to 5m0s for pod "pod-f07dbc6f-05b3-49c5-a34a-c0b8b0784315" in namespace "emptydir-8528" to be "Succeeded or Failed"
Feb 22 04:06:22.951: INFO: Pod "pod-f07dbc6f-05b3-49c5-a34a-c0b8b0784315": Phase="Pending", Reason="", readiness=false. Elapsed: 72.615146ms
Feb 22 04:06:24.968: INFO: Pod "pod-f07dbc6f-05b3-49c5-a34a-c0b8b0784315": Phase="Pending", Reason="", readiness=false. Elapsed: 2.088742611s
Feb 22 04:06:26.984: INFO: Pod "pod-f07dbc6f-05b3-49c5-a34a-c0b8b0784315": Phase="Pending", Reason="", readiness=false. Elapsed: 4.105088668s
Feb 22 04:06:29.008: INFO: Pod "pod-f07dbc6f-05b3-49c5-a34a-c0b8b0784315": Phase="Pending", Reason="", readiness=false. Elapsed: 6.128969809s
Feb 22 04:06:31.018: INFO: Pod "pod-f07dbc6f-05b3-49c5-a34a-c0b8b0784315": Phase="Pending", Reason="", readiness=false. Elapsed: 8.138863255s
Feb 22 04:06:33.032: INFO: Pod "pod-f07dbc6f-05b3-49c5-a34a-c0b8b0784315": Phase="Pending", Reason="", readiness=false. Elapsed: 10.153046584s
Feb 22 04:06:35.042: INFO: Pod "pod-f07dbc6f-05b3-49c5-a34a-c0b8b0784315": Phase="Pending", Reason="", readiness=false. Elapsed: 12.163164233s
Feb 22 04:06:37.240: INFO: Pod "pod-f07dbc6f-05b3-49c5-a34a-c0b8b0784315": Phase="Pending", Reason="", readiness=false. Elapsed: 14.360917412s
Feb 22 04:06:39.598: INFO: Pod "pod-f07dbc6f-05b3-49c5-a34a-c0b8b0784315": Phase="Pending", Reason="", readiness=false. Elapsed: 16.718936414s
Feb 22 04:06:41.669: INFO: Pod "pod-f07dbc6f-05b3-49c5-a34a-c0b8b0784315": Phase="Pending", Reason="", readiness=false. Elapsed: 18.790528458s
Feb 22 04:06:43.714: INFO: Pod "pod-f07dbc6f-05b3-49c5-a34a-c0b8b0784315": Phase="Pending", Reason="", readiness=false. Elapsed: 20.835468707s
Feb 22 04:06:45.735: INFO: Pod "pod-f07dbc6f-05b3-49c5-a34a-c0b8b0784315": Phase="Pending", Reason="", readiness=false. Elapsed: 22.856619729s
Feb 22 04:06:47.751: INFO: Pod "pod-f07dbc6f-05b3-49c5-a34a-c0b8b0784315": Phase="Pending", Reason="", readiness=false. Elapsed: 24.872575055s
Feb 22 04:06:49.761: INFO: Pod "pod-f07dbc6f-05b3-49c5-a34a-c0b8b0784315": Phase="Pending", Reason="", readiness=false. Elapsed: 26.882510976s
Feb 22 04:06:51.770: INFO: Pod "pod-f07dbc6f-05b3-49c5-a34a-c0b8b0784315": Phase="Pending", Reason="", readiness=false. Elapsed: 28.890907845s
Feb 22 04:06:53.781: INFO: Pod "pod-f07dbc6f-05b3-49c5-a34a-c0b8b0784315": Phase="Pending", Reason="", readiness=false. Elapsed: 30.901786736s
Feb 22 04:06:55.791: INFO: Pod "pod-f07dbc6f-05b3-49c5-a34a-c0b8b0784315": Phase="Pending", Reason="", readiness=false. Elapsed: 32.91205095s
Feb 22 04:06:57.802: INFO: Pod "pod-f07dbc6f-05b3-49c5-a34a-c0b8b0784315": Phase="Pending", Reason="", readiness=false. Elapsed: 34.923441892s
Feb 22 04:06:59.812: INFO: Pod "pod-f07dbc6f-05b3-49c5-a34a-c0b8b0784315": Phase="Pending", Reason="", readiness=false. Elapsed: 36.933551678s
Feb 22 04:07:01.820: INFO: Pod "pod-f07dbc6f-05b3-49c5-a34a-c0b8b0784315": Phase="Succeeded", Reason="", readiness=false. Elapsed: 38.941213783s
STEP: Saw pod success
Feb 22 04:07:01.821: INFO: Pod "pod-f07dbc6f-05b3-49c5-a34a-c0b8b0784315" satisfied condition "Succeeded or Failed"
Feb 22 04:07:01.828: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com pod pod-f07dbc6f-05b3-49c5-a34a-c0b8b0784315 container test-container: <nil>
STEP: delete the pod
Feb 22 04:07:01.946: INFO: Waiting for pod pod-f07dbc6f-05b3-49c5-a34a-c0b8b0784315 to disappear
Feb 22 04:07:01.966: INFO: Pod pod-f07dbc6f-05b3-49c5-a34a-c0b8b0784315 still exists
Feb 22 04:07:03.967: INFO: Waiting for pod pod-f07dbc6f-05b3-49c5-a34a-c0b8b0784315 to disappear
Feb 22 04:07:03.977: INFO: Pod pod-f07dbc6f-05b3-49c5-a34a-c0b8b0784315 still exists
Feb 22 04:07:05.967: INFO: Waiting for pod pod-f07dbc6f-05b3-49c5-a34a-c0b8b0784315 to disappear
Feb 22 04:07:06.001: INFO: Pod pod-f07dbc6f-05b3-49c5-a34a-c0b8b0784315 still exists
Feb 22 04:07:07.967: INFO: Waiting for pod pod-f07dbc6f-05b3-49c5-a34a-c0b8b0784315 to disappear
Feb 22 04:07:07.982: INFO: Pod pod-f07dbc6f-05b3-49c5-a34a-c0b8b0784315 still exists
Feb 22 04:07:09.972: INFO: Waiting for pod pod-f07dbc6f-05b3-49c5-a34a-c0b8b0784315 to disappear
Feb 22 04:07:10.019: INFO: Pod pod-f07dbc6f-05b3-49c5-a34a-c0b8b0784315 still exists
Feb 22 04:07:11.967: INFO: Waiting for pod pod-f07dbc6f-05b3-49c5-a34a-c0b8b0784315 to disappear
Feb 22 04:07:11.981: INFO: Pod pod-f07dbc6f-05b3-49c5-a34a-c0b8b0784315 still exists
Feb 22 04:07:13.967: INFO: Waiting for pod pod-f07dbc6f-05b3-49c5-a34a-c0b8b0784315 to disappear
Feb 22 04:07:13.975: INFO: Pod pod-f07dbc6f-05b3-49c5-a34a-c0b8b0784315 still exists
Feb 22 04:07:15.967: INFO: Waiting for pod pod-f07dbc6f-05b3-49c5-a34a-c0b8b0784315 to disappear
Feb 22 04:07:15.995: INFO: Pod pod-f07dbc6f-05b3-49c5-a34a-c0b8b0784315 still exists
Feb 22 04:07:17.967: INFO: Waiting for pod pod-f07dbc6f-05b3-49c5-a34a-c0b8b0784315 to disappear
Feb 22 04:07:17.973: INFO: Pod pod-f07dbc6f-05b3-49c5-a34a-c0b8b0784315 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 04:07:17.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8528" for this suite.

â€¢ [SLOW TEST:56.258 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:42
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":270,"completed":16,"skipped":306,"failed":0}
SSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 04:07:18.068: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-5146
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 22 04:07:19.370: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Feb 22 04:07:21.446: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563639, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563639, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563639, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563639, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:07:23.465: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563639, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563639, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563639, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563639, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:07:25.470: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563639, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563639, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563639, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563639, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:07:27.455: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563639, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563639, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563639, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563639, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:07:29.474: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563639, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563639, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563639, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563639, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:07:32.533: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563639, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563639, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563639, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563639, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:07:33.455: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563639, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563639, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563639, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563639, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:07:35.456: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563639, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563639, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563639, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563639, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:07:37.457: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563639, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563639, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563639, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563639, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:07:39.475: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563639, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563639, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563639, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563639, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:07:41.463: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563639, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563639, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563639, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563639, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:07:43.505: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563639, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563639, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563639, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563639, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:07:45.455: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563639, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563639, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563639, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563639, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:07:47.456: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563639, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563639, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563639, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563639, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 22 04:07:50.572: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod that should be denied by the webhook
STEP: create a pod that causes the webhook to hang
STEP: create a configmap that should be denied by the webhook
STEP: create a configmap that should be admitted by the webhook
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: create a namespace that bypass the webhook
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 04:08:01.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5146" for this suite.
STEP: Destroying namespace "webhook-5146-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

â€¢ [SLOW TEST:43.855 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]","total":270,"completed":17,"skipped":315,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch 
  watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 04:08:01.921: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename crd-watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-watch-4218
STEP: Waiting for a default service account to be provisioned in namespace
[It] watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Feb 22 04:08:02.263: INFO: >>> kubeConfig: /root/.kube/config
STEP: Creating first CR 
Feb 22 04:08:03.296: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2021-02-22T04:08:03Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2021-02-22T04:08:03Z]] name:name1 resourceVersion:53401 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:445af0c3-f18f-4cd1-8dea-269dcace2030] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR
Feb 22 04:08:13.338: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2021-02-22T04:08:13Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2021-02-22T04:08:13Z]] name:name2 resourceVersion:53530 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:a97e66da-89ee-4d4b-a83f-06cefbf97415] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR
Feb 22 04:08:23.353: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2021-02-22T04:08:03Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2021-02-22T04:08:23Z]] name:name1 resourceVersion:53647 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:445af0c3-f18f-4cd1-8dea-269dcace2030] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR
Feb 22 04:08:33.378: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2021-02-22T04:08:13Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2021-02-22T04:08:33Z]] name:name2 resourceVersion:53742 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:a97e66da-89ee-4d4b-a83f-06cefbf97415] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR
Feb 22 04:08:43.427: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2021-02-22T04:08:03Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2021-02-22T04:08:23Z]] name:name1 resourceVersion:53835 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:445af0c3-f18f-4cd1-8dea-269dcace2030] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR
Feb 22 04:08:53.447: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2021-02-22T04:08:13Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2021-02-22T04:08:33Z]] name:name2 resourceVersion:53930 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:a97e66da-89ee-4d4b-a83f-06cefbf97415] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 04:09:03.981: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-4218" for this suite.

â€¢ [SLOW TEST:62.230 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:42
    watch on custom resource definition objects [Conformance]
    /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]","total":270,"completed":18,"skipped":320,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 04:09:04.170: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-141
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Feb 22 04:09:05.142: INFO: Waiting up to 5m0s for pod "downwardapi-volume-565362c3-e14c-4b25-87f8-9de5429c8ec5" in namespace "projected-141" to be "Succeeded or Failed"
Feb 22 04:09:05.193: INFO: Pod "downwardapi-volume-565362c3-e14c-4b25-87f8-9de5429c8ec5": Phase="Pending", Reason="", readiness=false. Elapsed: 50.670297ms
Feb 22 04:09:07.202: INFO: Pod "downwardapi-volume-565362c3-e14c-4b25-87f8-9de5429c8ec5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.059101797s
Feb 22 04:09:09.278: INFO: Pod "downwardapi-volume-565362c3-e14c-4b25-87f8-9de5429c8ec5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.135189676s
Feb 22 04:09:11.290: INFO: Pod "downwardapi-volume-565362c3-e14c-4b25-87f8-9de5429c8ec5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.147478939s
Feb 22 04:09:13.298: INFO: Pod "downwardapi-volume-565362c3-e14c-4b25-87f8-9de5429c8ec5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.155974184s
Feb 22 04:09:15.323: INFO: Pod "downwardapi-volume-565362c3-e14c-4b25-87f8-9de5429c8ec5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.180454426s
Feb 22 04:09:17.338: INFO: Pod "downwardapi-volume-565362c3-e14c-4b25-87f8-9de5429c8ec5": Phase="Pending", Reason="", readiness=false. Elapsed: 12.195208424s
Feb 22 04:09:19.352: INFO: Pod "downwardapi-volume-565362c3-e14c-4b25-87f8-9de5429c8ec5": Phase="Pending", Reason="", readiness=false. Elapsed: 14.209422246s
Feb 22 04:09:21.366: INFO: Pod "downwardapi-volume-565362c3-e14c-4b25-87f8-9de5429c8ec5": Phase="Pending", Reason="", readiness=false. Elapsed: 16.223146723s
Feb 22 04:09:23.386: INFO: Pod "downwardapi-volume-565362c3-e14c-4b25-87f8-9de5429c8ec5": Phase="Pending", Reason="", readiness=false. Elapsed: 18.243678861s
Feb 22 04:09:25.396: INFO: Pod "downwardapi-volume-565362c3-e14c-4b25-87f8-9de5429c8ec5": Phase="Pending", Reason="", readiness=false. Elapsed: 20.253673405s
Feb 22 04:09:27.407: INFO: Pod "downwardapi-volume-565362c3-e14c-4b25-87f8-9de5429c8ec5": Phase="Pending", Reason="", readiness=false. Elapsed: 22.264111125s
Feb 22 04:09:29.416: INFO: Pod "downwardapi-volume-565362c3-e14c-4b25-87f8-9de5429c8ec5": Phase="Pending", Reason="", readiness=false. Elapsed: 24.273867239s
Feb 22 04:09:31.424: INFO: Pod "downwardapi-volume-565362c3-e14c-4b25-87f8-9de5429c8ec5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.281336462s
STEP: Saw pod success
Feb 22 04:09:31.424: INFO: Pod "downwardapi-volume-565362c3-e14c-4b25-87f8-9de5429c8ec5" satisfied condition "Succeeded or Failed"
Feb 22 04:09:31.430: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com pod downwardapi-volume-565362c3-e14c-4b25-87f8-9de5429c8ec5 container client-container: <nil>
STEP: delete the pod
Feb 22 04:09:31.492: INFO: Waiting for pod downwardapi-volume-565362c3-e14c-4b25-87f8-9de5429c8ec5 to disappear
Feb 22 04:09:31.515: INFO: Pod downwardapi-volume-565362c3-e14c-4b25-87f8-9de5429c8ec5 still exists
Feb 22 04:09:33.516: INFO: Waiting for pod downwardapi-volume-565362c3-e14c-4b25-87f8-9de5429c8ec5 to disappear
Feb 22 04:09:33.529: INFO: Pod downwardapi-volume-565362c3-e14c-4b25-87f8-9de5429c8ec5 still exists
Feb 22 04:09:35.517: INFO: Waiting for pod downwardapi-volume-565362c3-e14c-4b25-87f8-9de5429c8ec5 to disappear
Feb 22 04:09:35.530: INFO: Pod downwardapi-volume-565362c3-e14c-4b25-87f8-9de5429c8ec5 still exists
Feb 22 04:09:37.516: INFO: Waiting for pod downwardapi-volume-565362c3-e14c-4b25-87f8-9de5429c8ec5 to disappear
Feb 22 04:09:37.522: INFO: Pod downwardapi-volume-565362c3-e14c-4b25-87f8-9de5429c8ec5 still exists
Feb 22 04:09:39.516: INFO: Waiting for pod downwardapi-volume-565362c3-e14c-4b25-87f8-9de5429c8ec5 to disappear
Feb 22 04:09:39.534: INFO: Pod downwardapi-volume-565362c3-e14c-4b25-87f8-9de5429c8ec5 still exists
Feb 22 04:09:41.516: INFO: Waiting for pod downwardapi-volume-565362c3-e14c-4b25-87f8-9de5429c8ec5 to disappear
Feb 22 04:09:41.521: INFO: Pod downwardapi-volume-565362c3-e14c-4b25-87f8-9de5429c8ec5 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 04:09:41.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-141" for this suite.

â€¢ [SLOW TEST:37.403 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:36
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]","total":270,"completed":19,"skipped":354,"failed":0}
SSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 04:09:41.574: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-1405
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Feb 22 04:10:12.547: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 04:10:12.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1405" for this suite.

â€¢ [SLOW TEST:31.339 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  blackbox test
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:40
    on terminated container
    /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:133
      should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]","total":270,"completed":20,"skipped":359,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 04:10:12.930: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-2671
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating pod
Feb 22 04:10:46.115: INFO: Pod pod-hostip-de9831a3-7f9b-442c-b61f-64ec1eb54264 has hostIP: 10.192.179.105
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 04:10:46.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2671" for this suite.

â€¢ [SLOW TEST:33.307 seconds]
[k8s.io] Pods
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Pods should get a host IP [NodeConformance] [Conformance]","total":270,"completed":21,"skipped":374,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 04:10:46.239: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-608
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Feb 22 04:10:46.588: INFO: >>> kubeConfig: /root/.kube/config
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Feb 22 04:10:59.967: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-608 create -f -'
Feb 22 04:11:03.478: INFO: stderr: ""
Feb 22 04:11:03.478: INFO: stdout: "e2e-test-crd-publish-openapi-1342-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Feb 22 04:11:03.478: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-608 delete e2e-test-crd-publish-openapi-1342-crds test-cr'
Feb 22 04:11:03.713: INFO: stderr: ""
Feb 22 04:11:03.713: INFO: stdout: "e2e-test-crd-publish-openapi-1342-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Feb 22 04:11:03.713: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-608 apply -f -'
Feb 22 04:11:04.810: INFO: stderr: ""
Feb 22 04:11:04.810: INFO: stdout: "e2e-test-crd-publish-openapi-1342-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Feb 22 04:11:04.810: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-608 delete e2e-test-crd-publish-openapi-1342-crds test-cr'
Feb 22 04:11:05.050: INFO: stderr: ""
Feb 22 04:11:05.050: INFO: stdout: "e2e-test-crd-publish-openapi-1342-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Feb 22 04:11:05.050: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config explain e2e-test-crd-publish-openapi-1342-crds'
Feb 22 04:11:05.636: INFO: stderr: ""
Feb 22 04:11:05.637: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-1342-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<map[string]>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 04:11:14.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-608" for this suite.

â€¢ [SLOW TEST:28.759 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]","total":270,"completed":22,"skipped":390,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 04:11:15.003: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-6707
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod busybox-8f533863-b770-4d22-a271-95e9d1392131 in namespace container-probe-6707
Feb 22 04:11:43.350: INFO: Started pod busybox-8f533863-b770-4d22-a271-95e9d1392131 in namespace container-probe-6707
STEP: checking the pod's current state and verifying that restartCount is present
Feb 22 04:11:43.357: INFO: Initial restart count of pod busybox-8f533863-b770-4d22-a271-95e9d1392131 is 0
Feb 22 04:11:57.821: INFO: Restart count of pod container-probe-6707/busybox-8f533863-b770-4d22-a271-95e9d1392131 is now 1 (14.463271407s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 04:11:58.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6707" for this suite.

â€¢ [SLOW TEST:43.609 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container should be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","total":270,"completed":23,"skipped":426,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 04:11:58.657: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename crd-webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-webhook-3530
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Feb 22 04:12:00.577: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Feb 22 04:12:02.683: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563920, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563920, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563920, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563920, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-65c6cd5fdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:12:04.708: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563920, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563920, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563920, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563920, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-65c6cd5fdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:12:06.719: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563920, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563920, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563920, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563920, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-65c6cd5fdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:12:08.718: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563920, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563920, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563920, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563920, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-65c6cd5fdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:12:10.696: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563920, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563920, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563920, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563920, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-65c6cd5fdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:12:12.696: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563920, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563920, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563920, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563920, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-65c6cd5fdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:12:14.711: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563920, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563920, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563920, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563920, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-65c6cd5fdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:12:16.709: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563920, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563920, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563920, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563920, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-65c6cd5fdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:12:18.782: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563920, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563920, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563920, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563920, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-65c6cd5fdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:12:20.701: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563920, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563920, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563920, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563920, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-65c6cd5fdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:12:22.694: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563920, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563920, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563920, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563920, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-65c6cd5fdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:12:24.704: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563920, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563920, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563920, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563920, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-65c6cd5fdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:12:26.694: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563920, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563920, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563920, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563920, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-65c6cd5fdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:12:28.696: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563920, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563920, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563920, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749563920, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-65c6cd5fdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 22 04:12:31.783: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Feb 22 04:12:31.802: INFO: >>> kubeConfig: /root/.kube/config
STEP: Creating a v1 custom resource
STEP: v2 custom resource should be converted
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 04:12:34.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-3530" for this suite.
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

â€¢ [SLOW TEST:57.235 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]","total":270,"completed":24,"skipped":448,"failed":0}
SSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with readOnlyRootFilesystem 
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 04:12:55.897: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-5742
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:41
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Feb 22 04:13:22.101: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-306eb2d3-25a4-43aa-bd85-7c4e10940dc0" in namespace "security-context-test-5742" to be "Succeeded or Failed"
Feb 22 04:13:22.162: INFO: Pod "busybox-readonly-false-306eb2d3-25a4-43aa-bd85-7c4e10940dc0": Phase="Pending", Reason="", readiness=false. Elapsed: 60.683726ms
Feb 22 04:13:24.174: INFO: Pod "busybox-readonly-false-306eb2d3-25a4-43aa-bd85-7c4e10940dc0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.072905141s
Feb 22 04:13:26.253: INFO: Pod "busybox-readonly-false-306eb2d3-25a4-43aa-bd85-7c4e10940dc0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.151468815s
Feb 22 04:13:28.273: INFO: Pod "busybox-readonly-false-306eb2d3-25a4-43aa-bd85-7c4e10940dc0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.172218909s
Feb 22 04:13:30.361: INFO: Pod "busybox-readonly-false-306eb2d3-25a4-43aa-bd85-7c4e10940dc0": Phase="Pending", Reason="", readiness=false. Elapsed: 8.259950205s
Feb 22 04:13:32.378: INFO: Pod "busybox-readonly-false-306eb2d3-25a4-43aa-bd85-7c4e10940dc0": Phase="Pending", Reason="", readiness=false. Elapsed: 10.277143315s
Feb 22 04:13:34.388: INFO: Pod "busybox-readonly-false-306eb2d3-25a4-43aa-bd85-7c4e10940dc0": Phase="Pending", Reason="", readiness=false. Elapsed: 12.286573313s
Feb 22 04:13:36.405: INFO: Pod "busybox-readonly-false-306eb2d3-25a4-43aa-bd85-7c4e10940dc0": Phase="Pending", Reason="", readiness=false. Elapsed: 14.304170773s
Feb 22 04:13:38.422: INFO: Pod "busybox-readonly-false-306eb2d3-25a4-43aa-bd85-7c4e10940dc0": Phase="Pending", Reason="", readiness=false. Elapsed: 16.320496783s
Feb 22 04:13:40.475: INFO: Pod "busybox-readonly-false-306eb2d3-25a4-43aa-bd85-7c4e10940dc0": Phase="Pending", Reason="", readiness=false. Elapsed: 18.373468244s
Feb 22 04:13:42.502: INFO: Pod "busybox-readonly-false-306eb2d3-25a4-43aa-bd85-7c4e10940dc0": Phase="Pending", Reason="", readiness=false. Elapsed: 20.40135215s
Feb 22 04:13:44.528: INFO: Pod "busybox-readonly-false-306eb2d3-25a4-43aa-bd85-7c4e10940dc0": Phase="Pending", Reason="", readiness=false. Elapsed: 22.426830526s
Feb 22 04:13:46.553: INFO: Pod "busybox-readonly-false-306eb2d3-25a4-43aa-bd85-7c4e10940dc0": Phase="Pending", Reason="", readiness=false. Elapsed: 24.452291828s
Feb 22 04:13:48.573: INFO: Pod "busybox-readonly-false-306eb2d3-25a4-43aa-bd85-7c4e10940dc0": Phase="Pending", Reason="", readiness=false. Elapsed: 26.471658292s
Feb 22 04:13:50.609: INFO: Pod "busybox-readonly-false-306eb2d3-25a4-43aa-bd85-7c4e10940dc0": Phase="Pending", Reason="", readiness=false. Elapsed: 28.50809132s
Feb 22 04:13:52.626: INFO: Pod "busybox-readonly-false-306eb2d3-25a4-43aa-bd85-7c4e10940dc0": Phase="Pending", Reason="", readiness=false. Elapsed: 30.525424535s
Feb 22 04:13:54.662: INFO: Pod "busybox-readonly-false-306eb2d3-25a4-43aa-bd85-7c4e10940dc0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 32.561311731s
Feb 22 04:13:54.663: INFO: Pod "busybox-readonly-false-306eb2d3-25a4-43aa-bd85-7c4e10940dc0" satisfied condition "Succeeded or Failed"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 04:13:54.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-5742" for this suite.

â€¢ [SLOW TEST:58.843 seconds]
[k8s.io] Security Context
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  When creating a pod with readOnlyRootFilesystem
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:166
    should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
    /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]","total":270,"completed":25,"skipped":455,"failed":0}
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 04:13:54.741: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1434
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Feb 22 04:14:21.282: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-1434 PodName:pod-sharedvolume-9dc8b8f3-14ef-4656-9859-c34978116ab6 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 22 04:14:21.283: INFO: >>> kubeConfig: /root/.kube/config
Feb 22 04:14:21.484: INFO: Exec stderr: ""
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 04:14:21.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1434" for this suite.

â€¢ [SLOW TEST:26.813 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:42
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]","total":270,"completed":26,"skipped":458,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 04:14:21.555: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5780
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-upd-b31fdc51-4465-44f1-ba65-711d06d3a495
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-b31fdc51-4465-44f1-ba65-711d06d3a495
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 04:15:08.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5780" for this suite.

â€¢ [SLOW TEST:47.218 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:36
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]","total":270,"completed":27,"skipped":469,"failed":0}
SSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 04:15:08.787: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-9916
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Feb 22 04:15:38.703: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 04:15:39.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-9916" for this suite.

â€¢ [SLOW TEST:31.169 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]","total":270,"completed":28,"skipped":472,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 04:15:40.002: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3955
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0666 on tmpfs
Feb 22 04:15:40.482: INFO: Waiting up to 5m0s for pod "pod-409360b9-46ba-4afa-a6a5-0a350b647917" in namespace "emptydir-3955" to be "Succeeded or Failed"
Feb 22 04:15:40.500: INFO: Pod "pod-409360b9-46ba-4afa-a6a5-0a350b647917": Phase="Pending", Reason="", readiness=false. Elapsed: 17.80235ms
Feb 22 04:15:42.540: INFO: Pod "pod-409360b9-46ba-4afa-a6a5-0a350b647917": Phase="Pending", Reason="", readiness=false. Elapsed: 2.057483558s
Feb 22 04:15:44.557: INFO: Pod "pod-409360b9-46ba-4afa-a6a5-0a350b647917": Phase="Pending", Reason="", readiness=false. Elapsed: 4.074492033s
Feb 22 04:15:46.576: INFO: Pod "pod-409360b9-46ba-4afa-a6a5-0a350b647917": Phase="Pending", Reason="", readiness=false. Elapsed: 6.094026259s
Feb 22 04:15:48.599: INFO: Pod "pod-409360b9-46ba-4afa-a6a5-0a350b647917": Phase="Pending", Reason="", readiness=false. Elapsed: 8.117021724s
Feb 22 04:15:50.625: INFO: Pod "pod-409360b9-46ba-4afa-a6a5-0a350b647917": Phase="Pending", Reason="", readiness=false. Elapsed: 10.143231781s
Feb 22 04:15:52.683: INFO: Pod "pod-409360b9-46ba-4afa-a6a5-0a350b647917": Phase="Pending", Reason="", readiness=false. Elapsed: 12.200891204s
Feb 22 04:15:54.694: INFO: Pod "pod-409360b9-46ba-4afa-a6a5-0a350b647917": Phase="Pending", Reason="", readiness=false. Elapsed: 14.212421276s
Feb 22 04:15:56.705: INFO: Pod "pod-409360b9-46ba-4afa-a6a5-0a350b647917": Phase="Pending", Reason="", readiness=false. Elapsed: 16.223198844s
Feb 22 04:15:58.715: INFO: Pod "pod-409360b9-46ba-4afa-a6a5-0a350b647917": Phase="Pending", Reason="", readiness=false. Elapsed: 18.233047152s
Feb 22 04:16:00.724: INFO: Pod "pod-409360b9-46ba-4afa-a6a5-0a350b647917": Phase="Pending", Reason="", readiness=false. Elapsed: 20.241737418s
Feb 22 04:16:02.734: INFO: Pod "pod-409360b9-46ba-4afa-a6a5-0a350b647917": Phase="Pending", Reason="", readiness=false. Elapsed: 22.25191019s
Feb 22 04:16:04.817: INFO: Pod "pod-409360b9-46ba-4afa-a6a5-0a350b647917": Phase="Pending", Reason="", readiness=false. Elapsed: 24.334850617s
Feb 22 04:16:06.900: INFO: Pod "pod-409360b9-46ba-4afa-a6a5-0a350b647917": Phase="Pending", Reason="", readiness=false. Elapsed: 26.417495542s
Feb 22 04:16:08.930: INFO: Pod "pod-409360b9-46ba-4afa-a6a5-0a350b647917": Phase="Succeeded", Reason="", readiness=false. Elapsed: 28.447949259s
STEP: Saw pod success
Feb 22 04:16:08.936: INFO: Pod "pod-409360b9-46ba-4afa-a6a5-0a350b647917" satisfied condition "Succeeded or Failed"
Feb 22 04:16:08.947: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com pod pod-409360b9-46ba-4afa-a6a5-0a350b647917 container test-container: <nil>
STEP: delete the pod
Feb 22 04:16:09.095: INFO: Waiting for pod pod-409360b9-46ba-4afa-a6a5-0a350b647917 to disappear
Feb 22 04:16:09.325: INFO: Pod pod-409360b9-46ba-4afa-a6a5-0a350b647917 still exists
Feb 22 04:16:11.326: INFO: Waiting for pod pod-409360b9-46ba-4afa-a6a5-0a350b647917 to disappear
Feb 22 04:16:11.341: INFO: Pod pod-409360b9-46ba-4afa-a6a5-0a350b647917 still exists
Feb 22 04:16:13.326: INFO: Waiting for pod pod-409360b9-46ba-4afa-a6a5-0a350b647917 to disappear
Feb 22 04:16:13.337: INFO: Pod pod-409360b9-46ba-4afa-a6a5-0a350b647917 still exists
Feb 22 04:16:15.326: INFO: Waiting for pod pod-409360b9-46ba-4afa-a6a5-0a350b647917 to disappear
Feb 22 04:16:15.335: INFO: Pod pod-409360b9-46ba-4afa-a6a5-0a350b647917 still exists
Feb 22 04:16:17.326: INFO: Waiting for pod pod-409360b9-46ba-4afa-a6a5-0a350b647917 to disappear
Feb 22 04:16:17.337: INFO: Pod pod-409360b9-46ba-4afa-a6a5-0a350b647917 still exists
Feb 22 04:16:19.326: INFO: Waiting for pod pod-409360b9-46ba-4afa-a6a5-0a350b647917 to disappear
Feb 22 04:16:19.832: INFO: Pod pod-409360b9-46ba-4afa-a6a5-0a350b647917 still exists
Feb 22 04:16:21.327: INFO: Waiting for pod pod-409360b9-46ba-4afa-a6a5-0a350b647917 to disappear
Feb 22 04:16:21.341: INFO: Pod pod-409360b9-46ba-4afa-a6a5-0a350b647917 still exists
Feb 22 04:16:23.326: INFO: Waiting for pod pod-409360b9-46ba-4afa-a6a5-0a350b647917 to disappear
Feb 22 04:16:23.337: INFO: Pod pod-409360b9-46ba-4afa-a6a5-0a350b647917 still exists
Feb 22 04:16:25.326: INFO: Waiting for pod pod-409360b9-46ba-4afa-a6a5-0a350b647917 to disappear
Feb 22 04:16:25.335: INFO: Pod pod-409360b9-46ba-4afa-a6a5-0a350b647917 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 04:16:25.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3955" for this suite.

â€¢ [SLOW TEST:45.370 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:42
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":270,"completed":29,"skipped":495,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 04:16:25.402: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-6235
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Feb 22 04:16:52.634: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 04:16:52.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-6235" for this suite.

â€¢ [SLOW TEST:27.576 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  blackbox test
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:40
    on terminated container
    /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:133
      should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":270,"completed":30,"skipped":524,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 04:16:53.003: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-6789
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: getting the auto-created API token
Feb 22 04:16:54.232: INFO: created pod pod-service-account-defaultsa
Feb 22 04:16:54.232: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Feb 22 04:16:54.255: INFO: created pod pod-service-account-mountsa
Feb 22 04:16:54.255: INFO: pod pod-service-account-mountsa service account token volume mount: true
Feb 22 04:16:54.297: INFO: created pod pod-service-account-nomountsa
Feb 22 04:16:54.297: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Feb 22 04:16:54.330: INFO: created pod pod-service-account-defaultsa-mountspec
Feb 22 04:16:54.330: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Feb 22 04:16:54.398: INFO: created pod pod-service-account-mountsa-mountspec
Feb 22 04:16:54.398: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Feb 22 04:16:54.448: INFO: created pod pod-service-account-nomountsa-mountspec
Feb 22 04:16:54.448: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Feb 22 04:16:54.510: INFO: created pod pod-service-account-defaultsa-nomountspec
Feb 22 04:16:54.510: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Feb 22 04:16:54.631: INFO: created pod pod-service-account-mountsa-nomountspec
Feb 22 04:16:54.631: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Feb 22 04:16:54.870: INFO: created pod pod-service-account-nomountsa-nomountspec
Feb 22 04:16:54.870: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 04:16:54.870: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-6789" for this suite.
â€¢{"msg":"PASSED [sig-auth] ServiceAccounts should allow opting out of API token automount  [Conformance]","total":270,"completed":31,"skipped":535,"failed":0}
SS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 04:16:56.052: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-2741
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Feb 22 04:18:09.292: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 22 04:18:09.331: INFO: Pod pod-with-poststart-http-hook still exists
Feb 22 04:18:11.332: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 22 04:18:11.359: INFO: Pod pod-with-poststart-http-hook still exists
Feb 22 04:18:13.332: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 22 04:18:13.362: INFO: Pod pod-with-poststart-http-hook still exists
Feb 22 04:18:15.333: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 22 04:18:15.342: INFO: Pod pod-with-poststart-http-hook still exists
Feb 22 04:18:17.332: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 22 04:18:17.342: INFO: Pod pod-with-poststart-http-hook still exists
Feb 22 04:18:19.332: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 22 04:18:19.340: INFO: Pod pod-with-poststart-http-hook still exists
Feb 22 04:18:21.332: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 22 04:18:21.347: INFO: Pod pod-with-poststart-http-hook still exists
Feb 22 04:18:23.332: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 22 04:18:23.350: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 04:18:23.353: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-2741" for this suite.

â€¢ [SLOW TEST:87.409 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  when create a pod with lifecycle hook
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]","total":270,"completed":32,"skipped":537,"failed":0}
SSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 04:18:23.477: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-6393
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 04:18:24.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6393" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702
â€¢{"msg":"PASSED [sig-network] Services should provide secure master service  [Conformance]","total":270,"completed":33,"skipped":542,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 04:18:24.520: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8395
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Feb 22 04:18:24.829: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3fd2cb48-c1ac-491d-bb12-56042a264d20" in namespace "downward-api-8395" to be "Succeeded or Failed"
Feb 22 04:18:24.844: INFO: Pod "downwardapi-volume-3fd2cb48-c1ac-491d-bb12-56042a264d20": Phase="Pending", Reason="", readiness=false. Elapsed: 15.049507ms
Feb 22 04:18:26.850: INFO: Pod "downwardapi-volume-3fd2cb48-c1ac-491d-bb12-56042a264d20": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021657599s
Feb 22 04:18:28.861: INFO: Pod "downwardapi-volume-3fd2cb48-c1ac-491d-bb12-56042a264d20": Phase="Pending", Reason="", readiness=false. Elapsed: 4.031920823s
Feb 22 04:18:30.873: INFO: Pod "downwardapi-volume-3fd2cb48-c1ac-491d-bb12-56042a264d20": Phase="Pending", Reason="", readiness=false. Elapsed: 6.044548099s
Feb 22 04:18:32.890: INFO: Pod "downwardapi-volume-3fd2cb48-c1ac-491d-bb12-56042a264d20": Phase="Pending", Reason="", readiness=false. Elapsed: 8.061490058s
Feb 22 04:18:34.935: INFO: Pod "downwardapi-volume-3fd2cb48-c1ac-491d-bb12-56042a264d20": Phase="Pending", Reason="", readiness=false. Elapsed: 10.106708867s
Feb 22 04:18:36.946: INFO: Pod "downwardapi-volume-3fd2cb48-c1ac-491d-bb12-56042a264d20": Phase="Pending", Reason="", readiness=false. Elapsed: 12.117163448s
Feb 22 04:18:38.974: INFO: Pod "downwardapi-volume-3fd2cb48-c1ac-491d-bb12-56042a264d20": Phase="Pending", Reason="", readiness=false. Elapsed: 14.145743586s
Feb 22 04:18:40.986: INFO: Pod "downwardapi-volume-3fd2cb48-c1ac-491d-bb12-56042a264d20": Phase="Pending", Reason="", readiness=false. Elapsed: 16.157012148s
Feb 22 04:18:43.042: INFO: Pod "downwardapi-volume-3fd2cb48-c1ac-491d-bb12-56042a264d20": Phase="Pending", Reason="", readiness=false. Elapsed: 18.213272269s
Feb 22 04:18:45.053: INFO: Pod "downwardapi-volume-3fd2cb48-c1ac-491d-bb12-56042a264d20": Phase="Pending", Reason="", readiness=false. Elapsed: 20.224671111s
Feb 22 04:18:47.081: INFO: Pod "downwardapi-volume-3fd2cb48-c1ac-491d-bb12-56042a264d20": Phase="Pending", Reason="", readiness=false. Elapsed: 22.252501226s
Feb 22 04:18:49.091: INFO: Pod "downwardapi-volume-3fd2cb48-c1ac-491d-bb12-56042a264d20": Phase="Pending", Reason="", readiness=false. Elapsed: 24.262441401s
Feb 22 04:18:51.098: INFO: Pod "downwardapi-volume-3fd2cb48-c1ac-491d-bb12-56042a264d20": Phase="Pending", Reason="", readiness=false. Elapsed: 26.268884216s
Feb 22 04:18:53.112: INFO: Pod "downwardapi-volume-3fd2cb48-c1ac-491d-bb12-56042a264d20": Phase="Pending", Reason="", readiness=false. Elapsed: 28.283209228s
Feb 22 04:18:55.122: INFO: Pod "downwardapi-volume-3fd2cb48-c1ac-491d-bb12-56042a264d20": Phase="Pending", Reason="", readiness=false. Elapsed: 30.292827265s
Feb 22 04:18:57.184: INFO: Pod "downwardapi-volume-3fd2cb48-c1ac-491d-bb12-56042a264d20": Phase="Succeeded", Reason="", readiness=false. Elapsed: 32.355102305s
STEP: Saw pod success
Feb 22 04:18:57.184: INFO: Pod "downwardapi-volume-3fd2cb48-c1ac-491d-bb12-56042a264d20" satisfied condition "Succeeded or Failed"
Feb 22 04:18:57.199: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com pod downwardapi-volume-3fd2cb48-c1ac-491d-bb12-56042a264d20 container client-container: <nil>
STEP: delete the pod
Feb 22 04:18:57.290: INFO: Waiting for pod downwardapi-volume-3fd2cb48-c1ac-491d-bb12-56042a264d20 to disappear
Feb 22 04:18:57.319: INFO: Pod downwardapi-volume-3fd2cb48-c1ac-491d-bb12-56042a264d20 still exists
Feb 22 04:18:59.319: INFO: Waiting for pod downwardapi-volume-3fd2cb48-c1ac-491d-bb12-56042a264d20 to disappear
Feb 22 04:18:59.376: INFO: Pod downwardapi-volume-3fd2cb48-c1ac-491d-bb12-56042a264d20 still exists
Feb 22 04:19:01.319: INFO: Waiting for pod downwardapi-volume-3fd2cb48-c1ac-491d-bb12-56042a264d20 to disappear
Feb 22 04:19:01.340: INFO: Pod downwardapi-volume-3fd2cb48-c1ac-491d-bb12-56042a264d20 still exists
Feb 22 04:19:03.319: INFO: Waiting for pod downwardapi-volume-3fd2cb48-c1ac-491d-bb12-56042a264d20 to disappear
Feb 22 04:19:03.339: INFO: Pod downwardapi-volume-3fd2cb48-c1ac-491d-bb12-56042a264d20 still exists
Feb 22 04:19:05.319: INFO: Waiting for pod downwardapi-volume-3fd2cb48-c1ac-491d-bb12-56042a264d20 to disappear
Feb 22 04:19:05.332: INFO: Pod downwardapi-volume-3fd2cb48-c1ac-491d-bb12-56042a264d20 still exists
Feb 22 04:19:07.319: INFO: Waiting for pod downwardapi-volume-3fd2cb48-c1ac-491d-bb12-56042a264d20 to disappear
Feb 22 04:19:07.332: INFO: Pod downwardapi-volume-3fd2cb48-c1ac-491d-bb12-56042a264d20 still exists
Feb 22 04:19:09.319: INFO: Waiting for pod downwardapi-volume-3fd2cb48-c1ac-491d-bb12-56042a264d20 to disappear
Feb 22 04:19:09.329: INFO: Pod downwardapi-volume-3fd2cb48-c1ac-491d-bb12-56042a264d20 still exists
Feb 22 04:19:11.320: INFO: Waiting for pod downwardapi-volume-3fd2cb48-c1ac-491d-bb12-56042a264d20 to disappear
Feb 22 04:19:11.326: INFO: Pod downwardapi-volume-3fd2cb48-c1ac-491d-bb12-56042a264d20 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 04:19:11.327: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8395" for this suite.

â€¢ [SLOW TEST:46.864 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:37
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]","total":270,"completed":34,"skipped":557,"failed":0}
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 04:19:11.385: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-3721
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Feb 22 04:19:12.510: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-3721 /api/v1/namespaces/watch-3721/configmaps/e2e-watch-test-watch-closed 6ceefd45-29ee-4588-9bb5-bcb45782c2f7 60662 0 2021-02-22 04:19:12 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2021-02-22 04:19:12 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Feb 22 04:19:12.513: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-3721 /api/v1/namespaces/watch-3721/configmaps/e2e-watch-test-watch-closed 6ceefd45-29ee-4588-9bb5-bcb45782c2f7 60665 0 2021-02-22 04:19:12 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2021-02-22 04:19:12 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Feb 22 04:19:12.576: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-3721 /api/v1/namespaces/watch-3721/configmaps/e2e-watch-test-watch-closed 6ceefd45-29ee-4588-9bb5-bcb45782c2f7 60666 0 2021-02-22 04:19:12 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2021-02-22 04:19:12 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Feb 22 04:19:12.579: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-3721 /api/v1/namespaces/watch-3721/configmaps/e2e-watch-test-watch-closed 6ceefd45-29ee-4588-9bb5-bcb45782c2f7 60667 0 2021-02-22 04:19:12 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2021-02-22 04:19:12 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 04:19:12.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3721" for this suite.
â€¢{"msg":"PASSED [sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]","total":270,"completed":35,"skipped":557,"failed":0}
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 04:19:12.645: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9652
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0666 on node default medium
Feb 22 04:19:13.004: INFO: Waiting up to 5m0s for pod "pod-47e3fd5b-9c24-4618-8464-7442f936b1cf" in namespace "emptydir-9652" to be "Succeeded or Failed"
Feb 22 04:19:13.020: INFO: Pod "pod-47e3fd5b-9c24-4618-8464-7442f936b1cf": Phase="Pending", Reason="", readiness=false. Elapsed: 15.93019ms
Feb 22 04:19:15.028: INFO: Pod "pod-47e3fd5b-9c24-4618-8464-7442f936b1cf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024321244s
Feb 22 04:19:17.066: INFO: Pod "pod-47e3fd5b-9c24-4618-8464-7442f936b1cf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.062243367s
Feb 22 04:19:19.111: INFO: Pod "pod-47e3fd5b-9c24-4618-8464-7442f936b1cf": Phase="Pending", Reason="", readiness=false. Elapsed: 6.106919925s
Feb 22 04:19:21.122: INFO: Pod "pod-47e3fd5b-9c24-4618-8464-7442f936b1cf": Phase="Pending", Reason="", readiness=false. Elapsed: 8.118009627s
Feb 22 04:19:23.169: INFO: Pod "pod-47e3fd5b-9c24-4618-8464-7442f936b1cf": Phase="Pending", Reason="", readiness=false. Elapsed: 10.164655452s
Feb 22 04:19:25.176: INFO: Pod "pod-47e3fd5b-9c24-4618-8464-7442f936b1cf": Phase="Pending", Reason="", readiness=false. Elapsed: 12.171685731s
Feb 22 04:19:27.184: INFO: Pod "pod-47e3fd5b-9c24-4618-8464-7442f936b1cf": Phase="Pending", Reason="", readiness=false. Elapsed: 14.180487486s
Feb 22 04:19:29.193: INFO: Pod "pod-47e3fd5b-9c24-4618-8464-7442f936b1cf": Phase="Pending", Reason="", readiness=false. Elapsed: 16.188806094s
Feb 22 04:19:31.212: INFO: Pod "pod-47e3fd5b-9c24-4618-8464-7442f936b1cf": Phase="Pending", Reason="", readiness=false. Elapsed: 18.208132136s
Feb 22 04:19:33.235: INFO: Pod "pod-47e3fd5b-9c24-4618-8464-7442f936b1cf": Phase="Pending", Reason="", readiness=false. Elapsed: 20.230975872s
Feb 22 04:19:35.242: INFO: Pod "pod-47e3fd5b-9c24-4618-8464-7442f936b1cf": Phase="Pending", Reason="", readiness=false. Elapsed: 22.238286032s
Feb 22 04:19:37.251: INFO: Pod "pod-47e3fd5b-9c24-4618-8464-7442f936b1cf": Phase="Pending", Reason="", readiness=false. Elapsed: 24.246626255s
Feb 22 04:19:39.257: INFO: Pod "pod-47e3fd5b-9c24-4618-8464-7442f936b1cf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.252989866s
STEP: Saw pod success
Feb 22 04:19:39.257: INFO: Pod "pod-47e3fd5b-9c24-4618-8464-7442f936b1cf" satisfied condition "Succeeded or Failed"
Feb 22 04:19:39.264: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com pod pod-47e3fd5b-9c24-4618-8464-7442f936b1cf container test-container: <nil>
STEP: delete the pod
Feb 22 04:19:48.433: INFO: Waiting for pod pod-47e3fd5b-9c24-4618-8464-7442f936b1cf to disappear
Feb 22 04:19:48.452: INFO: Pod pod-47e3fd5b-9c24-4618-8464-7442f936b1cf still exists
Feb 22 04:19:50.453: INFO: Waiting for pod pod-47e3fd5b-9c24-4618-8464-7442f936b1cf to disappear
Feb 22 04:19:50.464: INFO: Pod pod-47e3fd5b-9c24-4618-8464-7442f936b1cf still exists
Feb 22 04:19:52.453: INFO: Waiting for pod pod-47e3fd5b-9c24-4618-8464-7442f936b1cf to disappear
Feb 22 04:19:52.465: INFO: Pod pod-47e3fd5b-9c24-4618-8464-7442f936b1cf still exists
Feb 22 04:19:54.453: INFO: Waiting for pod pod-47e3fd5b-9c24-4618-8464-7442f936b1cf to disappear
Feb 22 04:19:54.466: INFO: Pod pod-47e3fd5b-9c24-4618-8464-7442f936b1cf still exists
Feb 22 04:19:56.453: INFO: Waiting for pod pod-47e3fd5b-9c24-4618-8464-7442f936b1cf to disappear
Feb 22 04:19:56.463: INFO: Pod pod-47e3fd5b-9c24-4618-8464-7442f936b1cf still exists
Feb 22 04:19:58.453: INFO: Waiting for pod pod-47e3fd5b-9c24-4618-8464-7442f936b1cf to disappear
Feb 22 04:19:58.475: INFO: Pod pod-47e3fd5b-9c24-4618-8464-7442f936b1cf no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 04:19:58.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9652" for this suite.

â€¢ [SLOW TEST:45.940 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:42
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","total":270,"completed":36,"skipped":566,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] version v1
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 04:19:58.587: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-7193
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Feb 22 04:19:59.045: INFO: /api/v1/nodes/sc2-rdops-vm05-dhcp-163-39.eng.vmware.com:10250/proxy/logs/: no body (200; 35.69638ms)
Feb 22 04:19:59.063: INFO: /api/v1/nodes/sc2-rdops-vm05-dhcp-163-39.eng.vmware.com:10250/proxy/logs/: no body (200; 17.970409ms)
Feb 22 04:19:59.102: INFO: /api/v1/nodes/sc2-rdops-vm05-dhcp-163-39.eng.vmware.com:10250/proxy/logs/: no body (200; 39.09177ms)
Feb 22 04:19:59.135: INFO: /api/v1/nodes/sc2-rdops-vm05-dhcp-163-39.eng.vmware.com:10250/proxy/logs/: no body (200; 32.749514ms)
Feb 22 04:19:59.158: INFO: /api/v1/nodes/sc2-rdops-vm05-dhcp-163-39.eng.vmware.com:10250/proxy/logs/: no body (200; 22.539838ms)
Feb 22 04:19:59.180: INFO: /api/v1/nodes/sc2-rdops-vm05-dhcp-163-39.eng.vmware.com:10250/proxy/logs/: no body (200; 21.875322ms)
Feb 22 04:19:59.198: INFO: /api/v1/nodes/sc2-rdops-vm05-dhcp-163-39.eng.vmware.com:10250/proxy/logs/: no body (200; 17.975253ms)
Feb 22 04:19:59.225: INFO: /api/v1/nodes/sc2-rdops-vm05-dhcp-163-39.eng.vmware.com:10250/proxy/logs/: no body (200; 26.142061ms)
Feb 22 04:19:59.235: INFO: /api/v1/nodes/sc2-rdops-vm05-dhcp-163-39.eng.vmware.com:10250/proxy/logs/: no body (200; 10.25187ms)
Feb 22 04:19:59.260: INFO: /api/v1/nodes/sc2-rdops-vm05-dhcp-163-39.eng.vmware.com:10250/proxy/logs/: no body (200; 24.124406ms)
Feb 22 04:19:59.285: INFO: /api/v1/nodes/sc2-rdops-vm05-dhcp-163-39.eng.vmware.com:10250/proxy/logs/: no body (200; 25.205991ms)
Feb 22 04:19:59.297: INFO: /api/v1/nodes/sc2-rdops-vm05-dhcp-163-39.eng.vmware.com:10250/proxy/logs/: no body (200; 12.044706ms)
Feb 22 04:19:59.309: INFO: /api/v1/nodes/sc2-rdops-vm05-dhcp-163-39.eng.vmware.com:10250/proxy/logs/: no body (200; 11.867925ms)
Feb 22 04:19:59.316: INFO: /api/v1/nodes/sc2-rdops-vm05-dhcp-163-39.eng.vmware.com:10250/proxy/logs/: no body (200; 6.485304ms)
Feb 22 04:19:59.323: INFO: /api/v1/nodes/sc2-rdops-vm05-dhcp-163-39.eng.vmware.com:10250/proxy/logs/: no body (200; 6.769779ms)
Feb 22 04:19:59.332: INFO: /api/v1/nodes/sc2-rdops-vm05-dhcp-163-39.eng.vmware.com:10250/proxy/logs/: no body (200; 8.532448ms)
Feb 22 04:19:59.344: INFO: /api/v1/nodes/sc2-rdops-vm05-dhcp-163-39.eng.vmware.com:10250/proxy/logs/: no body (200; 11.393394ms)
Feb 22 04:19:59.355: INFO: /api/v1/nodes/sc2-rdops-vm05-dhcp-163-39.eng.vmware.com:10250/proxy/logs/: no body (200; 11.528043ms)
Feb 22 04:19:59.367: INFO: /api/v1/nodes/sc2-rdops-vm05-dhcp-163-39.eng.vmware.com:10250/proxy/logs/: no body (200; 11.726253ms)
Feb 22 04:19:59.376: INFO: /api/v1/nodes/sc2-rdops-vm05-dhcp-163-39.eng.vmware.com:10250/proxy/logs/: no body (200; 8.390006ms)
[AfterEach] version v1
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 04:19:59.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-7193" for this suite.
â€¢{"msg":"PASSED [sig-network] Proxy version v1 should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]","total":270,"completed":37,"skipped":580,"failed":0}
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 04:19:59.407: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-2088
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Feb 22 04:20:02.104: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 04:20:02.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2088" for this suite.
â€¢{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]","total":270,"completed":38,"skipped":584,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 04:20:02.758: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-5507
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 22 04:20:08.096: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564406, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564406, loc:(*time.Location)(0x7b501e0)}}, Reason:"NewReplicaSetCreated", Message:"Created new replica set \"sample-webhook-deployment-779fdc84d9\""}, v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564407, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564407, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:20:10.451: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564407, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564407, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564407, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564406, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:20:12.343: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564407, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564407, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564407, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564406, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:20:15.014: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564407, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564407, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564407, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564406, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:20:18.114: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564407, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564407, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564407, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564406, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:20:18.844: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564407, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564407, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564407, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564406, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:20:20.838: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564407, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564407, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564407, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564406, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:20:22.840: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564407, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564407, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564407, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564406, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:20:24.155: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564407, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564407, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564407, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564406, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:20:26.160: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564407, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564407, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564407, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564406, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:20:28.208: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564407, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564407, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564407, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564406, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:20:30.268: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564407, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564407, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564407, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564406, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:20:32.129: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564407, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564407, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564407, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564406, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:20:34.139: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564407, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564407, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564407, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564406, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:20:36.135: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564407, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564407, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564407, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564406, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:20:38.142: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564407, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564407, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564407, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564406, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:20:40.174: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564407, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564407, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564407, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564406, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:20:42.146: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564407, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564407, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564407, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564406, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:20:44.130: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564407, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564407, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564407, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564406, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:20:46.140: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564407, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564407, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564407, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564406, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 22 04:20:49.234: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the mutating pod webhook via the AdmissionRegistration API
Feb 22 04:20:49.544: INFO: Waiting for webhook configuration to be ready...
STEP: create a pod that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 04:20:49.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5507" for this suite.
STEP: Destroying namespace "webhook-5507-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

â€¢ [SLOW TEST:48.956 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]","total":270,"completed":39,"skipped":592,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 04:20:51.768: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6898
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Feb 22 04:20:52.958: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a8337d44-dc7b-43ec-9477-a39cae6e966f" in namespace "downward-api-6898" to be "Succeeded or Failed"
Feb 22 04:20:53.000: INFO: Pod "downwardapi-volume-a8337d44-dc7b-43ec-9477-a39cae6e966f": Phase="Pending", Reason="", readiness=false. Elapsed: 41.528966ms
Feb 22 04:20:55.686: INFO: Pod "downwardapi-volume-a8337d44-dc7b-43ec-9477-a39cae6e966f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.728384479s
Feb 22 04:20:58.162: INFO: Pod "downwardapi-volume-a8337d44-dc7b-43ec-9477-a39cae6e966f": Phase="Pending", Reason="", readiness=false. Elapsed: 5.20379248s
Feb 22 04:21:00.200: INFO: Pod "downwardapi-volume-a8337d44-dc7b-43ec-9477-a39cae6e966f": Phase="Pending", Reason="", readiness=false. Elapsed: 7.241704748s
Feb 22 04:21:02.315: INFO: Pod "downwardapi-volume-a8337d44-dc7b-43ec-9477-a39cae6e966f": Phase="Pending", Reason="", readiness=false. Elapsed: 9.356952227s
Feb 22 04:21:04.797: INFO: Pod "downwardapi-volume-a8337d44-dc7b-43ec-9477-a39cae6e966f": Phase="Pending", Reason="", readiness=false. Elapsed: 11.839066227s
Feb 22 04:21:06.896: INFO: Pod "downwardapi-volume-a8337d44-dc7b-43ec-9477-a39cae6e966f": Phase="Pending", Reason="", readiness=false. Elapsed: 13.937860036s
Feb 22 04:21:08.969: INFO: Pod "downwardapi-volume-a8337d44-dc7b-43ec-9477-a39cae6e966f": Phase="Pending", Reason="", readiness=false. Elapsed: 16.010717197s
Feb 22 04:21:11.074: INFO: Pod "downwardapi-volume-a8337d44-dc7b-43ec-9477-a39cae6e966f": Phase="Pending", Reason="", readiness=false. Elapsed: 18.116318294s
Feb 22 04:21:13.110: INFO: Pod "downwardapi-volume-a8337d44-dc7b-43ec-9477-a39cae6e966f": Phase="Pending", Reason="", readiness=false. Elapsed: 20.151981036s
Feb 22 04:21:15.132: INFO: Pod "downwardapi-volume-a8337d44-dc7b-43ec-9477-a39cae6e966f": Phase="Pending", Reason="", readiness=false. Elapsed: 22.17448905s
Feb 22 04:21:17.165: INFO: Pod "downwardapi-volume-a8337d44-dc7b-43ec-9477-a39cae6e966f": Phase="Pending", Reason="", readiness=false. Elapsed: 24.207303438s
Feb 22 04:21:20.001: INFO: Pod "downwardapi-volume-a8337d44-dc7b-43ec-9477-a39cae6e966f": Phase="Pending", Reason="", readiness=false. Elapsed: 27.043016699s
Feb 22 04:21:25.981: INFO: Pod "downwardapi-volume-a8337d44-dc7b-43ec-9477-a39cae6e966f": Phase="Pending", Reason="", readiness=false. Elapsed: 33.022765415s
Feb 22 04:21:29.201: INFO: Pod "downwardapi-volume-a8337d44-dc7b-43ec-9477-a39cae6e966f": Phase="Pending", Reason="", readiness=false. Elapsed: 36.243081358s
Feb 22 04:21:31.236: INFO: Pod "downwardapi-volume-a8337d44-dc7b-43ec-9477-a39cae6e966f": Phase="Pending", Reason="", readiness=false. Elapsed: 38.277685681s
Feb 22 04:21:33.266: INFO: Pod "downwardapi-volume-a8337d44-dc7b-43ec-9477-a39cae6e966f": Phase="Pending", Reason="", readiness=false. Elapsed: 40.307949243s
Feb 22 04:21:35.279: INFO: Pod "downwardapi-volume-a8337d44-dc7b-43ec-9477-a39cae6e966f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 42.320957354s
STEP: Saw pod success
Feb 22 04:21:35.279: INFO: Pod "downwardapi-volume-a8337d44-dc7b-43ec-9477-a39cae6e966f" satisfied condition "Succeeded or Failed"
Feb 22 04:21:35.290: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com pod downwardapi-volume-a8337d44-dc7b-43ec-9477-a39cae6e966f container client-container: <nil>
STEP: delete the pod
Feb 22 04:21:35.409: INFO: Waiting for pod downwardapi-volume-a8337d44-dc7b-43ec-9477-a39cae6e966f to disappear
Feb 22 04:21:35.433: INFO: Pod downwardapi-volume-a8337d44-dc7b-43ec-9477-a39cae6e966f still exists
Feb 22 04:21:37.434: INFO: Waiting for pod downwardapi-volume-a8337d44-dc7b-43ec-9477-a39cae6e966f to disappear
Feb 22 04:21:37.446: INFO: Pod downwardapi-volume-a8337d44-dc7b-43ec-9477-a39cae6e966f still exists
Feb 22 04:21:39.434: INFO: Waiting for pod downwardapi-volume-a8337d44-dc7b-43ec-9477-a39cae6e966f to disappear
Feb 22 04:21:39.467: INFO: Pod downwardapi-volume-a8337d44-dc7b-43ec-9477-a39cae6e966f still exists
Feb 22 04:21:41.434: INFO: Waiting for pod downwardapi-volume-a8337d44-dc7b-43ec-9477-a39cae6e966f to disappear
Feb 22 04:21:41.444: INFO: Pod downwardapi-volume-a8337d44-dc7b-43ec-9477-a39cae6e966f still exists
Feb 22 04:21:43.434: INFO: Waiting for pod downwardapi-volume-a8337d44-dc7b-43ec-9477-a39cae6e966f to disappear
Feb 22 04:21:43.444: INFO: Pod downwardapi-volume-a8337d44-dc7b-43ec-9477-a39cae6e966f still exists
Feb 22 04:21:45.434: INFO: Waiting for pod downwardapi-volume-a8337d44-dc7b-43ec-9477-a39cae6e966f to disappear
Feb 22 04:21:45.450: INFO: Pod downwardapi-volume-a8337d44-dc7b-43ec-9477-a39cae6e966f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 04:21:45.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6898" for this suite.

â€¢ [SLOW TEST:53.838 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:37
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]","total":270,"completed":40,"skipped":614,"failed":0}
SSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 04:21:45.618: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-6463
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Feb 22 04:22:38.258: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 22 04:22:38.300: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 22 04:22:40.303: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 22 04:22:40.333: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 22 04:22:42.303: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 22 04:22:42.364: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 22 04:22:44.301: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 22 04:22:44.316: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 22 04:22:46.301: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 22 04:22:46.313: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 22 04:22:48.301: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 22 04:22:48.338: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 22 04:22:50.301: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 22 04:22:50.312: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 22 04:22:52.301: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 22 04:22:52.311: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 22 04:22:54.301: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 22 04:22:54.323: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 22 04:22:56.301: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 22 04:22:56.311: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 04:22:56.312: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-6463" for this suite.

â€¢ [SLOW TEST:70.745 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  when create a pod with lifecycle hook
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]","total":270,"completed":41,"skipped":618,"failed":0}
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 04:22:56.381: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6684
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap configmap-6684/configmap-test-ac01a587-0eb0-4952-a590-921e69d6ba68
STEP: Creating a pod to test consume configMaps
Feb 22 04:22:56.817: INFO: Waiting up to 5m0s for pod "pod-configmaps-2ad1f62a-244a-4229-98f0-6f453ee0964f" in namespace "configmap-6684" to be "Succeeded or Failed"
Feb 22 04:22:56.835: INFO: Pod "pod-configmaps-2ad1f62a-244a-4229-98f0-6f453ee0964f": Phase="Pending", Reason="", readiness=false. Elapsed: 17.825341ms
Feb 22 04:22:58.847: INFO: Pod "pod-configmaps-2ad1f62a-244a-4229-98f0-6f453ee0964f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029751404s
Feb 22 04:23:00.862: INFO: Pod "pod-configmaps-2ad1f62a-244a-4229-98f0-6f453ee0964f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.044432888s
Feb 22 04:23:02.880: INFO: Pod "pod-configmaps-2ad1f62a-244a-4229-98f0-6f453ee0964f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.062656953s
Feb 22 04:23:04.965: INFO: Pod "pod-configmaps-2ad1f62a-244a-4229-98f0-6f453ee0964f": Phase="Pending", Reason="", readiness=false. Elapsed: 8.147653403s
Feb 22 04:23:06.977: INFO: Pod "pod-configmaps-2ad1f62a-244a-4229-98f0-6f453ee0964f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.159227616s
Feb 22 04:23:09.032: INFO: Pod "pod-configmaps-2ad1f62a-244a-4229-98f0-6f453ee0964f": Phase="Pending", Reason="", readiness=false. Elapsed: 12.214614106s
Feb 22 04:23:11.041: INFO: Pod "pod-configmaps-2ad1f62a-244a-4229-98f0-6f453ee0964f": Phase="Pending", Reason="", readiness=false. Elapsed: 14.222969412s
Feb 22 04:23:13.049: INFO: Pod "pod-configmaps-2ad1f62a-244a-4229-98f0-6f453ee0964f": Phase="Pending", Reason="", readiness=false. Elapsed: 16.231743093s
Feb 22 04:23:15.056: INFO: Pod "pod-configmaps-2ad1f62a-244a-4229-98f0-6f453ee0964f": Phase="Pending", Reason="", readiness=false. Elapsed: 18.238691193s
Feb 22 04:23:17.066: INFO: Pod "pod-configmaps-2ad1f62a-244a-4229-98f0-6f453ee0964f": Phase="Pending", Reason="", readiness=false. Elapsed: 20.248052793s
Feb 22 04:23:19.103: INFO: Pod "pod-configmaps-2ad1f62a-244a-4229-98f0-6f453ee0964f": Phase="Pending", Reason="", readiness=false. Elapsed: 22.285496512s
Feb 22 04:23:21.114: INFO: Pod "pod-configmaps-2ad1f62a-244a-4229-98f0-6f453ee0964f": Phase="Pending", Reason="", readiness=false. Elapsed: 24.296796911s
Feb 22 04:23:23.123: INFO: Pod "pod-configmaps-2ad1f62a-244a-4229-98f0-6f453ee0964f": Phase="Pending", Reason="", readiness=false. Elapsed: 26.305343247s
Feb 22 04:23:25.166: INFO: Pod "pod-configmaps-2ad1f62a-244a-4229-98f0-6f453ee0964f": Phase="Pending", Reason="", readiness=false. Elapsed: 28.348591252s
Feb 22 04:23:27.186: INFO: Pod "pod-configmaps-2ad1f62a-244a-4229-98f0-6f453ee0964f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 30.368584704s
STEP: Saw pod success
Feb 22 04:23:27.186: INFO: Pod "pod-configmaps-2ad1f62a-244a-4229-98f0-6f453ee0964f" satisfied condition "Succeeded or Failed"
Feb 22 04:23:27.200: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com pod pod-configmaps-2ad1f62a-244a-4229-98f0-6f453ee0964f container env-test: <nil>
STEP: delete the pod
Feb 22 04:23:32.989: INFO: Waiting for pod pod-configmaps-2ad1f62a-244a-4229-98f0-6f453ee0964f to disappear
Feb 22 04:23:33.023: INFO: Pod pod-configmaps-2ad1f62a-244a-4229-98f0-6f453ee0964f still exists
Feb 22 04:23:35.023: INFO: Waiting for pod pod-configmaps-2ad1f62a-244a-4229-98f0-6f453ee0964f to disappear
Feb 22 04:23:35.046: INFO: Pod pod-configmaps-2ad1f62a-244a-4229-98f0-6f453ee0964f still exists
Feb 22 04:23:37.023: INFO: Waiting for pod pod-configmaps-2ad1f62a-244a-4229-98f0-6f453ee0964f to disappear
Feb 22 04:23:37.034: INFO: Pod pod-configmaps-2ad1f62a-244a-4229-98f0-6f453ee0964f no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 04:23:37.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6684" for this suite.

â€¢ [SLOW TEST:40.800 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:34
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]","total":270,"completed":42,"skipped":618,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 04:23:37.182: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-6360
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:74
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Feb 22 04:23:37.613: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Feb 22 04:23:37.658: INFO: Pod name sample-pod: Found 0 pods out of 1
Feb 22 04:23:42.678: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 22 04:24:02.710: INFO: Creating deployment "test-rolling-update-deployment"
Feb 22 04:24:02.836: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Feb 22 04:24:03.092: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Feb 22 04:24:05.141: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Feb 22 04:24:05.219: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564643, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564643, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564643, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564643, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-59d5cb45c7\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:24:07.236: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564643, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564643, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564643, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564643, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-59d5cb45c7\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:24:09.228: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564643, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564643, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564643, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564643, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-59d5cb45c7\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:24:11.228: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564643, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564643, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564643, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564643, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-59d5cb45c7\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:24:13.239: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564643, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564643, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564643, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564643, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-59d5cb45c7\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:24:15.235: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564643, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564643, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564643, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564643, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-59d5cb45c7\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:24:17.229: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564643, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564643, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564643, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564643, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-59d5cb45c7\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:24:19.228: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564643, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564643, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564643, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564643, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-59d5cb45c7\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:24:21.228: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564643, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564643, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564643, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564643, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-59d5cb45c7\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:24:23.230: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564643, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564643, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564643, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564643, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-59d5cb45c7\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:24:25.228: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564643, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564643, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564643, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564643, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-59d5cb45c7\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:24:27.229: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564643, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564643, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564643, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564643, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-59d5cb45c7\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:24:29.228: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
Feb 22 04:24:29.271: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-6360 /apis/apps/v1/namespaces/deployment-6360/deployments/test-rolling-update-deployment 8e8b63d7-ec5e-49e7-80ce-3b8c335fea52 64119 1 2021-02-22 04:24:02 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] []  [{e2e.test Update apps/v1 2021-02-22 04:24:02 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 112 114 111 103 114 101 115 115 68 101 97 100 108 105 110 101 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 118 105 115 105 111 110 72 105 115 116 111 114 121 76 105 109 105 116 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 116 114 97 116 101 103 121 34 58 123 34 102 58 114 111 108 108 105 110 103 85 112 100 97 116 101 34 58 123 34 46 34 58 123 125 44 34 102 58 109 97 120 83 117 114 103 101 34 58 123 125 44 34 102 58 109 97 120 85 110 97 118 97 105 108 97 98 108 101 34 58 123 125 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2021-02-22 04:24:28 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 65 118 97 105 108 97 98 108 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 80 114 111 103 114 101 115 115 105 110 103 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 112 100 97 116 101 100 82 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00273a058 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2021-02-22 04:24:03 +0000 UTC,LastTransitionTime:2021-02-22 04:24:03 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-59d5cb45c7" has successfully progressed.,LastUpdateTime:2021-02-22 04:24:28 +0000 UTC,LastTransitionTime:2021-02-22 04:24:03 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Feb 22 04:24:29.278: INFO: New ReplicaSet "test-rolling-update-deployment-59d5cb45c7" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-59d5cb45c7  deployment-6360 /apis/apps/v1/namespaces/deployment-6360/replicasets/test-rolling-update-deployment-59d5cb45c7 8cf7f8f7-6301-4e8d-a77b-2d970d49d95e 64107 1 2021-02-22 04:24:03 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:59d5cb45c7] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 8e8b63d7-ec5e-49e7-80ce-3b8c335fea52 0xc0086d2e37 0xc0086d2e38}] []  [{kube-controller-manager Update apps/v1 2021-02-22 04:24:28 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 56 101 56 98 54 51 100 55 45 101 99 53 101 45 52 57 101 55 45 56 48 99 101 45 51 98 56 99 51 51 53 102 101 97 53 50 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 59d5cb45c7,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:59d5cb45c7] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0086d2ed8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Feb 22 04:24:29.278: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Feb 22 04:24:29.278: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-6360 /apis/apps/v1/namespaces/deployment-6360/replicasets/test-rolling-update-controller a819b77c-feaf-46ae-9ca8-fee73912c881 64118 2 2021-02-22 04:23:37 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 8e8b63d7-ec5e-49e7-80ce-3b8c335fea52 0xc0086d2d27 0xc0086d2d28}] []  [{e2e.test Update apps/v1 2021-02-22 04:23:37 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2021-02-22 04:24:28 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 56 101 56 98 54 51 100 55 45 101 99 53 101 45 52 57 101 55 45 56 48 99 101 45 51 98 56 99 51 51 53 102 101 97 53 50 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] []  []} {[] [] [{httpd mirror.gcr.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0086d2dc8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Feb 22 04:24:29.295: INFO: Pod "test-rolling-update-controller-8s4fk" is available:
&Pod{ObjectMeta:{test-rolling-update-controller-8s4fk test-rolling-update-controller- deployment-6360 /api/v1/namespaces/deployment-6360/pods/test-rolling-update-controller-8s4fk 6dd3853a-f4c9-4e08-a2af-4ef3103348ee 64114 0 2021-02-22 04:23:37 +0000 UTC 2021-02-22 04:24:28 +0000 UTC 0xc00273a4c8 map[name:sample-pod pod:httpd] map[attachment_id:e3eff268-47b2-47e6-ad6e-7ca1d322bf3f kubernetes.io/psp:e2e-test-privileged-psp mac:04:50:56:00:28:20 vlan:None vmware-system-ephemeral-disk-uuid:6000C295-f6a8-9c76-7227-e61052e11f1f vmware-system-image-references:{"httpd":"httpd-d22d0e2cfeeaa0c1d2773814f5199d564ac0eae2-v18721"} vmware-system-vm-moid:vm-338:6b180790-afb7-40a7-b1c1-16f00c9b6783 vmware-system-vm-uuid:502f5363-c290-d81f-4fac-2b66f8749519] [{apps/v1 ReplicaSet test-rolling-update-controller a819b77c-feaf-46ae-9ca8-fee73912c881 0xc00273a517 0xc00273a518}] [lifecycle-controller/system.vmware.com]  [{image-controller Update v1 2021-02-22 04:23:37 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 105 109 97 103 101 45 114 101 102 101 114 101 110 99 101 115 34 58 123 125 125 125 125],}} {kube-controller-manager Update v1 2021-02-22 04:23:37 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 97 56 49 57 98 55 55 99 45 102 101 97 102 45 52 54 97 101 45 57 99 97 56 45 102 101 101 55 51 57 49 50 99 56 56 49 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {nsx-ncp-75bf644549-ps9h2 Update v1 2021-02-22 04:23:46 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 97 116 116 97 99 104 109 101 110 116 95 105 100 34 58 123 125 44 34 102 58 109 97 99 34 58 123 125 44 34 102 58 118 108 97 110 34 58 123 125 125 125 125],}} {scheduler-extender Update v1 2021-02-22 04:23:54 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 101 112 104 101 109 101 114 97 108 45 100 105 115 107 45 117 117 105 100 34 58 123 125 44 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 118 109 45 109 111 105 100 34 58 123 125 44 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 118 109 45 117 117 105 100 34 58 123 125 125 44 34 102 58 102 105 110 97 108 105 122 101 114 115 34 58 123 34 46 34 58 123 125 44 34 118 58 92 34 108 105 102 101 99 121 99 108 101 45 99 111 110 116 114 111 108 108 101 114 47 115 121 115 116 101 109 46 118 109 119 97 114 101 46 99 111 109 92 34 34 58 123 125 125 125 125],}} {spherelet Update v1 2021-02-22 04:24:02 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 102 58 101 110 118 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 95 52 52 51 95 84 67 80 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 95 52 52 51 95 84 67 80 95 65 68 68 82 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 95 52 52 51 95 84 67 80 95 80 79 82 84 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 95 52 52 51 95 84 67 80 95 80 82 79 84 79 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 83 69 82 86 73 67 69 95 72 79 83 84 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 83 69 82 86 73 67 69 95 80 79 82 84 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 83 69 82 86 73 67 69 95 80 79 82 84 95 72 84 84 80 83 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 55 50 46 50 54 46 49 46 50 49 48 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-pt8bd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-pt8bd,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:mirror.gcr.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-pt8bd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:sc2-rdops-vm05-dhcp-174-51.eng.vmware.com,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 04:23:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 04:24:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 04:24:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 04:24:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.192.174.51,PodIP:172.26.1.210,StartTime:2021-02-22 04:24:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2021-02-22 04:24:01 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:mirror.gcr.io/library/httpd:2.4.38-alpine,ImageID:httpd-d22d0e2cfeeaa0c1d2773814f5199d564ac0eae2-v18721,ContainerID:9135168a-4616-4b40-beba-190222f905c9,Started:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.26.1.210,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 22 04:24:29.299: INFO: Pod "test-rolling-update-deployment-59d5cb45c7-bxgnp" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-59d5cb45c7-bxgnp test-rolling-update-deployment-59d5cb45c7- deployment-6360 /api/v1/namespaces/deployment-6360/pods/test-rolling-update-deployment-59d5cb45c7-bxgnp 9d4e27e6-38f6-4dc7-baa5-1dea4b18ba75 64105 0 2021-02-22 04:24:03 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:59d5cb45c7] map[attachment_id:25f3c6ea-5c87-46ba-aa49-52dd14e5dbcd kubernetes.io/psp:e2e-test-privileged-psp mac:04:50:56:00:28:1f vlan:None vmware-system-ephemeral-disk-uuid:6000C29c-2923-ea6f-da8b-87d5c4f58569 vmware-system-image-references:{"agnhost":"agnhost-4c5d323a799f707178acf281f8da2d9a581ad331-v58"} vmware-system-vm-moid:vm-340:6b180790-afb7-40a7-b1c1-16f00c9b6783 vmware-system-vm-uuid:502f83af-18ef-a606-2f90-f456328d9669] [{apps/v1 ReplicaSet test-rolling-update-deployment-59d5cb45c7 8cf7f8f7-6301-4e8d-a77b-2d970d49d95e 0xc00273a70f 0xc00273a720}] [lifecycle-controller/system.vmware.com]  [{image-controller Update v1 2021-02-22 04:24:03 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 105 109 97 103 101 45 114 101 102 101 114 101 110 99 101 115 34 58 123 125 125 125 125],}} {kube-controller-manager Update v1 2021-02-22 04:24:03 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 56 99 102 55 102 56 102 55 45 54 51 48 49 45 52 101 56 100 45 97 55 55 98 45 50 100 57 55 48 100 52 57 100 57 53 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {nsx-ncp-75bf644549-ps9h2 Update v1 2021-02-22 04:24:04 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 97 116 116 97 99 104 109 101 110 116 95 105 100 34 58 123 125 44 34 102 58 109 97 99 34 58 123 125 44 34 102 58 118 108 97 110 34 58 123 125 125 125 125],}} {scheduler-extender Update v1 2021-02-22 04:24:20 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 101 112 104 101 109 101 114 97 108 45 100 105 115 107 45 117 117 105 100 34 58 123 125 44 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 118 109 45 109 111 105 100 34 58 123 125 44 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 118 109 45 117 117 105 100 34 58 123 125 125 44 34 102 58 102 105 110 97 108 105 122 101 114 115 34 58 123 34 46 34 58 123 125 44 34 118 58 92 34 108 105 102 101 99 121 99 108 101 45 99 111 110 116 114 111 108 108 101 114 47 115 121 115 116 101 109 46 118 109 119 97 114 101 46 99 111 109 92 34 34 58 123 125 125 125 125],}} {spherelet Update v1 2021-02-22 04:24:28 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 102 58 101 110 118 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 95 52 52 51 95 84 67 80 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 95 52 52 51 95 84 67 80 95 65 68 68 82 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 95 52 52 51 95 84 67 80 95 80 79 82 84 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 95 52 52 51 95 84 67 80 95 80 82 79 84 79 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 83 69 82 86 73 67 69 95 72 79 83 84 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 83 69 82 86 73 67 69 95 80 79 82 84 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 83 69 82 86 73 67 69 95 80 79 82 84 95 72 84 84 80 83 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 55 50 46 50 54 46 49 46 50 49 49 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-pt8bd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-pt8bd,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-pt8bd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:sc2-rdops-vm05-dhcp-174-51.eng.vmware.com,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 04:24:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 04:24:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 04:24:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 04:24:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.192.174.51,PodIP:172.26.1.211,StartTime:2021-02-22 04:24:25 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2021-02-22 04:24:26 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,ImageID:agnhost-4c5d323a799f707178acf281f8da2d9a581ad331-v58,ContainerID:8c77f399-f5a3-40f7-9fca-f722cc5c5642,Started:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.26.1.211,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 04:24:29.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6360" for this suite.

â€¢ [SLOW TEST:52.172 seconds]
[sig-apps] Deployment
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]","total":270,"completed":43,"skipped":637,"failed":0}
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 04:24:29.355: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7283
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir volume type on node default medium
Feb 22 04:24:29.691: INFO: Waiting up to 5m0s for pod "pod-9eaa28f3-c3c8-448d-9168-0e0253b5d203" in namespace "emptydir-7283" to be "Succeeded or Failed"
Feb 22 04:24:29.703: INFO: Pod "pod-9eaa28f3-c3c8-448d-9168-0e0253b5d203": Phase="Pending", Reason="", readiness=false. Elapsed: 12.160638ms
Feb 22 04:24:31.712: INFO: Pod "pod-9eaa28f3-c3c8-448d-9168-0e0253b5d203": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021082515s
Feb 22 04:24:33.725: INFO: Pod "pod-9eaa28f3-c3c8-448d-9168-0e0253b5d203": Phase="Pending", Reason="", readiness=false. Elapsed: 4.03471689s
Feb 22 04:24:35.740: INFO: Pod "pod-9eaa28f3-c3c8-448d-9168-0e0253b5d203": Phase="Pending", Reason="", readiness=false. Elapsed: 6.049614632s
Feb 22 04:24:37.763: INFO: Pod "pod-9eaa28f3-c3c8-448d-9168-0e0253b5d203": Phase="Pending", Reason="", readiness=false. Elapsed: 8.072226105s
Feb 22 04:24:39.770: INFO: Pod "pod-9eaa28f3-c3c8-448d-9168-0e0253b5d203": Phase="Pending", Reason="", readiness=false. Elapsed: 10.079491416s
Feb 22 04:24:41.780: INFO: Pod "pod-9eaa28f3-c3c8-448d-9168-0e0253b5d203": Phase="Pending", Reason="", readiness=false. Elapsed: 12.088986198s
Feb 22 04:24:43.792: INFO: Pod "pod-9eaa28f3-c3c8-448d-9168-0e0253b5d203": Phase="Pending", Reason="", readiness=false. Elapsed: 14.100886906s
Feb 22 04:24:45.802: INFO: Pod "pod-9eaa28f3-c3c8-448d-9168-0e0253b5d203": Phase="Pending", Reason="", readiness=false. Elapsed: 16.111668712s
Feb 22 04:24:47.828: INFO: Pod "pod-9eaa28f3-c3c8-448d-9168-0e0253b5d203": Phase="Pending", Reason="", readiness=false. Elapsed: 18.136893367s
Feb 22 04:24:49.834: INFO: Pod "pod-9eaa28f3-c3c8-448d-9168-0e0253b5d203": Phase="Pending", Reason="", readiness=false. Elapsed: 20.143202267s
Feb 22 04:24:51.842: INFO: Pod "pod-9eaa28f3-c3c8-448d-9168-0e0253b5d203": Phase="Pending", Reason="", readiness=false. Elapsed: 22.151434079s
Feb 22 04:24:53.853: INFO: Pod "pod-9eaa28f3-c3c8-448d-9168-0e0253b5d203": Phase="Pending", Reason="", readiness=false. Elapsed: 24.162490236s
Feb 22 04:24:55.860: INFO: Pod "pod-9eaa28f3-c3c8-448d-9168-0e0253b5d203": Phase="Pending", Reason="", readiness=false. Elapsed: 26.169713814s
Feb 22 04:24:57.869: INFO: Pod "pod-9eaa28f3-c3c8-448d-9168-0e0253b5d203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 28.177997173s
STEP: Saw pod success
Feb 22 04:24:57.869: INFO: Pod "pod-9eaa28f3-c3c8-448d-9168-0e0253b5d203" satisfied condition "Succeeded or Failed"
Feb 22 04:24:57.878: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com pod pod-9eaa28f3-c3c8-448d-9168-0e0253b5d203 container test-container: <nil>
STEP: delete the pod
Feb 22 04:24:57.955: INFO: Waiting for pod pod-9eaa28f3-c3c8-448d-9168-0e0253b5d203 to disappear
Feb 22 04:24:57.986: INFO: Pod pod-9eaa28f3-c3c8-448d-9168-0e0253b5d203 still exists
Feb 22 04:24:59.993: INFO: Waiting for pod pod-9eaa28f3-c3c8-448d-9168-0e0253b5d203 to disappear
Feb 22 04:25:00.003: INFO: Pod pod-9eaa28f3-c3c8-448d-9168-0e0253b5d203 still exists
Feb 22 04:25:01.993: INFO: Waiting for pod pod-9eaa28f3-c3c8-448d-9168-0e0253b5d203 to disappear
Feb 22 04:25:02.015: INFO: Pod pod-9eaa28f3-c3c8-448d-9168-0e0253b5d203 still exists
Feb 22 04:25:03.994: INFO: Waiting for pod pod-9eaa28f3-c3c8-448d-9168-0e0253b5d203 to disappear
Feb 22 04:25:04.014: INFO: Pod pod-9eaa28f3-c3c8-448d-9168-0e0253b5d203 still exists
Feb 22 04:25:05.993: INFO: Waiting for pod pod-9eaa28f3-c3c8-448d-9168-0e0253b5d203 to disappear
Feb 22 04:25:06.003: INFO: Pod pod-9eaa28f3-c3c8-448d-9168-0e0253b5d203 still exists
Feb 22 04:25:07.993: INFO: Waiting for pod pod-9eaa28f3-c3c8-448d-9168-0e0253b5d203 to disappear
Feb 22 04:25:08.006: INFO: Pod pod-9eaa28f3-c3c8-448d-9168-0e0253b5d203 still exists
Feb 22 04:25:09.994: INFO: Waiting for pod pod-9eaa28f3-c3c8-448d-9168-0e0253b5d203 to disappear
Feb 22 04:25:10.016: INFO: Pod pod-9eaa28f3-c3c8-448d-9168-0e0253b5d203 still exists
Feb 22 04:25:11.993: INFO: Waiting for pod pod-9eaa28f3-c3c8-448d-9168-0e0253b5d203 to disappear
Feb 22 04:25:12.007: INFO: Pod pod-9eaa28f3-c3c8-448d-9168-0e0253b5d203 still exists
Feb 22 04:25:13.996: INFO: Waiting for pod pod-9eaa28f3-c3c8-448d-9168-0e0253b5d203 to disappear
Feb 22 04:25:14.477: INFO: Pod pod-9eaa28f3-c3c8-448d-9168-0e0253b5d203 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 04:25:14.482: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7283" for this suite.

â€¢ [SLOW TEST:45.706 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:42
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":270,"completed":44,"skipped":641,"failed":0}
SSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 04:25:15.075: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-7923
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 04:25:42.956: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-7923" for this suite.

â€¢ [SLOW TEST:27.978 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not conflict [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]","total":270,"completed":45,"skipped":646,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 04:25:43.082: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-6943
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 04:26:12.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6943" for this suite.

â€¢ [SLOW TEST:29.106 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  when scheduling a busybox command in a pod
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:41
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]","total":270,"completed":46,"skipped":707,"failed":0}
SSSSSSS
------------------------------
[k8s.io] [sig-node] NoExecuteTaintManager Single Pod [Serial] 
  removing taint cancels eviction [Disruptive] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 04:26:12.197: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename taint-single-pod
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in taint-single-pod-8031
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/taints.go:164
Feb 22 04:26:12.843: INFO: Waiting up to 1m0s for all nodes to be ready
Feb 22 04:27:13.212: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Disruptive] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Feb 22 04:27:13.235: INFO: Starting informer...
STEP: Starting pod...
Feb 22 04:27:13.520: INFO: Pod is running on sc2-rdops-vm05-dhcp-174-51.eng.vmware.com. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting short time to make sure Pod is queued for deletion
Feb 22 04:27:13.670: INFO: Pod wasn't evicted. Proceeding
Feb 22 04:27:13.670: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting some time to make sure that toleration time passed.
Feb 22 04:28:28.871: INFO: Pod wasn't evicted. Test successful
[AfterEach] [k8s.io] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 04:28:28.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-8031" for this suite.

â€¢ [SLOW TEST:136.798 seconds]
[k8s.io] [sig-node] NoExecuteTaintManager Single Pod [Serial]
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  removing taint cancels eviction [Disruptive] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] [sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]","total":270,"completed":47,"skipped":714,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 04:28:29.051: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5043
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Kubectl label
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1206
STEP: creating the pod
Feb 22 04:28:29.526: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config create -f - --namespace=kubectl-5043'
Feb 22 04:28:31.944: INFO: stderr: ""
Feb 22 04:28:31.944: INFO: stdout: "pod/pause created\n"
Feb 22 04:28:31.945: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Feb 22 04:28:31.946: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-5043" to be "running and ready"
Feb 22 04:28:31.989: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 43.390014ms
Feb 22 04:28:34.053: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.107106142s
Feb 22 04:28:36.085: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 4.139159273s
Feb 22 04:28:38.104: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 6.158237089s
Feb 22 04:28:40.116: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 8.17051539s
Feb 22 04:28:42.143: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 10.197486904s
Feb 22 04:28:44.162: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 12.215814796s
Feb 22 04:28:46.183: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 14.237248232s
Feb 22 04:28:48.197: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 16.251225336s
Feb 22 04:28:50.205: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 18.259007653s
Feb 22 04:28:52.214: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 20.268351251s
Feb 22 04:28:54.223: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 22.276890363s
Feb 22 04:28:56.231: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 24.285505444s
Feb 22 04:28:58.244: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 26.298119462s
Feb 22 04:28:58.244: INFO: Pod "pause" satisfied condition "running and ready"
Feb 22 04:28:58.244: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: adding the label testing-label with value testing-label-value to a pod
Feb 22 04:28:58.245: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config label pods pause testing-label=testing-label-value --namespace=kubectl-5043'
Feb 22 04:28:58.451: INFO: stderr: ""
Feb 22 04:28:58.451: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Feb 22 04:28:58.451: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pod pause -L testing-label --namespace=kubectl-5043'
Feb 22 04:28:58.790: INFO: stderr: ""
Feb 22 04:28:58.790: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          27s   testing-label-value\n"
STEP: removing the label testing-label of a pod
Feb 22 04:28:58.790: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config label pods pause testing-label- --namespace=kubectl-5043'
Feb 22 04:28:59.127: INFO: stderr: ""
Feb 22 04:28:59.127: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Feb 22 04:28:59.127: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pod pause -L testing-label --namespace=kubectl-5043'
Feb 22 04:28:59.444: INFO: stderr: ""
Feb 22 04:28:59.444: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          28s   \n"
[AfterEach] Kubectl label
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1213
STEP: using delete to clean up resources
Feb 22 04:28:59.444: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config delete --grace-period=0 --force -f - --namespace=kubectl-5043'
Feb 22 04:29:19.851: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 22 04:29:19.852: INFO: stdout: "pod \"pause\" force deleted\n"
Feb 22 04:29:19.852: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get rc,svc -l name=pause --no-headers --namespace=kubectl-5043'
Feb 22 04:29:20.212: INFO: stderr: "No resources found in kubectl-5043 namespace.\n"
Feb 22 04:29:20.212: INFO: stdout: ""
Feb 22 04:29:20.213: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods -l name=pause --namespace=kubectl-5043 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 22 04:29:20.566: INFO: stderr: ""
Feb 22 04:29:20.566: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 04:29:20.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5043" for this suite.

â€¢ [SLOW TEST:51.662 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl label
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1203
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl label should update the label on a resource  [Conformance]","total":270,"completed":48,"skipped":731,"failed":0}
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 04:29:20.715: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-7671
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 22 04:29:22.259: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb 22 04:29:24.311: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564962, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564962, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564962, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564962, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:29:26.320: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564962, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564962, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564962, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564962, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:29:28.363: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564962, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564962, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564962, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564962, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:29:30.778: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564962, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564962, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564962, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564962, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:29:32.471: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564962, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564962, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564962, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564962, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:29:34.383: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564962, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564962, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564962, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564962, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:29:36.325: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564962, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564962, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564962, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564962, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:29:38.365: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564962, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564962, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564962, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564962, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:29:40.344: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564962, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564962, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564962, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564962, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:29:42.323: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564962, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564962, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564962, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564962, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:29:44.321: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564962, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564962, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564962, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564962, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:29:46.325: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564962, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564962, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564962, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564962, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:29:48.319: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564962, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564962, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564962, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564962, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:29:50.324: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564962, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564962, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564962, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564962, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:29:52.319: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564962, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564962, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564962, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749564962, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 22 04:29:55.400: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Feb 22 04:29:55.430: INFO: >>> kubeConfig: /root/.kube/config
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-7962-crds.webhook.example.com via the AdmissionRegistration API
Feb 22 04:29:56.283: INFO: Waiting for webhook configuration to be ready...
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 04:29:57.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7671" for this suite.
STEP: Destroying namespace "webhook-7671-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

â€¢ [SLOW TEST:48.208 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]","total":270,"completed":49,"skipped":735,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 04:30:08.947: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-1241
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:91
Feb 22 04:30:14.561: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 22 04:30:15.379: INFO: Waiting for terminating namespaces to be deleted...
Feb 22 04:30:15.537: INFO: 
Logging pods the kubelet thinks is on node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com before test
Feb 22 04:30:15.689: INFO: nginx-private from test-image-pull-secrets-ns started at 2021-02-22 03:11:22 +0000 UTC (1 container statuses recorded)
Feb 22 04:30:15.689: INFO: 	Container nginx-private-container ready: true, restart count 0
Feb 22 04:30:15.689: INFO: test-docker-registry from test-private-image-registry-ns started at 2021-02-22 03:23:54 +0000 UTC (1 container statuses recorded)
Feb 22 04:30:15.689: INFO: 	Container test-docker-registry ready: true, restart count 0
Feb 22 04:30:15.689: INFO: schedext-test-affinity-3 from test-pod-affinity started at 2021-02-22 03:18:02 +0000 UTC (1 container statuses recorded)
Feb 22 04:30:15.689: INFO: 	Container hello ready: true, restart count 0
Feb 22 04:30:15.689: INFO: wcp-sanity-busybox-7bf494fc58-tlpw6 from test-update-workload-ns started at 2021-02-22 03:28:50 +0000 UTC (1 container statuses recorded)
Feb 22 04:30:15.689: INFO: 	Container wcp-sanity-busybox-container ready: true, restart count 0
Feb 22 04:30:15.689: INFO: helloworld from test-telemetry started at 2021-02-22 03:31:02 +0000 UTC (1 container statuses recorded)
Feb 22 04:30:15.689: INFO: 	Container hello ready: true, restart count 0
Feb 22 04:30:15.689: INFO: hello-web-1-5f76cbcd98-vs4bx from test-network-policy started at 2021-02-22 04:27:53 +0000 UTC (1 container statuses recorded)
Feb 22 04:30:15.689: INFO: 	Container hello-app ready: true, restart count 0
Feb 22 04:30:15.689: INFO: helloworld from test-kube-events-ns started at 2021-02-22 03:14:06 +0000 UTC (1 container statuses recorded)
Feb 22 04:30:15.689: INFO: 	Container hello ready: true, restart count 0
Feb 22 04:30:15.689: INFO: schedext-test-node-selector-1 from test-node-selector started at 2021-02-22 03:16:36 +0000 UTC (1 container statuses recorded)
Feb 22 04:30:15.689: INFO: 	Container hello ready: true, restart count 0
Feb 22 04:30:15.690: INFO: 
Logging pods the kubelet thinks is on node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com before test
Feb 22 04:30:15.846: INFO: wcp-sanity-busybox-7bf494fc58-rcpr6 from test-update-workload-ns started at 2021-02-22 04:28:23 +0000 UTC (1 container statuses recorded)
Feb 22 04:30:15.846: INFO: 	Container wcp-sanity-busybox-container ready: true, restart count 0
Feb 22 04:30:15.846: INFO: hello-web-2-dcbfdb96d-pcvm7 from test-network-policy started at 2021-02-22 04:27:55 +0000 UTC (1 container statuses recorded)
Feb 22 04:30:15.846: INFO: 	Container hello-app ready: true, restart count 0
Feb 22 04:30:15.846: INFO: sample-webhook-deployment-779fdc84d9-nk7ms from webhook-7671 started at 2021-02-22 04:29:51 +0000 UTC (1 container statuses recorded)
Feb 22 04:30:15.846: INFO: 	Container sample-webhook ready: true, restart count 0
Feb 22 04:30:15.846: INFO: 
Logging pods the kubelet thinks is on node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com before test
Feb 22 04:30:15.958: INFO: wcp-sanity-busybox-7bf494fc58-7sn7q from test-dataprovider-podvms-ns started at 2021-02-22 03:08:43 +0000 UTC (1 container statuses recorded)
Feb 22 04:30:15.958: INFO: 	Container wcp-sanity-busybox-container ready: true, restart count 0
Feb 22 04:30:15.958: INFO: wcp-sanity-busybox-7bf494fc58-pln4w from test-dataprovider-podvms-ns started at 2021-02-22 03:08:42 +0000 UTC (1 container statuses recorded)
Feb 22 04:30:15.958: INFO: 	Container wcp-sanity-busybox-container ready: true, restart count 0
Feb 22 04:30:15.958: INFO: podwithpersistentvolume from storage-policy-test started at 2021-02-22 03:27:14 +0000 UTC (1 container statuses recorded)
Feb 22 04:30:15.958: INFO: 	Container hello ready: true, restart count 0
Feb 22 04:30:15.958: INFO: wcp-sanity-busybox-7bf494fc58-npc5m from test-update-workload-ns started at 2021-02-22 03:28:52 +0000 UTC (1 container statuses recorded)
Feb 22 04:30:15.959: INFO: 	Container wcp-sanity-busybox-container ready: true, restart count 0
Feb 22 04:30:15.959: INFO: hello-web-5f76cbcd98-9f9j4 from test-cluster-ip-service started at 2021-02-22 04:27:54 +0000 UTC (1 container statuses recorded)
Feb 22 04:30:15.965: INFO: 	Container hello-app ready: true, restart count 0
Feb 22 04:30:15.965: INFO: curl-pod from test-cluster-ip-service started at 2021-02-22 03:04:01 +0000 UTC (1 container statuses recorded)
Feb 22 04:30:15.965: INFO: 	Container curl-container ready: true, restart count 0
Feb 22 04:30:15.965: INFO: curl-pod from test-network-policy started at 2021-02-22 03:15:49 +0000 UTC (1 container statuses recorded)
Feb 22 04:30:15.965: INFO: 	Container curl-container ready: true, restart count 0
Feb 22 04:30:15.965: INFO: schedext-test-affinity-1 from test-pod-affinity started at 2021-02-22 03:17:26 +0000 UTC (1 container statuses recorded)
Feb 22 04:30:15.965: INFO: 	Container hello ready: true, restart count 0
Feb 22 04:30:15.965: INFO: schedext-test-affinity-2 from test-pod-affinity started at 2021-02-22 03:17:50 +0000 UTC (1 container statuses recorded)
Feb 22 04:30:15.965: INFO: 	Container hello ready: true, restart count 0
Feb 22 04:30:15.965: INFO: busybox from test-pod-external-nw-access started at 2021-02-22 03:22:58 +0000 UTC (1 container statuses recorded)
Feb 22 04:30:15.965: INFO: 	Container busybox ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.1665f78ab4113c14], Reason = [FailedScheduling], Message = [0/6 nodes are available: 6 node(s) didn't match node selector.]
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.1665f78abbae77cc], Reason = [FailedScheduling], Message = [0/6 nodes are available: 6 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 04:30:17.645: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-1241" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:82

â€¢ [SLOW TEST:8.839 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching  [Conformance]","total":270,"completed":50,"skipped":769,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 04:30:17.786: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-3497
STEP: Waiting for a default service account to be provisioned in namespace
[It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3497 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-3497;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3497 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-3497;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3497.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-3497.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3497.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-3497.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-3497.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-3497.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-3497.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-3497.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-3497.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-3497.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-3497.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-3497.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3497.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 118.93.24.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.24.93.118_udp@PTR;check="$$(dig +tcp +noall +answer +search 118.93.24.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.24.93.118_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3497 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-3497;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3497 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-3497;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3497.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-3497.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3497.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-3497.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-3497.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-3497.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-3497.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-3497.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-3497.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-3497.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-3497.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-3497.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3497.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 118.93.24.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.24.93.118_udp@PTR;check="$$(dig +tcp +noall +answer +search 118.93.24.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.24.93.118_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 22 04:31:19.211: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-3497/dns-test-fac04fe6-4a6e-4e3f-ba4c-651b1ab55ab6: the server could not find the requested resource (get pods dns-test-fac04fe6-4a6e-4e3f-ba4c-651b1ab55ab6)
Feb 22 04:31:19.328: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-3497/dns-test-fac04fe6-4a6e-4e3f-ba4c-651b1ab55ab6: the server could not find the requested resource (get pods dns-test-fac04fe6-4a6e-4e3f-ba4c-651b1ab55ab6)
Feb 22 04:31:19.369: INFO: Unable to read wheezy_udp@dns-test-service.dns-3497 from pod dns-3497/dns-test-fac04fe6-4a6e-4e3f-ba4c-651b1ab55ab6: the server could not find the requested resource (get pods dns-test-fac04fe6-4a6e-4e3f-ba4c-651b1ab55ab6)
Feb 22 04:31:19.403: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3497 from pod dns-3497/dns-test-fac04fe6-4a6e-4e3f-ba4c-651b1ab55ab6: the server could not find the requested resource (get pods dns-test-fac04fe6-4a6e-4e3f-ba4c-651b1ab55ab6)
Feb 22 04:31:19.463: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3497.svc from pod dns-3497/dns-test-fac04fe6-4a6e-4e3f-ba4c-651b1ab55ab6: the server could not find the requested resource (get pods dns-test-fac04fe6-4a6e-4e3f-ba4c-651b1ab55ab6)
Feb 22 04:31:19.483: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3497.svc from pod dns-3497/dns-test-fac04fe6-4a6e-4e3f-ba4c-651b1ab55ab6: the server could not find the requested resource (get pods dns-test-fac04fe6-4a6e-4e3f-ba4c-651b1ab55ab6)
Feb 22 04:31:19.517: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3497.svc from pod dns-3497/dns-test-fac04fe6-4a6e-4e3f-ba4c-651b1ab55ab6: the server could not find the requested resource (get pods dns-test-fac04fe6-4a6e-4e3f-ba4c-651b1ab55ab6)
Feb 22 04:31:19.742: INFO: Unable to read jessie_udp@dns-test-service from pod dns-3497/dns-test-fac04fe6-4a6e-4e3f-ba4c-651b1ab55ab6: the server could not find the requested resource (get pods dns-test-fac04fe6-4a6e-4e3f-ba4c-651b1ab55ab6)
Feb 22 04:31:19.785: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-3497/dns-test-fac04fe6-4a6e-4e3f-ba4c-651b1ab55ab6: the server could not find the requested resource (get pods dns-test-fac04fe6-4a6e-4e3f-ba4c-651b1ab55ab6)
Feb 22 04:31:19.814: INFO: Unable to read jessie_udp@dns-test-service.dns-3497 from pod dns-3497/dns-test-fac04fe6-4a6e-4e3f-ba4c-651b1ab55ab6: the server could not find the requested resource (get pods dns-test-fac04fe6-4a6e-4e3f-ba4c-651b1ab55ab6)
Feb 22 04:31:19.847: INFO: Unable to read jessie_tcp@dns-test-service.dns-3497 from pod dns-3497/dns-test-fac04fe6-4a6e-4e3f-ba4c-651b1ab55ab6: the server could not find the requested resource (get pods dns-test-fac04fe6-4a6e-4e3f-ba4c-651b1ab55ab6)
Feb 22 04:31:19.966: INFO: Unable to read jessie_tcp@dns-test-service.dns-3497.svc from pod dns-3497/dns-test-fac04fe6-4a6e-4e3f-ba4c-651b1ab55ab6: the server could not find the requested resource (get pods dns-test-fac04fe6-4a6e-4e3f-ba4c-651b1ab55ab6)
Feb 22 04:31:19.985: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3497.svc from pod dns-3497/dns-test-fac04fe6-4a6e-4e3f-ba4c-651b1ab55ab6: the server could not find the requested resource (get pods dns-test-fac04fe6-4a6e-4e3f-ba4c-651b1ab55ab6)
Feb 22 04:31:19.999: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3497.svc from pod dns-3497/dns-test-fac04fe6-4a6e-4e3f-ba4c-651b1ab55ab6: the server could not find the requested resource (get pods dns-test-fac04fe6-4a6e-4e3f-ba4c-651b1ab55ab6)
Feb 22 04:31:20.169: INFO: Lookups using dns-3497/dns-test-fac04fe6-4a6e-4e3f-ba4c-651b1ab55ab6 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-3497 wheezy_tcp@dns-test-service.dns-3497 wheezy_tcp@dns-test-service.dns-3497.svc wheezy_udp@_http._tcp.dns-test-service.dns-3497.svc wheezy_tcp@_http._tcp.dns-test-service.dns-3497.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-3497 jessie_tcp@dns-test-service.dns-3497 jessie_tcp@dns-test-service.dns-3497.svc jessie_udp@_http._tcp.dns-test-service.dns-3497.svc jessie_tcp@_http._tcp.dns-test-service.dns-3497.svc]

Feb 22 04:31:25.601: INFO: DNS probes using dns-3497/dns-test-fac04fe6-4a6e-4e3f-ba4c-651b1ab55ab6 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 04:31:26.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3497" for this suite.

â€¢ [SLOW TEST:68.639 seconds]
[sig-network] DNS
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]","total":270,"completed":51,"skipped":781,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 04:31:26.458: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-1827
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod liveness-4b16bef9-0214-40e6-a8bd-3e0a1664fe47 in namespace container-probe-1827
Feb 22 04:31:52.937: INFO: Started pod liveness-4b16bef9-0214-40e6-a8bd-3e0a1664fe47 in namespace container-probe-1827
STEP: checking the pod's current state and verifying that restartCount is present
Feb 22 04:31:52.961: INFO: Initial restart count of pod liveness-4b16bef9-0214-40e6-a8bd-3e0a1664fe47 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 04:35:54.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1827" for this suite.

â€¢ [SLOW TEST:267.881 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]","total":270,"completed":52,"skipped":803,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 04:35:54.343: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-5892
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test env composition
Feb 22 04:35:54.898: INFO: Waiting up to 5m0s for pod "var-expansion-ebfa28f4-796e-43c9-9bd7-4e7b74c92311" in namespace "var-expansion-5892" to be "Succeeded or Failed"
Feb 22 04:35:54.921: INFO: Pod "var-expansion-ebfa28f4-796e-43c9-9bd7-4e7b74c92311": Phase="Pending", Reason="", readiness=false. Elapsed: 22.289413ms
Feb 22 04:35:56.946: INFO: Pod "var-expansion-ebfa28f4-796e-43c9-9bd7-4e7b74c92311": Phase="Pending", Reason="", readiness=false. Elapsed: 2.047153272s
Feb 22 04:35:58.957: INFO: Pod "var-expansion-ebfa28f4-796e-43c9-9bd7-4e7b74c92311": Phase="Pending", Reason="", readiness=false. Elapsed: 4.058480543s
Feb 22 04:36:01.353: INFO: Pod "var-expansion-ebfa28f4-796e-43c9-9bd7-4e7b74c92311": Phase="Pending", Reason="", readiness=false. Elapsed: 6.454642219s
Feb 22 04:36:03.506: INFO: Pod "var-expansion-ebfa28f4-796e-43c9-9bd7-4e7b74c92311": Phase="Pending", Reason="", readiness=false. Elapsed: 8.606926295s
Feb 22 04:36:05.963: INFO: Pod "var-expansion-ebfa28f4-796e-43c9-9bd7-4e7b74c92311": Phase="Pending", Reason="", readiness=false. Elapsed: 11.06412168s
Feb 22 04:36:08.104: INFO: Pod "var-expansion-ebfa28f4-796e-43c9-9bd7-4e7b74c92311": Phase="Pending", Reason="", readiness=false. Elapsed: 13.205020203s
Feb 22 04:36:10.217: INFO: Pod "var-expansion-ebfa28f4-796e-43c9-9bd7-4e7b74c92311": Phase="Pending", Reason="", readiness=false. Elapsed: 15.318191255s
Feb 22 04:36:12.248: INFO: Pod "var-expansion-ebfa28f4-796e-43c9-9bd7-4e7b74c92311": Phase="Pending", Reason="", readiness=false. Elapsed: 17.348908263s
Feb 22 04:36:14.257: INFO: Pod "var-expansion-ebfa28f4-796e-43c9-9bd7-4e7b74c92311": Phase="Pending", Reason="", readiness=false. Elapsed: 19.358644798s
Feb 22 04:36:16.271: INFO: Pod "var-expansion-ebfa28f4-796e-43c9-9bd7-4e7b74c92311": Phase="Pending", Reason="", readiness=false. Elapsed: 21.372374938s
Feb 22 04:36:18.285: INFO: Pod "var-expansion-ebfa28f4-796e-43c9-9bd7-4e7b74c92311": Phase="Pending", Reason="", readiness=false. Elapsed: 23.386699811s
Feb 22 04:36:20.320: INFO: Pod "var-expansion-ebfa28f4-796e-43c9-9bd7-4e7b74c92311": Phase="Pending", Reason="", readiness=false. Elapsed: 25.421367873s
Feb 22 04:36:22.351: INFO: Pod "var-expansion-ebfa28f4-796e-43c9-9bd7-4e7b74c92311": Phase="Pending", Reason="", readiness=false. Elapsed: 27.452298565s
Feb 22 04:36:24.362: INFO: Pod "var-expansion-ebfa28f4-796e-43c9-9bd7-4e7b74c92311": Phase="Pending", Reason="", readiness=false. Elapsed: 29.463764759s
Feb 22 04:36:26.387: INFO: Pod "var-expansion-ebfa28f4-796e-43c9-9bd7-4e7b74c92311": Phase="Pending", Reason="", readiness=false. Elapsed: 31.488687763s
Feb 22 04:36:28.400: INFO: Pod "var-expansion-ebfa28f4-796e-43c9-9bd7-4e7b74c92311": Phase="Pending", Reason="", readiness=false. Elapsed: 33.501214493s
Feb 22 04:36:30.430: INFO: Pod "var-expansion-ebfa28f4-796e-43c9-9bd7-4e7b74c92311": Phase="Pending", Reason="", readiness=false. Elapsed: 35.531854962s
Feb 22 04:36:32.443: INFO: Pod "var-expansion-ebfa28f4-796e-43c9-9bd7-4e7b74c92311": Phase="Pending", Reason="", readiness=false. Elapsed: 37.544035446s
Feb 22 04:36:34.452: INFO: Pod "var-expansion-ebfa28f4-796e-43c9-9bd7-4e7b74c92311": Phase="Pending", Reason="", readiness=false. Elapsed: 39.553879483s
Feb 22 04:36:36.464: INFO: Pod "var-expansion-ebfa28f4-796e-43c9-9bd7-4e7b74c92311": Phase="Pending", Reason="", readiness=false. Elapsed: 41.565655318s
Feb 22 04:36:38.490: INFO: Pod "var-expansion-ebfa28f4-796e-43c9-9bd7-4e7b74c92311": Phase="Pending", Reason="", readiness=false. Elapsed: 43.591112804s
Feb 22 04:36:40.505: INFO: Pod "var-expansion-ebfa28f4-796e-43c9-9bd7-4e7b74c92311": Phase="Succeeded", Reason="", readiness=false. Elapsed: 45.606478491s
STEP: Saw pod success
Feb 22 04:36:40.505: INFO: Pod "var-expansion-ebfa28f4-796e-43c9-9bd7-4e7b74c92311" satisfied condition "Succeeded or Failed"
Feb 22 04:36:40.528: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com pod var-expansion-ebfa28f4-796e-43c9-9bd7-4e7b74c92311 container dapi-container: <nil>
STEP: delete the pod
Feb 22 04:36:45.917: INFO: Waiting for pod var-expansion-ebfa28f4-796e-43c9-9bd7-4e7b74c92311 to disappear
Feb 22 04:36:45.962: INFO: Pod var-expansion-ebfa28f4-796e-43c9-9bd7-4e7b74c92311 still exists
Feb 22 04:36:47.963: INFO: Waiting for pod var-expansion-ebfa28f4-796e-43c9-9bd7-4e7b74c92311 to disappear
Feb 22 04:36:47.971: INFO: Pod var-expansion-ebfa28f4-796e-43c9-9bd7-4e7b74c92311 still exists
Feb 22 04:36:49.963: INFO: Waiting for pod var-expansion-ebfa28f4-796e-43c9-9bd7-4e7b74c92311 to disappear
Feb 22 04:36:50.000: INFO: Pod var-expansion-ebfa28f4-796e-43c9-9bd7-4e7b74c92311 still exists
Feb 22 04:36:51.963: INFO: Waiting for pod var-expansion-ebfa28f4-796e-43c9-9bd7-4e7b74c92311 to disappear
Feb 22 04:36:51.972: INFO: Pod var-expansion-ebfa28f4-796e-43c9-9bd7-4e7b74c92311 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 04:36:51.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-5892" for this suite.

â€¢ [SLOW TEST:57.699 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]","total":270,"completed":53,"skipped":821,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 04:36:52.077: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1954
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Feb 22 04:36:52.805: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2b1f1193-edc0-47bf-a575-ffe9e97635bd" in namespace "projected-1954" to be "Succeeded or Failed"
Feb 22 04:36:52.823: INFO: Pod "downwardapi-volume-2b1f1193-edc0-47bf-a575-ffe9e97635bd": Phase="Pending", Reason="", readiness=false. Elapsed: 18.307843ms
Feb 22 04:36:54.837: INFO: Pod "downwardapi-volume-2b1f1193-edc0-47bf-a575-ffe9e97635bd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032166819s
Feb 22 04:36:56.854: INFO: Pod "downwardapi-volume-2b1f1193-edc0-47bf-a575-ffe9e97635bd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.048602136s
Feb 22 04:36:58.905: INFO: Pod "downwardapi-volume-2b1f1193-edc0-47bf-a575-ffe9e97635bd": Phase="Pending", Reason="", readiness=false. Elapsed: 6.100365192s
Feb 22 04:37:00.922: INFO: Pod "downwardapi-volume-2b1f1193-edc0-47bf-a575-ffe9e97635bd": Phase="Pending", Reason="", readiness=false. Elapsed: 8.117024632s
Feb 22 04:37:02.969: INFO: Pod "downwardapi-volume-2b1f1193-edc0-47bf-a575-ffe9e97635bd": Phase="Pending", Reason="", readiness=false. Elapsed: 10.164185493s
Feb 22 04:37:05.025: INFO: Pod "downwardapi-volume-2b1f1193-edc0-47bf-a575-ffe9e97635bd": Phase="Pending", Reason="", readiness=false. Elapsed: 12.220482458s
Feb 22 04:37:07.038: INFO: Pod "downwardapi-volume-2b1f1193-edc0-47bf-a575-ffe9e97635bd": Phase="Pending", Reason="", readiness=false. Elapsed: 14.232675213s
Feb 22 04:37:09.117: INFO: Pod "downwardapi-volume-2b1f1193-edc0-47bf-a575-ffe9e97635bd": Phase="Pending", Reason="", readiness=false. Elapsed: 16.312375846s
Feb 22 04:37:11.127: INFO: Pod "downwardapi-volume-2b1f1193-edc0-47bf-a575-ffe9e97635bd": Phase="Pending", Reason="", readiness=false. Elapsed: 18.321565738s
Feb 22 04:37:13.135: INFO: Pod "downwardapi-volume-2b1f1193-edc0-47bf-a575-ffe9e97635bd": Phase="Pending", Reason="", readiness=false. Elapsed: 20.330282308s
Feb 22 04:37:15.148: INFO: Pod "downwardapi-volume-2b1f1193-edc0-47bf-a575-ffe9e97635bd": Phase="Pending", Reason="", readiness=false. Elapsed: 22.342847842s
Feb 22 04:37:17.177: INFO: Pod "downwardapi-volume-2b1f1193-edc0-47bf-a575-ffe9e97635bd": Phase="Pending", Reason="", readiness=false. Elapsed: 24.371724611s
Feb 22 04:37:19.185: INFO: Pod "downwardapi-volume-2b1f1193-edc0-47bf-a575-ffe9e97635bd": Phase="Pending", Reason="", readiness=false. Elapsed: 26.380527299s
Feb 22 04:37:21.638: INFO: Pod "downwardapi-volume-2b1f1193-edc0-47bf-a575-ffe9e97635bd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 28.833474512s
STEP: Saw pod success
Feb 22 04:37:21.654: INFO: Pod "downwardapi-volume-2b1f1193-edc0-47bf-a575-ffe9e97635bd" satisfied condition "Succeeded or Failed"
Feb 22 04:37:21.707: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com pod downwardapi-volume-2b1f1193-edc0-47bf-a575-ffe9e97635bd container client-container: <nil>
STEP: delete the pod
Feb 22 04:37:28.698: INFO: Waiting for pod downwardapi-volume-2b1f1193-edc0-47bf-a575-ffe9e97635bd to disappear
Feb 22 04:37:28.800: INFO: Pod downwardapi-volume-2b1f1193-edc0-47bf-a575-ffe9e97635bd still exists
Feb 22 04:37:30.800: INFO: Waiting for pod downwardapi-volume-2b1f1193-edc0-47bf-a575-ffe9e97635bd to disappear
Feb 22 04:37:30.818: INFO: Pod downwardapi-volume-2b1f1193-edc0-47bf-a575-ffe9e97635bd still exists
Feb 22 04:37:32.801: INFO: Waiting for pod downwardapi-volume-2b1f1193-edc0-47bf-a575-ffe9e97635bd to disappear
Feb 22 04:37:32.848: INFO: Pod downwardapi-volume-2b1f1193-edc0-47bf-a575-ffe9e97635bd still exists
Feb 22 04:37:34.800: INFO: Waiting for pod downwardapi-volume-2b1f1193-edc0-47bf-a575-ffe9e97635bd to disappear
Feb 22 04:37:34.810: INFO: Pod downwardapi-volume-2b1f1193-edc0-47bf-a575-ffe9e97635bd still exists
Feb 22 04:37:36.800: INFO: Waiting for pod downwardapi-volume-2b1f1193-edc0-47bf-a575-ffe9e97635bd to disappear
Feb 22 04:37:36.817: INFO: Pod downwardapi-volume-2b1f1193-edc0-47bf-a575-ffe9e97635bd still exists
Feb 22 04:37:38.800: INFO: Waiting for pod downwardapi-volume-2b1f1193-edc0-47bf-a575-ffe9e97635bd to disappear
Feb 22 04:37:38.815: INFO: Pod downwardapi-volume-2b1f1193-edc0-47bf-a575-ffe9e97635bd no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 04:37:38.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1954" for this suite.

â€¢ [SLOW TEST:46.903 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:36
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","total":270,"completed":54,"skipped":851,"failed":0}
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 04:37:38.981: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-9142
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod pod-subpath-test-secret-sc6k
STEP: Creating a pod to test atomic-volume-subpath
Feb 22 04:37:39.756: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-sc6k" in namespace "subpath-9142" to be "Succeeded or Failed"
Feb 22 04:37:39.797: INFO: Pod "pod-subpath-test-secret-sc6k": Phase="Pending", Reason="", readiness=false. Elapsed: 40.610907ms
Feb 22 04:37:41.809: INFO: Pod "pod-subpath-test-secret-sc6k": Phase="Pending", Reason="", readiness=false. Elapsed: 2.052996304s
Feb 22 04:37:43.823: INFO: Pod "pod-subpath-test-secret-sc6k": Phase="Pending", Reason="", readiness=false. Elapsed: 4.066596755s
Feb 22 04:37:45.846: INFO: Pod "pod-subpath-test-secret-sc6k": Phase="Pending", Reason="", readiness=false. Elapsed: 6.090096849s
Feb 22 04:37:47.861: INFO: Pod "pod-subpath-test-secret-sc6k": Phase="Pending", Reason="", readiness=false. Elapsed: 8.104731387s
Feb 22 04:37:49.914: INFO: Pod "pod-subpath-test-secret-sc6k": Phase="Pending", Reason="", readiness=false. Elapsed: 10.158212937s
Feb 22 04:37:52.060: INFO: Pod "pod-subpath-test-secret-sc6k": Phase="Pending", Reason="", readiness=false. Elapsed: 12.304076523s
Feb 22 04:37:54.073: INFO: Pod "pod-subpath-test-secret-sc6k": Phase="Pending", Reason="", readiness=false. Elapsed: 14.316963033s
Feb 22 04:37:56.085: INFO: Pod "pod-subpath-test-secret-sc6k": Phase="Pending", Reason="", readiness=false. Elapsed: 16.328821448s
Feb 22 04:37:58.097: INFO: Pod "pod-subpath-test-secret-sc6k": Phase="Pending", Reason="", readiness=false. Elapsed: 18.340981282s
Feb 22 04:38:00.109: INFO: Pod "pod-subpath-test-secret-sc6k": Phase="Pending", Reason="", readiness=false. Elapsed: 20.353209324s
Feb 22 04:38:02.120: INFO: Pod "pod-subpath-test-secret-sc6k": Phase="Pending", Reason="", readiness=false. Elapsed: 22.364361284s
Feb 22 04:38:04.134: INFO: Pod "pod-subpath-test-secret-sc6k": Phase="Pending", Reason="", readiness=false. Elapsed: 24.377799668s
Feb 22 04:38:06.164: INFO: Pod "pod-subpath-test-secret-sc6k": Phase="Running", Reason="", readiness=true. Elapsed: 26.407565315s
Feb 22 04:38:08.174: INFO: Pod "pod-subpath-test-secret-sc6k": Phase="Running", Reason="", readiness=true. Elapsed: 28.418393062s
Feb 22 04:38:10.192: INFO: Pod "pod-subpath-test-secret-sc6k": Phase="Running", Reason="", readiness=true. Elapsed: 30.436369849s
Feb 22 04:38:12.210: INFO: Pod "pod-subpath-test-secret-sc6k": Phase="Running", Reason="", readiness=true. Elapsed: 32.453513961s
Feb 22 04:38:14.241: INFO: Pod "pod-subpath-test-secret-sc6k": Phase="Running", Reason="", readiness=true. Elapsed: 34.484745969s
Feb 22 04:38:16.317: INFO: Pod "pod-subpath-test-secret-sc6k": Phase="Running", Reason="", readiness=true. Elapsed: 36.560749997s
Feb 22 04:38:18.333: INFO: Pod "pod-subpath-test-secret-sc6k": Phase="Running", Reason="", readiness=true. Elapsed: 38.577276455s
Feb 22 04:38:20.342: INFO: Pod "pod-subpath-test-secret-sc6k": Phase="Running", Reason="", readiness=true. Elapsed: 40.585702046s
Feb 22 04:38:22.364: INFO: Pod "pod-subpath-test-secret-sc6k": Phase="Running", Reason="", readiness=true. Elapsed: 42.607541317s
Feb 22 04:38:24.378: INFO: Pod "pod-subpath-test-secret-sc6k": Phase="Running", Reason="", readiness=true. Elapsed: 44.62231393s
Feb 22 04:38:26.388: INFO: Pod "pod-subpath-test-secret-sc6k": Phase="Succeeded", Reason="", readiness=false. Elapsed: 46.631915454s
STEP: Saw pod success
Feb 22 04:38:26.388: INFO: Pod "pod-subpath-test-secret-sc6k" satisfied condition "Succeeded or Failed"
Feb 22 04:38:26.399: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com pod pod-subpath-test-secret-sc6k container test-container-subpath-secret-sc6k: <nil>
STEP: delete the pod
Feb 22 04:38:31.454: INFO: Waiting for pod pod-subpath-test-secret-sc6k to disappear
Feb 22 04:38:31.472: INFO: Pod pod-subpath-test-secret-sc6k still exists
Feb 22 04:38:33.473: INFO: Waiting for pod pod-subpath-test-secret-sc6k to disappear
Feb 22 04:38:33.481: INFO: Pod pod-subpath-test-secret-sc6k still exists
Feb 22 04:38:35.473: INFO: Waiting for pod pod-subpath-test-secret-sc6k to disappear
Feb 22 04:38:35.485: INFO: Pod pod-subpath-test-secret-sc6k still exists
Feb 22 04:38:37.473: INFO: Waiting for pod pod-subpath-test-secret-sc6k to disappear
Feb 22 04:38:37.494: INFO: Pod pod-subpath-test-secret-sc6k no longer exists
STEP: Deleting pod pod-subpath-test-secret-sc6k
Feb 22 04:38:37.494: INFO: Deleting pod "pod-subpath-test-secret-sc6k" in namespace "subpath-9142"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 04:38:37.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9142" for this suite.

â€¢ [SLOW TEST:58.586 seconds]
[sig-storage] Subpath
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [LinuxOnly] [Conformance]","total":270,"completed":55,"skipped":854,"failed":0}
SSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 04:38:37.571: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2257
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward api env vars
Feb 22 04:38:37.983: INFO: Waiting up to 5m0s for pod "downward-api-5421a185-256b-40ad-84f6-543c7ec0288f" in namespace "downward-api-2257" to be "Succeeded or Failed"
Feb 22 04:38:38.006: INFO: Pod "downward-api-5421a185-256b-40ad-84f6-543c7ec0288f": Phase="Pending", Reason="", readiness=false. Elapsed: 21.671964ms
Feb 22 04:38:40.052: INFO: Pod "downward-api-5421a185-256b-40ad-84f6-543c7ec0288f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.067800953s
Feb 22 04:38:42.085: INFO: Pod "downward-api-5421a185-256b-40ad-84f6-543c7ec0288f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.101515359s
Feb 22 04:38:44.128: INFO: Pod "downward-api-5421a185-256b-40ad-84f6-543c7ec0288f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.143835884s
Feb 22 04:38:46.138: INFO: Pod "downward-api-5421a185-256b-40ad-84f6-543c7ec0288f": Phase="Pending", Reason="", readiness=false. Elapsed: 8.154480872s
Feb 22 04:38:48.162: INFO: Pod "downward-api-5421a185-256b-40ad-84f6-543c7ec0288f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.178432219s
Feb 22 04:38:50.177: INFO: Pod "downward-api-5421a185-256b-40ad-84f6-543c7ec0288f": Phase="Pending", Reason="", readiness=false. Elapsed: 12.193339231s
Feb 22 04:38:52.189: INFO: Pod "downward-api-5421a185-256b-40ad-84f6-543c7ec0288f": Phase="Pending", Reason="", readiness=false. Elapsed: 14.204890738s
Feb 22 04:38:54.210: INFO: Pod "downward-api-5421a185-256b-40ad-84f6-543c7ec0288f": Phase="Pending", Reason="", readiness=false. Elapsed: 16.225982643s
Feb 22 04:38:56.245: INFO: Pod "downward-api-5421a185-256b-40ad-84f6-543c7ec0288f": Phase="Pending", Reason="", readiness=false. Elapsed: 18.261129205s
Feb 22 04:38:58.258: INFO: Pod "downward-api-5421a185-256b-40ad-84f6-543c7ec0288f": Phase="Pending", Reason="", readiness=false. Elapsed: 20.274258066s
Feb 22 04:39:00.278: INFO: Pod "downward-api-5421a185-256b-40ad-84f6-543c7ec0288f": Phase="Pending", Reason="", readiness=false. Elapsed: 22.293962717s
Feb 22 04:39:02.292: INFO: Pod "downward-api-5421a185-256b-40ad-84f6-543c7ec0288f": Phase="Pending", Reason="", readiness=false. Elapsed: 24.307922841s
Feb 22 04:39:04.302: INFO: Pod "downward-api-5421a185-256b-40ad-84f6-543c7ec0288f": Phase="Pending", Reason="", readiness=false. Elapsed: 26.318036459s
Feb 22 04:39:06.352: INFO: Pod "downward-api-5421a185-256b-40ad-84f6-543c7ec0288f": Phase="Pending", Reason="", readiness=false. Elapsed: 28.367624972s
Feb 22 04:39:08.464: INFO: Pod "downward-api-5421a185-256b-40ad-84f6-543c7ec0288f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 30.479681802s
STEP: Saw pod success
Feb 22 04:39:08.464: INFO: Pod "downward-api-5421a185-256b-40ad-84f6-543c7ec0288f" satisfied condition "Succeeded or Failed"
Feb 22 04:39:08.487: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com pod downward-api-5421a185-256b-40ad-84f6-543c7ec0288f container dapi-container: <nil>
STEP: delete the pod
Feb 22 04:39:15.204: INFO: Waiting for pod downward-api-5421a185-256b-40ad-84f6-543c7ec0288f to disappear
Feb 22 04:39:15.234: INFO: Pod downward-api-5421a185-256b-40ad-84f6-543c7ec0288f still exists
Feb 22 04:39:17.234: INFO: Waiting for pod downward-api-5421a185-256b-40ad-84f6-543c7ec0288f to disappear
Feb 22 04:39:17.261: INFO: Pod downward-api-5421a185-256b-40ad-84f6-543c7ec0288f still exists
Feb 22 04:39:19.234: INFO: Waiting for pod downward-api-5421a185-256b-40ad-84f6-543c7ec0288f to disappear
Feb 22 04:39:19.258: INFO: Pod downward-api-5421a185-256b-40ad-84f6-543c7ec0288f still exists
Feb 22 04:39:21.234: INFO: Waiting for pod downward-api-5421a185-256b-40ad-84f6-543c7ec0288f to disappear
Feb 22 04:39:21.252: INFO: Pod downward-api-5421a185-256b-40ad-84f6-543c7ec0288f still exists
Feb 22 04:39:23.234: INFO: Waiting for pod downward-api-5421a185-256b-40ad-84f6-543c7ec0288f to disappear
Feb 22 04:39:23.248: INFO: Pod downward-api-5421a185-256b-40ad-84f6-543c7ec0288f still exists
Feb 22 04:39:25.235: INFO: Waiting for pod downward-api-5421a185-256b-40ad-84f6-543c7ec0288f to disappear
Feb 22 04:39:25.249: INFO: Pod downward-api-5421a185-256b-40ad-84f6-543c7ec0288f still exists
Feb 22 04:39:27.234: INFO: Waiting for pod downward-api-5421a185-256b-40ad-84f6-543c7ec0288f to disappear
Feb 22 04:39:27.251: INFO: Pod downward-api-5421a185-256b-40ad-84f6-543c7ec0288f still exists
Feb 22 04:39:29.234: INFO: Waiting for pod downward-api-5421a185-256b-40ad-84f6-543c7ec0288f to disappear
Feb 22 04:39:29.270: INFO: Pod downward-api-5421a185-256b-40ad-84f6-543c7ec0288f still exists
Feb 22 04:39:31.234: INFO: Waiting for pod downward-api-5421a185-256b-40ad-84f6-543c7ec0288f to disappear
Feb 22 04:39:31.242: INFO: Pod downward-api-5421a185-256b-40ad-84f6-543c7ec0288f no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 04:39:31.244: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2257" for this suite.

â€¢ [SLOW TEST:53.758 seconds]
[sig-node] Downward API
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:34
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]","total":270,"completed":56,"skipped":863,"failed":0}
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 04:39:31.352: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3762
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 22 04:39:32.828: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Feb 22 04:39:34.885: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749565572, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749565572, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749565573, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749565572, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:39:36.897: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749565572, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749565572, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749565573, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749565572, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:39:38.935: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749565572, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749565572, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749565573, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749565572, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:39:40.909: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749565572, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749565572, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749565573, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749565572, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:39:42.902: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749565572, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749565572, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749565573, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749565572, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:39:44.912: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749565572, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749565572, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749565573, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749565572, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:39:46.901: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749565572, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749565572, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749565573, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749565572, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:39:48.908: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749565572, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749565572, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749565573, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749565572, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:39:50.896: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749565572, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749565572, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749565573, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749565572, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:39:52.936: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749565572, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749565572, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749565573, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749565572, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:39:54.898: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749565572, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749565572, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749565573, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749565572, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:39:56.915: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749565572, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749565572, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749565573, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749565572, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:39:58.898: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749565572, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749565572, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749565573, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749565572, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:40:00.897: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749565572, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749565572, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749565573, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749565572, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 04:40:03.108: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749565572, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749565572, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749565573, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749565572, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 22 04:40:10.104: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API
STEP: create a namespace for the webhook
STEP: create a configmap should be unconditionally rejected by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 04:40:12.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3762" for this suite.
STEP: Destroying namespace "webhook-3762-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

â€¢ [SLOW TEST:41.378 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]","total":270,"completed":57,"skipped":863,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 04:40:12.746: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-2488
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod liveness-ce481709-78f7-40bd-94f7-8305c7d18401 in namespace container-probe-2488
Feb 22 04:40:41.472: INFO: Started pod liveness-ce481709-78f7-40bd-94f7-8305c7d18401 in namespace container-probe-2488
STEP: checking the pod's current state and verifying that restartCount is present
Feb 22 04:40:41.858: INFO: Initial restart count of pod liveness-ce481709-78f7-40bd-94f7-8305c7d18401 is 0
Feb 22 04:40:58.348: INFO: Restart count of pod container-probe-2488/liveness-ce481709-78f7-40bd-94f7-8305c7d18401 is now 1 (16.489891301s elapsed)
Feb 22 04:41:14.106: INFO: Restart count of pod container-probe-2488/liveness-ce481709-78f7-40bd-94f7-8305c7d18401 is now 2 (32.248029158s elapsed)
Feb 22 04:41:26.190: INFO: Restart count of pod container-probe-2488/liveness-ce481709-78f7-40bd-94f7-8305c7d18401 is now 3 (44.332388692s elapsed)
Feb 22 04:41:40.285: INFO: Restart count of pod container-probe-2488/liveness-ce481709-78f7-40bd-94f7-8305c7d18401 is now 4 (58.426948657s elapsed)
Feb 22 04:41:56.532: INFO: Restart count of pod container-probe-2488/liveness-ce481709-78f7-40bd-94f7-8305c7d18401 is now 5 (1m14.673964571s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 04:41:56.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2488" for this suite.

â€¢ [SLOW TEST:104.410 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]","total":270,"completed":58,"skipped":877,"failed":0}
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 04:41:57.171: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-6417
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Feb 22 04:41:59.654: INFO: Pod name wrapped-volume-race-ea83b831-8930-436d-906f-5ccaaa2f4430: Found 0 pods out of 5
Feb 22 04:42:04.891: INFO: Pod name wrapped-volume-race-ea83b831-8930-436d-906f-5ccaaa2f4430: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-ea83b831-8930-436d-906f-5ccaaa2f4430 in namespace emptydir-wrapper-6417, will wait for the garbage collector to delete the pods
Feb 22 04:42:43.513: INFO: Deleting ReplicationController wrapped-volume-race-ea83b831-8930-436d-906f-5ccaaa2f4430 took: 81.738468ms
Feb 22 04:42:45.415: INFO: Terminating ReplicationController wrapped-volume-race-ea83b831-8930-436d-906f-5ccaaa2f4430 pods took: 1.901734457s
STEP: Creating RC which spawns configmap-volume pods
Feb 22 04:43:03.634: INFO: Pod name wrapped-volume-race-48353e58-1de7-46bf-a2e4-790e5e271e5c: Found 0 pods out of 5
Feb 22 04:43:08.664: INFO: Pod name wrapped-volume-race-48353e58-1de7-46bf-a2e4-790e5e271e5c: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-48353e58-1de7-46bf-a2e4-790e5e271e5c in namespace emptydir-wrapper-6417, will wait for the garbage collector to delete the pods
Feb 22 04:43:46.217: INFO: Deleting ReplicationController wrapped-volume-race-48353e58-1de7-46bf-a2e4-790e5e271e5c took: 108.201462ms
Feb 22 04:43:48.318: INFO: Terminating ReplicationController wrapped-volume-race-48353e58-1de7-46bf-a2e4-790e5e271e5c pods took: 2.101078409s
STEP: Creating RC which spawns configmap-volume pods
Feb 22 04:44:09.333: INFO: Pod name wrapped-volume-race-d79df484-2246-4d74-96cd-60abfffc85a7: Found 0 pods out of 5
Feb 22 04:44:14.366: INFO: Pod name wrapped-volume-race-d79df484-2246-4d74-96cd-60abfffc85a7: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-d79df484-2246-4d74-96cd-60abfffc85a7 in namespace emptydir-wrapper-6417, will wait for the garbage collector to delete the pods
Feb 22 04:44:47.860: INFO: Deleting ReplicationController wrapped-volume-race-d79df484-2246-4d74-96cd-60abfffc85a7 took: 151.566162ms
Feb 22 04:44:51.783: INFO: Terminating ReplicationController wrapped-volume-race-d79df484-2246-4d74-96cd-60abfffc85a7 pods took: 3.923373123s
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 04:45:14.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-6417" for this suite.

â€¢ [SLOW TEST:197.506 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]","total":270,"completed":59,"skipped":886,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 04:45:14.690: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3594
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0644 on node default medium
Feb 22 04:45:15.217: INFO: Waiting up to 5m0s for pod "pod-df36d5b6-ed62-4240-b195-60d72b1f7332" in namespace "emptydir-3594" to be "Succeeded or Failed"
Feb 22 04:45:15.250: INFO: Pod "pod-df36d5b6-ed62-4240-b195-60d72b1f7332": Phase="Pending", Reason="", readiness=false. Elapsed: 33.429245ms
Feb 22 04:45:17.290: INFO: Pod "pod-df36d5b6-ed62-4240-b195-60d72b1f7332": Phase="Pending", Reason="", readiness=false. Elapsed: 2.073099294s
Feb 22 04:45:19.316: INFO: Pod "pod-df36d5b6-ed62-4240-b195-60d72b1f7332": Phase="Pending", Reason="", readiness=false. Elapsed: 4.098996365s
Feb 22 04:45:21.331: INFO: Pod "pod-df36d5b6-ed62-4240-b195-60d72b1f7332": Phase="Pending", Reason="", readiness=false. Elapsed: 6.113897099s
Feb 22 04:45:24.286: INFO: Pod "pod-df36d5b6-ed62-4240-b195-60d72b1f7332": Phase="Pending", Reason="", readiness=false. Elapsed: 9.069056365s
Feb 22 04:45:26.835: INFO: Pod "pod-df36d5b6-ed62-4240-b195-60d72b1f7332": Phase="Pending", Reason="", readiness=false. Elapsed: 11.617873861s
Feb 22 04:45:29.097: INFO: Pod "pod-df36d5b6-ed62-4240-b195-60d72b1f7332": Phase="Pending", Reason="", readiness=false. Elapsed: 13.879681918s
Feb 22 04:45:31.282: INFO: Pod "pod-df36d5b6-ed62-4240-b195-60d72b1f7332": Phase="Pending", Reason="", readiness=false. Elapsed: 16.065134475s
Feb 22 04:45:33.312: INFO: Pod "pod-df36d5b6-ed62-4240-b195-60d72b1f7332": Phase="Pending", Reason="", readiness=false. Elapsed: 18.094805003s
Feb 22 04:45:35.383: INFO: Pod "pod-df36d5b6-ed62-4240-b195-60d72b1f7332": Phase="Pending", Reason="", readiness=false. Elapsed: 20.166508925s
Feb 22 04:45:37.499: INFO: Pod "pod-df36d5b6-ed62-4240-b195-60d72b1f7332": Phase="Pending", Reason="", readiness=false. Elapsed: 22.282173064s
Feb 22 04:45:39.536: INFO: Pod "pod-df36d5b6-ed62-4240-b195-60d72b1f7332": Phase="Pending", Reason="", readiness=false. Elapsed: 24.31917113s
Feb 22 04:45:41.571: INFO: Pod "pod-df36d5b6-ed62-4240-b195-60d72b1f7332": Phase="Pending", Reason="", readiness=false. Elapsed: 26.35400584s
Feb 22 04:45:43.622: INFO: Pod "pod-df36d5b6-ed62-4240-b195-60d72b1f7332": Phase="Pending", Reason="", readiness=false. Elapsed: 28.405119126s
Feb 22 04:45:45.724: INFO: Pod "pod-df36d5b6-ed62-4240-b195-60d72b1f7332": Phase="Succeeded", Reason="", readiness=false. Elapsed: 30.506660961s
STEP: Saw pod success
Feb 22 04:45:45.724: INFO: Pod "pod-df36d5b6-ed62-4240-b195-60d72b1f7332" satisfied condition "Succeeded or Failed"
Feb 22 04:45:45.804: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com pod pod-df36d5b6-ed62-4240-b195-60d72b1f7332 container test-container: <nil>
STEP: delete the pod
Feb 22 04:45:46.089: INFO: Waiting for pod pod-df36d5b6-ed62-4240-b195-60d72b1f7332 to disappear
Feb 22 04:45:46.133: INFO: Pod pod-df36d5b6-ed62-4240-b195-60d72b1f7332 still exists
Feb 22 04:45:48.134: INFO: Waiting for pod pod-df36d5b6-ed62-4240-b195-60d72b1f7332 to disappear
Feb 22 04:45:48.156: INFO: Pod pod-df36d5b6-ed62-4240-b195-60d72b1f7332 still exists
Feb 22 04:45:50.133: INFO: Waiting for pod pod-df36d5b6-ed62-4240-b195-60d72b1f7332 to disappear
Feb 22 04:45:50.161: INFO: Pod pod-df36d5b6-ed62-4240-b195-60d72b1f7332 still exists
Feb 22 04:45:52.134: INFO: Waiting for pod pod-df36d5b6-ed62-4240-b195-60d72b1f7332 to disappear
Feb 22 04:45:52.175: INFO: Pod pod-df36d5b6-ed62-4240-b195-60d72b1f7332 still exists
Feb 22 04:45:54.134: INFO: Waiting for pod pod-df36d5b6-ed62-4240-b195-60d72b1f7332 to disappear
Feb 22 04:45:54.148: INFO: Pod pod-df36d5b6-ed62-4240-b195-60d72b1f7332 still exists
Feb 22 04:45:56.134: INFO: Waiting for pod pod-df36d5b6-ed62-4240-b195-60d72b1f7332 to disappear
Feb 22 04:45:56.173: INFO: Pod pod-df36d5b6-ed62-4240-b195-60d72b1f7332 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 04:45:56.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3594" for this suite.

â€¢ [SLOW TEST:41.586 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:42
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","total":270,"completed":60,"skipped":898,"failed":0}
S
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 04:45:56.288: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-2439
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 04:46:56.834: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2439" for this suite.

â€¢ [SLOW TEST:60.689 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]","total":270,"completed":61,"skipped":899,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 04:46:57.025: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9265
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-1e4bbd88-91bb-470f-bea4-5d076ae663b9
STEP: Creating a pod to test consume configMaps
Feb 22 04:46:57.901: INFO: Waiting up to 5m0s for pod "pod-configmaps-f8c5bb74-a3ec-402a-9b6a-94d1c857ef3f" in namespace "configmap-9265" to be "Succeeded or Failed"
Feb 22 04:46:57.944: INFO: Pod "pod-configmaps-f8c5bb74-a3ec-402a-9b6a-94d1c857ef3f": Phase="Pending", Reason="", readiness=false. Elapsed: 42.875916ms
Feb 22 04:46:59.986: INFO: Pod "pod-configmaps-f8c5bb74-a3ec-402a-9b6a-94d1c857ef3f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.084857796s
Feb 22 04:47:02.006: INFO: Pod "pod-configmaps-f8c5bb74-a3ec-402a-9b6a-94d1c857ef3f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.10418114s
Feb 22 04:47:04.021: INFO: Pod "pod-configmaps-f8c5bb74-a3ec-402a-9b6a-94d1c857ef3f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.119574998s
Feb 22 04:47:06.097: INFO: Pod "pod-configmaps-f8c5bb74-a3ec-402a-9b6a-94d1c857ef3f": Phase="Pending", Reason="", readiness=false. Elapsed: 8.195758882s
Feb 22 04:47:08.162: INFO: Pod "pod-configmaps-f8c5bb74-a3ec-402a-9b6a-94d1c857ef3f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.26071837s
Feb 22 04:47:10.208: INFO: Pod "pod-configmaps-f8c5bb74-a3ec-402a-9b6a-94d1c857ef3f": Phase="Pending", Reason="", readiness=false. Elapsed: 12.306457891s
Feb 22 04:47:12.317: INFO: Pod "pod-configmaps-f8c5bb74-a3ec-402a-9b6a-94d1c857ef3f": Phase="Pending", Reason="", readiness=false. Elapsed: 14.415212742s
Feb 22 04:47:14.340: INFO: Pod "pod-configmaps-f8c5bb74-a3ec-402a-9b6a-94d1c857ef3f": Phase="Pending", Reason="", readiness=false. Elapsed: 16.438514679s
Feb 22 04:47:16.350: INFO: Pod "pod-configmaps-f8c5bb74-a3ec-402a-9b6a-94d1c857ef3f": Phase="Pending", Reason="", readiness=false. Elapsed: 18.448745456s
Feb 22 04:47:18.388: INFO: Pod "pod-configmaps-f8c5bb74-a3ec-402a-9b6a-94d1c857ef3f": Phase="Pending", Reason="", readiness=false. Elapsed: 20.486135073s
Feb 22 04:47:20.398: INFO: Pod "pod-configmaps-f8c5bb74-a3ec-402a-9b6a-94d1c857ef3f": Phase="Pending", Reason="", readiness=false. Elapsed: 22.496805122s
Feb 22 04:47:22.407: INFO: Pod "pod-configmaps-f8c5bb74-a3ec-402a-9b6a-94d1c857ef3f": Phase="Pending", Reason="", readiness=false. Elapsed: 24.505365235s
Feb 22 04:47:24.423: INFO: Pod "pod-configmaps-f8c5bb74-a3ec-402a-9b6a-94d1c857ef3f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.521175121s
STEP: Saw pod success
Feb 22 04:47:24.423: INFO: Pod "pod-configmaps-f8c5bb74-a3ec-402a-9b6a-94d1c857ef3f" satisfied condition "Succeeded or Failed"
Feb 22 04:47:24.445: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com pod pod-configmaps-f8c5bb74-a3ec-402a-9b6a-94d1c857ef3f container configmap-volume-test: <nil>
STEP: delete the pod
Feb 22 04:47:30.869: INFO: Waiting for pod pod-configmaps-f8c5bb74-a3ec-402a-9b6a-94d1c857ef3f to disappear
Feb 22 04:47:30.903: INFO: Pod pod-configmaps-f8c5bb74-a3ec-402a-9b6a-94d1c857ef3f still exists
Feb 22 04:47:32.904: INFO: Waiting for pod pod-configmaps-f8c5bb74-a3ec-402a-9b6a-94d1c857ef3f to disappear
Feb 22 04:47:32.931: INFO: Pod pod-configmaps-f8c5bb74-a3ec-402a-9b6a-94d1c857ef3f still exists
Feb 22 04:47:34.904: INFO: Waiting for pod pod-configmaps-f8c5bb74-a3ec-402a-9b6a-94d1c857ef3f to disappear
Feb 22 04:47:34.920: INFO: Pod pod-configmaps-f8c5bb74-a3ec-402a-9b6a-94d1c857ef3f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 04:47:34.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9265" for this suite.

â€¢ [SLOW TEST:37.943 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:36
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","total":270,"completed":62,"skipped":942,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 04:47:34.992: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-8807
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ConfigMap
STEP: Ensuring resource quota status captures configMap creation
STEP: Deleting a ConfigMap
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 04:47:51.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8807" for this suite.

â€¢ [SLOW TEST:16.535 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]","total":270,"completed":63,"skipped":983,"failed":0}
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 04:47:51.528: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-1138
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:91
Feb 22 04:47:51.846: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 22 04:47:51.926: INFO: Waiting for terminating namespaces to be deleted...
Feb 22 04:47:51.995: INFO: 
Logging pods the kubelet thinks is on node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com before test
Feb 22 04:47:52.161: INFO: schedext-test-node-selector-1 from test-node-selector started at 2021-02-22 03:16:36 +0000 UTC (1 container statuses recorded)
Feb 22 04:47:52.162: INFO: 	Container hello ready: true, restart count 0
Feb 22 04:47:52.162: INFO: schedext-test-affinity-3 from test-pod-affinity started at 2021-02-22 03:18:02 +0000 UTC (1 container statuses recorded)
Feb 22 04:47:52.162: INFO: 	Container hello ready: true, restart count 0
Feb 22 04:47:52.162: INFO: wcp-sanity-busybox-7bf494fc58-tlpw6 from test-update-workload-ns started at 2021-02-22 03:28:50 +0000 UTC (1 container statuses recorded)
Feb 22 04:47:52.162: INFO: 	Container wcp-sanity-busybox-container ready: true, restart count 0
Feb 22 04:47:52.162: INFO: helloworld from test-telemetry started at 2021-02-22 03:31:02 +0000 UTC (1 container statuses recorded)
Feb 22 04:47:52.162: INFO: 	Container hello ready: true, restart count 0
Feb 22 04:47:52.162: INFO: hello-web-1-5f76cbcd98-vs4bx from test-network-policy started at 2021-02-22 04:27:53 +0000 UTC (1 container statuses recorded)
Feb 22 04:47:52.162: INFO: 	Container hello-app ready: true, restart count 0
Feb 22 04:47:52.162: INFO: helloworld from test-kube-events-ns started at 2021-02-22 03:14:06 +0000 UTC (1 container statuses recorded)
Feb 22 04:47:52.163: INFO: 	Container hello ready: true, restart count 0
Feb 22 04:47:52.163: INFO: test-docker-registry from test-private-image-registry-ns started at 2021-02-22 03:23:54 +0000 UTC (1 container statuses recorded)
Feb 22 04:47:52.163: INFO: 	Container test-docker-registry ready: true, restart count 0
Feb 22 04:47:52.163: INFO: nginx-private from test-image-pull-secrets-ns started at 2021-02-22 03:11:22 +0000 UTC (1 container statuses recorded)
Feb 22 04:47:52.163: INFO: 	Container nginx-private-container ready: true, restart count 0
Feb 22 04:47:52.163: INFO: 
Logging pods the kubelet thinks is on node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com before test
Feb 22 04:47:52.394: INFO: wcp-sanity-busybox-7bf494fc58-rcpr6 from test-update-workload-ns started at 2021-02-22 04:28:23 +0000 UTC (1 container statuses recorded)
Feb 22 04:47:52.394: INFO: 	Container wcp-sanity-busybox-container ready: true, restart count 0
Feb 22 04:47:52.394: INFO: hello-web-2-dcbfdb96d-pcvm7 from test-network-policy started at 2021-02-22 04:27:55 +0000 UTC (1 container statuses recorded)
Feb 22 04:47:52.394: INFO: 	Container hello-app ready: true, restart count 0
Feb 22 04:47:52.394: INFO: 
Logging pods the kubelet thinks is on node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com before test
Feb 22 04:47:52.497: INFO: wcp-sanity-busybox-7bf494fc58-pln4w from test-dataprovider-podvms-ns started at 2021-02-22 03:08:42 +0000 UTC (1 container statuses recorded)
Feb 22 04:47:52.498: INFO: 	Container wcp-sanity-busybox-container ready: true, restart count 0
Feb 22 04:47:52.498: INFO: podwithpersistentvolume from storage-policy-test started at 2021-02-22 03:27:14 +0000 UTC (1 container statuses recorded)
Feb 22 04:47:52.498: INFO: 	Container hello ready: true, restart count 0
Feb 22 04:47:52.498: INFO: wcp-sanity-busybox-7bf494fc58-npc5m from test-update-workload-ns started at 2021-02-22 03:28:52 +0000 UTC (1 container statuses recorded)
Feb 22 04:47:52.498: INFO: 	Container wcp-sanity-busybox-container ready: true, restart count 0
Feb 22 04:47:52.498: INFO: hello-web-5f76cbcd98-9f9j4 from test-cluster-ip-service started at 2021-02-22 04:27:54 +0000 UTC (1 container statuses recorded)
Feb 22 04:47:52.498: INFO: 	Container hello-app ready: true, restart count 0
Feb 22 04:47:52.498: INFO: wcp-sanity-busybox-7bf494fc58-7sn7q from test-dataprovider-podvms-ns started at 2021-02-22 03:08:43 +0000 UTC (1 container statuses recorded)
Feb 22 04:47:52.498: INFO: 	Container wcp-sanity-busybox-container ready: true, restart count 0
Feb 22 04:47:52.498: INFO: curl-pod from test-network-policy started at 2021-02-22 03:15:49 +0000 UTC (1 container statuses recorded)
Feb 22 04:47:52.498: INFO: 	Container curl-container ready: true, restart count 0
Feb 22 04:47:52.499: INFO: schedext-test-affinity-1 from test-pod-affinity started at 2021-02-22 03:17:26 +0000 UTC (1 container statuses recorded)
Feb 22 04:47:52.499: INFO: 	Container hello ready: true, restart count 0
Feb 22 04:47:52.499: INFO: schedext-test-affinity-2 from test-pod-affinity started at 2021-02-22 03:17:50 +0000 UTC (1 container statuses recorded)
Feb 22 04:47:52.499: INFO: 	Container hello ready: true, restart count 0
Feb 22 04:47:52.499: INFO: busybox from test-pod-external-nw-access started at 2021-02-22 03:22:58 +0000 UTC (1 container statuses recorded)
Feb 22 04:47:52.499: INFO: 	Container busybox ready: true, restart count 0
Feb 22 04:47:52.500: INFO: curl-pod from test-cluster-ip-service started at 2021-02-22 03:04:01 +0000 UTC (1 container statuses recorded)
Feb 22 04:47:52.500: INFO: 	Container curl-container ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-3d98f2b1-9622-47f2-94ce-602c69984469 95
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 127.0.0.1 on the node which pod4 resides and expect not scheduled
STEP: removing the label kubernetes.io/e2e-3d98f2b1-9622-47f2-94ce-602c69984469 off the node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com
STEP: verifying the node doesn't have the label kubernetes.io/e2e-3d98f2b1-9622-47f2-94ce-602c69984469
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 04:53:41.255: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-1138" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:82

â€¢ [SLOW TEST:349.859 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]","total":270,"completed":64,"skipped":983,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 04:53:41.412: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-8
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-8.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-8.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-8.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-8.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 22 04:54:18.730: INFO: DNS probes using dns-8/dns-test-53ab96c9-3542-4ef5-87a6-9bbd8ebcb1b7 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 04:54:18.810: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8" for this suite.

â€¢ [SLOW TEST:37.621 seconds]
[sig-network] DNS
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] DNS should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]","total":270,"completed":65,"skipped":996,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  custom resource defaulting for requests and from storage works  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 04:54:19.052: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-2546
STEP: Waiting for a default service account to be provisioned in namespace
[It] custom resource defaulting for requests and from storage works  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Feb 22 04:54:19.616: INFO: >>> kubeConfig: /root/.kube/config
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 04:54:21.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-2546" for this suite.
â€¢{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works  [Conformance]","total":270,"completed":66,"skipped":1012,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 04:54:22.303: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-434
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 04:54:53.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-434" for this suite.

â€¢ [SLOW TEST:31.386 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] ReplicationController should adopt matching pods on creation [Conformance]","total":270,"completed":67,"skipped":1152,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 04:54:53.704: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3474
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-map-be247b2b-da19-4882-b4e2-4ce214015e5b
STEP: Creating a pod to test consume secrets
Feb 22 04:54:54.071: INFO: Waiting up to 5m0s for pod "pod-secrets-954bb733-0bf3-4095-959b-b3d8d7921876" in namespace "secrets-3474" to be "Succeeded or Failed"
Feb 22 04:54:54.081: INFO: Pod "pod-secrets-954bb733-0bf3-4095-959b-b3d8d7921876": Phase="Pending", Reason="", readiness=false. Elapsed: 10.417443ms
Feb 22 04:54:56.095: INFO: Pod "pod-secrets-954bb733-0bf3-4095-959b-b3d8d7921876": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02406422s
Feb 22 04:54:58.110: INFO: Pod "pod-secrets-954bb733-0bf3-4095-959b-b3d8d7921876": Phase="Pending", Reason="", readiness=false. Elapsed: 4.039247005s
Feb 22 04:55:00.133: INFO: Pod "pod-secrets-954bb733-0bf3-4095-959b-b3d8d7921876": Phase="Pending", Reason="", readiness=false. Elapsed: 6.062451932s
Feb 22 04:55:03.182: INFO: Pod "pod-secrets-954bb733-0bf3-4095-959b-b3d8d7921876": Phase="Pending", Reason="", readiness=false. Elapsed: 9.111545278s
Feb 22 04:55:05.349: INFO: Pod "pod-secrets-954bb733-0bf3-4095-959b-b3d8d7921876": Phase="Pending", Reason="", readiness=false. Elapsed: 11.278622649s
Feb 22 04:55:07.363: INFO: Pod "pod-secrets-954bb733-0bf3-4095-959b-b3d8d7921876": Phase="Pending", Reason="", readiness=false. Elapsed: 13.292602059s
Feb 22 04:55:09.381: INFO: Pod "pod-secrets-954bb733-0bf3-4095-959b-b3d8d7921876": Phase="Pending", Reason="", readiness=false. Elapsed: 15.310410314s
Feb 22 04:55:11.507: INFO: Pod "pod-secrets-954bb733-0bf3-4095-959b-b3d8d7921876": Phase="Pending", Reason="", readiness=false. Elapsed: 17.436614814s
Feb 22 04:55:13.531: INFO: Pod "pod-secrets-954bb733-0bf3-4095-959b-b3d8d7921876": Phase="Pending", Reason="", readiness=false. Elapsed: 19.460176094s
Feb 22 04:55:15.580: INFO: Pod "pod-secrets-954bb733-0bf3-4095-959b-b3d8d7921876": Phase="Pending", Reason="", readiness=false. Elapsed: 21.50937572s
Feb 22 04:55:17.593: INFO: Pod "pod-secrets-954bb733-0bf3-4095-959b-b3d8d7921876": Phase="Pending", Reason="", readiness=false. Elapsed: 23.521825669s
Feb 22 04:55:19.624: INFO: Pod "pod-secrets-954bb733-0bf3-4095-959b-b3d8d7921876": Phase="Pending", Reason="", readiness=false. Elapsed: 25.553167163s
Feb 22 04:55:21.638: INFO: Pod "pod-secrets-954bb733-0bf3-4095-959b-b3d8d7921876": Phase="Succeeded", Reason="", readiness=false. Elapsed: 27.567078797s
STEP: Saw pod success
Feb 22 04:55:21.638: INFO: Pod "pod-secrets-954bb733-0bf3-4095-959b-b3d8d7921876" satisfied condition "Succeeded or Failed"
Feb 22 04:55:21.651: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com pod pod-secrets-954bb733-0bf3-4095-959b-b3d8d7921876 container secret-volume-test: <nil>
STEP: delete the pod
Feb 22 04:55:21.790: INFO: Waiting for pod pod-secrets-954bb733-0bf3-4095-959b-b3d8d7921876 to disappear
Feb 22 04:55:21.837: INFO: Pod pod-secrets-954bb733-0bf3-4095-959b-b3d8d7921876 still exists
Feb 22 04:55:23.838: INFO: Waiting for pod pod-secrets-954bb733-0bf3-4095-959b-b3d8d7921876 to disappear
Feb 22 04:55:23.853: INFO: Pod pod-secrets-954bb733-0bf3-4095-959b-b3d8d7921876 still exists
Feb 22 04:55:25.852: INFO: Waiting for pod pod-secrets-954bb733-0bf3-4095-959b-b3d8d7921876 to disappear
Feb 22 04:55:25.879: INFO: Pod pod-secrets-954bb733-0bf3-4095-959b-b3d8d7921876 still exists
Feb 22 04:55:27.838: INFO: Waiting for pod pod-secrets-954bb733-0bf3-4095-959b-b3d8d7921876 to disappear
Feb 22 04:55:27.862: INFO: Pod pod-secrets-954bb733-0bf3-4095-959b-b3d8d7921876 still exists
Feb 22 04:55:29.838: INFO: Waiting for pod pod-secrets-954bb733-0bf3-4095-959b-b3d8d7921876 to disappear
Feb 22 04:55:29.900: INFO: Pod pod-secrets-954bb733-0bf3-4095-959b-b3d8d7921876 still exists
Feb 22 04:55:31.838: INFO: Waiting for pod pod-secrets-954bb733-0bf3-4095-959b-b3d8d7921876 to disappear
Feb 22 04:55:31.864: INFO: Pod pod-secrets-954bb733-0bf3-4095-959b-b3d8d7921876 still exists
Feb 22 04:55:33.838: INFO: Waiting for pod pod-secrets-954bb733-0bf3-4095-959b-b3d8d7921876 to disappear
Feb 22 04:55:33.855: INFO: Pod pod-secrets-954bb733-0bf3-4095-959b-b3d8d7921876 still exists
Feb 22 04:55:35.838: INFO: Waiting for pod pod-secrets-954bb733-0bf3-4095-959b-b3d8d7921876 to disappear
Feb 22 04:55:35.859: INFO: Pod pod-secrets-954bb733-0bf3-4095-959b-b3d8d7921876 still exists
Feb 22 04:55:37.838: INFO: Waiting for pod pod-secrets-954bb733-0bf3-4095-959b-b3d8d7921876 to disappear
Feb 22 04:55:37.846: INFO: Pod pod-secrets-954bb733-0bf3-4095-959b-b3d8d7921876 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 04:55:37.848: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3474" for this suite.

â€¢ [SLOW TEST:44.218 seconds]
[sig-storage] Secrets
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:36
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":270,"completed":68,"skipped":1170,"failed":0}
SSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 04:55:37.940: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-33
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test override arguments
Feb 22 04:55:38.401: INFO: Waiting up to 5m0s for pod "client-containers-e1135eca-bcaa-4ec3-b328-7ca71bc77d70" in namespace "containers-33" to be "Succeeded or Failed"
Feb 22 04:55:38.423: INFO: Pod "client-containers-e1135eca-bcaa-4ec3-b328-7ca71bc77d70": Phase="Pending", Reason="", readiness=false. Elapsed: 21.998041ms
Feb 22 04:55:40.458: INFO: Pod "client-containers-e1135eca-bcaa-4ec3-b328-7ca71bc77d70": Phase="Pending", Reason="", readiness=false. Elapsed: 2.056766315s
Feb 22 04:55:42.493: INFO: Pod "client-containers-e1135eca-bcaa-4ec3-b328-7ca71bc77d70": Phase="Pending", Reason="", readiness=false. Elapsed: 4.091478803s
Feb 22 04:55:44.503: INFO: Pod "client-containers-e1135eca-bcaa-4ec3-b328-7ca71bc77d70": Phase="Pending", Reason="", readiness=false. Elapsed: 6.102339311s
Feb 22 04:55:46.526: INFO: Pod "client-containers-e1135eca-bcaa-4ec3-b328-7ca71bc77d70": Phase="Pending", Reason="", readiness=false. Elapsed: 8.125225149s
Feb 22 04:55:48.543: INFO: Pod "client-containers-e1135eca-bcaa-4ec3-b328-7ca71bc77d70": Phase="Pending", Reason="", readiness=false. Elapsed: 10.141504978s
Feb 22 04:55:50.550: INFO: Pod "client-containers-e1135eca-bcaa-4ec3-b328-7ca71bc77d70": Phase="Pending", Reason="", readiness=false. Elapsed: 12.149314016s
Feb 22 04:55:52.559: INFO: Pod "client-containers-e1135eca-bcaa-4ec3-b328-7ca71bc77d70": Phase="Pending", Reason="", readiness=false. Elapsed: 14.158134988s
Feb 22 04:55:54.570: INFO: Pod "client-containers-e1135eca-bcaa-4ec3-b328-7ca71bc77d70": Phase="Pending", Reason="", readiness=false. Elapsed: 16.168859496s
Feb 22 04:55:56.585: INFO: Pod "client-containers-e1135eca-bcaa-4ec3-b328-7ca71bc77d70": Phase="Pending", Reason="", readiness=false. Elapsed: 18.183462805s
Feb 22 04:55:58.597: INFO: Pod "client-containers-e1135eca-bcaa-4ec3-b328-7ca71bc77d70": Phase="Pending", Reason="", readiness=false. Elapsed: 20.196377493s
Feb 22 04:56:00.606: INFO: Pod "client-containers-e1135eca-bcaa-4ec3-b328-7ca71bc77d70": Phase="Pending", Reason="", readiness=false. Elapsed: 22.20475028s
Feb 22 04:56:02.613: INFO: Pod "client-containers-e1135eca-bcaa-4ec3-b328-7ca71bc77d70": Phase="Pending", Reason="", readiness=false. Elapsed: 24.212317958s
Feb 22 04:56:04.631: INFO: Pod "client-containers-e1135eca-bcaa-4ec3-b328-7ca71bc77d70": Phase="Pending", Reason="", readiness=false. Elapsed: 26.22942423s
Feb 22 04:56:06.639: INFO: Pod "client-containers-e1135eca-bcaa-4ec3-b328-7ca71bc77d70": Phase="Pending", Reason="", readiness=false. Elapsed: 28.237968964s
Feb 22 04:56:08.672: INFO: Pod "client-containers-e1135eca-bcaa-4ec3-b328-7ca71bc77d70": Phase="Succeeded", Reason="", readiness=false. Elapsed: 30.270620062s
STEP: Saw pod success
Feb 22 04:56:08.672: INFO: Pod "client-containers-e1135eca-bcaa-4ec3-b328-7ca71bc77d70" satisfied condition "Succeeded or Failed"
Feb 22 04:56:08.685: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com pod client-containers-e1135eca-bcaa-4ec3-b328-7ca71bc77d70 container test-container: <nil>
STEP: delete the pod
Feb 22 04:56:17.746: INFO: Waiting for pod client-containers-e1135eca-bcaa-4ec3-b328-7ca71bc77d70 to disappear
Feb 22 04:56:17.765: INFO: Pod client-containers-e1135eca-bcaa-4ec3-b328-7ca71bc77d70 still exists
Feb 22 04:56:19.765: INFO: Waiting for pod client-containers-e1135eca-bcaa-4ec3-b328-7ca71bc77d70 to disappear
Feb 22 04:56:19.775: INFO: Pod client-containers-e1135eca-bcaa-4ec3-b328-7ca71bc77d70 still exists
Feb 22 04:56:21.765: INFO: Waiting for pod client-containers-e1135eca-bcaa-4ec3-b328-7ca71bc77d70 to disappear
Feb 22 04:56:21.776: INFO: Pod client-containers-e1135eca-bcaa-4ec3-b328-7ca71bc77d70 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 04:56:21.776: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-33" for this suite.

â€¢ [SLOW TEST:43.892 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Docker Containers should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]","total":270,"completed":69,"skipped":1180,"failed":0}
SSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 04:56:21.829: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-1028
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:82
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 04:56:22.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1028" for this suite.
â€¢{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]","total":270,"completed":70,"skipped":1187,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 04:56:22.226: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svc-latency-2003
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Feb 22 04:56:22.466: INFO: >>> kubeConfig: /root/.kube/config
STEP: creating replication controller svc-latency-rc in namespace svc-latency-2003
Feb 22 04:56:54.844: INFO: Created: latency-svc-rkd5c
Feb 22 04:56:54.881: INFO: Got endpoints: latency-svc-rkd5c [80.290074ms]
Feb 22 04:56:54.963: INFO: Created: latency-svc-95xp9
Feb 22 04:56:54.983: INFO: Got endpoints: latency-svc-95xp9 [100.614718ms]
Feb 22 04:56:55.013: INFO: Created: latency-svc-rb2w8
Feb 22 04:56:55.045: INFO: Got endpoints: latency-svc-rb2w8 [160.507156ms]
Feb 22 04:56:55.062: INFO: Created: latency-svc-fxz9m
Feb 22 04:56:55.069: INFO: Got endpoints: latency-svc-fxz9m [186.830471ms]
Feb 22 04:56:55.213: INFO: Created: latency-svc-mf7qc
Feb 22 04:56:55.240: INFO: Got endpoints: latency-svc-mf7qc [356.699616ms]
Feb 22 04:56:55.271: INFO: Created: latency-svc-zm4m9
Feb 22 04:56:55.306: INFO: Got endpoints: latency-svc-zm4m9 [422.467167ms]
Feb 22 04:56:55.339: INFO: Created: latency-svc-gp4r9
Feb 22 04:56:55.362: INFO: Got endpoints: latency-svc-gp4r9 [476.136577ms]
Feb 22 04:56:55.385: INFO: Created: latency-svc-jqk8d
Feb 22 04:56:55.506: INFO: Got endpoints: latency-svc-jqk8d [619.134321ms]
Feb 22 04:56:55.557: INFO: Created: latency-svc-57z7q
Feb 22 04:56:55.609: INFO: Got endpoints: latency-svc-57z7q [722.435754ms]
Feb 22 04:56:55.664: INFO: Created: latency-svc-szdst
Feb 22 04:56:55.686: INFO: Got endpoints: latency-svc-szdst [799.900278ms]
Feb 22 04:56:55.737: INFO: Created: latency-svc-wxzsv
Feb 22 04:56:55.815: INFO: Got endpoints: latency-svc-wxzsv [930.753491ms]
Feb 22 04:56:55.872: INFO: Created: latency-svc-lsdm4
Feb 22 04:56:55.900: INFO: Got endpoints: latency-svc-lsdm4 [1.014154841s]
Feb 22 04:56:56.115: INFO: Created: latency-svc-kphhj
Feb 22 04:56:56.159: INFO: Got endpoints: latency-svc-kphhj [1.273114056s]
Feb 22 04:56:56.240: INFO: Created: latency-svc-dq8cs
Feb 22 04:56:56.327: INFO: Got endpoints: latency-svc-dq8cs [1.440202646s]
Feb 22 04:56:56.337: INFO: Created: latency-svc-qxv9q
Feb 22 04:56:56.392: INFO: Got endpoints: latency-svc-qxv9q [1.505109665s]
Feb 22 04:56:56.452: INFO: Created: latency-svc-6shmv
Feb 22 04:56:56.467: INFO: Got endpoints: latency-svc-6shmv [1.58048567s]
Feb 22 04:56:56.513: INFO: Created: latency-svc-njpnn
Feb 22 04:56:56.604: INFO: Got endpoints: latency-svc-njpnn [1.620932113s]
Feb 22 04:56:56.625: INFO: Created: latency-svc-7wts7
Feb 22 04:56:56.665: INFO: Got endpoints: latency-svc-7wts7 [1.620093671s]
Feb 22 04:56:56.670: INFO: Created: latency-svc-wrsfh
Feb 22 04:56:56.725: INFO: Got endpoints: latency-svc-wrsfh [1.655731291s]
Feb 22 04:56:56.813: INFO: Created: latency-svc-2wqnr
Feb 22 04:56:56.833: INFO: Got endpoints: latency-svc-2wqnr [1.592568936s]
Feb 22 04:56:56.896: INFO: Created: latency-svc-kp84g
Feb 22 04:56:56.922: INFO: Got endpoints: latency-svc-kp84g [1.615964365s]
Feb 22 04:56:56.939: INFO: Created: latency-svc-qkj6q
Feb 22 04:56:56.970: INFO: Got endpoints: latency-svc-qkj6q [1.607468012s]
Feb 22 04:56:57.018: INFO: Created: latency-svc-wmwjb
Feb 22 04:56:57.038: INFO: Got endpoints: latency-svc-wmwjb [1.532421337s]
Feb 22 04:56:57.056: INFO: Created: latency-svc-95gx4
Feb 22 04:56:57.107: INFO: Got endpoints: latency-svc-95gx4 [1.49788393s]
Feb 22 04:56:57.203: INFO: Created: latency-svc-5rbfx
Feb 22 04:56:57.236: INFO: Got endpoints: latency-svc-5rbfx [1.549921525s]
Feb 22 04:56:57.279: INFO: Created: latency-svc-8rmbj
Feb 22 04:56:57.402: INFO: Got endpoints: latency-svc-8rmbj [1.586363018s]
Feb 22 04:56:57.431: INFO: Created: latency-svc-mqrkp
Feb 22 04:56:57.467: INFO: Got endpoints: latency-svc-mqrkp [1.566191521s]
Feb 22 04:56:57.505: INFO: Created: latency-svc-x8f2m
Feb 22 04:56:57.586: INFO: Got endpoints: latency-svc-x8f2m [1.426013398s]
Feb 22 04:56:57.610: INFO: Created: latency-svc-8l4jc
Feb 22 04:56:57.724: INFO: Got endpoints: latency-svc-8l4jc [1.395999351s]
Feb 22 04:56:57.765: INFO: Created: latency-svc-5nqnv
Feb 22 04:56:57.802: INFO: Got endpoints: latency-svc-5nqnv [1.409673686s]
Feb 22 04:56:57.927: INFO: Created: latency-svc-qvw9w
Feb 22 04:56:57.978: INFO: Got endpoints: latency-svc-qvw9w [1.510174515s]
Feb 22 04:56:58.056: INFO: Created: latency-svc-lmgzh
Feb 22 04:56:58.066: INFO: Got endpoints: latency-svc-lmgzh [1.462636151s]
Feb 22 04:56:58.196: INFO: Created: latency-svc-q6v2x
Feb 22 04:56:58.203: INFO: Got endpoints: latency-svc-q6v2x [1.53803158s]
Feb 22 04:56:58.255: INFO: Created: latency-svc-78mmr
Feb 22 04:56:58.279: INFO: Got endpoints: latency-svc-78mmr [1.554047902s]
Feb 22 04:56:58.297: INFO: Created: latency-svc-mztlx
Feb 22 04:56:58.351: INFO: Got endpoints: latency-svc-mztlx [1.518117383s]
Feb 22 04:56:58.430: INFO: Created: latency-svc-l26v9
Feb 22 04:56:58.479: INFO: Got endpoints: latency-svc-l26v9 [1.556625382s]
Feb 22 04:56:58.570: INFO: Created: latency-svc-vlrtm
Feb 22 04:56:58.595: INFO: Got endpoints: latency-svc-vlrtm [1.625037581s]
Feb 22 04:56:58.650: INFO: Created: latency-svc-rwztd
Feb 22 04:56:58.698: INFO: Got endpoints: latency-svc-rwztd [1.659907388s]
Feb 22 04:56:58.777: INFO: Created: latency-svc-6tsz4
Feb 22 04:56:58.887: INFO: Got endpoints: latency-svc-6tsz4 [1.780083199s]
Feb 22 04:56:58.983: INFO: Created: latency-svc-nzfkh
Feb 22 04:56:59.137: INFO: Got endpoints: latency-svc-nzfkh [1.901557093s]
Feb 22 04:56:59.330: INFO: Created: latency-svc-qxlzr
Feb 22 04:56:59.425: INFO: Got endpoints: latency-svc-qxlzr [2.023261211s]
Feb 22 04:56:59.514: INFO: Created: latency-svc-cdqfd
Feb 22 04:56:59.587: INFO: Got endpoints: latency-svc-cdqfd [2.119923165s]
Feb 22 04:56:59.636: INFO: Created: latency-svc-7jmpf
Feb 22 04:56:59.675: INFO: Got endpoints: latency-svc-7jmpf [2.088851405s]
Feb 22 04:56:59.781: INFO: Created: latency-svc-qdrn9
Feb 22 04:56:59.795: INFO: Got endpoints: latency-svc-qdrn9 [2.07100713s]
Feb 22 04:56:59.890: INFO: Created: latency-svc-zrl28
Feb 22 04:56:59.972: INFO: Got endpoints: latency-svc-zrl28 [2.169895376s]
Feb 22 04:57:00.086: INFO: Created: latency-svc-sts25
Feb 22 04:57:00.086: INFO: Got endpoints: latency-svc-sts25 [2.108471611s]
Feb 22 04:57:00.108: INFO: Created: latency-svc-r8scm
Feb 22 04:57:00.168: INFO: Created: latency-svc-hzd6r
Feb 22 04:57:00.231: INFO: Got endpoints: latency-svc-r8scm [2.164505055s]
Feb 22 04:57:00.246: INFO: Got endpoints: latency-svc-hzd6r [2.043096521s]
Feb 22 04:57:00.296: INFO: Created: latency-svc-lrsvw
Feb 22 04:57:00.342: INFO: Got endpoints: latency-svc-lrsvw [2.062459778s]
Feb 22 04:57:00.473: INFO: Created: latency-svc-gs8x6
Feb 22 04:57:00.499: INFO: Got endpoints: latency-svc-gs8x6 [2.148515639s]
Feb 22 04:57:00.533: INFO: Created: latency-svc-tw6js
Feb 22 04:57:00.571: INFO: Got endpoints: latency-svc-tw6js [2.091107737s]
Feb 22 04:57:00.612: INFO: Created: latency-svc-l6tm6
Feb 22 04:57:00.724: INFO: Got endpoints: latency-svc-l6tm6 [2.129104398s]
Feb 22 04:57:00.731: INFO: Created: latency-svc-2rvgj
Feb 22 04:57:00.775: INFO: Got endpoints: latency-svc-2rvgj [2.076194446s]
Feb 22 04:57:00.829: INFO: Created: latency-svc-lg6vs
Feb 22 04:57:00.891: INFO: Got endpoints: latency-svc-lg6vs [2.003243196s]
Feb 22 04:57:00.920: INFO: Created: latency-svc-sc8cc
Feb 22 04:57:01.000: INFO: Got endpoints: latency-svc-sc8cc [1.862305038s]
Feb 22 04:57:01.077: INFO: Created: latency-svc-sfcb7
Feb 22 04:57:01.116: INFO: Got endpoints: latency-svc-sfcb7 [1.690289606s]
Feb 22 04:57:01.194: INFO: Created: latency-svc-lm5j7
Feb 22 04:57:01.228: INFO: Got endpoints: latency-svc-lm5j7 [1.640816814s]
Feb 22 04:57:01.268: INFO: Created: latency-svc-d8z9n
Feb 22 04:57:01.463: INFO: Got endpoints: latency-svc-d8z9n [1.788364608s]
Feb 22 04:57:01.565: INFO: Created: latency-svc-b7lpr
Feb 22 04:57:01.596: INFO: Got endpoints: latency-svc-b7lpr [1.800863219s]
Feb 22 04:57:01.724: INFO: Created: latency-svc-96kdv
Feb 22 04:57:01.765: INFO: Got endpoints: latency-svc-96kdv [1.793162441s]
Feb 22 04:57:01.905: INFO: Created: latency-svc-cdtmw
Feb 22 04:57:01.996: INFO: Created: latency-svc-v688d
Feb 22 04:57:02.001: INFO: Got endpoints: latency-svc-cdtmw [1.914598328s]
Feb 22 04:57:02.171: INFO: Got endpoints: latency-svc-v688d [1.940115881s]
Feb 22 04:57:02.306: INFO: Created: latency-svc-82xpd
Feb 22 04:57:02.370: INFO: Got endpoints: latency-svc-82xpd [2.123226604s]
Feb 22 04:57:02.594: INFO: Created: latency-svc-zwtds
Feb 22 04:57:02.642: INFO: Got endpoints: latency-svc-zwtds [2.299591588s]
Feb 22 04:57:02.737: INFO: Created: latency-svc-86lh7
Feb 22 04:57:02.794: INFO: Got endpoints: latency-svc-86lh7 [2.294894137s]
Feb 22 04:57:02.842: INFO: Created: latency-svc-flzzc
Feb 22 04:57:02.968: INFO: Got endpoints: latency-svc-flzzc [2.397558978s]
Feb 22 04:57:02.977: INFO: Created: latency-svc-bjmrt
Feb 22 04:57:03.107: INFO: Got endpoints: latency-svc-bjmrt [2.383134105s]
Feb 22 04:57:03.197: INFO: Created: latency-svc-5qsl2
Feb 22 04:57:03.261: INFO: Got endpoints: latency-svc-5qsl2 [2.485862601s]
Feb 22 04:57:03.298: INFO: Created: latency-svc-vqd42
Feb 22 04:57:03.328: INFO: Got endpoints: latency-svc-vqd42 [2.436826514s]
Feb 22 04:57:03.381: INFO: Created: latency-svc-dtc2h
Feb 22 04:57:03.437: INFO: Got endpoints: latency-svc-dtc2h [2.436962815s]
Feb 22 04:57:03.554: INFO: Created: latency-svc-b6877
Feb 22 04:57:03.586: INFO: Got endpoints: latency-svc-b6877 [2.470543674s]
Feb 22 04:57:03.686: INFO: Created: latency-svc-wlt82
Feb 22 04:57:03.769: INFO: Got endpoints: latency-svc-wlt82 [2.541036195s]
Feb 22 04:57:03.883: INFO: Created: latency-svc-gf6xl
Feb 22 04:57:04.128: INFO: Got endpoints: latency-svc-gf6xl [2.6647432s]
Feb 22 04:57:04.374: INFO: Created: latency-svc-7cwzn
Feb 22 04:57:04.500: INFO: Created: latency-svc-v4w7j
Feb 22 04:57:04.538: INFO: Got endpoints: latency-svc-7cwzn [2.942030581s]
Feb 22 04:57:04.574: INFO: Got endpoints: latency-svc-v4w7j [2.808700414s]
Feb 22 04:57:04.721: INFO: Created: latency-svc-nss66
Feb 22 04:57:04.741: INFO: Got endpoints: latency-svc-nss66 [2.739780488s]
Feb 22 04:57:04.873: INFO: Created: latency-svc-vh4mn
Feb 22 04:57:04.947: INFO: Got endpoints: latency-svc-vh4mn [2.775751939s]
Feb 22 04:57:05.022: INFO: Created: latency-svc-bd9vb
Feb 22 04:57:05.069: INFO: Got endpoints: latency-svc-bd9vb [2.698974211s]
Feb 22 04:57:05.150: INFO: Created: latency-svc-bg4bs
Feb 22 04:57:05.177: INFO: Got endpoints: latency-svc-bg4bs [2.535641147s]
Feb 22 04:57:05.209: INFO: Created: latency-svc-xt2bv
Feb 22 04:57:05.229: INFO: Got endpoints: latency-svc-xt2bv [2.433939671s]
Feb 22 04:57:05.318: INFO: Created: latency-svc-mnsjq
Feb 22 04:57:05.384: INFO: Got endpoints: latency-svc-mnsjq [2.416094538s]
Feb 22 04:57:05.390: INFO: Created: latency-svc-fdmwb
Feb 22 04:57:05.444: INFO: Got endpoints: latency-svc-fdmwb [2.336388573s]
Feb 22 04:57:05.550: INFO: Created: latency-svc-6pqmv
Feb 22 04:57:05.611: INFO: Got endpoints: latency-svc-6pqmv [2.350243419s]
Feb 22 04:57:05.636: INFO: Created: latency-svc-glq5k
Feb 22 04:57:05.673: INFO: Got endpoints: latency-svc-glq5k [2.345531191s]
Feb 22 04:57:05.709: INFO: Created: latency-svc-68sn4
Feb 22 04:57:05.805: INFO: Got endpoints: latency-svc-68sn4 [2.367692537s]
Feb 22 04:57:05.980: INFO: Created: latency-svc-gfqbc
Feb 22 04:57:06.025: INFO: Got endpoints: latency-svc-gfqbc [2.438296749s]
Feb 22 04:57:06.148: INFO: Created: latency-svc-dzvb5
Feb 22 04:57:06.148: INFO: Got endpoints: latency-svc-dzvb5 [2.37874761s]
Feb 22 04:57:06.233: INFO: Created: latency-svc-27kln
Feb 22 04:57:06.250: INFO: Got endpoints: latency-svc-27kln [2.121283243s]
Feb 22 04:57:06.334: INFO: Created: latency-svc-q4sgq
Feb 22 04:57:06.368: INFO: Got endpoints: latency-svc-q4sgq [1.829681818s]
Feb 22 04:57:06.424: INFO: Created: latency-svc-t26mk
Feb 22 04:57:06.455: INFO: Got endpoints: latency-svc-t26mk [205.207719ms]
Feb 22 04:57:06.531: INFO: Created: latency-svc-w2544
Feb 22 04:57:06.582: INFO: Got endpoints: latency-svc-w2544 [2.008291315s]
Feb 22 04:57:06.658: INFO: Created: latency-svc-j5m99
Feb 22 04:57:06.710: INFO: Got endpoints: latency-svc-j5m99 [1.969386347s]
Feb 22 04:57:06.720: INFO: Created: latency-svc-fr4d5
Feb 22 04:57:06.775: INFO: Got endpoints: latency-svc-fr4d5 [1.827419466s]
Feb 22 04:57:06.859: INFO: Created: latency-svc-85f6z
Feb 22 04:57:06.873: INFO: Got endpoints: latency-svc-85f6z [1.804375937s]
Feb 22 04:57:06.896: INFO: Created: latency-svc-xbr54
Feb 22 04:57:06.923: INFO: Got endpoints: latency-svc-xbr54 [1.745453041s]
Feb 22 04:57:06.969: INFO: Created: latency-svc-qw8sq
Feb 22 04:57:07.007: INFO: Got endpoints: latency-svc-qw8sq [1.778863004s]
Feb 22 04:57:07.050: INFO: Created: latency-svc-2z2m8
Feb 22 04:57:07.095: INFO: Got endpoints: latency-svc-2z2m8 [1.710747881s]
Feb 22 04:57:07.151: INFO: Created: latency-svc-2956t
Feb 22 04:57:07.155: INFO: Got endpoints: latency-svc-2956t [1.710679892s]
Feb 22 04:57:07.207: INFO: Created: latency-svc-prbs2
Feb 22 04:57:07.225: INFO: Got endpoints: latency-svc-prbs2 [1.613549114s]
Feb 22 04:57:07.274: INFO: Created: latency-svc-bd7kg
Feb 22 04:57:07.307: INFO: Got endpoints: latency-svc-bd7kg [1.633039095s]
Feb 22 04:57:07.362: INFO: Created: latency-svc-kkkms
Feb 22 04:57:07.404: INFO: Got endpoints: latency-svc-kkkms [1.59888954s]
Feb 22 04:57:07.481: INFO: Created: latency-svc-95wlm
Feb 22 04:57:07.525: INFO: Got endpoints: latency-svc-95wlm [1.499563718s]
Feb 22 04:57:07.575: INFO: Created: latency-svc-jkbvc
Feb 22 04:57:07.595: INFO: Got endpoints: latency-svc-jkbvc [1.44704073s]
Feb 22 04:57:07.633: INFO: Created: latency-svc-9qgxd
Feb 22 04:57:07.689: INFO: Got endpoints: latency-svc-9qgxd [1.320397694s]
Feb 22 04:57:07.720: INFO: Created: latency-svc-zlrkq
Feb 22 04:57:07.780: INFO: Got endpoints: latency-svc-zlrkq [1.324588879s]
Feb 22 04:57:07.861: INFO: Created: latency-svc-6tsfk
Feb 22 04:57:07.921: INFO: Got endpoints: latency-svc-6tsfk [1.338912873s]
Feb 22 04:57:07.964: INFO: Created: latency-svc-7s4g6
Feb 22 04:57:07.986: INFO: Got endpoints: latency-svc-7s4g6 [1.276085239s]
Feb 22 04:57:08.053: INFO: Created: latency-svc-mgwdm
Feb 22 04:57:08.061: INFO: Got endpoints: latency-svc-mgwdm [1.286549518s]
Feb 22 04:57:08.140: INFO: Created: latency-svc-5zkmv
Feb 22 04:57:08.160: INFO: Got endpoints: latency-svc-5zkmv [1.286363275s]
Feb 22 04:57:08.224: INFO: Created: latency-svc-rkzwr
Feb 22 04:57:08.254: INFO: Got endpoints: latency-svc-rkzwr [1.33117833s]
Feb 22 04:57:08.291: INFO: Created: latency-svc-xtz8x
Feb 22 04:57:08.372: INFO: Got endpoints: latency-svc-xtz8x [1.364662355s]
Feb 22 04:57:08.385: INFO: Created: latency-svc-zdnsd
Feb 22 04:57:08.455: INFO: Got endpoints: latency-svc-zdnsd [1.359748872s]
Feb 22 04:57:08.601: INFO: Created: latency-svc-758fk
Feb 22 04:57:08.632: INFO: Got endpoints: latency-svc-758fk [1.476902972s]
Feb 22 04:57:08.671: INFO: Created: latency-svc-sfcv8
Feb 22 04:57:08.788: INFO: Got endpoints: latency-svc-sfcv8 [1.563023092s]
Feb 22 04:57:08.851: INFO: Created: latency-svc-g626m
Feb 22 04:57:08.865: INFO: Got endpoints: latency-svc-g626m [1.558472683s]
Feb 22 04:57:08.967: INFO: Created: latency-svc-hxz29
Feb 22 04:57:08.984: INFO: Got endpoints: latency-svc-hxz29 [1.579881744s]
Feb 22 04:57:09.057: INFO: Created: latency-svc-vbwcp
Feb 22 04:57:09.081: INFO: Got endpoints: latency-svc-vbwcp [1.556123881s]
Feb 22 04:57:09.134: INFO: Created: latency-svc-wgp5f
Feb 22 04:57:09.148: INFO: Created: latency-svc-cwnvx
Feb 22 04:57:09.154: INFO: Got endpoints: latency-svc-wgp5f [1.559149075s]
Feb 22 04:57:09.169: INFO: Got endpoints: latency-svc-cwnvx [1.480248881s]
Feb 22 04:57:09.260: INFO: Created: latency-svc-k8rwh
Feb 22 04:57:09.275: INFO: Got endpoints: latency-svc-k8rwh [1.495076987s]
Feb 22 04:57:09.335: INFO: Created: latency-svc-cnv8z
Feb 22 04:57:09.399: INFO: Got endpoints: latency-svc-cnv8z [1.477950174s]
Feb 22 04:57:09.419: INFO: Created: latency-svc-wmgrs
Feb 22 04:57:09.445: INFO: Got endpoints: latency-svc-wmgrs [1.458240182s]
Feb 22 04:57:09.472: INFO: Created: latency-svc-x7t5p
Feb 22 04:57:09.507: INFO: Got endpoints: latency-svc-x7t5p [1.445085715s]
Feb 22 04:57:09.573: INFO: Created: latency-svc-rr7lv
Feb 22 04:57:09.610: INFO: Created: latency-svc-7bqwd
Feb 22 04:57:09.624: INFO: Got endpoints: latency-svc-rr7lv [1.464495082s]
Feb 22 04:57:09.709: INFO: Got endpoints: latency-svc-7bqwd [1.455020832s]
Feb 22 04:57:09.710: INFO: Created: latency-svc-tfp8t
Feb 22 04:57:09.756: INFO: Got endpoints: latency-svc-tfp8t [1.384044978s]
Feb 22 04:57:09.784: INFO: Created: latency-svc-qdqkc
Feb 22 04:57:09.845: INFO: Got endpoints: latency-svc-qdqkc [1.389834758s]
Feb 22 04:57:09.907: INFO: Created: latency-svc-t4bbm
Feb 22 04:57:09.955: INFO: Got endpoints: latency-svc-t4bbm [1.323116461s]
Feb 22 04:57:10.013: INFO: Created: latency-svc-997j4
Feb 22 04:57:10.068: INFO: Got endpoints: latency-svc-997j4 [1.279715079s]
Feb 22 04:57:10.128: INFO: Created: latency-svc-9rbvq
Feb 22 04:57:10.209: INFO: Got endpoints: latency-svc-9rbvq [1.343904846s]
Feb 22 04:57:10.235: INFO: Created: latency-svc-pnp2p
Feb 22 04:57:10.347: INFO: Got endpoints: latency-svc-pnp2p [1.363303844s]
Feb 22 04:57:10.464: INFO: Created: latency-svc-pnsns
Feb 22 04:57:10.490: INFO: Got endpoints: latency-svc-pnsns [1.409215612s]
Feb 22 04:57:10.577: INFO: Created: latency-svc-zhlq6
Feb 22 04:57:10.592: INFO: Got endpoints: latency-svc-zhlq6 [1.437728631s]
Feb 22 04:57:10.629: INFO: Created: latency-svc-8tqrb
Feb 22 04:57:10.689: INFO: Got endpoints: latency-svc-8tqrb [1.520362687s]
Feb 22 04:57:10.728: INFO: Created: latency-svc-k9ksv
Feb 22 04:57:10.753: INFO: Got endpoints: latency-svc-k9ksv [1.478254143s]
Feb 22 04:57:10.822: INFO: Created: latency-svc-w47mf
Feb 22 04:57:10.848: INFO: Got endpoints: latency-svc-w47mf [1.448036581s]
Feb 22 04:57:10.885: INFO: Created: latency-svc-4kjkk
Feb 22 04:57:10.927: INFO: Got endpoints: latency-svc-4kjkk [1.482237422s]
Feb 22 04:57:11.005: INFO: Created: latency-svc-4np47
Feb 22 04:57:11.033: INFO: Got endpoints: latency-svc-4np47 [1.526602868s]
Feb 22 04:57:11.068: INFO: Created: latency-svc-xvrl6
Feb 22 04:57:11.082: INFO: Got endpoints: latency-svc-xvrl6 [1.457447745s]
Feb 22 04:57:11.132: INFO: Created: latency-svc-4zj5r
Feb 22 04:57:11.183: INFO: Got endpoints: latency-svc-4zj5r [1.473429274s]
Feb 22 04:57:11.247: INFO: Created: latency-svc-jjvxk
Feb 22 04:57:11.369: INFO: Got endpoints: latency-svc-jjvxk [1.612243087s]
Feb 22 04:57:11.426: INFO: Created: latency-svc-bsbpb
Feb 22 04:57:11.456: INFO: Got endpoints: latency-svc-bsbpb [1.610950435s]
Feb 22 04:57:11.551: INFO: Created: latency-svc-498pr
Feb 22 04:57:11.597: INFO: Got endpoints: latency-svc-498pr [1.641283213s]
Feb 22 04:57:11.734: INFO: Created: latency-svc-g7lm5
Feb 22 04:57:11.799: INFO: Got endpoints: latency-svc-g7lm5 [1.731660544s]
Feb 22 04:57:11.865: INFO: Created: latency-svc-jd2t5
Feb 22 04:57:11.896: INFO: Got endpoints: latency-svc-jd2t5 [1.686386641s]
Feb 22 04:57:12.037: INFO: Created: latency-svc-4249k
Feb 22 04:57:12.063: INFO: Got endpoints: latency-svc-4249k [1.71556823s]
Feb 22 04:57:12.117: INFO: Created: latency-svc-kswm5
Feb 22 04:57:12.157: INFO: Got endpoints: latency-svc-kswm5 [1.666968173s]
Feb 22 04:57:12.169: INFO: Created: latency-svc-5hz5m
Feb 22 04:57:12.220: INFO: Got endpoints: latency-svc-5hz5m [1.627734576s]
Feb 22 04:57:12.250: INFO: Created: latency-svc-8jpmm
Feb 22 04:57:12.279: INFO: Got endpoints: latency-svc-8jpmm [1.589714857s]
Feb 22 04:57:12.343: INFO: Created: latency-svc-rqjpx
Feb 22 04:57:12.365: INFO: Got endpoints: latency-svc-rqjpx [1.611487754s]
Feb 22 04:57:12.532: INFO: Created: latency-svc-s6dst
Feb 22 04:57:12.581: INFO: Got endpoints: latency-svc-s6dst [1.733051747s]
Feb 22 04:57:12.627: INFO: Created: latency-svc-n6wbc
Feb 22 04:57:12.648: INFO: Got endpoints: latency-svc-n6wbc [1.721362725s]
Feb 22 04:57:12.717: INFO: Created: latency-svc-tmngx
Feb 22 04:57:12.749: INFO: Got endpoints: latency-svc-tmngx [1.715915114s]
Feb 22 04:57:12.837: INFO: Created: latency-svc-7d5jk
Feb 22 04:57:12.861: INFO: Got endpoints: latency-svc-7d5jk [1.778751778s]
Feb 22 04:57:12.871: INFO: Created: latency-svc-plq7v
Feb 22 04:57:12.921: INFO: Got endpoints: latency-svc-plq7v [1.738238998s]
Feb 22 04:57:12.964: INFO: Created: latency-svc-dmn9b
Feb 22 04:57:12.979: INFO: Got endpoints: latency-svc-dmn9b [1.610183449s]
Feb 22 04:57:13.038: INFO: Created: latency-svc-ql8cr
Feb 22 04:57:13.083: INFO: Got endpoints: latency-svc-ql8cr [1.626305705s]
Feb 22 04:57:13.126: INFO: Created: latency-svc-hbq8h
Feb 22 04:57:13.160: INFO: Got endpoints: latency-svc-hbq8h [1.563215251s]
Feb 22 04:57:13.233: INFO: Created: latency-svc-xm8dn
Feb 22 04:57:13.258: INFO: Got endpoints: latency-svc-xm8dn [1.458325121s]
Feb 22 04:57:13.313: INFO: Created: latency-svc-lhfff
Feb 22 04:57:13.330: INFO: Got endpoints: latency-svc-lhfff [1.4340664s]
Feb 22 04:57:13.361: INFO: Created: latency-svc-x8ndc
Feb 22 04:57:13.394: INFO: Got endpoints: latency-svc-x8ndc [1.33151902s]
Feb 22 04:57:13.421: INFO: Created: latency-svc-pzgfl
Feb 22 04:57:13.469: INFO: Got endpoints: latency-svc-pzgfl [1.311759372s]
Feb 22 04:57:13.501: INFO: Created: latency-svc-4mfqm
Feb 22 04:57:13.547: INFO: Got endpoints: latency-svc-4mfqm [1.327156337s]
Feb 22 04:57:13.612: INFO: Created: latency-svc-rghkr
Feb 22 04:57:13.658: INFO: Got endpoints: latency-svc-rghkr [1.378300128s]
Feb 22 04:57:13.681: INFO: Created: latency-svc-8vkkq
Feb 22 04:57:13.778: INFO: Got endpoints: latency-svc-8vkkq [1.412892116s]
Feb 22 04:57:13.889: INFO: Created: latency-svc-795tq
Feb 22 04:57:13.922: INFO: Got endpoints: latency-svc-795tq [1.341296282s]
Feb 22 04:57:13.952: INFO: Created: latency-svc-96h84
Feb 22 04:57:13.989: INFO: Got endpoints: latency-svc-96h84 [1.340772539s]
Feb 22 04:57:14.045: INFO: Created: latency-svc-6z5bb
Feb 22 04:57:14.061: INFO: Got endpoints: latency-svc-6z5bb [1.311920142s]
Feb 22 04:57:14.122: INFO: Created: latency-svc-4gnxh
Feb 22 04:57:14.162: INFO: Got endpoints: latency-svc-4gnxh [1.301032306s]
Feb 22 04:57:14.254: INFO: Created: latency-svc-8ptqx
Feb 22 04:57:14.298: INFO: Got endpoints: latency-svc-8ptqx [1.376222742s]
Feb 22 04:57:14.338: INFO: Created: latency-svc-vb64z
Feb 22 04:57:14.363: INFO: Got endpoints: latency-svc-vb64z [1.383977219s]
Feb 22 04:57:14.482: INFO: Created: latency-svc-rs76f
Feb 22 04:57:14.497: INFO: Created: latency-svc-dlpbd
Feb 22 04:57:14.542: INFO: Got endpoints: latency-svc-rs76f [1.459284045s]
Feb 22 04:57:14.586: INFO: Got endpoints: latency-svc-dlpbd [1.426191842s]
Feb 22 04:57:14.704: INFO: Created: latency-svc-x2qwb
Feb 22 04:57:14.761: INFO: Got endpoints: latency-svc-x2qwb [1.502714846s]
Feb 22 04:57:14.885: INFO: Created: latency-svc-6m5px
Feb 22 04:57:14.942: INFO: Got endpoints: latency-svc-6m5px [1.611934993s]
Feb 22 04:57:15.007: INFO: Created: latency-svc-4fvpr
Feb 22 04:57:15.052: INFO: Got endpoints: latency-svc-4fvpr [1.657596555s]
Feb 22 04:57:15.073: INFO: Created: latency-svc-w67r8
Feb 22 04:57:15.118: INFO: Got endpoints: latency-svc-w67r8 [1.64893421s]
Feb 22 04:57:15.198: INFO: Created: latency-svc-qk7vr
Feb 22 04:57:15.372: INFO: Got endpoints: latency-svc-qk7vr [1.824898833s]
Feb 22 04:57:15.601: INFO: Created: latency-svc-fm6cj
Feb 22 04:57:15.697: INFO: Got endpoints: latency-svc-fm6cj [2.038841785s]
Feb 22 04:57:15.840: INFO: Created: latency-svc-7swqb
Feb 22 04:57:15.925: INFO: Got endpoints: latency-svc-7swqb [2.146661142s]
Feb 22 04:57:15.986: INFO: Created: latency-svc-54jfz
Feb 22 04:57:16.146: INFO: Got endpoints: latency-svc-54jfz [2.223435559s]
Feb 22 04:57:16.186: INFO: Created: latency-svc-s22m7
Feb 22 04:57:16.228: INFO: Got endpoints: latency-svc-s22m7 [2.238707364s]
Feb 22 04:57:16.320: INFO: Created: latency-svc-47dh5
Feb 22 04:57:16.356: INFO: Got endpoints: latency-svc-47dh5 [2.295185387s]
Feb 22 04:57:16.467: INFO: Created: latency-svc-whvr2
Feb 22 04:57:16.470: INFO: Got endpoints: latency-svc-whvr2 [2.307902127s]
Feb 22 04:57:16.600: INFO: Created: latency-svc-md9rt
Feb 22 04:57:16.687: INFO: Got endpoints: latency-svc-md9rt [2.389714292s]
Feb 22 04:57:16.862: INFO: Created: latency-svc-4c4cn
Feb 22 04:57:16.889: INFO: Got endpoints: latency-svc-4c4cn [2.525725436s]
Feb 22 04:57:16.968: INFO: Created: latency-svc-7lhmp
Feb 22 04:57:17.007: INFO: Got endpoints: latency-svc-7lhmp [2.464482308s]
Feb 22 04:57:17.109: INFO: Created: latency-svc-vp9x7
Feb 22 04:57:17.163: INFO: Created: latency-svc-zhz8q
Feb 22 04:57:17.188: INFO: Got endpoints: latency-svc-vp9x7 [2.601073152s]
Feb 22 04:57:17.229: INFO: Got endpoints: latency-svc-zhz8q [2.468285153s]
Feb 22 04:57:17.255: INFO: Created: latency-svc-d7xgc
Feb 22 04:57:17.305: INFO: Got endpoints: latency-svc-d7xgc [2.362967568s]
Feb 22 04:57:17.348: INFO: Created: latency-svc-wz8dn
Feb 22 04:57:17.381: INFO: Got endpoints: latency-svc-wz8dn [2.32885166s]
Feb 22 04:57:17.461: INFO: Created: latency-svc-bm7d5
Feb 22 04:57:17.469: INFO: Got endpoints: latency-svc-bm7d5 [2.350858679s]
Feb 22 04:57:17.530: INFO: Created: latency-svc-f8rwp
Feb 22 04:57:17.567: INFO: Got endpoints: latency-svc-f8rwp [2.194314115s]
Feb 22 04:57:17.598: INFO: Created: latency-svc-nq2w6
Feb 22 04:57:17.671: INFO: Got endpoints: latency-svc-nq2w6 [1.974178718s]
Feb 22 04:57:17.763: INFO: Created: latency-svc-z4rv4
Feb 22 04:57:17.801: INFO: Got endpoints: latency-svc-z4rv4 [1.87580917s]
Feb 22 04:57:17.880: INFO: Created: latency-svc-4vdqn
Feb 22 04:57:17.922: INFO: Got endpoints: latency-svc-4vdqn [1.776173271s]
Feb 22 04:57:17.999: INFO: Created: latency-svc-8l6rk
Feb 22 04:57:18.073: INFO: Created: latency-svc-g4jx7
Feb 22 04:57:18.081: INFO: Got endpoints: latency-svc-8l6rk [1.852679956s]
Feb 22 04:57:18.106: INFO: Got endpoints: latency-svc-g4jx7 [1.749251391s]
Feb 22 04:57:18.164: INFO: Created: latency-svc-k5mgs
Feb 22 04:57:18.240: INFO: Got endpoints: latency-svc-k5mgs [1.769755095s]
Feb 22 04:57:18.289: INFO: Created: latency-svc-f74ks
Feb 22 04:57:18.329: INFO: Got endpoints: latency-svc-f74ks [1.641328065s]
Feb 22 04:57:18.408: INFO: Created: latency-svc-7kjhz
Feb 22 04:57:18.425: INFO: Got endpoints: latency-svc-7kjhz [1.5364946s]
Feb 22 04:57:18.426: INFO: Latencies: [100.614718ms 160.507156ms 186.830471ms 205.207719ms 356.699616ms 422.467167ms 476.136577ms 619.134321ms 722.435754ms 799.900278ms 930.753491ms 1.014154841s 1.273114056s 1.276085239s 1.279715079s 1.286363275s 1.286549518s 1.301032306s 1.311759372s 1.311920142s 1.320397694s 1.323116461s 1.324588879s 1.327156337s 1.33117833s 1.33151902s 1.338912873s 1.340772539s 1.341296282s 1.343904846s 1.359748872s 1.363303844s 1.364662355s 1.376222742s 1.378300128s 1.383977219s 1.384044978s 1.389834758s 1.395999351s 1.409215612s 1.409673686s 1.412892116s 1.426013398s 1.426191842s 1.4340664s 1.437728631s 1.440202646s 1.445085715s 1.44704073s 1.448036581s 1.455020832s 1.457447745s 1.458240182s 1.458325121s 1.459284045s 1.462636151s 1.464495082s 1.473429274s 1.476902972s 1.477950174s 1.478254143s 1.480248881s 1.482237422s 1.495076987s 1.49788393s 1.499563718s 1.502714846s 1.505109665s 1.510174515s 1.518117383s 1.520362687s 1.526602868s 1.532421337s 1.5364946s 1.53803158s 1.549921525s 1.554047902s 1.556123881s 1.556625382s 1.558472683s 1.559149075s 1.563023092s 1.563215251s 1.566191521s 1.579881744s 1.58048567s 1.586363018s 1.589714857s 1.592568936s 1.59888954s 1.607468012s 1.610183449s 1.610950435s 1.611487754s 1.611934993s 1.612243087s 1.613549114s 1.615964365s 1.620093671s 1.620932113s 1.625037581s 1.626305705s 1.627734576s 1.633039095s 1.640816814s 1.641283213s 1.641328065s 1.64893421s 1.655731291s 1.657596555s 1.659907388s 1.666968173s 1.686386641s 1.690289606s 1.710679892s 1.710747881s 1.71556823s 1.715915114s 1.721362725s 1.731660544s 1.733051747s 1.738238998s 1.745453041s 1.749251391s 1.769755095s 1.776173271s 1.778751778s 1.778863004s 1.780083199s 1.788364608s 1.793162441s 1.800863219s 1.804375937s 1.824898833s 1.827419466s 1.829681818s 1.852679956s 1.862305038s 1.87580917s 1.901557093s 1.914598328s 1.940115881s 1.969386347s 1.974178718s 2.003243196s 2.008291315s 2.023261211s 2.038841785s 2.043096521s 2.062459778s 2.07100713s 2.076194446s 2.088851405s 2.091107737s 2.108471611s 2.119923165s 2.121283243s 2.123226604s 2.129104398s 2.146661142s 2.148515639s 2.164505055s 2.169895376s 2.194314115s 2.223435559s 2.238707364s 2.294894137s 2.295185387s 2.299591588s 2.307902127s 2.32885166s 2.336388573s 2.345531191s 2.350243419s 2.350858679s 2.362967568s 2.367692537s 2.37874761s 2.383134105s 2.389714292s 2.397558978s 2.416094538s 2.433939671s 2.436826514s 2.436962815s 2.438296749s 2.464482308s 2.468285153s 2.470543674s 2.485862601s 2.525725436s 2.535641147s 2.541036195s 2.601073152s 2.6647432s 2.698974211s 2.739780488s 2.775751939s 2.808700414s 2.942030581s]
Feb 22 04:57:18.426: INFO: 50 %ile: 1.625037581s
Feb 22 04:57:18.426: INFO: 90 %ile: 2.397558978s
Feb 22 04:57:18.426: INFO: 99 %ile: 2.808700414s
Feb 22 04:57:18.426: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 04:57:18.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-2003" for this suite.

â€¢ [SLOW TEST:56.314 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Service endpoints latency should not be very high  [Conformance]","total":270,"completed":71,"skipped":1215,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 04:57:18.546: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-955
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation
Feb 22 04:57:18.953: INFO: >>> kubeConfig: /root/.kube/config
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation
Feb 22 04:58:07.261: INFO: >>> kubeConfig: /root/.kube/config
Feb 22 04:58:19.593: INFO: >>> kubeConfig: /root/.kube/config
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 04:59:06.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-955" for this suite.

â€¢ [SLOW TEST:108.908 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]","total":270,"completed":72,"skipped":1240,"failed":0}
SSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 04:59:07.456: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2530
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with configMap that has name projected-configmap-test-upd-34d9e6e6-c7f5-4c20-9e8d-7384bc35be1a
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-34d9e6e6-c7f5-4c20-9e8d-7384bc35be1a
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 05:00:19.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2530" for this suite.

â€¢ [SLOW TEST:71.699 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:36
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]","total":270,"completed":73,"skipped":1246,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 05:00:19.178: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-9707
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod liveness-36aa3804-b14f-4744-9375-34334284b8e2 in namespace container-probe-9707
Feb 22 05:00:53.816: INFO: Started pod liveness-36aa3804-b14f-4744-9375-34334284b8e2 in namespace container-probe-9707
STEP: checking the pod's current state and verifying that restartCount is present
Feb 22 05:00:53.825: INFO: Initial restart count of pod liveness-36aa3804-b14f-4744-9375-34334284b8e2 is 0
Feb 22 05:01:10.022: INFO: Restart count of pod container-probe-9707/liveness-36aa3804-b14f-4744-9375-34334284b8e2 is now 1 (16.196306549s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 05:01:10.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9707" for this suite.

â€¢ [SLOW TEST:51.036 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","total":270,"completed":74,"skipped":1271,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 05:01:10.240: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-3224
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Feb 22 05:01:34.935: INFO: Waiting up to 5m0s for pod "client-envvars-df453992-608d-4875-9761-81a89bf2bd89" in namespace "pods-3224" to be "Succeeded or Failed"
Feb 22 05:01:35.041: INFO: Pod "client-envvars-df453992-608d-4875-9761-81a89bf2bd89": Phase="Pending", Reason="", readiness=false. Elapsed: 105.519565ms
Feb 22 05:01:37.068: INFO: Pod "client-envvars-df453992-608d-4875-9761-81a89bf2bd89": Phase="Pending", Reason="", readiness=false. Elapsed: 2.132928582s
Feb 22 05:01:39.087: INFO: Pod "client-envvars-df453992-608d-4875-9761-81a89bf2bd89": Phase="Pending", Reason="", readiness=false. Elapsed: 4.151428869s
Feb 22 05:01:41.101: INFO: Pod "client-envvars-df453992-608d-4875-9761-81a89bf2bd89": Phase="Pending", Reason="", readiness=false. Elapsed: 6.166131186s
Feb 22 05:01:43.114: INFO: Pod "client-envvars-df453992-608d-4875-9761-81a89bf2bd89": Phase="Pending", Reason="", readiness=false. Elapsed: 8.178265326s
Feb 22 05:01:45.127: INFO: Pod "client-envvars-df453992-608d-4875-9761-81a89bf2bd89": Phase="Pending", Reason="", readiness=false. Elapsed: 10.19200331s
Feb 22 05:01:47.137: INFO: Pod "client-envvars-df453992-608d-4875-9761-81a89bf2bd89": Phase="Pending", Reason="", readiness=false. Elapsed: 12.201870035s
Feb 22 05:01:49.151: INFO: Pod "client-envvars-df453992-608d-4875-9761-81a89bf2bd89": Phase="Pending", Reason="", readiness=false. Elapsed: 14.216060887s
Feb 22 05:01:51.169: INFO: Pod "client-envvars-df453992-608d-4875-9761-81a89bf2bd89": Phase="Pending", Reason="", readiness=false. Elapsed: 16.233682436s
Feb 22 05:01:53.189: INFO: Pod "client-envvars-df453992-608d-4875-9761-81a89bf2bd89": Phase="Pending", Reason="", readiness=false. Elapsed: 18.25370921s
Feb 22 05:01:55.197: INFO: Pod "client-envvars-df453992-608d-4875-9761-81a89bf2bd89": Phase="Pending", Reason="", readiness=false. Elapsed: 20.261792189s
Feb 22 05:01:57.203: INFO: Pod "client-envvars-df453992-608d-4875-9761-81a89bf2bd89": Phase="Pending", Reason="", readiness=false. Elapsed: 22.268054956s
Feb 22 05:01:59.214: INFO: Pod "client-envvars-df453992-608d-4875-9761-81a89bf2bd89": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.278812603s
STEP: Saw pod success
Feb 22 05:01:59.214: INFO: Pod "client-envvars-df453992-608d-4875-9761-81a89bf2bd89" satisfied condition "Succeeded or Failed"
Feb 22 05:01:59.227: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com pod client-envvars-df453992-608d-4875-9761-81a89bf2bd89 container env3cont: <nil>
STEP: delete the pod
Feb 22 05:01:59.350: INFO: Waiting for pod client-envvars-df453992-608d-4875-9761-81a89bf2bd89 to disappear
Feb 22 05:01:59.371: INFO: Pod client-envvars-df453992-608d-4875-9761-81a89bf2bd89 still exists
Feb 22 05:02:01.372: INFO: Waiting for pod client-envvars-df453992-608d-4875-9761-81a89bf2bd89 to disappear
Feb 22 05:02:01.396: INFO: Pod client-envvars-df453992-608d-4875-9761-81a89bf2bd89 still exists
Feb 22 05:02:03.372: INFO: Waiting for pod client-envvars-df453992-608d-4875-9761-81a89bf2bd89 to disappear
Feb 22 05:02:03.412: INFO: Pod client-envvars-df453992-608d-4875-9761-81a89bf2bd89 still exists
Feb 22 05:02:05.373: INFO: Waiting for pod client-envvars-df453992-608d-4875-9761-81a89bf2bd89 to disappear
Feb 22 05:02:05.385: INFO: Pod client-envvars-df453992-608d-4875-9761-81a89bf2bd89 still exists
Feb 22 05:02:07.372: INFO: Waiting for pod client-envvars-df453992-608d-4875-9761-81a89bf2bd89 to disappear
Feb 22 05:02:07.382: INFO: Pod client-envvars-df453992-608d-4875-9761-81a89bf2bd89 still exists
Feb 22 05:02:09.372: INFO: Waiting for pod client-envvars-df453992-608d-4875-9761-81a89bf2bd89 to disappear
Feb 22 05:02:09.380: INFO: Pod client-envvars-df453992-608d-4875-9761-81a89bf2bd89 still exists
Feb 22 05:02:11.375: INFO: Waiting for pod client-envvars-df453992-608d-4875-9761-81a89bf2bd89 to disappear
Feb 22 05:02:11.393: INFO: Pod client-envvars-df453992-608d-4875-9761-81a89bf2bd89 still exists
Feb 22 05:02:13.372: INFO: Waiting for pod client-envvars-df453992-608d-4875-9761-81a89bf2bd89 to disappear
Feb 22 05:02:13.389: INFO: Pod client-envvars-df453992-608d-4875-9761-81a89bf2bd89 still exists
Feb 22 05:02:15.372: INFO: Waiting for pod client-envvars-df453992-608d-4875-9761-81a89bf2bd89 to disappear
Feb 22 05:02:15.382: INFO: Pod client-envvars-df453992-608d-4875-9761-81a89bf2bd89 still exists
Feb 22 05:02:17.372: INFO: Waiting for pod client-envvars-df453992-608d-4875-9761-81a89bf2bd89 to disappear
Feb 22 05:02:17.379: INFO: Pod client-envvars-df453992-608d-4875-9761-81a89bf2bd89 still exists
Feb 22 05:02:19.372: INFO: Waiting for pod client-envvars-df453992-608d-4875-9761-81a89bf2bd89 to disappear
Feb 22 05:02:19.378: INFO: Pod client-envvars-df453992-608d-4875-9761-81a89bf2bd89 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 05:02:19.379: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3224" for this suite.

â€¢ [SLOW TEST:69.170 seconds]
[k8s.io] Pods
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Pods should contain environment variables for services [NodeConformance] [Conformance]","total":270,"completed":75,"skipped":1289,"failed":0}
SSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 05:02:19.409: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8259
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-projected-all-test-volume-e0c47545-1cb2-405b-bb1e-d9b64a64945d
STEP: Creating secret with name secret-projected-all-test-volume-5417bdd2-a78b-45ce-94dd-cf72ba493906
STEP: Creating a pod to test Check all projections for projected volume plugin
Feb 22 05:02:19.787: INFO: Waiting up to 5m0s for pod "projected-volume-029463e5-cba5-42dc-b61c-af0229ce9f33" in namespace "projected-8259" to be "Succeeded or Failed"
Feb 22 05:02:19.799: INFO: Pod "projected-volume-029463e5-cba5-42dc-b61c-af0229ce9f33": Phase="Pending", Reason="", readiness=false. Elapsed: 11.481328ms
Feb 22 05:02:21.809: INFO: Pod "projected-volume-029463e5-cba5-42dc-b61c-af0229ce9f33": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021228014s
Feb 22 05:02:23.818: INFO: Pod "projected-volume-029463e5-cba5-42dc-b61c-af0229ce9f33": Phase="Pending", Reason="", readiness=false. Elapsed: 4.030824603s
Feb 22 05:02:25.826: INFO: Pod "projected-volume-029463e5-cba5-42dc-b61c-af0229ce9f33": Phase="Pending", Reason="", readiness=false. Elapsed: 6.038416533s
Feb 22 05:02:27.833: INFO: Pod "projected-volume-029463e5-cba5-42dc-b61c-af0229ce9f33": Phase="Pending", Reason="", readiness=false. Elapsed: 8.045361464s
Feb 22 05:02:29.842: INFO: Pod "projected-volume-029463e5-cba5-42dc-b61c-af0229ce9f33": Phase="Pending", Reason="", readiness=false. Elapsed: 10.055049684s
Feb 22 05:02:31.859: INFO: Pod "projected-volume-029463e5-cba5-42dc-b61c-af0229ce9f33": Phase="Pending", Reason="", readiness=false. Elapsed: 12.071207956s
Feb 22 05:02:33.872: INFO: Pod "projected-volume-029463e5-cba5-42dc-b61c-af0229ce9f33": Phase="Pending", Reason="", readiness=false. Elapsed: 14.084303343s
Feb 22 05:02:35.882: INFO: Pod "projected-volume-029463e5-cba5-42dc-b61c-af0229ce9f33": Phase="Pending", Reason="", readiness=false. Elapsed: 16.094940622s
Feb 22 05:02:37.905: INFO: Pod "projected-volume-029463e5-cba5-42dc-b61c-af0229ce9f33": Phase="Pending", Reason="", readiness=false. Elapsed: 18.117153395s
Feb 22 05:02:39.917: INFO: Pod "projected-volume-029463e5-cba5-42dc-b61c-af0229ce9f33": Phase="Pending", Reason="", readiness=false. Elapsed: 20.129376279s
Feb 22 05:02:41.925: INFO: Pod "projected-volume-029463e5-cba5-42dc-b61c-af0229ce9f33": Phase="Pending", Reason="", readiness=false. Elapsed: 22.137416706s
Feb 22 05:02:43.934: INFO: Pod "projected-volume-029463e5-cba5-42dc-b61c-af0229ce9f33": Phase="Pending", Reason="", readiness=false. Elapsed: 24.146203885s
Feb 22 05:02:45.947: INFO: Pod "projected-volume-029463e5-cba5-42dc-b61c-af0229ce9f33": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.159586912s
STEP: Saw pod success
Feb 22 05:02:45.947: INFO: Pod "projected-volume-029463e5-cba5-42dc-b61c-af0229ce9f33" satisfied condition "Succeeded or Failed"
Feb 22 05:02:45.955: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com pod projected-volume-029463e5-cba5-42dc-b61c-af0229ce9f33 container projected-all-volume-test: <nil>
STEP: delete the pod
Feb 22 05:02:46.110: INFO: Waiting for pod projected-volume-029463e5-cba5-42dc-b61c-af0229ce9f33 to disappear
Feb 22 05:02:46.145: INFO: Pod projected-volume-029463e5-cba5-42dc-b61c-af0229ce9f33 still exists
Feb 22 05:02:48.145: INFO: Waiting for pod projected-volume-029463e5-cba5-42dc-b61c-af0229ce9f33 to disappear
Feb 22 05:02:48.159: INFO: Pod projected-volume-029463e5-cba5-42dc-b61c-af0229ce9f33 still exists
Feb 22 05:02:50.145: INFO: Waiting for pod projected-volume-029463e5-cba5-42dc-b61c-af0229ce9f33 to disappear
Feb 22 05:02:50.155: INFO: Pod projected-volume-029463e5-cba5-42dc-b61c-af0229ce9f33 still exists
Feb 22 05:02:52.145: INFO: Waiting for pod projected-volume-029463e5-cba5-42dc-b61c-af0229ce9f33 to disappear
Feb 22 05:02:52.154: INFO: Pod projected-volume-029463e5-cba5-42dc-b61c-af0229ce9f33 still exists
Feb 22 05:02:54.145: INFO: Waiting for pod projected-volume-029463e5-cba5-42dc-b61c-af0229ce9f33 to disappear
Feb 22 05:02:54.154: INFO: Pod projected-volume-029463e5-cba5-42dc-b61c-af0229ce9f33 still exists
Feb 22 05:02:56.145: INFO: Waiting for pod projected-volume-029463e5-cba5-42dc-b61c-af0229ce9f33 to disappear
Feb 22 05:02:56.166: INFO: Pod projected-volume-029463e5-cba5-42dc-b61c-af0229ce9f33 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 05:02:56.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8259" for this suite.

â€¢ [SLOW TEST:36.826 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:32
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected combined should project all components that make up the projection API [Projection][NodeConformance] [Conformance]","total":270,"completed":76,"skipped":1295,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 05:02:56.237: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-347
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating replication controller my-hostname-basic-787d31b2-82f6-4b05-88c0-ec39cdbc7f5d
Feb 22 05:02:56.587: INFO: Pod name my-hostname-basic-787d31b2-82f6-4b05-88c0-ec39cdbc7f5d: Found 0 pods out of 1
Feb 22 05:03:01.599: INFO: Pod name my-hostname-basic-787d31b2-82f6-4b05-88c0-ec39cdbc7f5d: Found 1 pods out of 1
Feb 22 05:03:01.599: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-787d31b2-82f6-4b05-88c0-ec39cdbc7f5d" are running
Feb 22 05:03:21.660: INFO: Pod "my-hostname-basic-787d31b2-82f6-4b05-88c0-ec39cdbc7f5d-kwzb5" is running (conditions: [{Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2021-02-22 05:02:56 +0000 UTC Reason: Message:}])
Feb 22 05:03:21.661: INFO: Trying to dial the pod
Feb 22 05:03:26.720: INFO: Controller my-hostname-basic-787d31b2-82f6-4b05-88c0-ec39cdbc7f5d: Got expected result from replica 1 [my-hostname-basic-787d31b2-82f6-4b05-88c0-ec39cdbc7f5d-kwzb5]: "my-hostname-basic-787d31b2-82f6-4b05-88c0-ec39cdbc7f5d-kwzb5", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 05:03:26.721: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-347" for this suite.

â€¢ [SLOW TEST:30.522 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] ReplicationController should serve a basic image on each replica with a public image  [Conformance]","total":270,"completed":77,"skipped":1308,"failed":0}
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 05:03:26.762: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2557
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0777 on node default medium
Feb 22 05:03:27.083: INFO: Waiting up to 5m0s for pod "pod-b050a963-708a-4c69-a032-6a1afe373ca2" in namespace "emptydir-2557" to be "Succeeded or Failed"
Feb 22 05:03:27.105: INFO: Pod "pod-b050a963-708a-4c69-a032-6a1afe373ca2": Phase="Pending", Reason="", readiness=false. Elapsed: 20.960646ms
Feb 22 05:03:29.113: INFO: Pod "pod-b050a963-708a-4c69-a032-6a1afe373ca2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029860298s
Feb 22 05:03:31.121: INFO: Pod "pod-b050a963-708a-4c69-a032-6a1afe373ca2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.037127005s
Feb 22 05:03:33.128: INFO: Pod "pod-b050a963-708a-4c69-a032-6a1afe373ca2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.044563806s
Feb 22 05:03:35.134: INFO: Pod "pod-b050a963-708a-4c69-a032-6a1afe373ca2": Phase="Pending", Reason="", readiness=false. Elapsed: 8.050447289s
Feb 22 05:03:37.143: INFO: Pod "pod-b050a963-708a-4c69-a032-6a1afe373ca2": Phase="Pending", Reason="", readiness=false. Elapsed: 10.059576021s
Feb 22 05:03:39.158: INFO: Pod "pod-b050a963-708a-4c69-a032-6a1afe373ca2": Phase="Pending", Reason="", readiness=false. Elapsed: 12.074638246s
Feb 22 05:03:41.175: INFO: Pod "pod-b050a963-708a-4c69-a032-6a1afe373ca2": Phase="Pending", Reason="", readiness=false. Elapsed: 14.091323621s
Feb 22 05:03:43.187: INFO: Pod "pod-b050a963-708a-4c69-a032-6a1afe373ca2": Phase="Pending", Reason="", readiness=false. Elapsed: 16.103199375s
Feb 22 05:03:45.196: INFO: Pod "pod-b050a963-708a-4c69-a032-6a1afe373ca2": Phase="Pending", Reason="", readiness=false. Elapsed: 18.112265997s
Feb 22 05:03:47.202: INFO: Pod "pod-b050a963-708a-4c69-a032-6a1afe373ca2": Phase="Pending", Reason="", readiness=false. Elapsed: 20.117973563s
Feb 22 05:03:49.210: INFO: Pod "pod-b050a963-708a-4c69-a032-6a1afe373ca2": Phase="Pending", Reason="", readiness=false. Elapsed: 22.126147479s
Feb 22 05:03:51.227: INFO: Pod "pod-b050a963-708a-4c69-a032-6a1afe373ca2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.143376331s
STEP: Saw pod success
Feb 22 05:03:51.227: INFO: Pod "pod-b050a963-708a-4c69-a032-6a1afe373ca2" satisfied condition "Succeeded or Failed"
Feb 22 05:03:51.245: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com pod pod-b050a963-708a-4c69-a032-6a1afe373ca2 container test-container: <nil>
STEP: delete the pod
Feb 22 05:03:58.138: INFO: Waiting for pod pod-b050a963-708a-4c69-a032-6a1afe373ca2 to disappear
Feb 22 05:03:58.148: INFO: Pod pod-b050a963-708a-4c69-a032-6a1afe373ca2 still exists
Feb 22 05:04:00.149: INFO: Waiting for pod pod-b050a963-708a-4c69-a032-6a1afe373ca2 to disappear
Feb 22 05:04:00.155: INFO: Pod pod-b050a963-708a-4c69-a032-6a1afe373ca2 still exists
Feb 22 05:04:02.149: INFO: Waiting for pod pod-b050a963-708a-4c69-a032-6a1afe373ca2 to disappear
Feb 22 05:04:02.164: INFO: Pod pod-b050a963-708a-4c69-a032-6a1afe373ca2 still exists
Feb 22 05:04:04.149: INFO: Waiting for pod pod-b050a963-708a-4c69-a032-6a1afe373ca2 to disappear
Feb 22 05:04:04.157: INFO: Pod pod-b050a963-708a-4c69-a032-6a1afe373ca2 still exists
Feb 22 05:04:06.149: INFO: Waiting for pod pod-b050a963-708a-4c69-a032-6a1afe373ca2 to disappear
Feb 22 05:04:06.162: INFO: Pod pod-b050a963-708a-4c69-a032-6a1afe373ca2 still exists
Feb 22 05:04:08.149: INFO: Waiting for pod pod-b050a963-708a-4c69-a032-6a1afe373ca2 to disappear
Feb 22 05:04:08.163: INFO: Pod pod-b050a963-708a-4c69-a032-6a1afe373ca2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 05:04:08.163: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2557" for this suite.

â€¢ [SLOW TEST:41.442 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:42
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","total":270,"completed":78,"skipped":1310,"failed":0}
SSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 05:04:08.206: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-2073
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Feb 22 05:04:37.240: INFO: Successfully updated pod "pod-update-activedeadlineseconds-b6cf3242-4a9c-47d8-83ae-5fb640f1f1d9"
Feb 22 05:04:37.240: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-b6cf3242-4a9c-47d8-83ae-5fb640f1f1d9" in namespace "pods-2073" to be "terminated due to deadline exceeded"
Feb 22 05:04:37.252: INFO: Pod "pod-update-activedeadlineseconds-b6cf3242-4a9c-47d8-83ae-5fb640f1f1d9": Phase="Running", Reason="", readiness=true. Elapsed: 11.762793ms
Feb 22 05:04:39.281: INFO: Pod "pod-update-activedeadlineseconds-b6cf3242-4a9c-47d8-83ae-5fb640f1f1d9": Phase="Running", Reason="", readiness=true. Elapsed: 2.040671896s
Feb 22 05:04:41.291: INFO: Pod "pod-update-activedeadlineseconds-b6cf3242-4a9c-47d8-83ae-5fb640f1f1d9": Phase="Failed", Reason="DeadlineExceeded", readiness=true. Elapsed: 4.05085307s
Feb 22 05:04:41.291: INFO: Pod "pod-update-activedeadlineseconds-b6cf3242-4a9c-47d8-83ae-5fb640f1f1d9" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 05:04:41.291: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2073" for this suite.

â€¢ [SLOW TEST:33.142 seconds]
[k8s.io] Pods
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]","total":270,"completed":79,"skipped":1318,"failed":0}
SSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 05:04:41.352: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-4457
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: getting the auto-created API token
STEP: reading a file in the container
Feb 22 05:05:06.335: INFO: Running '/usr/bin/kubectl exec --namespace=svcaccounts-4457 pod-service-account-dc531017-8412-47d3-8e6e-58c80b0d5466 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Feb 22 05:05:06.767: INFO: Running '/usr/bin/kubectl exec --namespace=svcaccounts-4457 pod-service-account-dc531017-8412-47d3-8e6e-58c80b0d5466 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Feb 22 05:05:07.078: INFO: Running '/usr/bin/kubectl exec --namespace=svcaccounts-4457 pod-service-account-dc531017-8412-47d3-8e6e-58c80b0d5466 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 05:05:07.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-4457" for this suite.

â€¢ [SLOW TEST:26.151 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-auth] ServiceAccounts should mount an API token into pods  [Conformance]","total":270,"completed":80,"skipped":1325,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a container with runAsUser 
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 05:05:07.505: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-6810
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:41
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Feb 22 05:05:07.837: INFO: Waiting up to 5m0s for pod "busybox-user-65534-591d7c98-83a4-4eb7-b522-3c71d01ce928" in namespace "security-context-test-6810" to be "Succeeded or Failed"
Feb 22 05:05:07.844: INFO: Pod "busybox-user-65534-591d7c98-83a4-4eb7-b522-3c71d01ce928": Phase="Pending", Reason="", readiness=false. Elapsed: 6.595506ms
Feb 22 05:05:09.858: INFO: Pod "busybox-user-65534-591d7c98-83a4-4eb7-b522-3c71d01ce928": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021188742s
Feb 22 05:05:11.879: INFO: Pod "busybox-user-65534-591d7c98-83a4-4eb7-b522-3c71d01ce928": Phase="Pending", Reason="", readiness=false. Elapsed: 4.042290223s
Feb 22 05:05:13.946: INFO: Pod "busybox-user-65534-591d7c98-83a4-4eb7-b522-3c71d01ce928": Phase="Pending", Reason="", readiness=false. Elapsed: 6.10904297s
Feb 22 05:05:15.970: INFO: Pod "busybox-user-65534-591d7c98-83a4-4eb7-b522-3c71d01ce928": Phase="Pending", Reason="", readiness=false. Elapsed: 8.13334592s
Feb 22 05:05:17.981: INFO: Pod "busybox-user-65534-591d7c98-83a4-4eb7-b522-3c71d01ce928": Phase="Pending", Reason="", readiness=false. Elapsed: 10.143691804s
Feb 22 05:05:19.992: INFO: Pod "busybox-user-65534-591d7c98-83a4-4eb7-b522-3c71d01ce928": Phase="Pending", Reason="", readiness=false. Elapsed: 12.155251068s
Feb 22 05:05:22.002: INFO: Pod "busybox-user-65534-591d7c98-83a4-4eb7-b522-3c71d01ce928": Phase="Pending", Reason="", readiness=false. Elapsed: 14.165055735s
Feb 22 05:05:24.009: INFO: Pod "busybox-user-65534-591d7c98-83a4-4eb7-b522-3c71d01ce928": Phase="Pending", Reason="", readiness=false. Elapsed: 16.172140702s
Feb 22 05:05:26.028: INFO: Pod "busybox-user-65534-591d7c98-83a4-4eb7-b522-3c71d01ce928": Phase="Pending", Reason="", readiness=false. Elapsed: 18.191331037s
Feb 22 05:05:28.036: INFO: Pod "busybox-user-65534-591d7c98-83a4-4eb7-b522-3c71d01ce928": Phase="Pending", Reason="", readiness=false. Elapsed: 20.199110114s
Feb 22 05:05:30.054: INFO: Pod "busybox-user-65534-591d7c98-83a4-4eb7-b522-3c71d01ce928": Phase="Pending", Reason="", readiness=false. Elapsed: 22.216967068s
Feb 22 05:05:32.085: INFO: Pod "busybox-user-65534-591d7c98-83a4-4eb7-b522-3c71d01ce928": Phase="Pending", Reason="", readiness=false. Elapsed: 24.247928134s
Feb 22 05:05:34.106: INFO: Pod "busybox-user-65534-591d7c98-83a4-4eb7-b522-3c71d01ce928": Phase="Pending", Reason="", readiness=false. Elapsed: 26.268618422s
Feb 22 05:05:36.169: INFO: Pod "busybox-user-65534-591d7c98-83a4-4eb7-b522-3c71d01ce928": Phase="Pending", Reason="", readiness=false. Elapsed: 28.331595547s
Feb 22 05:05:38.178: INFO: Pod "busybox-user-65534-591d7c98-83a4-4eb7-b522-3c71d01ce928": Phase="Succeeded", Reason="", readiness=false. Elapsed: 30.340854863s
Feb 22 05:05:38.178: INFO: Pod "busybox-user-65534-591d7c98-83a4-4eb7-b522-3c71d01ce928" satisfied condition "Succeeded or Failed"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 05:05:38.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-6810" for this suite.

â€¢ [SLOW TEST:30.711 seconds]
[k8s.io] Security Context
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  When creating a container with runAsUser
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:45
    should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]","total":270,"completed":81,"skipped":1340,"failed":0}
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 05:05:38.216: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-4344
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Feb 22 05:05:38.697: INFO: Create a RollingUpdate DaemonSet
Feb 22 05:05:38.736: INFO: Check that daemon pods launch on every node of the cluster
Feb 22 05:05:38.776: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:05:38.777: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:05:38.777: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:05:38.827: INFO: Number of nodes with available pods: 0
Feb 22 05:05:38.827: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:05:39.838: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:05:39.839: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:05:39.839: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:05:39.855: INFO: Number of nodes with available pods: 0
Feb 22 05:05:39.855: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:05:40.868: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:05:40.869: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:05:40.869: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:05:40.905: INFO: Number of nodes with available pods: 0
Feb 22 05:05:40.905: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:05:41.850: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:05:41.850: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:05:41.850: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:05:41.863: INFO: Number of nodes with available pods: 0
Feb 22 05:05:41.863: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:05:42.853: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:05:42.853: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:05:42.853: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:05:42.910: INFO: Number of nodes with available pods: 0
Feb 22 05:05:42.911: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:05:43.849: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:05:43.849: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:05:43.850: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:05:43.865: INFO: Number of nodes with available pods: 0
Feb 22 05:05:43.865: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:05:44.848: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:05:44.848: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:05:44.848: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:05:44.862: INFO: Number of nodes with available pods: 0
Feb 22 05:05:44.862: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:05:45.843: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:05:45.843: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:05:45.845: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:05:45.861: INFO: Number of nodes with available pods: 0
Feb 22 05:05:45.861: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:05:46.898: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:05:46.898: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:05:46.899: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:05:46.935: INFO: Number of nodes with available pods: 0
Feb 22 05:05:46.935: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:05:47.854: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:05:47.854: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:05:47.855: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:05:47.906: INFO: Number of nodes with available pods: 0
Feb 22 05:05:47.906: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:05:48.935: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:05:48.935: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:05:48.935: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:05:48.972: INFO: Number of nodes with available pods: 0
Feb 22 05:05:48.972: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:05:49.847: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:05:49.847: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:05:49.847: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:05:49.862: INFO: Number of nodes with available pods: 0
Feb 22 05:05:49.862: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:05:50.845: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:05:50.845: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:05:50.846: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:05:50.873: INFO: Number of nodes with available pods: 0
Feb 22 05:05:50.873: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:05:51.839: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:05:51.839: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:05:51.839: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:05:51.850: INFO: Number of nodes with available pods: 0
Feb 22 05:05:51.850: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:05:52.876: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:05:52.876: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:05:52.876: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:05:52.914: INFO: Number of nodes with available pods: 0
Feb 22 05:05:52.914: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:05:53.847: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:05:53.847: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:05:53.847: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:05:53.862: INFO: Number of nodes with available pods: 0
Feb 22 05:05:53.862: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:05:54.841: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:05:54.841: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:05:54.841: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:05:54.858: INFO: Number of nodes with available pods: 0
Feb 22 05:05:54.858: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:05:55.842: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:05:55.843: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:05:55.844: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:05:55.860: INFO: Number of nodes with available pods: 0
Feb 22 05:05:55.860: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:05:56.842: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:05:56.843: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:05:56.844: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:05:56.859: INFO: Number of nodes with available pods: 0
Feb 22 05:05:56.860: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:05:57.852: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:05:57.852: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:05:57.853: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:05:57.872: INFO: Number of nodes with available pods: 0
Feb 22 05:05:57.872: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:05:58.846: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:05:58.846: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:05:58.847: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:05:58.866: INFO: Number of nodes with available pods: 0
Feb 22 05:05:58.866: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:05:59.841: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:05:59.842: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:05:59.842: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:05:59.852: INFO: Number of nodes with available pods: 0
Feb 22 05:05:59.852: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:06:00.848: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:06:00.849: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:06:00.852: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:06:00.871: INFO: Number of nodes with available pods: 0
Feb 22 05:06:00.871: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:06:01.919: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:06:01.919: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:06:01.920: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:06:01.967: INFO: Number of nodes with available pods: 0
Feb 22 05:06:01.967: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:06:02.874: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:06:02.874: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:06:02.875: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:06:02.909: INFO: Number of nodes with available pods: 0
Feb 22 05:06:02.910: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:06:03.868: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:06:03.868: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:06:03.868: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:06:03.919: INFO: Number of nodes with available pods: 0
Feb 22 05:06:03.919: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:06:04.855: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:06:04.855: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:06:04.856: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:06:04.879: INFO: Number of nodes with available pods: 0
Feb 22 05:06:04.879: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:06:05.840: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:06:05.843: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:06:05.844: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:06:05.860: INFO: Number of nodes with available pods: 0
Feb 22 05:06:05.860: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:06:06.851: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:06:06.851: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:06:06.851: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:06:06.873: INFO: Number of nodes with available pods: 0
Feb 22 05:06:06.873: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:06:07.838: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:06:07.838: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:06:07.838: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:06:07.853: INFO: Number of nodes with available pods: 1
Feb 22 05:06:07.853: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:06:08.836: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:06:08.836: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:06:08.836: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:06:08.851: INFO: Number of nodes with available pods: 1
Feb 22 05:06:08.851: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:06:09.919: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:06:09.919: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:06:09.919: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:06:10.008: INFO: Number of nodes with available pods: 1
Feb 22 05:06:10.008: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:06:10.851: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:06:10.851: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:06:10.851: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:06:10.867: INFO: Number of nodes with available pods: 1
Feb 22 05:06:10.867: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:06:11.874: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:06:11.874: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:06:11.874: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:06:11.883: INFO: Number of nodes with available pods: 1
Feb 22 05:06:11.883: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:06:12.855: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:06:12.855: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:06:12.855: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:06:12.887: INFO: Number of nodes with available pods: 2
Feb 22 05:06:12.888: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:06:13.843: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:06:13.844: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:06:13.844: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:06:13.857: INFO: Number of nodes with available pods: 3
Feb 22 05:06:13.857: INFO: Number of running nodes: 3, number of available pods: 3
Feb 22 05:06:13.857: INFO: Update the DaemonSet to trigger a rollout
Feb 22 05:06:13.886: INFO: Updating DaemonSet daemon-set
Feb 22 05:06:27.998: INFO: Roll back the DaemonSet before rollout is complete
Feb 22 05:06:28.112: INFO: Updating DaemonSet daemon-set
Feb 22 05:06:28.112: INFO: Make sure DaemonSet rollback is complete
Feb 22 05:06:28.130: INFO: Wrong image for pod: daemon-set-8qt2k. Expected: mirror.gcr.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Feb 22 05:06:28.130: INFO: Pod daemon-set-8qt2k is not available
Feb 22 05:06:28.146: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:06:28.147: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:06:28.148: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:06:29.167: INFO: Pod daemon-set-hbqpw is not available
Feb 22 05:06:29.208: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:06:29.209: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:06:29.209: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4344, will wait for the garbage collector to delete the pods
Feb 22 05:06:29.501: INFO: Deleting DaemonSet.extensions daemon-set took: 90.355398ms
Feb 22 05:06:31.402: INFO: Terminating DaemonSet.extensions daemon-set pods took: 1.900784628s
Feb 22 05:06:48.116: INFO: Number of nodes with available pods: 0
Feb 22 05:06:48.116: INFO: Number of running nodes: 0, number of available pods: 0
Feb 22 05:06:48.144: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-4344/daemonsets","resourceVersion":"93385"},"items":null}

Feb 22 05:06:48.156: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-4344/pods","resourceVersion":"93385"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 05:06:48.212: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4344" for this suite.

â€¢ [SLOW TEST:70.176 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]","total":270,"completed":82,"skipped":1340,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 05:06:48.435: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-232
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:74
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Feb 22 05:06:48.907: INFO: Pod name rollover-pod: Found 0 pods out of 1
Feb 22 05:06:53.922: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 22 05:07:13.972: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Feb 22 05:07:15.978: INFO: Creating deployment "test-rollover-deployment"
Feb 22 05:07:16.016: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Feb 22 05:07:18.069: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Feb 22 05:07:18.088: INFO: Ensure that both replica sets have 1 created replica
Feb 22 05:07:18.104: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Feb 22 05:07:18.168: INFO: Updating deployment test-rollover-deployment
Feb 22 05:07:18.169: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Feb 22 05:07:20.194: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Feb 22 05:07:20.210: INFO: Make sure deployment "test-rollover-deployment" is complete
Feb 22 05:07:20.230: INFO: all replica sets need to contain the pod-template-hash label
Feb 22 05:07:20.231: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567236, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567236, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567238, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567236, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:07:22.268: INFO: all replica sets need to contain the pod-template-hash label
Feb 22 05:07:22.269: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567236, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567236, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567238, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567236, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:07:24.251: INFO: all replica sets need to contain the pod-template-hash label
Feb 22 05:07:24.252: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567236, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567236, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567238, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567236, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:07:26.305: INFO: all replica sets need to contain the pod-template-hash label
Feb 22 05:07:26.305: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567236, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567236, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567238, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567236, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:07:28.316: INFO: all replica sets need to contain the pod-template-hash label
Feb 22 05:07:28.316: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567236, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567236, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567238, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567236, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:07:30.261: INFO: all replica sets need to contain the pod-template-hash label
Feb 22 05:07:30.261: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567236, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567236, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567238, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567236, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:07:32.253: INFO: all replica sets need to contain the pod-template-hash label
Feb 22 05:07:32.253: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567236, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567236, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567238, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567236, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:07:34.246: INFO: all replica sets need to contain the pod-template-hash label
Feb 22 05:07:34.246: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567236, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567236, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567238, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567236, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:07:36.246: INFO: all replica sets need to contain the pod-template-hash label
Feb 22 05:07:36.246: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567236, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567236, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567238, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567236, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:07:38.261: INFO: all replica sets need to contain the pod-template-hash label
Feb 22 05:07:38.261: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567236, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567236, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567238, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567236, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:07:40.248: INFO: all replica sets need to contain the pod-template-hash label
Feb 22 05:07:40.248: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567236, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567236, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567238, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567236, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:07:42.258: INFO: all replica sets need to contain the pod-template-hash label
Feb 22 05:07:42.258: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567236, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567236, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567238, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567236, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:07:44.248: INFO: all replica sets need to contain the pod-template-hash label
Feb 22 05:07:44.249: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567236, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567236, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567264, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567236, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:07:46.257: INFO: all replica sets need to contain the pod-template-hash label
Feb 22 05:07:46.257: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567236, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567236, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567264, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567236, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:07:48.252: INFO: all replica sets need to contain the pod-template-hash label
Feb 22 05:07:48.252: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567236, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567236, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567264, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567236, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:07:50.260: INFO: all replica sets need to contain the pod-template-hash label
Feb 22 05:07:50.260: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567236, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567236, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567264, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567236, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:07:52.250: INFO: all replica sets need to contain the pod-template-hash label
Feb 22 05:07:52.250: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567236, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567236, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567264, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567236, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:07:54.311: INFO: 
Feb 22 05:07:54.311: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:2, UnavailableReplicas:0, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567236, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567236, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567274, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749567236, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:07:56.307: INFO: 
Feb 22 05:07:56.307: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
Feb 22 05:07:56.393: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-232 /apis/apps/v1/namespaces/deployment-232/deployments/test-rollover-deployment fb7b651b-f398-442a-9682-c55e9698f1ec 94207 2 2021-02-22 05:07:15 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2021-02-22 05:07:18 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 109 105 110 82 101 97 100 121 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 112 114 111 103 114 101 115 115 68 101 97 100 108 105 110 101 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 118 105 115 105 111 110 72 105 115 116 111 114 121 76 105 109 105 116 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 116 114 97 116 101 103 121 34 58 123 34 102 58 114 111 108 108 105 110 103 85 112 100 97 116 101 34 58 123 34 46 34 58 123 125 44 34 102 58 109 97 120 83 117 114 103 101 34 58 123 125 44 34 102 58 109 97 120 85 110 97 118 97 105 108 97 98 108 101 34 58 123 125 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2021-02-22 05:07:54 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 65 118 97 105 108 97 98 108 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 80 114 111 103 114 101 115 115 105 110 103 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 112 100 97 116 101 100 82 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc007feb3d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2021-02-22 05:07:16 +0000 UTC,LastTransitionTime:2021-02-22 05:07:16 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-84f7f6f64b" has successfully progressed.,LastUpdateTime:2021-02-22 05:07:54 +0000 UTC,LastTransitionTime:2021-02-22 05:07:16 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Feb 22 05:07:56.412: INFO: New ReplicaSet "test-rollover-deployment-84f7f6f64b" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-84f7f6f64b  deployment-232 /apis/apps/v1/namespaces/deployment-232/replicasets/test-rollover-deployment-84f7f6f64b b0f2d75b-0c07-4392-b26d-6a1dce176094 94197 2 2021-02-22 05:07:18 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:84f7f6f64b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment fb7b651b-f398-442a-9682-c55e9698f1ec 0xc007feba27 0xc007feba28}] []  [{kube-controller-manager Update apps/v1 2021-02-22 05:07:54 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 102 98 55 98 54 53 49 98 45 102 51 57 56 45 52 52 50 97 45 57 54 56 50 45 99 53 53 101 57 54 57 56 102 49 101 99 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 109 105 110 82 101 97 100 121 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 84f7f6f64b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:84f7f6f64b] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc007febab8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Feb 22 05:07:56.413: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Feb 22 05:07:56.415: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-232 /apis/apps/v1/namespaces/deployment-232/replicasets/test-rollover-controller 317f1966-3449-4bbe-9996-cc33772e3d86 94206 2 2021-02-22 05:06:48 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment fb7b651b-f398-442a-9682-c55e9698f1ec 0xc007feb817 0xc007feb818}] []  [{e2e.test Update apps/v1 2021-02-22 05:06:48 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2021-02-22 05:07:54 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 102 98 55 98 54 53 49 98 45 102 51 57 56 45 52 52 50 97 45 57 54 56 50 45 99 53 53 101 57 54 57 56 102 49 101 99 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] []  []} {[] [] [{httpd mirror.gcr.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc007feb8b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Feb 22 05:07:56.422: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-5686c4cfd5  deployment-232 /apis/apps/v1/namespaces/deployment-232/replicasets/test-rollover-deployment-5686c4cfd5 13077d62-ed91-4310-9169-e7dd135a4271 93826 2 2021-02-22 05:07:16 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:5686c4cfd5] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment fb7b651b-f398-442a-9682-c55e9698f1ec 0xc007feb927 0xc007feb928}] []  [{kube-controller-manager Update apps/v1 2021-02-22 05:07:18 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 102 98 55 98 54 53 49 98 45 102 51 57 56 45 52 52 50 97 45 57 54 56 50 45 99 53 53 101 57 54 57 56 102 49 101 99 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 109 105 110 82 101 97 100 121 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 114 101 100 105 115 45 115 108 97 118 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 5686c4cfd5,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:5686c4cfd5] map[] [] []  []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc007feb9b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Feb 22 05:07:56.455: INFO: Pod "test-rollover-controller-6lkvq" is available:
&Pod{ObjectMeta:{test-rollover-controller-6lkvq test-rollover-controller- deployment-232 /api/v1/namespaces/deployment-232/pods/test-rollover-controller-6lkvq bb085040-0908-4e52-88d8-9bc63164469b 94201 0 2021-02-22 05:06:48 +0000 UTC 2021-02-22 05:07:54 +0000 UTC 0xc007e9c068 map[name:rollover-pod pod:httpd] map[attachment_id:64646be2-0d95-4739-9310-00d53f3f4837 kubernetes.io/psp:e2e-test-privileged-psp mac:04:50:56:00:28:0e vlan:None vmware-system-ephemeral-disk-uuid:6000C292-8061-2d24-082c-78c91913a872 vmware-system-image-references:{"httpd":"httpd-d22d0e2cfeeaa0c1d2773814f5199d564ac0eae2-v63281"} vmware-system-vm-moid:vm-443:6b180790-afb7-40a7-b1c1-16f00c9b6783 vmware-system-vm-uuid:502f044c-22d8-cbdc-0184-576027a50518] [{apps/v1 ReplicaSet test-rollover-controller 317f1966-3449-4bbe-9996-cc33772e3d86 0xc007e9c0b7 0xc007e9c0b8}] [lifecycle-controller/system.vmware.com]  [{kube-controller-manager Update v1 2021-02-22 05:06:48 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 51 49 55 102 49 57 54 54 45 51 52 52 57 45 52 98 98 101 45 57 57 57 54 45 99 99 51 51 55 55 50 101 51 100 56 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {image-controller Update v1 2021-02-22 05:06:49 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 105 109 97 103 101 45 114 101 102 101 114 101 110 99 101 115 34 58 123 125 125 125 125],}} {nsx-ncp-75bf644549-ps9h2 Update v1 2021-02-22 05:06:56 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 97 116 116 97 99 104 109 101 110 116 95 105 100 34 58 123 125 44 34 102 58 109 97 99 34 58 123 125 44 34 102 58 118 108 97 110 34 58 123 125 125 125 125],}} {scheduler-extender Update v1 2021-02-22 05:07:04 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 101 112 104 101 109 101 114 97 108 45 100 105 115 107 45 117 117 105 100 34 58 123 125 44 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 118 109 45 109 111 105 100 34 58 123 125 44 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 118 109 45 117 117 105 100 34 58 123 125 125 44 34 102 58 102 105 110 97 108 105 122 101 114 115 34 58 123 34 46 34 58 123 125 44 34 118 58 92 34 108 105 102 101 99 121 99 108 101 45 99 111 110 116 114 111 108 108 101 114 47 115 121 115 116 101 109 46 118 109 119 97 114 101 46 99 111 109 92 34 34 58 123 125 125 125 125],}} {spherelet Update v1 2021-02-22 05:07:13 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 102 58 101 110 118 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 95 52 52 51 95 84 67 80 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 95 52 52 51 95 84 67 80 95 65 68 68 82 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 95 52 52 51 95 84 67 80 95 80 79 82 84 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 95 52 52 51 95 84 67 80 95 80 82 79 84 79 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 83 69 82 86 73 67 69 95 72 79 83 84 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 83 69 82 86 73 67 69 95 80 79 82 84 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 83 69 82 86 73 67 69 95 80 79 82 84 95 72 84 84 80 83 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 55 50 46 50 54 46 49 46 50 49 48 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-hxv4g,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-hxv4g,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:mirror.gcr.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-hxv4g,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:sc2-rdops-vm05-dhcp-174-51.eng.vmware.com,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 05:06:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 05:07:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 05:07:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 05:07:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.192.174.51,PodIP:172.26.1.210,StartTime:2021-02-22 05:07:10 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2021-02-22 05:07:11 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:mirror.gcr.io/library/httpd:2.4.38-alpine,ImageID:httpd-d22d0e2cfeeaa0c1d2773814f5199d564ac0eae2-v63281,ContainerID:6ed69909-c427-470a-88af-bba5a78ef9b7,Started:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.26.1.210,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 22 05:07:56.458: INFO: Pod "test-rollover-deployment-84f7f6f64b-db7c8" is available:
&Pod{ObjectMeta:{test-rollover-deployment-84f7f6f64b-db7c8 test-rollover-deployment-84f7f6f64b- deployment-232 /api/v1/namespaces/deployment-232/pods/test-rollover-deployment-84f7f6f64b-db7c8 f9b5a180-2ee5-4c7d-a07a-9a7c389114b8 94099 0 2021-02-22 05:07:18 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:84f7f6f64b] map[attachment_id:cf24429a-0bc7-4a83-9a12-d9d345759cb2 kubernetes.io/psp:e2e-test-privileged-psp mac:04:50:56:00:28:03 vlan:None vmware-system-ephemeral-disk-uuid:6000C29f-b578-665e-aa98-f3785659a74e vmware-system-image-references:{"agnhost":"agnhost-4c5d323a799f707178acf281f8da2d9a581ad331-v70822"} vmware-system-vm-moid:vm-446:6b180790-afb7-40a7-b1c1-16f00c9b6783 vmware-system-vm-uuid:502f8b34-77a5-9d8a-2e1e-17abe3c3b87b] [{apps/v1 ReplicaSet test-rollover-deployment-84f7f6f64b b0f2d75b-0c07-4392-b26d-6a1dce176094 0xc007e9c2cf 0xc007e9c2e0}] [lifecycle-controller/system.vmware.com]  [{image-controller Update v1 2021-02-22 05:07:18 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 105 109 97 103 101 45 114 101 102 101 114 101 110 99 101 115 34 58 123 125 125 125 125],}} {kube-controller-manager Update v1 2021-02-22 05:07:18 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 98 48 102 50 100 55 53 98 45 48 99 48 55 45 52 51 57 50 45 98 50 54 100 45 54 97 49 100 99 101 49 55 54 48 57 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {nsx-ncp-75bf644549-ps9h2 Update v1 2021-02-22 05:07:19 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 97 116 116 97 99 104 109 101 110 116 95 105 100 34 58 123 125 44 34 102 58 109 97 99 34 58 123 125 44 34 102 58 118 108 97 110 34 58 123 125 125 125 125],}} {scheduler-extender Update v1 2021-02-22 05:07:37 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 101 112 104 101 109 101 114 97 108 45 100 105 115 107 45 117 117 105 100 34 58 123 125 44 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 118 109 45 109 111 105 100 34 58 123 125 44 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 118 109 45 117 117 105 100 34 58 123 125 125 44 34 102 58 102 105 110 97 108 105 122 101 114 115 34 58 123 34 46 34 58 123 125 44 34 118 58 92 34 108 105 102 101 99 121 99 108 101 45 99 111 110 116 114 111 108 108 101 114 47 115 121 115 116 101 109 46 118 109 119 97 114 101 46 99 111 109 92 34 34 58 123 125 125 125 125],}} {spherelet Update v1 2021-02-22 05:07:44 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 102 58 101 110 118 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 95 52 52 51 95 84 67 80 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 95 52 52 51 95 84 67 80 95 65 68 68 82 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 95 52 52 51 95 84 67 80 95 80 79 82 84 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 95 52 52 51 95 84 67 80 95 80 82 79 84 79 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 83 69 82 86 73 67 69 95 72 79 83 84 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 83 69 82 86 73 67 69 95 80 79 82 84 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 83 69 82 86 73 67 69 95 80 79 82 84 95 72 84 84 80 83 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 55 50 46 50 54 46 49 46 50 49 50 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-hxv4g,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-hxv4g,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-hxv4g,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:sc2-rdops-vm05-dhcp-174-51.eng.vmware.com,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 05:07:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 05:07:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 05:07:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 05:07:44 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.192.174.51,PodIP:172.26.1.212,StartTime:2021-02-22 05:07:42 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2021-02-22 05:07:43 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,ImageID:agnhost-4c5d323a799f707178acf281f8da2d9a581ad331-v70822,ContainerID:663659bc-9e30-425f-bc07-c3ea5ee14829,Started:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.26.1.212,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 05:07:56.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-232" for this suite.

â€¢ [SLOW TEST:68.127 seconds]
[sig-apps] Deployment
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should support rollover [Conformance]","total":270,"completed":83,"skipped":1358,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 05:07:56.609: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-9864
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a ResourceQuota with terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a long running pod
STEP: Ensuring resource quota with not terminating scope captures the pod usage
STEP: Ensuring resource quota with terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a terminating pod
STEP: Ensuring resource quota with terminating scope captures the pod usage
STEP: Ensuring resource quota with not terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 05:08:16.104: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9864" for this suite.

â€¢ [SLOW TEST:19.647 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]","total":270,"completed":84,"skipped":1401,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 05:08:16.286: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-2391
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-2391
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-2391
STEP: creating replication controller externalsvc in namespace services-2391
STEP: changing the ClusterIP service to type=ExternalName
Feb 22 05:08:53.354: INFO: Creating new exec pod
Feb 22 05:09:15.423: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=services-2391 execpod6bzq6 -- /bin/sh -x -c nslookup clusterip-service'
Feb 22 05:09:16.271: INFO: stderr: "+ nslookup clusterip-service\n"
Feb 22 05:09:16.271: INFO: stdout: "Server:\t\t172.24.0.10\nAddress:\t172.24.0.10#53\n\nclusterip-service.services-2391.svc.cluster.local\tcanonical name = externalsvc.services-2391.svc.cluster.local.\nName:\texternalsvc.services-2391.svc.cluster.local\nAddress: 172.24.109.164\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-2391, will wait for the garbage collector to delete the pods
Feb 22 05:09:16.369: INFO: Deleting ReplicationController externalsvc took: 33.980444ms
Feb 22 05:09:18.170: INFO: Terminating ReplicationController externalsvc pods took: 1.800439065s
Feb 22 05:09:37.939: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 05:09:38.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2391" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702

â€¢ [SLOW TEST:81.908 seconds]
[sig-network] Services
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]","total":270,"completed":85,"skipped":1431,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 05:09:38.205: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1783
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Kubectl logs
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1288
STEP: creating an pod
Feb 22 05:09:40.459: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config run logs-generator --image=us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 --namespace=kubectl-1783 -- logs-generator --log-lines-total 100 --run-duration 20s'
Feb 22 05:09:40.862: INFO: stderr: ""
Feb 22 05:09:40.862: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Waiting for log generator to start.
Feb 22 05:09:40.863: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Feb 22 05:09:40.864: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-1783" to be "running and ready, or succeeded"
Feb 22 05:09:40.876: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 11.779965ms
Feb 22 05:09:42.895: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031333418s
Feb 22 05:09:44.914: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 4.05036135s
Feb 22 05:09:46.939: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 6.074970082s
Feb 22 05:09:48.951: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 8.086900547s
Feb 22 05:09:50.959: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 10.095298544s
Feb 22 05:09:52.979: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 12.114681121s
Feb 22 05:09:54.990: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 14.126422071s
Feb 22 05:09:57.013: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 16.14927104s
Feb 22 05:09:59.024: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 18.160083601s
Feb 22 05:10:01.063: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 20.199350888s
Feb 22 05:10:03.078: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 22.214568832s
Feb 22 05:10:05.158: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 24.293619849s
Feb 22 05:10:07.169: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 26.30493024s
Feb 22 05:10:09.195: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 28.330901007s
Feb 22 05:10:09.195: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Feb 22 05:10:09.195: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings
Feb 22 05:10:09.195: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config logs logs-generator logs-generator --namespace=kubectl-1783'
Feb 22 05:10:09.707: INFO: stderr: ""
Feb 22 05:10:09.709: INFO: stdout: "I0222 05:10:04.579551       1 logs_generator.go:76] 0 POST /api/v1/namespaces/kube-system/pods/5h46 429\nI0222 05:10:04.776340       1 logs_generator.go:76] 1 POST /api/v1/namespaces/default/pods/p9t 272\nI0222 05:10:04.976461       1 logs_generator.go:76] 2 POST /api/v1/namespaces/default/pods/hmx 503\nI0222 05:10:05.176409       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/ns/pods/9pzc 502\nI0222 05:10:05.376390       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/ns/pods/zcz 532\nI0222 05:10:05.576394       1 logs_generator.go:76] 5 POST /api/v1/namespaces/ns/pods/q8mx 245\nI0222 05:10:05.776769       1 logs_generator.go:76] 6 GET /api/v1/namespaces/default/pods/knvd 576\nI0222 05:10:05.976427       1 logs_generator.go:76] 7 POST /api/v1/namespaces/ns/pods/8z7 415\nI0222 05:10:06.176393       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/default/pods/flz 231\nI0222 05:10:06.376700       1 logs_generator.go:76] 9 GET /api/v1/namespaces/kube-system/pods/kqs 431\nI0222 05:10:06.591416       1 logs_generator.go:76] 10 POST /api/v1/namespaces/default/pods/vtlk 569\nI0222 05:10:06.776534       1 logs_generator.go:76] 11 POST /api/v1/namespaces/default/pods/r6gh 334\nI0222 05:10:06.976665       1 logs_generator.go:76] 12 PUT /api/v1/namespaces/ns/pods/sgln 399\nI0222 05:10:07.176566       1 logs_generator.go:76] 13 GET /api/v1/namespaces/kube-system/pods/vfq 347\nI0222 05:10:07.376542       1 logs_generator.go:76] 14 PUT /api/v1/namespaces/ns/pods/jbrv 232\nI0222 05:10:07.576474       1 logs_generator.go:76] 15 POST /api/v1/namespaces/default/pods/mn5s 309\nI0222 05:10:07.776408       1 logs_generator.go:76] 16 PUT /api/v1/namespaces/default/pods/6fd 494\nI0222 05:10:07.976413       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/kube-system/pods/vdwb 224\nI0222 05:10:08.176472       1 logs_generator.go:76] 18 POST /api/v1/namespaces/ns/pods/tnx 427\nI0222 05:10:08.376371       1 logs_generator.go:76] 19 POST /api/v1/namespaces/default/pods/rwwd 531\nI0222 05:10:08.576561       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/ns/pods/bvz 371\nI0222 05:10:08.776417       1 logs_generator.go:76] 21 PUT /api/v1/namespaces/kube-system/pods/hr6l 424\nI0222 05:10:08.976569       1 logs_generator.go:76] 22 GET /api/v1/namespaces/kube-system/pods/gtj 243\nI0222 05:10:09.176355       1 logs_generator.go:76] 23 POST /api/v1/namespaces/default/pods/6xs 559\nI0222 05:10:09.376414       1 logs_generator.go:76] 24 POST /api/v1/namespaces/default/pods/dzm9 255\nI0222 05:10:09.576298       1 logs_generator.go:76] 25 PUT /api/v1/namespaces/default/pods/6k8c 301\nI0222 05:10:09.776429       1 logs_generator.go:76] 26 GET /api/v1/namespaces/default/pods/5rmc 472\nI0222 05:10:09.976468       1 logs_generator.go:76] 27 PUT /api/v1/namespaces/default/pods/bls 304\nI0222 05:10:10.176450       1 logs_generator.go:76] 28 GET /api/v1/namespaces/kube-system/pods/gjsw 463\n"
STEP: limiting log lines
Feb 22 05:10:09.712: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config logs logs-generator logs-generator --namespace=kubectl-1783 --tail=1'
Feb 22 05:10:10.103: INFO: stderr: ""
Feb 22 05:10:10.103: INFO: stdout: "I0222 05:10:10.576617       1 logs_generator.go:76] 30 GET /api/v1/namespaces/ns/pods/22qf 334\n"
Feb 22 05:10:10.103: INFO: got output "I0222 05:10:10.576617       1 logs_generator.go:76] 30 GET /api/v1/namespaces/ns/pods/22qf 334\n"
STEP: limiting log bytes
Feb 22 05:10:10.103: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config logs logs-generator logs-generator --namespace=kubectl-1783 --limit-bytes=1'
Feb 22 05:10:10.483: INFO: stderr: ""
Feb 22 05:10:10.484: INFO: stdout: "I"
Feb 22 05:10:10.484: INFO: got output "I"
STEP: exposing timestamps
Feb 22 05:10:10.484: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config logs logs-generator logs-generator --namespace=kubectl-1783 --tail=1 --timestamps'
Feb 22 05:10:10.899: INFO: stderr: ""
Feb 22 05:10:10.899: INFO: stdout: "2021-02-22T05:10:11.376760761Z I0222 05:10:11.376537       1 logs_generator.go:76] 34 PUT /api/v1/namespaces/ns/pods/frb 591\n"
Feb 22 05:10:10.899: INFO: got output "2021-02-22T05:10:11.376760761Z I0222 05:10:11.376537       1 logs_generator.go:76] 34 PUT /api/v1/namespaces/ns/pods/frb 591\n"
STEP: restricting to a time range
Feb 22 05:10:13.400: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config logs logs-generator logs-generator --namespace=kubectl-1783 --since=1s'
Feb 22 05:10:14.285: INFO: stderr: ""
Feb 22 05:10:14.286: INFO: stdout: "I0222 05:10:13.976658       1 logs_generator.go:76] 47 POST /api/v1/namespaces/default/pods/z28v 354\nI0222 05:10:14.176445       1 logs_generator.go:76] 48 GET /api/v1/namespaces/kube-system/pods/k49 282\nI0222 05:10:14.376515       1 logs_generator.go:76] 49 POST /api/v1/namespaces/default/pods/5pb 573\nI0222 05:10:14.576442       1 logs_generator.go:76] 50 GET /api/v1/namespaces/ns/pods/wsm 550\nI0222 05:10:14.776567       1 logs_generator.go:76] 51 GET /api/v1/namespaces/default/pods/vpqw 483\n"
Feb 22 05:10:14.286: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config logs logs-generator logs-generator --namespace=kubectl-1783 --since=24h'
Feb 22 05:10:14.874: INFO: stderr: ""
Feb 22 05:10:14.874: INFO: stdout: "I0222 05:10:04.579551       1 logs_generator.go:76] 0 POST /api/v1/namespaces/kube-system/pods/5h46 429\nI0222 05:10:04.776340       1 logs_generator.go:76] 1 POST /api/v1/namespaces/default/pods/p9t 272\nI0222 05:10:04.976461       1 logs_generator.go:76] 2 POST /api/v1/namespaces/default/pods/hmx 503\nI0222 05:10:05.176409       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/ns/pods/9pzc 502\nI0222 05:10:05.376390       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/ns/pods/zcz 532\nI0222 05:10:05.576394       1 logs_generator.go:76] 5 POST /api/v1/namespaces/ns/pods/q8mx 245\nI0222 05:10:05.776769       1 logs_generator.go:76] 6 GET /api/v1/namespaces/default/pods/knvd 576\nI0222 05:10:05.976427       1 logs_generator.go:76] 7 POST /api/v1/namespaces/ns/pods/8z7 415\nI0222 05:10:06.176393       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/default/pods/flz 231\nI0222 05:10:06.376700       1 logs_generator.go:76] 9 GET /api/v1/namespaces/kube-system/pods/kqs 431\nI0222 05:10:06.591416       1 logs_generator.go:76] 10 POST /api/v1/namespaces/default/pods/vtlk 569\nI0222 05:10:06.776534       1 logs_generator.go:76] 11 POST /api/v1/namespaces/default/pods/r6gh 334\nI0222 05:10:06.976665       1 logs_generator.go:76] 12 PUT /api/v1/namespaces/ns/pods/sgln 399\nI0222 05:10:07.176566       1 logs_generator.go:76] 13 GET /api/v1/namespaces/kube-system/pods/vfq 347\nI0222 05:10:07.376542       1 logs_generator.go:76] 14 PUT /api/v1/namespaces/ns/pods/jbrv 232\nI0222 05:10:07.576474       1 logs_generator.go:76] 15 POST /api/v1/namespaces/default/pods/mn5s 309\nI0222 05:10:07.776408       1 logs_generator.go:76] 16 PUT /api/v1/namespaces/default/pods/6fd 494\nI0222 05:10:07.976413       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/kube-system/pods/vdwb 224\nI0222 05:10:08.176472       1 logs_generator.go:76] 18 POST /api/v1/namespaces/ns/pods/tnx 427\nI0222 05:10:08.376371       1 logs_generator.go:76] 19 POST /api/v1/namespaces/default/pods/rwwd 531\nI0222 05:10:08.576561       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/ns/pods/bvz 371\nI0222 05:10:08.776417       1 logs_generator.go:76] 21 PUT /api/v1/namespaces/kube-system/pods/hr6l 424\nI0222 05:10:08.976569       1 logs_generator.go:76] 22 GET /api/v1/namespaces/kube-system/pods/gtj 243\nI0222 05:10:09.176355       1 logs_generator.go:76] 23 POST /api/v1/namespaces/default/pods/6xs 559\nI0222 05:10:09.376414       1 logs_generator.go:76] 24 POST /api/v1/namespaces/default/pods/dzm9 255\nI0222 05:10:09.576298       1 logs_generator.go:76] 25 PUT /api/v1/namespaces/default/pods/6k8c 301\nI0222 05:10:09.776429       1 logs_generator.go:76] 26 GET /api/v1/namespaces/default/pods/5rmc 472\nI0222 05:10:09.976468       1 logs_generator.go:76] 27 PUT /api/v1/namespaces/default/pods/bls 304\nI0222 05:10:10.176450       1 logs_generator.go:76] 28 GET /api/v1/namespaces/kube-system/pods/gjsw 463\nI0222 05:10:10.376400       1 logs_generator.go:76] 29 PUT /api/v1/namespaces/kube-system/pods/2qg 365\nI0222 05:10:10.576617       1 logs_generator.go:76] 30 GET /api/v1/namespaces/ns/pods/22qf 334\nI0222 05:10:10.776441       1 logs_generator.go:76] 31 POST /api/v1/namespaces/ns/pods/7jq 593\nI0222 05:10:10.976719       1 logs_generator.go:76] 32 POST /api/v1/namespaces/kube-system/pods/g4dl 489\nI0222 05:10:11.176651       1 logs_generator.go:76] 33 POST /api/v1/namespaces/ns/pods/ql4n 466\nI0222 05:10:11.376537       1 logs_generator.go:76] 34 PUT /api/v1/namespaces/ns/pods/frb 591\nI0222 05:10:11.576428       1 logs_generator.go:76] 35 PUT /api/v1/namespaces/ns/pods/chx 343\nI0222 05:10:11.776456       1 logs_generator.go:76] 36 GET /api/v1/namespaces/kube-system/pods/fhpn 228\nI0222 05:10:11.976629       1 logs_generator.go:76] 37 PUT /api/v1/namespaces/default/pods/7b4 362\nI0222 05:10:12.176445       1 logs_generator.go:76] 38 POST /api/v1/namespaces/kube-system/pods/84q 384\nI0222 05:10:12.376429       1 logs_generator.go:76] 39 POST /api/v1/namespaces/default/pods/tnhf 245\nI0222 05:10:12.576365       1 logs_generator.go:76] 40 GET /api/v1/namespaces/kube-system/pods/wbfw 259\nI0222 05:10:12.776414       1 logs_generator.go:76] 41 GET /api/v1/namespaces/kube-system/pods/d2sb 400\nI0222 05:10:12.976404       1 logs_generator.go:76] 42 GET /api/v1/namespaces/ns/pods/knn 251\nI0222 05:10:13.176292       1 logs_generator.go:76] 43 GET /api/v1/namespaces/kube-system/pods/2q4k 426\nI0222 05:10:13.376449       1 logs_generator.go:76] 44 GET /api/v1/namespaces/ns/pods/dlw 512\nI0222 05:10:13.576504       1 logs_generator.go:76] 45 POST /api/v1/namespaces/ns/pods/7q9 474\nI0222 05:10:13.776642       1 logs_generator.go:76] 46 PUT /api/v1/namespaces/default/pods/rwrm 498\nI0222 05:10:13.976658       1 logs_generator.go:76] 47 POST /api/v1/namespaces/default/pods/z28v 354\nI0222 05:10:14.176445       1 logs_generator.go:76] 48 GET /api/v1/namespaces/kube-system/pods/k49 282\nI0222 05:10:14.376515       1 logs_generator.go:76] 49 POST /api/v1/namespaces/default/pods/5pb 573\nI0222 05:10:14.576442       1 logs_generator.go:76] 50 GET /api/v1/namespaces/ns/pods/wsm 550\nI0222 05:10:14.776567       1 logs_generator.go:76] 51 GET /api/v1/namespaces/default/pods/vpqw 483\nI0222 05:10:14.976508       1 logs_generator.go:76] 52 GET /api/v1/namespaces/kube-system/pods/wf9 461\nI0222 05:10:15.176398       1 logs_generator.go:76] 53 PUT /api/v1/namespaces/default/pods/mwc 291\nI0222 05:10:15.376383       1 logs_generator.go:76] 54 POST /api/v1/namespaces/default/pods/tkj 488\n"
[AfterEach] Kubectl logs
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1294
Feb 22 05:10:14.875: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config delete pod logs-generator --namespace=kubectl-1783'
Feb 22 05:10:26.724: INFO: stderr: ""
Feb 22 05:10:26.724: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 05:10:26.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1783" for this suite.

â€¢ [SLOW TEST:48.612 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl logs
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1284
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl logs should be able to retrieve and filter logs  [Conformance]","total":270,"completed":86,"skipped":1454,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 05:10:26.852: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3178
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-6f16b60b-ab16-4c57-936a-8b3d976be426
STEP: Creating a pod to test consume configMaps
Feb 22 05:10:27.283: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-6a1ad100-8609-4e11-af05-f23051c6ed0e" in namespace "projected-3178" to be "Succeeded or Failed"
Feb 22 05:10:27.302: INFO: Pod "pod-projected-configmaps-6a1ad100-8609-4e11-af05-f23051c6ed0e": Phase="Pending", Reason="", readiness=false. Elapsed: 18.678055ms
Feb 22 05:10:29.316: INFO: Pod "pod-projected-configmaps-6a1ad100-8609-4e11-af05-f23051c6ed0e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032405051s
Feb 22 05:10:31.330: INFO: Pod "pod-projected-configmaps-6a1ad100-8609-4e11-af05-f23051c6ed0e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.046075548s
Feb 22 05:10:33.356: INFO: Pod "pod-projected-configmaps-6a1ad100-8609-4e11-af05-f23051c6ed0e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.072972748s
Feb 22 05:10:35.382: INFO: Pod "pod-projected-configmaps-6a1ad100-8609-4e11-af05-f23051c6ed0e": Phase="Pending", Reason="", readiness=false. Elapsed: 8.098308445s
Feb 22 05:10:37.441: INFO: Pod "pod-projected-configmaps-6a1ad100-8609-4e11-af05-f23051c6ed0e": Phase="Pending", Reason="", readiness=false. Elapsed: 10.157518269s
Feb 22 05:10:39.469: INFO: Pod "pod-projected-configmaps-6a1ad100-8609-4e11-af05-f23051c6ed0e": Phase="Pending", Reason="", readiness=false. Elapsed: 12.185652992s
Feb 22 05:10:41.477: INFO: Pod "pod-projected-configmaps-6a1ad100-8609-4e11-af05-f23051c6ed0e": Phase="Pending", Reason="", readiness=false. Elapsed: 14.193821538s
Feb 22 05:10:43.489: INFO: Pod "pod-projected-configmaps-6a1ad100-8609-4e11-af05-f23051c6ed0e": Phase="Pending", Reason="", readiness=false. Elapsed: 16.205174214s
Feb 22 05:10:45.506: INFO: Pod "pod-projected-configmaps-6a1ad100-8609-4e11-af05-f23051c6ed0e": Phase="Pending", Reason="", readiness=false. Elapsed: 18.222121872s
Feb 22 05:10:47.539: INFO: Pod "pod-projected-configmaps-6a1ad100-8609-4e11-af05-f23051c6ed0e": Phase="Pending", Reason="", readiness=false. Elapsed: 20.255072645s
Feb 22 05:10:49.554: INFO: Pod "pod-projected-configmaps-6a1ad100-8609-4e11-af05-f23051c6ed0e": Phase="Pending", Reason="", readiness=false. Elapsed: 22.270863149s
Feb 22 05:10:51.563: INFO: Pod "pod-projected-configmaps-6a1ad100-8609-4e11-af05-f23051c6ed0e": Phase="Pending", Reason="", readiness=false. Elapsed: 24.279403087s
Feb 22 05:10:53.883: INFO: Pod "pod-projected-configmaps-6a1ad100-8609-4e11-af05-f23051c6ed0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.599650318s
STEP: Saw pod success
Feb 22 05:10:53.888: INFO: Pod "pod-projected-configmaps-6a1ad100-8609-4e11-af05-f23051c6ed0e" satisfied condition "Succeeded or Failed"
Feb 22 05:10:54.003: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com pod pod-projected-configmaps-6a1ad100-8609-4e11-af05-f23051c6ed0e container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 22 05:10:54.474: INFO: Waiting for pod pod-projected-configmaps-6a1ad100-8609-4e11-af05-f23051c6ed0e to disappear
Feb 22 05:10:54.577: INFO: Pod pod-projected-configmaps-6a1ad100-8609-4e11-af05-f23051c6ed0e still exists
Feb 22 05:10:56.578: INFO: Waiting for pod pod-projected-configmaps-6a1ad100-8609-4e11-af05-f23051c6ed0e to disappear
Feb 22 05:10:56.614: INFO: Pod pod-projected-configmaps-6a1ad100-8609-4e11-af05-f23051c6ed0e still exists
Feb 22 05:10:58.579: INFO: Waiting for pod pod-projected-configmaps-6a1ad100-8609-4e11-af05-f23051c6ed0e to disappear
Feb 22 05:10:58.599: INFO: Pod pod-projected-configmaps-6a1ad100-8609-4e11-af05-f23051c6ed0e still exists
Feb 22 05:11:00.578: INFO: Waiting for pod pod-projected-configmaps-6a1ad100-8609-4e11-af05-f23051c6ed0e to disappear
Feb 22 05:11:00.590: INFO: Pod pod-projected-configmaps-6a1ad100-8609-4e11-af05-f23051c6ed0e still exists
Feb 22 05:11:02.578: INFO: Waiting for pod pod-projected-configmaps-6a1ad100-8609-4e11-af05-f23051c6ed0e to disappear
Feb 22 05:11:02.603: INFO: Pod pod-projected-configmaps-6a1ad100-8609-4e11-af05-f23051c6ed0e still exists
Feb 22 05:11:04.578: INFO: Waiting for pod pod-projected-configmaps-6a1ad100-8609-4e11-af05-f23051c6ed0e to disappear
Feb 22 05:11:04.592: INFO: Pod pod-projected-configmaps-6a1ad100-8609-4e11-af05-f23051c6ed0e still exists
Feb 22 05:11:06.578: INFO: Waiting for pod pod-projected-configmaps-6a1ad100-8609-4e11-af05-f23051c6ed0e to disappear
Feb 22 05:11:06.605: INFO: Pod pod-projected-configmaps-6a1ad100-8609-4e11-af05-f23051c6ed0e still exists
Feb 22 05:11:08.578: INFO: Waiting for pod pod-projected-configmaps-6a1ad100-8609-4e11-af05-f23051c6ed0e to disappear
Feb 22 05:11:08.629: INFO: Pod pod-projected-configmaps-6a1ad100-8609-4e11-af05-f23051c6ed0e still exists
Feb 22 05:11:10.578: INFO: Waiting for pod pod-projected-configmaps-6a1ad100-8609-4e11-af05-f23051c6ed0e to disappear
Feb 22 05:11:10.591: INFO: Pod pod-projected-configmaps-6a1ad100-8609-4e11-af05-f23051c6ed0e no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 05:11:10.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3178" for this suite.

â€¢ [SLOW TEST:43.815 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:36
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]","total":270,"completed":87,"skipped":1483,"failed":0}
SSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 05:11:10.674: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-9861
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Performing setup for networking test in namespace pod-network-test-9861
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 22 05:11:11.001: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Feb 22 05:11:11.130: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Feb 22 05:11:13.142: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Feb 22 05:11:15.140: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Feb 22 05:11:17.141: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Feb 22 05:11:19.201: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Feb 22 05:11:21.143: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Feb 22 05:11:23.138: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Feb 22 05:11:25.139: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Feb 22 05:11:27.140: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Feb 22 05:11:29.138: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Feb 22 05:11:31.139: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Feb 22 05:11:33.140: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Feb 22 05:11:35.141: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Feb 22 05:11:37.145: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Feb 22 05:11:39.190: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Feb 22 05:11:41.173: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Feb 22 05:11:43.210: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Feb 22 05:11:45.142: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Feb 22 05:11:47.144: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Feb 22 05:11:49.148: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Feb 22 05:11:51.140: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Feb 22 05:11:53.148: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Feb 22 05:11:55.137: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Feb 22 05:11:57.164: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Feb 22 05:11:59.178: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Feb 22 05:12:01.225: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Feb 22 05:12:03.154: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Feb 22 05:12:05.156: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Feb 22 05:12:07.157: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Feb 22 05:12:09.193: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Feb 22 05:12:11.176: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Feb 22 05:12:13.144: INFO: The status of Pod netserver-0 is Running (Ready = false)
Feb 22 05:12:15.140: INFO: The status of Pod netserver-0 is Running (Ready = false)
Feb 22 05:12:17.152: INFO: The status of Pod netserver-0 is Running (Ready = false)
Feb 22 05:12:19.138: INFO: The status of Pod netserver-0 is Running (Ready = false)
Feb 22 05:12:21.138: INFO: The status of Pod netserver-0 is Running (Ready = false)
Feb 22 05:12:23.142: INFO: The status of Pod netserver-0 is Running (Ready = true)
Feb 22 05:12:23.166: INFO: The status of Pod netserver-1 is Running (Ready = true)
Feb 22 05:12:23.183: INFO: The status of Pod netserver-2 is Running (Ready = true)
STEP: Creating test pods
Feb 22 05:12:43.274: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.26.1.197:8080/dial?request=hostname&protocol=udp&host=172.26.1.194&port=8081&tries=1'] Namespace:pod-network-test-9861 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 22 05:12:43.282: INFO: >>> kubeConfig: /root/.kube/config
Feb 22 05:12:43.832: INFO: Waiting for responses: map[]
Feb 22 05:12:43.844: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.26.1.197:8080/dial?request=hostname&protocol=udp&host=172.26.1.195&port=8081&tries=1'] Namespace:pod-network-test-9861 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 22 05:12:43.844: INFO: >>> kubeConfig: /root/.kube/config
Feb 22 05:12:44.135: INFO: Waiting for responses: map[]
Feb 22 05:12:44.166: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.26.1.197:8080/dial?request=hostname&protocol=udp&host=172.26.1.196&port=8081&tries=1'] Namespace:pod-network-test-9861 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 22 05:12:44.167: INFO: >>> kubeConfig: /root/.kube/config
Feb 22 05:12:44.350: INFO: Waiting for responses: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 05:12:44.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-9861" for this suite.

â€¢ [SLOW TEST:93.836 seconds]
[sig-network] Networking
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:26
  Granular Checks: Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:29
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance]","total":270,"completed":88,"skipped":1491,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 05:12:44.589: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1363
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Feb 22 05:12:45.369: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1a07c958-0555-45ee-b173-930b5b644245" in namespace "projected-1363" to be "Succeeded or Failed"
Feb 22 05:12:45.412: INFO: Pod "downwardapi-volume-1a07c958-0555-45ee-b173-930b5b644245": Phase="Pending", Reason="", readiness=false. Elapsed: 43.304933ms
Feb 22 05:12:47.428: INFO: Pod "downwardapi-volume-1a07c958-0555-45ee-b173-930b5b644245": Phase="Pending", Reason="", readiness=false. Elapsed: 2.05926092s
Feb 22 05:12:49.465: INFO: Pod "downwardapi-volume-1a07c958-0555-45ee-b173-930b5b644245": Phase="Pending", Reason="", readiness=false. Elapsed: 4.095701936s
Feb 22 05:12:51.853: INFO: Pod "downwardapi-volume-1a07c958-0555-45ee-b173-930b5b644245": Phase="Pending", Reason="", readiness=false. Elapsed: 6.483856794s
Feb 22 05:12:53.923: INFO: Pod "downwardapi-volume-1a07c958-0555-45ee-b173-930b5b644245": Phase="Pending", Reason="", readiness=false. Elapsed: 8.553407266s
Feb 22 05:12:55.962: INFO: Pod "downwardapi-volume-1a07c958-0555-45ee-b173-930b5b644245": Phase="Pending", Reason="", readiness=false. Elapsed: 10.59326255s
Feb 22 05:12:57.974: INFO: Pod "downwardapi-volume-1a07c958-0555-45ee-b173-930b5b644245": Phase="Pending", Reason="", readiness=false. Elapsed: 12.605248742s
Feb 22 05:12:59.993: INFO: Pod "downwardapi-volume-1a07c958-0555-45ee-b173-930b5b644245": Phase="Pending", Reason="", readiness=false. Elapsed: 14.623818448s
Feb 22 05:13:02.007: INFO: Pod "downwardapi-volume-1a07c958-0555-45ee-b173-930b5b644245": Phase="Pending", Reason="", readiness=false. Elapsed: 16.637574765s
Feb 22 05:13:04.034: INFO: Pod "downwardapi-volume-1a07c958-0555-45ee-b173-930b5b644245": Phase="Pending", Reason="", readiness=false. Elapsed: 18.664806195s
Feb 22 05:13:06.055: INFO: Pod "downwardapi-volume-1a07c958-0555-45ee-b173-930b5b644245": Phase="Pending", Reason="", readiness=false. Elapsed: 20.685623518s
Feb 22 05:13:08.062: INFO: Pod "downwardapi-volume-1a07c958-0555-45ee-b173-930b5b644245": Phase="Pending", Reason="", readiness=false. Elapsed: 22.692697639s
Feb 22 05:13:10.083: INFO: Pod "downwardapi-volume-1a07c958-0555-45ee-b173-930b5b644245": Phase="Pending", Reason="", readiness=false. Elapsed: 24.713387851s
Feb 22 05:13:12.093: INFO: Pod "downwardapi-volume-1a07c958-0555-45ee-b173-930b5b644245": Phase="Pending", Reason="", readiness=false. Elapsed: 26.724159878s
Feb 22 05:13:14.102: INFO: Pod "downwardapi-volume-1a07c958-0555-45ee-b173-930b5b644245": Phase="Succeeded", Reason="", readiness=false. Elapsed: 28.733140436s
STEP: Saw pod success
Feb 22 05:13:14.103: INFO: Pod "downwardapi-volume-1a07c958-0555-45ee-b173-930b5b644245" satisfied condition "Succeeded or Failed"
Feb 22 05:13:14.113: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com pod downwardapi-volume-1a07c958-0555-45ee-b173-930b5b644245 container client-container: <nil>
STEP: delete the pod
Feb 22 05:13:14.201: INFO: Waiting for pod downwardapi-volume-1a07c958-0555-45ee-b173-930b5b644245 to disappear
Feb 22 05:13:14.217: INFO: Pod downwardapi-volume-1a07c958-0555-45ee-b173-930b5b644245 still exists
Feb 22 05:13:16.217: INFO: Waiting for pod downwardapi-volume-1a07c958-0555-45ee-b173-930b5b644245 to disappear
Feb 22 05:13:16.225: INFO: Pod downwardapi-volume-1a07c958-0555-45ee-b173-930b5b644245 still exists
Feb 22 05:13:18.218: INFO: Waiting for pod downwardapi-volume-1a07c958-0555-45ee-b173-930b5b644245 to disappear
Feb 22 05:13:18.225: INFO: Pod downwardapi-volume-1a07c958-0555-45ee-b173-930b5b644245 still exists
Feb 22 05:13:20.218: INFO: Waiting for pod downwardapi-volume-1a07c958-0555-45ee-b173-930b5b644245 to disappear
Feb 22 05:13:20.224: INFO: Pod downwardapi-volume-1a07c958-0555-45ee-b173-930b5b644245 still exists
Feb 22 05:13:22.218: INFO: Waiting for pod downwardapi-volume-1a07c958-0555-45ee-b173-930b5b644245 to disappear
Feb 22 05:13:22.232: INFO: Pod downwardapi-volume-1a07c958-0555-45ee-b173-930b5b644245 still exists
Feb 22 05:13:24.217: INFO: Waiting for pod downwardapi-volume-1a07c958-0555-45ee-b173-930b5b644245 to disappear
Feb 22 05:13:24.228: INFO: Pod downwardapi-volume-1a07c958-0555-45ee-b173-930b5b644245 still exists
Feb 22 05:13:26.218: INFO: Waiting for pod downwardapi-volume-1a07c958-0555-45ee-b173-930b5b644245 to disappear
Feb 22 05:13:26.227: INFO: Pod downwardapi-volume-1a07c958-0555-45ee-b173-930b5b644245 still exists
Feb 22 05:13:28.217: INFO: Waiting for pod downwardapi-volume-1a07c958-0555-45ee-b173-930b5b644245 to disappear
Feb 22 05:13:28.233: INFO: Pod downwardapi-volume-1a07c958-0555-45ee-b173-930b5b644245 still exists
Feb 22 05:13:30.218: INFO: Waiting for pod downwardapi-volume-1a07c958-0555-45ee-b173-930b5b644245 to disappear
Feb 22 05:13:30.230: INFO: Pod downwardapi-volume-1a07c958-0555-45ee-b173-930b5b644245 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 05:13:30.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1363" for this suite.

â€¢ [SLOW TEST:45.763 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:36
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","total":270,"completed":89,"skipped":1520,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 05:13:30.359: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6951
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating Agnhost RC
Feb 22 05:13:30.956: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config create -f - --namespace=kubectl-6951'
Feb 22 05:13:34.168: INFO: stderr: ""
Feb 22 05:13:34.168: INFO: stdout: "replicationcontroller/agnhost-master created\n"
STEP: Waiting for Agnhost master to start.
Feb 22 05:13:35.179: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 05:13:35.179: INFO: Found 0 / 1
Feb 22 05:13:36.199: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 05:13:36.199: INFO: Found 0 / 1
Feb 22 05:13:37.186: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 05:13:37.186: INFO: Found 0 / 1
Feb 22 05:13:38.176: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 05:13:38.176: INFO: Found 0 / 1
Feb 22 05:13:39.198: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 05:13:39.198: INFO: Found 0 / 1
Feb 22 05:13:40.182: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 05:13:40.182: INFO: Found 0 / 1
Feb 22 05:13:41.178: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 05:13:41.178: INFO: Found 0 / 1
Feb 22 05:13:42.180: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 05:13:42.180: INFO: Found 0 / 1
Feb 22 05:13:43.179: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 05:13:43.179: INFO: Found 0 / 1
Feb 22 05:13:44.202: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 05:13:44.202: INFO: Found 0 / 1
Feb 22 05:13:45.189: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 05:13:45.189: INFO: Found 0 / 1
Feb 22 05:13:46.183: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 05:13:46.183: INFO: Found 0 / 1
Feb 22 05:13:47.181: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 05:13:47.181: INFO: Found 0 / 1
Feb 22 05:13:48.178: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 05:13:48.179: INFO: Found 0 / 1
Feb 22 05:13:49.200: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 05:13:49.200: INFO: Found 0 / 1
Feb 22 05:13:50.177: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 05:13:50.177: INFO: Found 0 / 1
Feb 22 05:13:51.180: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 05:13:51.180: INFO: Found 0 / 1
Feb 22 05:13:52.178: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 05:13:52.178: INFO: Found 0 / 1
Feb 22 05:13:53.176: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 05:13:53.176: INFO: Found 0 / 1
Feb 22 05:13:54.179: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 05:13:54.179: INFO: Found 0 / 1
Feb 22 05:13:55.184: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 05:13:55.185: INFO: Found 0 / 1
Feb 22 05:13:56.227: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 05:13:56.227: INFO: Found 0 / 1
Feb 22 05:13:57.179: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 05:13:57.179: INFO: Found 0 / 1
Feb 22 05:13:58.178: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 05:13:58.178: INFO: Found 0 / 1
Feb 22 05:13:59.187: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 05:13:59.188: INFO: Found 1 / 1
Feb 22 05:13:59.188: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Feb 22 05:13:59.201: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 05:13:59.201: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 22 05:13:59.201: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config patch pod agnhost-master-9vbsw --namespace=kubectl-6951 -p {"metadata":{"annotations":{"x":"y"}}}'
Feb 22 05:13:59.455: INFO: stderr: ""
Feb 22 05:13:59.455: INFO: stdout: "pod/agnhost-master-9vbsw patched\n"
STEP: checking annotations
Feb 22 05:13:59.468: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 05:13:59.468: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 05:13:59.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6951" for this suite.

â€¢ [SLOW TEST:29.228 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl patch
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1363
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc  [Conformance]","total":270,"completed":90,"skipped":1548,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 05:13:59.591: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-6667
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
Feb 22 05:13:59.882: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 05:16:54.838: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6667" for this suite.

â€¢ [SLOW TEST:175.390 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]","total":270,"completed":91,"skipped":1611,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 05:16:54.994: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-2277
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD without validation schema [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Feb 22 05:16:55.296: INFO: >>> kubeConfig: /root/.kube/config
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Feb 22 05:17:08.554: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-2277 create -f -'
Feb 22 05:17:11.738: INFO: stderr: ""
Feb 22 05:17:11.738: INFO: stdout: "e2e-test-crd-publish-openapi-7961-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Feb 22 05:17:11.738: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-2277 delete e2e-test-crd-publish-openapi-7961-crds test-cr'
Feb 22 05:17:12.111: INFO: stderr: ""
Feb 22 05:17:12.111: INFO: stdout: "e2e-test-crd-publish-openapi-7961-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Feb 22 05:17:12.111: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-2277 apply -f -'
Feb 22 05:17:13.521: INFO: stderr: ""
Feb 22 05:17:13.521: INFO: stdout: "e2e-test-crd-publish-openapi-7961-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Feb 22 05:17:13.521: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-2277 delete e2e-test-crd-publish-openapi-7961-crds test-cr'
Feb 22 05:17:13.767: INFO: stderr: ""
Feb 22 05:17:13.767: INFO: stdout: "e2e-test-crd-publish-openapi-7961-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema
Feb 22 05:17:13.767: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config explain e2e-test-crd-publish-openapi-7961-crds'
Feb 22 05:17:14.618: INFO: stderr: ""
Feb 22 05:17:14.618: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-7961-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 05:17:23.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2277" for this suite.

â€¢ [SLOW TEST:28.433 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]","total":270,"completed":92,"skipped":1616,"failed":0}
SSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 05:17:23.432: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-6030
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-6030, will wait for the garbage collector to delete the pods
Feb 22 05:17:47.933: INFO: Deleting Job.batch foo took: 40.402286ms
Feb 22 05:17:49.734: INFO: Terminating Job.batch foo pods took: 1.800501091s
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 05:18:37.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-6030" for this suite.

â€¢ [SLOW TEST:74.121 seconds]
[sig-apps] Job
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Job should delete a job [Conformance]","total":270,"completed":93,"skipped":1620,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 05:18:37.615: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-595
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation
Feb 22 05:18:38.021: INFO: >>> kubeConfig: /root/.kube/config
Feb 22 05:18:57.564: INFO: >>> kubeConfig: /root/.kube/config
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 05:20:09.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-595" for this suite.

â€¢ [SLOW TEST:91.769 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]","total":270,"completed":94,"skipped":1631,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 05:20:09.432: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-9664
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod pod-subpath-test-downwardapi-ztbr
STEP: Creating a pod to test atomic-volume-subpath
Feb 22 05:20:33.061: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-ztbr" in namespace "subpath-9664" to be "Succeeded or Failed"
Feb 22 05:20:33.182: INFO: Pod "pod-subpath-test-downwardapi-ztbr": Phase="Pending", Reason="", readiness=false. Elapsed: 121.044743ms
Feb 22 05:20:35.287: INFO: Pod "pod-subpath-test-downwardapi-ztbr": Phase="Pending", Reason="", readiness=false. Elapsed: 2.225709251s
Feb 22 05:20:37.309: INFO: Pod "pod-subpath-test-downwardapi-ztbr": Phase="Pending", Reason="", readiness=false. Elapsed: 4.248112396s
Feb 22 05:20:39.337: INFO: Pod "pod-subpath-test-downwardapi-ztbr": Phase="Pending", Reason="", readiness=false. Elapsed: 6.276108661s
Feb 22 05:20:41.365: INFO: Pod "pod-subpath-test-downwardapi-ztbr": Phase="Pending", Reason="", readiness=false. Elapsed: 8.303581493s
Feb 22 05:20:43.389: INFO: Pod "pod-subpath-test-downwardapi-ztbr": Phase="Pending", Reason="", readiness=false. Elapsed: 10.327871576s
Feb 22 05:20:45.399: INFO: Pod "pod-subpath-test-downwardapi-ztbr": Phase="Pending", Reason="", readiness=false. Elapsed: 12.337990174s
Feb 22 05:20:47.461: INFO: Pod "pod-subpath-test-downwardapi-ztbr": Phase="Pending", Reason="", readiness=false. Elapsed: 14.399543903s
Feb 22 05:20:49.471: INFO: Pod "pod-subpath-test-downwardapi-ztbr": Phase="Pending", Reason="", readiness=false. Elapsed: 16.409644185s
Feb 22 05:20:51.480: INFO: Pod "pod-subpath-test-downwardapi-ztbr": Phase="Pending", Reason="", readiness=false. Elapsed: 18.418549886s
Feb 22 05:20:53.490: INFO: Pod "pod-subpath-test-downwardapi-ztbr": Phase="Pending", Reason="", readiness=false. Elapsed: 20.42919443s
Feb 22 05:20:55.500: INFO: Pod "pod-subpath-test-downwardapi-ztbr": Phase="Pending", Reason="", readiness=false. Elapsed: 22.43925332s
Feb 22 05:20:57.695: INFO: Pod "pod-subpath-test-downwardapi-ztbr": Phase="Running", Reason="", readiness=true. Elapsed: 24.633384567s
Feb 22 05:20:59.823: INFO: Pod "pod-subpath-test-downwardapi-ztbr": Phase="Running", Reason="", readiness=true. Elapsed: 26.761580558s
Feb 22 05:21:01.875: INFO: Pod "pod-subpath-test-downwardapi-ztbr": Phase="Running", Reason="", readiness=true. Elapsed: 28.81417485s
Feb 22 05:21:03.936: INFO: Pod "pod-subpath-test-downwardapi-ztbr": Phase="Running", Reason="", readiness=true. Elapsed: 30.874615455s
Feb 22 05:21:05.948: INFO: Pod "pod-subpath-test-downwardapi-ztbr": Phase="Running", Reason="", readiness=true. Elapsed: 32.886954934s
Feb 22 05:21:08.027: INFO: Pod "pod-subpath-test-downwardapi-ztbr": Phase="Running", Reason="", readiness=true. Elapsed: 34.965701455s
Feb 22 05:21:10.081: INFO: Pod "pod-subpath-test-downwardapi-ztbr": Phase="Running", Reason="", readiness=true. Elapsed: 37.019531948s
Feb 22 05:21:12.104: INFO: Pod "pod-subpath-test-downwardapi-ztbr": Phase="Running", Reason="", readiness=true. Elapsed: 39.04329159s
Feb 22 05:21:14.113: INFO: Pod "pod-subpath-test-downwardapi-ztbr": Phase="Running", Reason="", readiness=true. Elapsed: 41.052184224s
Feb 22 05:21:16.257: INFO: Pod "pod-subpath-test-downwardapi-ztbr": Phase="Running", Reason="", readiness=true. Elapsed: 43.195655043s
Feb 22 05:21:18.276: INFO: Pod "pod-subpath-test-downwardapi-ztbr": Phase="Succeeded", Reason="", readiness=false. Elapsed: 45.214665062s
STEP: Saw pod success
Feb 22 05:21:18.276: INFO: Pod "pod-subpath-test-downwardapi-ztbr" satisfied condition "Succeeded or Failed"
Feb 22 05:21:18.308: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com pod pod-subpath-test-downwardapi-ztbr container test-container-subpath-downwardapi-ztbr: <nil>
STEP: delete the pod
Feb 22 05:21:18.460: INFO: Waiting for pod pod-subpath-test-downwardapi-ztbr to disappear
Feb 22 05:21:18.517: INFO: Pod pod-subpath-test-downwardapi-ztbr still exists
Feb 22 05:21:20.518: INFO: Waiting for pod pod-subpath-test-downwardapi-ztbr to disappear
Feb 22 05:21:20.530: INFO: Pod pod-subpath-test-downwardapi-ztbr still exists
Feb 22 05:21:22.518: INFO: Waiting for pod pod-subpath-test-downwardapi-ztbr to disappear
Feb 22 05:21:22.530: INFO: Pod pod-subpath-test-downwardapi-ztbr still exists
Feb 22 05:21:24.518: INFO: Waiting for pod pod-subpath-test-downwardapi-ztbr to disappear
Feb 22 05:21:24.530: INFO: Pod pod-subpath-test-downwardapi-ztbr still exists
Feb 22 05:21:26.518: INFO: Waiting for pod pod-subpath-test-downwardapi-ztbr to disappear
Feb 22 05:21:26.589: INFO: Pod pod-subpath-test-downwardapi-ztbr still exists
Feb 22 05:21:28.519: INFO: Waiting for pod pod-subpath-test-downwardapi-ztbr to disappear
Feb 22 05:21:28.532: INFO: Pod pod-subpath-test-downwardapi-ztbr no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-ztbr
Feb 22 05:21:28.532: INFO: Deleting pod "pod-subpath-test-downwardapi-ztbr" in namespace "subpath-9664"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 05:21:28.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9664" for this suite.

â€¢ [SLOW TEST:79.247 seconds]
[sig-storage] Subpath
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [LinuxOnly] [Conformance]","total":270,"completed":95,"skipped":1655,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 05:21:28.712: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-7388
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-7388
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a new StatefulSet
Feb 22 05:21:29.759: INFO: Found 0 stateful pods, waiting for 3
Feb 22 05:21:39.775: INFO: Found 1 stateful pods, waiting for 3
Feb 22 05:21:49.786: INFO: Found 1 stateful pods, waiting for 3
Feb 22 05:21:59.770: INFO: Found 2 stateful pods, waiting for 3
Feb 22 05:22:09.807: INFO: Found 2 stateful pods, waiting for 3
Feb 22 05:22:19.795: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 22 05:22:19.796: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 22 05:22:19.796: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Feb 22 05:22:29.793: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 22 05:22:29.794: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 22 05:22:29.794: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Feb 22 05:22:39.910: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 22 05:22:39.921: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 22 05:22:39.921: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Feb 22 05:22:49.774: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 22 05:22:49.774: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 22 05:22:49.774: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Feb 22 05:22:49.834: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-7388 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb 22 05:22:50.525: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb 22 05:22:50.525: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb 22 05:22:50.525: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from mirror.gcr.io/library/httpd:2.4.38-alpine to mirror.gcr.io/library/httpd:2.4.39-alpine
Feb 22 05:23:00.667: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Feb 22 05:23:10.766: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-7388 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 22 05:23:11.253: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Feb 22 05:23:11.253: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb 22 05:23:11.253: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Feb 22 05:23:21.336: INFO: Waiting for StatefulSet statefulset-7388/ss2 to complete update
Feb 22 05:23:21.337: INFO: Waiting for Pod statefulset-7388/ss2-0 to have revision ss2-6dc56fb9cb update revision ss2-6969d67667
Feb 22 05:23:21.337: INFO: Waiting for Pod statefulset-7388/ss2-1 to have revision ss2-6dc56fb9cb update revision ss2-6969d67667
Feb 22 05:23:21.337: INFO: Waiting for Pod statefulset-7388/ss2-2 to have revision ss2-6dc56fb9cb update revision ss2-6969d67667
Feb 22 05:23:31.370: INFO: Waiting for StatefulSet statefulset-7388/ss2 to complete update
Feb 22 05:23:31.370: INFO: Waiting for Pod statefulset-7388/ss2-0 to have revision ss2-6dc56fb9cb update revision ss2-6969d67667
Feb 22 05:23:31.370: INFO: Waiting for Pod statefulset-7388/ss2-1 to have revision ss2-6dc56fb9cb update revision ss2-6969d67667
Feb 22 05:23:41.363: INFO: Waiting for StatefulSet statefulset-7388/ss2 to complete update
Feb 22 05:23:41.363: INFO: Waiting for Pod statefulset-7388/ss2-0 to have revision ss2-6dc56fb9cb update revision ss2-6969d67667
Feb 22 05:23:41.363: INFO: Waiting for Pod statefulset-7388/ss2-1 to have revision ss2-6dc56fb9cb update revision ss2-6969d67667
Feb 22 05:23:51.369: INFO: Waiting for StatefulSet statefulset-7388/ss2 to complete update
Feb 22 05:23:51.369: INFO: Waiting for Pod statefulset-7388/ss2-0 to have revision ss2-6dc56fb9cb update revision ss2-6969d67667
Feb 22 05:23:51.369: INFO: Waiting for Pod statefulset-7388/ss2-1 to have revision ss2-6dc56fb9cb update revision ss2-6969d67667
Feb 22 05:24:01.371: INFO: Waiting for StatefulSet statefulset-7388/ss2 to complete update
Feb 22 05:24:01.371: INFO: Waiting for Pod statefulset-7388/ss2-0 to have revision ss2-6dc56fb9cb update revision ss2-6969d67667
Feb 22 05:24:01.371: INFO: Waiting for Pod statefulset-7388/ss2-1 to have revision ss2-6dc56fb9cb update revision ss2-6969d67667
Feb 22 05:24:11.403: INFO: Waiting for StatefulSet statefulset-7388/ss2 to complete update
Feb 22 05:24:11.404: INFO: Waiting for Pod statefulset-7388/ss2-0 to have revision ss2-6dc56fb9cb update revision ss2-6969d67667
Feb 22 05:24:11.404: INFO: Waiting for Pod statefulset-7388/ss2-1 to have revision ss2-6dc56fb9cb update revision ss2-6969d67667
Feb 22 05:24:21.359: INFO: Waiting for StatefulSet statefulset-7388/ss2 to complete update
Feb 22 05:24:21.360: INFO: Waiting for Pod statefulset-7388/ss2-0 to have revision ss2-6dc56fb9cb update revision ss2-6969d67667
Feb 22 05:24:21.360: INFO: Waiting for Pod statefulset-7388/ss2-1 to have revision ss2-6dc56fb9cb update revision ss2-6969d67667
Feb 22 05:24:31.389: INFO: Waiting for StatefulSet statefulset-7388/ss2 to complete update
Feb 22 05:24:31.389: INFO: Waiting for Pod statefulset-7388/ss2-0 to have revision ss2-6dc56fb9cb update revision ss2-6969d67667
Feb 22 05:24:41.355: INFO: Waiting for StatefulSet statefulset-7388/ss2 to complete update
Feb 22 05:24:41.355: INFO: Waiting for Pod statefulset-7388/ss2-0 to have revision ss2-6dc56fb9cb update revision ss2-6969d67667
Feb 22 05:24:51.391: INFO: Waiting for StatefulSet statefulset-7388/ss2 to complete update
Feb 22 05:24:51.391: INFO: Waiting for Pod statefulset-7388/ss2-0 to have revision ss2-6dc56fb9cb update revision ss2-6969d67667
Feb 22 05:25:01.352: INFO: Waiting for StatefulSet statefulset-7388/ss2 to complete update
Feb 22 05:25:01.352: INFO: Waiting for Pod statefulset-7388/ss2-0 to have revision ss2-6dc56fb9cb update revision ss2-6969d67667
Feb 22 05:25:11.379: INFO: Waiting for StatefulSet statefulset-7388/ss2 to complete update
Feb 22 05:25:21.482: INFO: Waiting for StatefulSet statefulset-7388/ss2 to complete update
Feb 22 05:25:31.442: INFO: Waiting for StatefulSet statefulset-7388/ss2 to complete update
STEP: Rolling back to a previous revision
Feb 22 05:25:41.473: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-7388 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb 22 05:25:42.168: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb 22 05:25:42.169: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb 22 05:25:42.169: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb 22 05:25:52.312: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Feb 22 05:26:02.430: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-7388 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 22 05:26:03.029: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Feb 22 05:26:03.029: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb 22 05:26:03.029: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Feb 22 05:26:13.196: INFO: Waiting for StatefulSet statefulset-7388/ss2 to complete update
Feb 22 05:26:13.198: INFO: Waiting for Pod statefulset-7388/ss2-0 to have revision ss2-6969d67667 update revision ss2-6dc56fb9cb
Feb 22 05:26:13.198: INFO: Waiting for Pod statefulset-7388/ss2-1 to have revision ss2-6969d67667 update revision ss2-6dc56fb9cb
Feb 22 05:26:13.199: INFO: Waiting for Pod statefulset-7388/ss2-2 to have revision ss2-6969d67667 update revision ss2-6dc56fb9cb
Feb 22 05:26:23.237: INFO: Waiting for StatefulSet statefulset-7388/ss2 to complete update
Feb 22 05:26:23.238: INFO: Waiting for Pod statefulset-7388/ss2-0 to have revision ss2-6969d67667 update revision ss2-6dc56fb9cb
Feb 22 05:26:23.239: INFO: Waiting for Pod statefulset-7388/ss2-1 to have revision ss2-6969d67667 update revision ss2-6dc56fb9cb
Feb 22 05:26:33.222: INFO: Waiting for StatefulSet statefulset-7388/ss2 to complete update
Feb 22 05:26:33.222: INFO: Waiting for Pod statefulset-7388/ss2-0 to have revision ss2-6969d67667 update revision ss2-6dc56fb9cb
Feb 22 05:26:33.222: INFO: Waiting for Pod statefulset-7388/ss2-1 to have revision ss2-6969d67667 update revision ss2-6dc56fb9cb
Feb 22 05:26:43.229: INFO: Waiting for StatefulSet statefulset-7388/ss2 to complete update
Feb 22 05:26:43.229: INFO: Waiting for Pod statefulset-7388/ss2-0 to have revision ss2-6969d67667 update revision ss2-6dc56fb9cb
Feb 22 05:26:43.229: INFO: Waiting for Pod statefulset-7388/ss2-1 to have revision ss2-6969d67667 update revision ss2-6dc56fb9cb
Feb 22 05:26:53.744: INFO: Waiting for StatefulSet statefulset-7388/ss2 to complete update
Feb 22 05:26:53.748: INFO: Waiting for Pod statefulset-7388/ss2-0 to have revision ss2-6969d67667 update revision ss2-6dc56fb9cb
Feb 22 05:26:53.748: INFO: Waiting for Pod statefulset-7388/ss2-1 to have revision ss2-6969d67667 update revision ss2-6dc56fb9cb
Feb 22 05:27:03.232: INFO: Waiting for StatefulSet statefulset-7388/ss2 to complete update
Feb 22 05:27:03.232: INFO: Waiting for Pod statefulset-7388/ss2-0 to have revision ss2-6969d67667 update revision ss2-6dc56fb9cb
Feb 22 05:27:13.241: INFO: Waiting for StatefulSet statefulset-7388/ss2 to complete update
Feb 22 05:27:13.241: INFO: Waiting for Pod statefulset-7388/ss2-0 to have revision ss2-6969d67667 update revision ss2-6dc56fb9cb
Feb 22 05:27:23.245: INFO: Waiting for StatefulSet statefulset-7388/ss2 to complete update
Feb 22 05:27:23.245: INFO: Waiting for Pod statefulset-7388/ss2-0 to have revision ss2-6969d67667 update revision ss2-6dc56fb9cb
Feb 22 05:27:33.280: INFO: Waiting for StatefulSet statefulset-7388/ss2 to complete update
Feb 22 05:27:33.280: INFO: Waiting for Pod statefulset-7388/ss2-0 to have revision ss2-6969d67667 update revision ss2-6dc56fb9cb
Feb 22 05:27:43.224: INFO: Waiting for StatefulSet statefulset-7388/ss2 to complete update
Feb 22 05:27:53.224: INFO: Waiting for StatefulSet statefulset-7388/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Feb 22 05:28:03.234: INFO: Deleting all statefulset in ns statefulset-7388
Feb 22 05:28:03.251: INFO: Scaling statefulset ss2 to 0
Feb 22 05:29:03.333: INFO: Waiting for statefulset status.replicas updated to 0
Feb 22 05:29:03.360: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 05:29:03.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7388" for this suite.

â€¢ [SLOW TEST:454.995 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]","total":270,"completed":96,"skipped":1672,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 05:29:03.727: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5772
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name s-test-opt-del-31caf03a-c4f1-4b52-beb6-9071119b5ce1
STEP: Creating secret with name s-test-opt-upd-1931ecdc-12a4-4211-8688-63c55fb3cb97
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-31caf03a-c4f1-4b52-beb6-9071119b5ce1
STEP: Updating secret s-test-opt-upd-1931ecdc-12a4-4211-8688-63c55fb3cb97
STEP: Creating secret with name s-test-opt-create-cdbff643-7866-4dfb-84d7-2d045661c907
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 05:30:18.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5772" for this suite.

â€¢ [SLOW TEST:74.596 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]","total":270,"completed":97,"skipped":1680,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 05:30:18.364: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-5486
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Feb 22 05:30:19.363: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:19.373: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:19.373: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:19.459: INFO: Number of nodes with available pods: 0
Feb 22 05:30:19.459: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:30:20.610: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:20.611: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:20.611: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:20.730: INFO: Number of nodes with available pods: 0
Feb 22 05:30:20.731: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:30:21.476: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:21.477: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:21.477: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:21.495: INFO: Number of nodes with available pods: 0
Feb 22 05:30:21.496: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:30:22.501: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:22.501: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:22.501: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:22.535: INFO: Number of nodes with available pods: 0
Feb 22 05:30:22.536: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:30:23.619: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:23.619: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:23.619: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:23.660: INFO: Number of nodes with available pods: 0
Feb 22 05:30:23.660: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:30:24.503: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:24.504: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:24.504: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:24.558: INFO: Number of nodes with available pods: 0
Feb 22 05:30:24.559: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:30:25.486: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:25.486: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:25.487: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:25.507: INFO: Number of nodes with available pods: 0
Feb 22 05:30:25.507: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:30:26.510: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:26.510: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:26.510: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:26.596: INFO: Number of nodes with available pods: 0
Feb 22 05:30:26.596: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:30:27.559: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:27.560: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:27.561: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:27.604: INFO: Number of nodes with available pods: 0
Feb 22 05:30:27.604: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:30:28.507: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:28.507: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:28.507: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:28.534: INFO: Number of nodes with available pods: 0
Feb 22 05:30:28.535: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:30:29.544: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:29.545: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:29.545: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:29.564: INFO: Number of nodes with available pods: 0
Feb 22 05:30:29.564: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:30:30.490: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:30.491: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:30.492: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:30.546: INFO: Number of nodes with available pods: 0
Feb 22 05:30:30.547: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:30:31.498: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:31.499: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:31.499: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:31.536: INFO: Number of nodes with available pods: 0
Feb 22 05:30:31.536: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:30:32.674: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:32.675: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:32.676: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:32.887: INFO: Number of nodes with available pods: 0
Feb 22 05:30:32.888: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:30:33.957: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:33.958: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:33.960: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:34.444: INFO: Number of nodes with available pods: 0
Feb 22 05:30:34.444: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:30:35.097: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:35.097: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:35.097: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:35.224: INFO: Number of nodes with available pods: 0
Feb 22 05:30:35.224: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:30:35.554: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:35.554: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:35.554: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:35.606: INFO: Number of nodes with available pods: 0
Feb 22 05:30:35.606: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:30:36.497: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:36.503: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:36.507: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:36.536: INFO: Number of nodes with available pods: 0
Feb 22 05:30:36.537: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:30:37.479: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:37.479: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:37.479: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:37.496: INFO: Number of nodes with available pods: 0
Feb 22 05:30:37.496: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:30:38.537: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:38.540: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:38.541: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:38.596: INFO: Number of nodes with available pods: 0
Feb 22 05:30:38.598: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:30:39.548: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:39.548: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:39.548: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:39.577: INFO: Number of nodes with available pods: 0
Feb 22 05:30:39.578: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:30:40.473: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:40.473: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:40.473: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:40.486: INFO: Number of nodes with available pods: 0
Feb 22 05:30:40.486: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:30:41.500: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:41.501: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:41.501: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:41.581: INFO: Number of nodes with available pods: 0
Feb 22 05:30:41.581: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:30:42.802: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:42.803: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:42.803: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:42.824: INFO: Number of nodes with available pods: 0
Feb 22 05:30:42.824: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:30:43.685: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:43.685: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:43.686: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:43.838: INFO: Number of nodes with available pods: 0
Feb 22 05:30:43.839: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:30:44.475: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:44.476: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:44.476: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:44.493: INFO: Number of nodes with available pods: 0
Feb 22 05:30:44.493: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:30:45.473: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:45.473: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:45.474: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:45.485: INFO: Number of nodes with available pods: 0
Feb 22 05:30:45.485: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:30:46.523: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:46.524: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:46.524: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:46.539: INFO: Number of nodes with available pods: 0
Feb 22 05:30:46.539: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:30:47.483: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:47.486: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:47.487: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:47.502: INFO: Number of nodes with available pods: 0
Feb 22 05:30:47.503: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:30:50.563: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:50.587: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:50.592: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:51.697: INFO: Number of nodes with available pods: 0
Feb 22 05:30:51.697: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:30:52.543: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:52.545: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:52.545: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:52.580: INFO: Number of nodes with available pods: 0
Feb 22 05:30:52.580: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:30:53.481: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:53.481: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:53.489: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:53.533: INFO: Number of nodes with available pods: 1
Feb 22 05:30:53.533: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:30:54.486: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:54.487: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:54.487: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:54.511: INFO: Number of nodes with available pods: 1
Feb 22 05:30:54.511: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:30:55.508: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:55.508: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:55.509: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:55.539: INFO: Number of nodes with available pods: 1
Feb 22 05:30:55.539: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:30:56.498: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:56.499: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:56.499: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:56.542: INFO: Number of nodes with available pods: 1
Feb 22 05:30:56.542: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:30:57.599: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:57.600: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:57.600: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:57.696: INFO: Number of nodes with available pods: 1
Feb 22 05:30:57.696: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 05:30:58.488: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:58.488: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:58.488: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:58.509: INFO: Number of nodes with available pods: 2
Feb 22 05:30:58.509: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 05:30:59.476: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:59.476: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:59.477: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:30:59.496: INFO: Number of nodes with available pods: 2
Feb 22 05:30:59.496: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 05:31:00.473: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:31:00.473: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:31:00.474: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:31:00.498: INFO: Number of nodes with available pods: 2
Feb 22 05:31:00.499: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 05:31:01.485: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:31:01.487: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:31:01.489: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:31:01.510: INFO: Number of nodes with available pods: 2
Feb 22 05:31:01.511: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 05:31:02.585: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:31:02.585: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:31:02.585: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:31:02.620: INFO: Number of nodes with available pods: 3
Feb 22 05:31:02.620: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Feb 22 05:31:02.760: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:31:02.761: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:31:02.761: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 05:31:02.861: INFO: Number of nodes with available pods: 3
Feb 22 05:31:02.862: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5486, will wait for the garbage collector to delete the pods
Feb 22 05:31:18.134: INFO: Deleting DaemonSet.extensions daemon-set took: 53.693285ms
Feb 22 05:31:18.235: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.465558ms
Feb 22 05:31:35.857: INFO: Number of nodes with available pods: 0
Feb 22 05:31:35.857: INFO: Number of running nodes: 0, number of available pods: 0
Feb 22 05:31:35.877: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-5486/daemonsets","resourceVersion":"108845"},"items":null}

Feb 22 05:31:35.896: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-5486/pods","resourceVersion":"108846"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 05:31:35.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5486" for this suite.

â€¢ [SLOW TEST:77.675 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]","total":270,"completed":98,"skipped":1702,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 05:31:36.054: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-519
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-d7850cc5-b519-497e-b9d8-92cabffdc000
STEP: Creating a pod to test consume configMaps
Feb 22 05:31:36.559: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ba8c0dad-1b76-407c-90b6-16a0bb2fa13e" in namespace "projected-519" to be "Succeeded or Failed"
Feb 22 05:31:36.587: INFO: Pod "pod-projected-configmaps-ba8c0dad-1b76-407c-90b6-16a0bb2fa13e": Phase="Pending", Reason="", readiness=false. Elapsed: 27.920297ms
Feb 22 05:31:38.603: INFO: Pod "pod-projected-configmaps-ba8c0dad-1b76-407c-90b6-16a0bb2fa13e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.043361484s
Feb 22 05:31:40.775: INFO: Pod "pod-projected-configmaps-ba8c0dad-1b76-407c-90b6-16a0bb2fa13e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.215499112s
Feb 22 05:31:42.818: INFO: Pod "pod-projected-configmaps-ba8c0dad-1b76-407c-90b6-16a0bb2fa13e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.258446877s
Feb 22 05:31:44.877: INFO: Pod "pod-projected-configmaps-ba8c0dad-1b76-407c-90b6-16a0bb2fa13e": Phase="Pending", Reason="", readiness=false. Elapsed: 8.317876094s
Feb 22 05:31:46.901: INFO: Pod "pod-projected-configmaps-ba8c0dad-1b76-407c-90b6-16a0bb2fa13e": Phase="Pending", Reason="", readiness=false. Elapsed: 10.341799354s
Feb 22 05:31:48.977: INFO: Pod "pod-projected-configmaps-ba8c0dad-1b76-407c-90b6-16a0bb2fa13e": Phase="Pending", Reason="", readiness=false. Elapsed: 12.418175075s
Feb 22 05:31:50.987: INFO: Pod "pod-projected-configmaps-ba8c0dad-1b76-407c-90b6-16a0bb2fa13e": Phase="Pending", Reason="", readiness=false. Elapsed: 14.427819542s
Feb 22 05:31:52.997: INFO: Pod "pod-projected-configmaps-ba8c0dad-1b76-407c-90b6-16a0bb2fa13e": Phase="Pending", Reason="", readiness=false. Elapsed: 16.437397694s
Feb 22 05:31:55.284: INFO: Pod "pod-projected-configmaps-ba8c0dad-1b76-407c-90b6-16a0bb2fa13e": Phase="Pending", Reason="", readiness=false. Elapsed: 18.725007604s
Feb 22 05:31:57.316: INFO: Pod "pod-projected-configmaps-ba8c0dad-1b76-407c-90b6-16a0bb2fa13e": Phase="Pending", Reason="", readiness=false. Elapsed: 20.756571672s
Feb 22 05:31:59.325: INFO: Pod "pod-projected-configmaps-ba8c0dad-1b76-407c-90b6-16a0bb2fa13e": Phase="Pending", Reason="", readiness=false. Elapsed: 22.766023737s
Feb 22 05:32:01.337: INFO: Pod "pod-projected-configmaps-ba8c0dad-1b76-407c-90b6-16a0bb2fa13e": Phase="Pending", Reason="", readiness=false. Elapsed: 24.777835725s
Feb 22 05:32:03.568: INFO: Pod "pod-projected-configmaps-ba8c0dad-1b76-407c-90b6-16a0bb2fa13e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 27.00904195s
STEP: Saw pod success
Feb 22 05:32:03.569: INFO: Pod "pod-projected-configmaps-ba8c0dad-1b76-407c-90b6-16a0bb2fa13e" satisfied condition "Succeeded or Failed"
Feb 22 05:32:03.663: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com pod pod-projected-configmaps-ba8c0dad-1b76-407c-90b6-16a0bb2fa13e container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 22 05:32:03.983: INFO: Waiting for pod pod-projected-configmaps-ba8c0dad-1b76-407c-90b6-16a0bb2fa13e to disappear
Feb 22 05:32:04.113: INFO: Pod pod-projected-configmaps-ba8c0dad-1b76-407c-90b6-16a0bb2fa13e still exists
Feb 22 05:32:06.114: INFO: Waiting for pod pod-projected-configmaps-ba8c0dad-1b76-407c-90b6-16a0bb2fa13e to disappear
Feb 22 05:32:06.135: INFO: Pod pod-projected-configmaps-ba8c0dad-1b76-407c-90b6-16a0bb2fa13e still exists
Feb 22 05:32:08.114: INFO: Waiting for pod pod-projected-configmaps-ba8c0dad-1b76-407c-90b6-16a0bb2fa13e to disappear
Feb 22 05:32:08.125: INFO: Pod pod-projected-configmaps-ba8c0dad-1b76-407c-90b6-16a0bb2fa13e still exists
Feb 22 05:32:10.114: INFO: Waiting for pod pod-projected-configmaps-ba8c0dad-1b76-407c-90b6-16a0bb2fa13e to disappear
Feb 22 05:32:10.180: INFO: Pod pod-projected-configmaps-ba8c0dad-1b76-407c-90b6-16a0bb2fa13e still exists
Feb 22 05:32:12.115: INFO: Waiting for pod pod-projected-configmaps-ba8c0dad-1b76-407c-90b6-16a0bb2fa13e to disappear
Feb 22 05:32:12.134: INFO: Pod pod-projected-configmaps-ba8c0dad-1b76-407c-90b6-16a0bb2fa13e still exists
Feb 22 05:32:14.114: INFO: Waiting for pod pod-projected-configmaps-ba8c0dad-1b76-407c-90b6-16a0bb2fa13e to disappear
Feb 22 05:32:14.129: INFO: Pod pod-projected-configmaps-ba8c0dad-1b76-407c-90b6-16a0bb2fa13e still exists
Feb 22 05:32:16.114: INFO: Waiting for pod pod-projected-configmaps-ba8c0dad-1b76-407c-90b6-16a0bb2fa13e to disappear
Feb 22 05:32:16.126: INFO: Pod pod-projected-configmaps-ba8c0dad-1b76-407c-90b6-16a0bb2fa13e still exists
Feb 22 05:32:18.114: INFO: Waiting for pod pod-projected-configmaps-ba8c0dad-1b76-407c-90b6-16a0bb2fa13e to disappear
Feb 22 05:32:18.127: INFO: Pod pod-projected-configmaps-ba8c0dad-1b76-407c-90b6-16a0bb2fa13e no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 05:32:18.129: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-519" for this suite.

â€¢ [SLOW TEST:42.217 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:36
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","total":270,"completed":99,"skipped":1723,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 05:32:18.300: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9962
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward api env vars
Feb 22 05:32:18.752: INFO: Waiting up to 5m0s for pod "downward-api-e8354aed-4b03-4884-87b1-c771b490a89f" in namespace "downward-api-9962" to be "Succeeded or Failed"
Feb 22 05:32:18.909: INFO: Pod "downward-api-e8354aed-4b03-4884-87b1-c771b490a89f": Phase="Pending", Reason="", readiness=false. Elapsed: 155.993379ms
Feb 22 05:32:20.977: INFO: Pod "downward-api-e8354aed-4b03-4884-87b1-c771b490a89f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.223570216s
Feb 22 05:32:22.993: INFO: Pod "downward-api-e8354aed-4b03-4884-87b1-c771b490a89f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.239715804s
Feb 22 05:32:25.013: INFO: Pod "downward-api-e8354aed-4b03-4884-87b1-c771b490a89f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.260043441s
Feb 22 05:32:27.048: INFO: Pod "downward-api-e8354aed-4b03-4884-87b1-c771b490a89f": Phase="Pending", Reason="", readiness=false. Elapsed: 8.295216491s
Feb 22 05:32:29.058: INFO: Pod "downward-api-e8354aed-4b03-4884-87b1-c771b490a89f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.304637049s
Feb 22 05:32:31.079: INFO: Pod "downward-api-e8354aed-4b03-4884-87b1-c771b490a89f": Phase="Pending", Reason="", readiness=false. Elapsed: 12.325901655s
Feb 22 05:32:33.089: INFO: Pod "downward-api-e8354aed-4b03-4884-87b1-c771b490a89f": Phase="Pending", Reason="", readiness=false. Elapsed: 14.336347901s
Feb 22 05:32:35.099: INFO: Pod "downward-api-e8354aed-4b03-4884-87b1-c771b490a89f": Phase="Pending", Reason="", readiness=false. Elapsed: 16.345934468s
Feb 22 05:32:37.110: INFO: Pod "downward-api-e8354aed-4b03-4884-87b1-c771b490a89f": Phase="Pending", Reason="", readiness=false. Elapsed: 18.357037706s
Feb 22 05:32:39.234: INFO: Pod "downward-api-e8354aed-4b03-4884-87b1-c771b490a89f": Phase="Pending", Reason="", readiness=false. Elapsed: 20.480901214s
Feb 22 05:32:41.250: INFO: Pod "downward-api-e8354aed-4b03-4884-87b1-c771b490a89f": Phase="Pending", Reason="", readiness=false. Elapsed: 22.497147646s
Feb 22 05:32:43.295: INFO: Pod "downward-api-e8354aed-4b03-4884-87b1-c771b490a89f": Phase="Pending", Reason="", readiness=false. Elapsed: 24.542158657s
Feb 22 05:32:45.312: INFO: Pod "downward-api-e8354aed-4b03-4884-87b1-c771b490a89f": Phase="Pending", Reason="", readiness=false. Elapsed: 26.558693537s
Feb 22 05:32:47.330: INFO: Pod "downward-api-e8354aed-4b03-4884-87b1-c771b490a89f": Phase="Pending", Reason="", readiness=false. Elapsed: 28.576783343s
Feb 22 05:32:49.355: INFO: Pod "downward-api-e8354aed-4b03-4884-87b1-c771b490a89f": Phase="Pending", Reason="", readiness=false. Elapsed: 30.602175046s
Feb 22 05:32:51.364: INFO: Pod "downward-api-e8354aed-4b03-4884-87b1-c771b490a89f": Phase="Pending", Reason="", readiness=false. Elapsed: 32.611484118s
Feb 22 05:32:53.379: INFO: Pod "downward-api-e8354aed-4b03-4884-87b1-c771b490a89f": Phase="Pending", Reason="", readiness=false. Elapsed: 34.626482407s
Feb 22 05:32:55.389: INFO: Pod "downward-api-e8354aed-4b03-4884-87b1-c771b490a89f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 36.636364396s
STEP: Saw pod success
Feb 22 05:32:55.389: INFO: Pod "downward-api-e8354aed-4b03-4884-87b1-c771b490a89f" satisfied condition "Succeeded or Failed"
Feb 22 05:32:55.407: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com pod downward-api-e8354aed-4b03-4884-87b1-c771b490a89f container dapi-container: <nil>
STEP: delete the pod
Feb 22 05:32:55.544: INFO: Waiting for pod downward-api-e8354aed-4b03-4884-87b1-c771b490a89f to disappear
Feb 22 05:32:55.570: INFO: Pod downward-api-e8354aed-4b03-4884-87b1-c771b490a89f still exists
Feb 22 05:32:57.572: INFO: Waiting for pod downward-api-e8354aed-4b03-4884-87b1-c771b490a89f to disappear
Feb 22 05:32:57.604: INFO: Pod downward-api-e8354aed-4b03-4884-87b1-c771b490a89f still exists
Feb 22 05:32:59.572: INFO: Waiting for pod downward-api-e8354aed-4b03-4884-87b1-c771b490a89f to disappear
Feb 22 05:32:59.612: INFO: Pod downward-api-e8354aed-4b03-4884-87b1-c771b490a89f still exists
Feb 22 05:33:01.572: INFO: Waiting for pod downward-api-e8354aed-4b03-4884-87b1-c771b490a89f to disappear
Feb 22 05:33:01.592: INFO: Pod downward-api-e8354aed-4b03-4884-87b1-c771b490a89f still exists
Feb 22 05:33:03.572: INFO: Waiting for pod downward-api-e8354aed-4b03-4884-87b1-c771b490a89f to disappear
Feb 22 05:33:03.597: INFO: Pod downward-api-e8354aed-4b03-4884-87b1-c771b490a89f still exists
Feb 22 05:33:05.572: INFO: Waiting for pod downward-api-e8354aed-4b03-4884-87b1-c771b490a89f to disappear
Feb 22 05:33:05.588: INFO: Pod downward-api-e8354aed-4b03-4884-87b1-c771b490a89f still exists
Feb 22 05:33:07.572: INFO: Waiting for pod downward-api-e8354aed-4b03-4884-87b1-c771b490a89f to disappear
Feb 22 05:33:07.599: INFO: Pod downward-api-e8354aed-4b03-4884-87b1-c771b490a89f still exists
Feb 22 05:33:09.573: INFO: Waiting for pod downward-api-e8354aed-4b03-4884-87b1-c771b490a89f to disappear
Feb 22 05:33:09.580: INFO: Pod downward-api-e8354aed-4b03-4884-87b1-c771b490a89f no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 05:33:09.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9962" for this suite.

â€¢ [SLOW TEST:51.320 seconds]
[sig-node] Downward API
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:34
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]","total":270,"completed":100,"skipped":1748,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-scheduling] LimitRange 
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] LimitRange
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 05:33:09.641: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename limitrange
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in limitrange-6130
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a LimitRange
STEP: Setting up watch
STEP: Submitting a LimitRange
Feb 22 05:33:09.979: INFO: observed the limitRanges list
STEP: Verifying LimitRange creation was observed
STEP: Fetching the LimitRange to ensure it has proper values
Feb 22 05:33:10.021: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Feb 22 05:33:10.021: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with no resource requirements
STEP: Ensuring Pod has resource requirements applied from LimitRange
Feb 22 05:33:10.134: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Feb 22 05:33:10.134: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with partial resource requirements
STEP: Ensuring Pod has merged resource requirements applied from LimitRange
Feb 22 05:33:10.202: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
Feb 22 05:33:10.202: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Failing to create a Pod with less than min resources
STEP: Failing to create a Pod with more than max resources
STEP: Updating a LimitRange
STEP: Verifying LimitRange updating is effective
STEP: Creating a Pod with less than former min resources
STEP: Failing to create a Pod with more than max resources
STEP: Deleting a LimitRange
STEP: Verifying the LimitRange was deleted
Feb 22 05:33:17.574: INFO: limitRange is already deleted
STEP: Creating a Pod with more than former max resources
[AfterEach] [sig-scheduling] LimitRange
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 05:33:17.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "limitrange-6130" for this suite.

â€¢ [SLOW TEST:8.284 seconds]
[sig-scheduling] LimitRange
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]","total":270,"completed":101,"skipped":1760,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 05:33:17.927: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-8007
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Feb 22 05:33:18.379: INFO: Pod name pod-release: Found 0 pods out of 1
Feb 22 05:33:24.255: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 05:33:24.783: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-8007" for this suite.

â€¢ [SLOW TEST:7.202 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] ReplicationController should release no longer matching pods [Conformance]","total":270,"completed":102,"skipped":1785,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 05:33:25.143: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-7252
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7252.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-7252.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7252.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7252.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-7252.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-7252.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-7252.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-7252.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7252.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7252.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-7252.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7252.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-7252.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-7252.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-7252.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-7252.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-7252.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7252.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 22 05:34:00.515: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-7252.svc.cluster.local from pod dns-7252/dns-test-345f3ba1-5a76-416e-82cc-58e458ea7cf0: the server is currently unable to handle the request (get pods dns-test-345f3ba1-5a76-416e-82cc-58e458ea7cf0)
Feb 22 05:34:00.538: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7252.svc.cluster.local from pod dns-7252/dns-test-345f3ba1-5a76-416e-82cc-58e458ea7cf0: the server is currently unable to handle the request (get pods dns-test-345f3ba1-5a76-416e-82cc-58e458ea7cf0)
Feb 22 05:34:00.564: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-7252.svc.cluster.local from pod dns-7252/dns-test-345f3ba1-5a76-416e-82cc-58e458ea7cf0: the server is currently unable to handle the request (get pods dns-test-345f3ba1-5a76-416e-82cc-58e458ea7cf0)
Feb 22 05:34:00.584: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-7252.svc.cluster.local from pod dns-7252/dns-test-345f3ba1-5a76-416e-82cc-58e458ea7cf0: the server is currently unable to handle the request (get pods dns-test-345f3ba1-5a76-416e-82cc-58e458ea7cf0)
Feb 22 05:34:00.596: INFO: Unable to read wheezy_udp@PodARecord from pod dns-7252/dns-test-345f3ba1-5a76-416e-82cc-58e458ea7cf0: the server is currently unable to handle the request (get pods dns-test-345f3ba1-5a76-416e-82cc-58e458ea7cf0)
Feb 22 05:34:00.609: INFO: Unable to read wheezy_tcp@PodARecord from pod dns-7252/dns-test-345f3ba1-5a76-416e-82cc-58e458ea7cf0: the server is currently unable to handle the request (get pods dns-test-345f3ba1-5a76-416e-82cc-58e458ea7cf0)
Feb 22 05:34:00.630: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-7252.svc.cluster.local from pod dns-7252/dns-test-345f3ba1-5a76-416e-82cc-58e458ea7cf0: the server is currently unable to handle the request (get pods dns-test-345f3ba1-5a76-416e-82cc-58e458ea7cf0)
Feb 22 05:34:00.669: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-7252.svc.cluster.local from pod dns-7252/dns-test-345f3ba1-5a76-416e-82cc-58e458ea7cf0: the server is currently unable to handle the request (get pods dns-test-345f3ba1-5a76-416e-82cc-58e458ea7cf0)
Feb 22 05:34:00.681: INFO: Unable to read jessie_udp@dns-test-service-2.dns-7252.svc.cluster.local from pod dns-7252/dns-test-345f3ba1-5a76-416e-82cc-58e458ea7cf0: the server is currently unable to handle the request (get pods dns-test-345f3ba1-5a76-416e-82cc-58e458ea7cf0)
Feb 22 05:34:00.696: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-7252.svc.cluster.local from pod dns-7252/dns-test-345f3ba1-5a76-416e-82cc-58e458ea7cf0: the server is currently unable to handle the request (get pods dns-test-345f3ba1-5a76-416e-82cc-58e458ea7cf0)
Feb 22 05:34:00.711: INFO: Unable to read jessie_udp@PodARecord from pod dns-7252/dns-test-345f3ba1-5a76-416e-82cc-58e458ea7cf0: the server is currently unable to handle the request (get pods dns-test-345f3ba1-5a76-416e-82cc-58e458ea7cf0)
Feb 22 05:34:00.725: INFO: Unable to read jessie_tcp@PodARecord from pod dns-7252/dns-test-345f3ba1-5a76-416e-82cc-58e458ea7cf0: the server is currently unable to handle the request (get pods dns-test-345f3ba1-5a76-416e-82cc-58e458ea7cf0)
Feb 22 05:34:00.725: INFO: Lookups using dns-7252/dns-test-345f3ba1-5a76-416e-82cc-58e458ea7cf0 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-7252.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7252.svc.cluster.local wheezy_udp@dns-test-service-2.dns-7252.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-7252.svc.cluster.local wheezy_udp@PodARecord wheezy_tcp@PodARecord jessie_udp@dns-querier-2.dns-test-service-2.dns-7252.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-7252.svc.cluster.local jessie_udp@dns-test-service-2.dns-7252.svc.cluster.local jessie_tcp@dns-test-service-2.dns-7252.svc.cluster.local jessie_udp@PodARecord jessie_tcp@PodARecord]

Feb 22 05:34:05.806: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-7252.svc.cluster.local from pod dns-7252/dns-test-345f3ba1-5a76-416e-82cc-58e458ea7cf0: the server could not find the requested resource (get pods dns-test-345f3ba1-5a76-416e-82cc-58e458ea7cf0)
Feb 22 05:34:06.057: INFO: Lookups using dns-7252/dns-test-345f3ba1-5a76-416e-82cc-58e458ea7cf0 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-7252.svc.cluster.local]

Feb 22 05:34:11.329: INFO: DNS probes using dns-7252/dns-test-345f3ba1-5a76-416e-82cc-58e458ea7cf0 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 05:34:11.685: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7252" for this suite.

â€¢ [SLOW TEST:46.655 seconds]
[sig-network] DNS
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Subdomain [Conformance]","total":270,"completed":103,"skipped":1799,"failed":0}
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 05:34:11.801: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-550
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Update Demo
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:271
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a replication controller
Feb 22 05:34:12.413: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config create -f - --namespace=kubectl-550'
Feb 22 05:34:14.228: INFO: stderr: ""
Feb 22 05:34:14.228: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 22 05:34:14.231: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-550'
Feb 22 05:34:14.788: INFO: stderr: ""
Feb 22 05:34:14.789: INFO: stdout: "update-demo-nautilus-2lh4d update-demo-nautilus-lqpxv "
Feb 22 05:34:14.789: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods update-demo-nautilus-2lh4d -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-550'
Feb 22 05:34:15.274: INFO: stderr: ""
Feb 22 05:34:15.274: INFO: stdout: ""
Feb 22 05:34:15.274: INFO: update-demo-nautilus-2lh4d is created but not running
Feb 22 05:34:20.275: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-550'
Feb 22 05:34:20.695: INFO: stderr: ""
Feb 22 05:34:20.695: INFO: stdout: "update-demo-nautilus-2lh4d update-demo-nautilus-lqpxv "
Feb 22 05:34:20.695: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods update-demo-nautilus-2lh4d -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-550'
Feb 22 05:34:20.938: INFO: stderr: ""
Feb 22 05:34:20.938: INFO: stdout: ""
Feb 22 05:34:20.938: INFO: update-demo-nautilus-2lh4d is created but not running
Feb 22 05:34:25.938: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-550'
Feb 22 05:34:26.276: INFO: stderr: ""
Feb 22 05:34:26.276: INFO: stdout: "update-demo-nautilus-2lh4d update-demo-nautilus-lqpxv "
Feb 22 05:34:26.279: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods update-demo-nautilus-2lh4d -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-550'
Feb 22 05:34:26.581: INFO: stderr: ""
Feb 22 05:34:26.581: INFO: stdout: ""
Feb 22 05:34:26.581: INFO: update-demo-nautilus-2lh4d is created but not running
Feb 22 05:34:31.582: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-550'
Feb 22 05:34:31.948: INFO: stderr: ""
Feb 22 05:34:31.948: INFO: stdout: "update-demo-nautilus-2lh4d update-demo-nautilus-lqpxv "
Feb 22 05:34:31.948: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods update-demo-nautilus-2lh4d -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-550'
Feb 22 05:34:32.177: INFO: stderr: ""
Feb 22 05:34:32.177: INFO: stdout: ""
Feb 22 05:34:32.177: INFO: update-demo-nautilus-2lh4d is created but not running
Feb 22 05:34:37.178: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-550'
Feb 22 05:34:37.517: INFO: stderr: ""
Feb 22 05:34:37.517: INFO: stdout: "update-demo-nautilus-2lh4d update-demo-nautilus-lqpxv "
Feb 22 05:34:37.517: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods update-demo-nautilus-2lh4d -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-550'
Feb 22 05:34:37.763: INFO: stderr: ""
Feb 22 05:34:37.763: INFO: stdout: ""
Feb 22 05:34:37.763: INFO: update-demo-nautilus-2lh4d is created but not running
Feb 22 05:34:42.764: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-550'
Feb 22 05:34:43.083: INFO: stderr: ""
Feb 22 05:34:43.083: INFO: stdout: "update-demo-nautilus-2lh4d update-demo-nautilus-lqpxv "
Feb 22 05:34:43.083: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods update-demo-nautilus-2lh4d -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-550'
Feb 22 05:34:43.397: INFO: stderr: ""
Feb 22 05:34:43.397: INFO: stdout: ""
Feb 22 05:34:43.397: INFO: update-demo-nautilus-2lh4d is created but not running
Feb 22 05:34:48.397: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-550'
Feb 22 05:34:48.945: INFO: stderr: ""
Feb 22 05:34:48.945: INFO: stdout: "update-demo-nautilus-2lh4d update-demo-nautilus-lqpxv "
Feb 22 05:34:48.946: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods update-demo-nautilus-2lh4d -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-550'
Feb 22 05:34:49.301: INFO: stderr: ""
Feb 22 05:34:49.301: INFO: stdout: ""
Feb 22 05:34:49.301: INFO: update-demo-nautilus-2lh4d is created but not running
Feb 22 05:34:54.319: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-550'
Feb 22 05:34:54.649: INFO: stderr: ""
Feb 22 05:34:54.649: INFO: stdout: "update-demo-nautilus-2lh4d update-demo-nautilus-lqpxv "
Feb 22 05:34:54.649: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods update-demo-nautilus-2lh4d -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-550'
Feb 22 05:34:54.919: INFO: stderr: ""
Feb 22 05:34:54.919: INFO: stdout: ""
Feb 22 05:34:54.919: INFO: update-demo-nautilus-2lh4d is created but not running
Feb 22 05:34:59.919: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-550'
Feb 22 05:35:00.175: INFO: stderr: ""
Feb 22 05:35:00.176: INFO: stdout: "update-demo-nautilus-2lh4d update-demo-nautilus-lqpxv "
Feb 22 05:35:00.176: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods update-demo-nautilus-2lh4d -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-550'
Feb 22 05:35:00.511: INFO: stderr: ""
Feb 22 05:35:00.511: INFO: stdout: "true"
Feb 22 05:35:00.511: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods update-demo-nautilus-2lh4d -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-550'
Feb 22 05:35:00.889: INFO: stderr: ""
Feb 22 05:35:00.889: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 22 05:35:00.889: INFO: validating pod update-demo-nautilus-2lh4d
Feb 22 05:35:00.987: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 22 05:35:00.988: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 22 05:35:00.988: INFO: update-demo-nautilus-2lh4d is verified up and running
Feb 22 05:35:00.989: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods update-demo-nautilus-lqpxv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-550'
Feb 22 05:35:01.348: INFO: stderr: ""
Feb 22 05:35:01.348: INFO: stdout: "true"
Feb 22 05:35:01.348: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods update-demo-nautilus-lqpxv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-550'
Feb 22 05:35:01.638: INFO: stderr: ""
Feb 22 05:35:01.638: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 22 05:35:01.638: INFO: validating pod update-demo-nautilus-lqpxv
Feb 22 05:35:01.739: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 22 05:35:01.739: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 22 05:35:01.739: INFO: update-demo-nautilus-lqpxv is verified up and running
STEP: scaling down the replication controller
Feb 22 05:35:01.920: INFO: scanned /root for discovery docs: <nil>
Feb 22 05:35:01.921: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-550'
Feb 22 05:35:03.471: INFO: stderr: ""
Feb 22 05:35:03.472: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 22 05:35:03.472: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-550'
Feb 22 05:35:03.710: INFO: stderr: ""
Feb 22 05:35:03.710: INFO: stdout: "update-demo-nautilus-2lh4d update-demo-nautilus-lqpxv "
STEP: Replicas for name=update-demo: expected=1 actual=2
Feb 22 05:35:08.710: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-550'
Feb 22 05:35:09.031: INFO: stderr: ""
Feb 22 05:35:09.031: INFO: stdout: "update-demo-nautilus-2lh4d update-demo-nautilus-lqpxv "
STEP: Replicas for name=update-demo: expected=1 actual=2
Feb 22 05:35:14.031: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-550'
Feb 22 05:35:14.204: INFO: stderr: ""
Feb 22 05:35:14.204: INFO: stdout: "update-demo-nautilus-2lh4d update-demo-nautilus-lqpxv "
STEP: Replicas for name=update-demo: expected=1 actual=2
Feb 22 05:35:19.205: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-550'
Feb 22 05:35:19.695: INFO: stderr: ""
Feb 22 05:35:19.696: INFO: stdout: "update-demo-nautilus-2lh4d update-demo-nautilus-lqpxv "
STEP: Replicas for name=update-demo: expected=1 actual=2
Feb 22 05:35:24.701: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-550'
Feb 22 05:35:25.185: INFO: stderr: ""
Feb 22 05:35:25.185: INFO: stdout: "update-demo-nautilus-2lh4d "
Feb 22 05:35:25.189: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods update-demo-nautilus-2lh4d -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-550'
Feb 22 05:35:25.439: INFO: stderr: ""
Feb 22 05:35:25.439: INFO: stdout: "true"
Feb 22 05:35:25.439: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods update-demo-nautilus-2lh4d -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-550'
Feb 22 05:35:25.675: INFO: stderr: ""
Feb 22 05:35:25.675: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 22 05:35:25.675: INFO: validating pod update-demo-nautilus-2lh4d
Feb 22 05:35:25.737: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 22 05:35:25.742: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 22 05:35:25.743: INFO: update-demo-nautilus-2lh4d is verified up and running
STEP: scaling up the replication controller
Feb 22 05:35:25.850: INFO: scanned /root for discovery docs: <nil>
Feb 22 05:35:25.853: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-550'
Feb 22 05:35:27.616: INFO: stderr: ""
Feb 22 05:35:27.616: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 22 05:35:27.616: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-550'
Feb 22 05:35:27.901: INFO: stderr: ""
Feb 22 05:35:27.901: INFO: stdout: "update-demo-nautilus-2lh4d update-demo-nautilus-mc2l4 "
Feb 22 05:35:27.901: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods update-demo-nautilus-2lh4d -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-550'
Feb 22 05:35:28.232: INFO: stderr: ""
Feb 22 05:35:28.232: INFO: stdout: "true"
Feb 22 05:35:28.232: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods update-demo-nautilus-2lh4d -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-550'
Feb 22 05:35:28.529: INFO: stderr: ""
Feb 22 05:35:28.529: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 22 05:35:28.529: INFO: validating pod update-demo-nautilus-2lh4d
Feb 22 05:35:28.585: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 22 05:35:28.585: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 22 05:35:28.585: INFO: update-demo-nautilus-2lh4d is verified up and running
Feb 22 05:35:28.585: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods update-demo-nautilus-mc2l4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-550'
Feb 22 05:35:29.017: INFO: stderr: ""
Feb 22 05:35:29.017: INFO: stdout: ""
Feb 22 05:35:29.017: INFO: update-demo-nautilus-mc2l4 is created but not running
Feb 22 05:35:34.018: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-550'
Feb 22 05:35:34.378: INFO: stderr: ""
Feb 22 05:35:34.378: INFO: stdout: "update-demo-nautilus-2lh4d update-demo-nautilus-mc2l4 "
Feb 22 05:35:34.378: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods update-demo-nautilus-2lh4d -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-550'
Feb 22 05:35:34.812: INFO: stderr: ""
Feb 22 05:35:34.812: INFO: stdout: "true"
Feb 22 05:35:34.812: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods update-demo-nautilus-2lh4d -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-550'
Feb 22 05:35:35.127: INFO: stderr: ""
Feb 22 05:35:35.127: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 22 05:35:35.127: INFO: validating pod update-demo-nautilus-2lh4d
Feb 22 05:35:35.145: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 22 05:35:35.145: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 22 05:35:35.145: INFO: update-demo-nautilus-2lh4d is verified up and running
Feb 22 05:35:35.146: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods update-demo-nautilus-mc2l4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-550'
Feb 22 05:35:35.527: INFO: stderr: ""
Feb 22 05:35:35.527: INFO: stdout: ""
Feb 22 05:35:35.527: INFO: update-demo-nautilus-mc2l4 is created but not running
Feb 22 05:35:40.528: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-550'
Feb 22 05:35:40.846: INFO: stderr: ""
Feb 22 05:35:40.846: INFO: stdout: "update-demo-nautilus-2lh4d update-demo-nautilus-mc2l4 "
Feb 22 05:35:40.846: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods update-demo-nautilus-2lh4d -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-550'
Feb 22 05:35:41.055: INFO: stderr: ""
Feb 22 05:35:41.055: INFO: stdout: "true"
Feb 22 05:35:41.057: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods update-demo-nautilus-2lh4d -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-550'
Feb 22 05:35:41.356: INFO: stderr: ""
Feb 22 05:35:41.357: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 22 05:35:41.358: INFO: validating pod update-demo-nautilus-2lh4d
Feb 22 05:35:41.389: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 22 05:35:41.389: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 22 05:35:41.389: INFO: update-demo-nautilus-2lh4d is verified up and running
Feb 22 05:35:41.389: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods update-demo-nautilus-mc2l4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-550'
Feb 22 05:35:41.718: INFO: stderr: ""
Feb 22 05:35:41.718: INFO: stdout: ""
Feb 22 05:35:41.718: INFO: update-demo-nautilus-mc2l4 is created but not running
Feb 22 05:35:46.719: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-550'
Feb 22 05:35:47.077: INFO: stderr: ""
Feb 22 05:35:47.077: INFO: stdout: "update-demo-nautilus-2lh4d update-demo-nautilus-mc2l4 "
Feb 22 05:35:47.077: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods update-demo-nautilus-2lh4d -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-550'
Feb 22 05:35:47.388: INFO: stderr: ""
Feb 22 05:35:47.388: INFO: stdout: "true"
Feb 22 05:35:47.388: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods update-demo-nautilus-2lh4d -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-550'
Feb 22 05:35:47.806: INFO: stderr: ""
Feb 22 05:35:47.806: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 22 05:35:47.806: INFO: validating pod update-demo-nautilus-2lh4d
Feb 22 05:35:47.828: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 22 05:35:47.828: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 22 05:35:47.828: INFO: update-demo-nautilus-2lh4d is verified up and running
Feb 22 05:35:47.828: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods update-demo-nautilus-mc2l4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-550'
Feb 22 05:35:48.094: INFO: stderr: ""
Feb 22 05:35:48.094: INFO: stdout: ""
Feb 22 05:35:48.094: INFO: update-demo-nautilus-mc2l4 is created but not running
Feb 22 05:35:53.096: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-550'
Feb 22 05:35:53.336: INFO: stderr: ""
Feb 22 05:35:53.337: INFO: stdout: "update-demo-nautilus-2lh4d update-demo-nautilus-mc2l4 "
Feb 22 05:35:53.337: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods update-demo-nautilus-2lh4d -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-550'
Feb 22 05:35:53.649: INFO: stderr: ""
Feb 22 05:35:53.649: INFO: stdout: "true"
Feb 22 05:35:53.650: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods update-demo-nautilus-2lh4d -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-550'
Feb 22 05:35:53.934: INFO: stderr: ""
Feb 22 05:35:53.934: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 22 05:35:53.934: INFO: validating pod update-demo-nautilus-2lh4d
Feb 22 05:35:53.951: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 22 05:35:53.951: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 22 05:35:53.951: INFO: update-demo-nautilus-2lh4d is verified up and running
Feb 22 05:35:53.952: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods update-demo-nautilus-mc2l4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-550'
Feb 22 05:35:54.176: INFO: stderr: ""
Feb 22 05:35:54.176: INFO: stdout: "true"
Feb 22 05:35:54.176: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods update-demo-nautilus-mc2l4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-550'
Feb 22 05:35:54.352: INFO: stderr: ""
Feb 22 05:35:54.352: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 22 05:35:54.352: INFO: validating pod update-demo-nautilus-mc2l4
Feb 22 05:35:54.427: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 22 05:35:54.427: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 22 05:35:54.427: INFO: update-demo-nautilus-mc2l4 is verified up and running
STEP: using delete to clean up resources
Feb 22 05:35:54.428: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config delete --grace-period=0 --force -f - --namespace=kubectl-550'
Feb 22 05:35:54.745: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 22 05:35:54.745: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Feb 22 05:35:54.746: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get rc,svc -l name=update-demo --no-headers --namespace=kubectl-550'
Feb 22 05:35:55.158: INFO: stderr: "No resources found in kubectl-550 namespace.\n"
Feb 22 05:35:55.158: INFO: stdout: ""
Feb 22 05:35:55.158: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods -l name=update-demo --namespace=kubectl-550 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 22 05:35:55.453: INFO: stderr: ""
Feb 22 05:35:55.453: INFO: stdout: "update-demo-nautilus-2lh4d\nupdate-demo-nautilus-mc2l4\n"
Feb 22 05:35:55.954: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get rc,svc -l name=update-demo --no-headers --namespace=kubectl-550'
Feb 22 05:35:56.528: INFO: stderr: "No resources found in kubectl-550 namespace.\n"
Feb 22 05:35:56.528: INFO: stdout: ""
Feb 22 05:35:56.528: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods -l name=update-demo --namespace=kubectl-550 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 22 05:35:56.884: INFO: stderr: ""
Feb 22 05:35:56.888: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 05:35:56.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-550" for this suite.

â€¢ [SLOW TEST:105.359 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:269
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should scale a replication controller  [Conformance]","total":270,"completed":104,"skipped":1809,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 05:35:57.189: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-6169
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Feb 22 05:35:57.811: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"af72789d-92de-4c54-88ae-37ae8898861e", Controller:(*bool)(0xc008af6b7a), BlockOwnerDeletion:(*bool)(0xc008af6b7b)}}
Feb 22 05:35:57.867: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"cbb0c177-7bff-42b0-8912-f3a03bbb1274", Controller:(*bool)(0xc008bb7742), BlockOwnerDeletion:(*bool)(0xc008bb7743)}}
Feb 22 05:35:57.957: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"ae871c9e-1f6a-405b-9714-9eac768b4ede", Controller:(*bool)(0xc008af6d62), BlockOwnerDeletion:(*bool)(0xc008af6d63)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 05:36:03.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6169" for this suite.

â€¢ [SLOW TEST:6.146 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]","total":270,"completed":105,"skipped":1843,"failed":0}
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 05:36:03.346: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-2154
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 22 05:36:10.309: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb 22 05:36:14.535: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749568970, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749568970, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749568971, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749568970, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:36:17.601: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749568970, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749568970, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749568971, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749568970, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:36:19.462: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749568970, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749568970, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749568971, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749568970, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:36:20.617: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749568970, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749568970, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749568971, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749568970, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:36:23.381: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749568970, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749568970, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749568971, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749568970, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:36:24.608: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749568970, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749568970, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749568971, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749568970, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:36:26.767: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749568970, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749568970, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749568971, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749568970, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:36:28.577: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749568970, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749568970, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749568971, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749568970, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:36:31.431: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749568970, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749568970, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749568971, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749568970, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:36:32.567: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749568970, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749568970, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749568971, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749568970, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:36:34.563: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749568970, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749568970, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749568971, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749568970, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:36:36.586: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749568970, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749568970, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749568971, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749568970, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:36:38.568: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749568970, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749568970, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749568971, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749568970, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:36:40.569: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749568970, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749568970, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749568971, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749568970, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:36:42.808: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749568970, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749568970, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749568971, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749568970, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:36:44.561: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749568970, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749568970, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749568971, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749568970, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:36:46.564: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749568970, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749568970, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749568971, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749568970, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 22 05:36:49.624: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 05:36:50.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2154" for this suite.
STEP: Destroying namespace "webhook-2154-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

â€¢ [SLOW TEST:47.722 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]","total":270,"completed":106,"skipped":1847,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 05:36:51.094: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-8534
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 22 05:36:52.095: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb 22 05:36:54.128: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569012, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569012, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569012, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569012, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:36:56.143: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569012, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569012, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569012, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569012, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:36:58.147: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569012, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569012, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569012, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569012, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:37:01.087: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569012, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569012, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569012, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569012, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:37:02.208: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569012, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569012, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569012, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569012, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:37:04.429: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569012, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569012, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569012, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569012, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:37:06.137: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569012, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569012, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569012, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569012, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:37:08.148: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569012, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569012, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569012, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569012, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:37:10.142: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569012, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569012, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569012, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569012, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:37:12.202: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569012, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569012, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569012, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569012, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:37:14.151: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569012, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569012, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569012, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569012, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:37:16.138: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569012, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569012, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569012, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569012, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:37:18.149: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569012, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569012, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569012, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569012, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:37:20.141: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569012, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569012, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569012, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569012, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:37:22.167: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569012, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569012, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569012, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569012, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 22 05:37:25.289: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Feb 22 05:37:25.300: INFO: >>> kubeConfig: /root/.kube/config
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-4045-crds.webhook.example.com via the AdmissionRegistration API
Feb 22 05:37:26.304: INFO: Waiting for webhook configuration to be ready...
STEP: Creating a custom resource while v1 is storage version
STEP: Patching Custom Resource Definition to set v2 as storage
STEP: Patching the custom resource while v2 is storage version
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 05:37:29.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8534" for this suite.
STEP: Destroying namespace "webhook-8534-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

â€¢ [SLOW TEST:42.725 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]","total":270,"completed":107,"skipped":1871,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 05:37:33.834: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-6394
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-2340
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-8735
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 05:37:48.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-6394" for this suite.
STEP: Destroying namespace "nsdeletetest-2340" for this suite.
Feb 22 05:37:48.710: INFO: Namespace nsdeletetest-2340 was already deleted
STEP: Destroying namespace "nsdeletetest-8735" for this suite.

â€¢ [SLOW TEST:14.953 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]","total":270,"completed":108,"skipped":1903,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 05:37:48.791: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-2984
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD with validation schema [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Feb 22 05:37:49.160: INFO: >>> kubeConfig: /root/.kube/config
STEP: client-side validation (kubectl create and apply) allows request with known and required properties
Feb 22 05:38:05.848: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-2984 create -f -'
Feb 22 05:38:10.042: INFO: stderr: ""
Feb 22 05:38:10.042: INFO: stdout: "e2e-test-crd-publish-openapi-681-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Feb 22 05:38:10.042: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-2984 delete e2e-test-crd-publish-openapi-681-crds test-foo'
Feb 22 05:38:10.767: INFO: stderr: ""
Feb 22 05:38:10.767: INFO: stdout: "e2e-test-crd-publish-openapi-681-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Feb 22 05:38:10.768: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-2984 apply -f -'
Feb 22 05:38:14.090: INFO: stderr: ""
Feb 22 05:38:14.090: INFO: stdout: "e2e-test-crd-publish-openapi-681-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Feb 22 05:38:14.090: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-2984 delete e2e-test-crd-publish-openapi-681-crds test-foo'
Feb 22 05:38:14.492: INFO: stderr: ""
Feb 22 05:38:14.492: INFO: stdout: "e2e-test-crd-publish-openapi-681-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: client-side validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema
Feb 22 05:38:14.492: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-2984 create -f -'
Feb 22 05:38:15.177: INFO: rc: 1
Feb 22 05:38:15.178: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-2984 apply -f -'
Feb 22 05:38:16.021: INFO: rc: 1
STEP: client-side validation (kubectl create and apply) rejects request without required properties
Feb 22 05:38:16.021: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-2984 create -f -'
Feb 22 05:38:17.213: INFO: rc: 1
Feb 22 05:38:17.213: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-2984 apply -f -'
Feb 22 05:38:18.392: INFO: rc: 1
STEP: kubectl explain works to explain CR properties
Feb 22 05:38:18.392: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config explain e2e-test-crd-publish-openapi-681-crds'
Feb 22 05:38:19.596: INFO: stderr: ""
Feb 22 05:38:19.596: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-681-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively
Feb 22 05:38:19.603: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config explain e2e-test-crd-publish-openapi-681-crds.metadata'
Feb 22 05:38:20.485: INFO: stderr: ""
Feb 22 05:38:20.485: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-681-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   clusterName\t<string>\n     The name of the cluster which the object belongs to. This is used to\n     distinguish resources with same name and namespace in different clusters.\n     This field is not set anywhere right now and apiserver is going to ignore\n     it if set in create or update request.\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC. Populated by the system.\n     Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested. Populated by the system when a graceful deletion is\n     requested. Read-only. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server. If this field is specified and the generated name exists, the\n     server will NOT return a 409 - instead, it will either return 201 Created\n     or 500 with Reason ServerTimeout indicating a unique name could not be\n     found in the time allotted, and the client should retry (optionally after\n     the time indicated in the Retry-After header). Applied only if Name is not\n     specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty. Must\n     be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources. Populated by the system.\n     Read-only. Value must be treated as opaque by clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     SelfLink is a URL representing this object. Populated by the system.\n     Read-only. DEPRECATED Kubernetes will stop propagating this field in 1.20\n     release and the field is planned to be removed in 1.21 release.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations. Populated by the system. Read-only.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Feb 22 05:38:20.488: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config explain e2e-test-crd-publish-openapi-681-crds.spec'
Feb 22 05:38:21.090: INFO: stderr: ""
Feb 22 05:38:21.090: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-681-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Feb 22 05:38:21.093: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config explain e2e-test-crd-publish-openapi-681-crds.spec.bars'
Feb 22 05:38:21.541: INFO: stderr: ""
Feb 22 05:38:21.541: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-681-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist
Feb 22 05:38:21.547: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config explain e2e-test-crd-publish-openapi-681-crds.spec.bars2'
Feb 22 05:38:21.970: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 05:38:35.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2984" for this suite.

â€¢ [SLOW TEST:46.382 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]","total":270,"completed":109,"skipped":1936,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 05:38:35.177: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-8410
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Service
STEP: Ensuring resource quota status captures service creation
STEP: Deleting a Service
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 05:38:47.493: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8410" for this suite.

â€¢ [SLOW TEST:12.507 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]","total":270,"completed":110,"skipped":1951,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 05:38:47.700: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1151
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Feb 22 05:38:48.317: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6ebeebc1-1173-4046-bd2b-8a1371832f66" in namespace "downward-api-1151" to be "Succeeded or Failed"
Feb 22 05:38:48.434: INFO: Pod "downwardapi-volume-6ebeebc1-1173-4046-bd2b-8a1371832f66": Phase="Pending", Reason="", readiness=false. Elapsed: 117.124661ms
Feb 22 05:38:50.448: INFO: Pod "downwardapi-volume-6ebeebc1-1173-4046-bd2b-8a1371832f66": Phase="Pending", Reason="", readiness=false. Elapsed: 2.13049957s
Feb 22 05:38:52.461: INFO: Pod "downwardapi-volume-6ebeebc1-1173-4046-bd2b-8a1371832f66": Phase="Pending", Reason="", readiness=false. Elapsed: 4.143932481s
Feb 22 05:38:54.473: INFO: Pod "downwardapi-volume-6ebeebc1-1173-4046-bd2b-8a1371832f66": Phase="Pending", Reason="", readiness=false. Elapsed: 6.155689837s
Feb 22 05:38:56.487: INFO: Pod "downwardapi-volume-6ebeebc1-1173-4046-bd2b-8a1371832f66": Phase="Pending", Reason="", readiness=false. Elapsed: 8.170305439s
Feb 22 05:38:58.495: INFO: Pod "downwardapi-volume-6ebeebc1-1173-4046-bd2b-8a1371832f66": Phase="Pending", Reason="", readiness=false. Elapsed: 10.178072398s
Feb 22 05:39:00.508: INFO: Pod "downwardapi-volume-6ebeebc1-1173-4046-bd2b-8a1371832f66": Phase="Pending", Reason="", readiness=false. Elapsed: 12.190876113s
Feb 22 05:39:02.528: INFO: Pod "downwardapi-volume-6ebeebc1-1173-4046-bd2b-8a1371832f66": Phase="Pending", Reason="", readiness=false. Elapsed: 14.210877499s
Feb 22 05:39:04.553: INFO: Pod "downwardapi-volume-6ebeebc1-1173-4046-bd2b-8a1371832f66": Phase="Pending", Reason="", readiness=false. Elapsed: 16.235908689s
Feb 22 05:39:06.565: INFO: Pod "downwardapi-volume-6ebeebc1-1173-4046-bd2b-8a1371832f66": Phase="Pending", Reason="", readiness=false. Elapsed: 18.24828967s
Feb 22 05:39:08.574: INFO: Pod "downwardapi-volume-6ebeebc1-1173-4046-bd2b-8a1371832f66": Phase="Pending", Reason="", readiness=false. Elapsed: 20.257041776s
Feb 22 05:39:10.587: INFO: Pod "downwardapi-volume-6ebeebc1-1173-4046-bd2b-8a1371832f66": Phase="Pending", Reason="", readiness=false. Elapsed: 22.269482335s
Feb 22 05:39:12.615: INFO: Pod "downwardapi-volume-6ebeebc1-1173-4046-bd2b-8a1371832f66": Phase="Pending", Reason="", readiness=false. Elapsed: 24.298326301s
Feb 22 05:39:14.675: INFO: Pod "downwardapi-volume-6ebeebc1-1173-4046-bd2b-8a1371832f66": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.358427626s
STEP: Saw pod success
Feb 22 05:39:14.676: INFO: Pod "downwardapi-volume-6ebeebc1-1173-4046-bd2b-8a1371832f66" satisfied condition "Succeeded or Failed"
Feb 22 05:39:14.689: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com pod downwardapi-volume-6ebeebc1-1173-4046-bd2b-8a1371832f66 container client-container: <nil>
STEP: delete the pod
Feb 22 05:39:14.835: INFO: Waiting for pod downwardapi-volume-6ebeebc1-1173-4046-bd2b-8a1371832f66 to disappear
Feb 22 05:39:14.892: INFO: Pod downwardapi-volume-6ebeebc1-1173-4046-bd2b-8a1371832f66 still exists
Feb 22 05:39:16.892: INFO: Waiting for pod downwardapi-volume-6ebeebc1-1173-4046-bd2b-8a1371832f66 to disappear
Feb 22 05:39:16.902: INFO: Pod downwardapi-volume-6ebeebc1-1173-4046-bd2b-8a1371832f66 still exists
Feb 22 05:39:18.892: INFO: Waiting for pod downwardapi-volume-6ebeebc1-1173-4046-bd2b-8a1371832f66 to disappear
Feb 22 05:39:18.944: INFO: Pod downwardapi-volume-6ebeebc1-1173-4046-bd2b-8a1371832f66 still exists
Feb 22 05:39:20.892: INFO: Waiting for pod downwardapi-volume-6ebeebc1-1173-4046-bd2b-8a1371832f66 to disappear
Feb 22 05:39:20.907: INFO: Pod downwardapi-volume-6ebeebc1-1173-4046-bd2b-8a1371832f66 still exists
Feb 22 05:39:22.892: INFO: Waiting for pod downwardapi-volume-6ebeebc1-1173-4046-bd2b-8a1371832f66 to disappear
Feb 22 05:39:22.909: INFO: Pod downwardapi-volume-6ebeebc1-1173-4046-bd2b-8a1371832f66 still exists
Feb 22 05:39:24.892: INFO: Waiting for pod downwardapi-volume-6ebeebc1-1173-4046-bd2b-8a1371832f66 to disappear
Feb 22 05:39:24.906: INFO: Pod downwardapi-volume-6ebeebc1-1173-4046-bd2b-8a1371832f66 still exists
Feb 22 05:39:26.892: INFO: Waiting for pod downwardapi-volume-6ebeebc1-1173-4046-bd2b-8a1371832f66 to disappear
Feb 22 05:39:26.909: INFO: Pod downwardapi-volume-6ebeebc1-1173-4046-bd2b-8a1371832f66 still exists
Feb 22 05:39:28.892: INFO: Waiting for pod downwardapi-volume-6ebeebc1-1173-4046-bd2b-8a1371832f66 to disappear
Feb 22 05:39:28.904: INFO: Pod downwardapi-volume-6ebeebc1-1173-4046-bd2b-8a1371832f66 still exists
Feb 22 05:39:30.892: INFO: Waiting for pod downwardapi-volume-6ebeebc1-1173-4046-bd2b-8a1371832f66 to disappear
Feb 22 05:39:30.912: INFO: Pod downwardapi-volume-6ebeebc1-1173-4046-bd2b-8a1371832f66 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 05:39:30.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1151" for this suite.

â€¢ [SLOW TEST:43.302 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:37
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]","total":270,"completed":111,"skipped":1987,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 05:39:31.022: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-2900
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 22 05:39:33.676: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb 22 05:39:35.798: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569173, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569173, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569173, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569173, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:39:37.837: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569173, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569173, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569173, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569173, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:39:39.814: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569173, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569173, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569173, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569173, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:39:41.806: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569173, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569173, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569173, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569173, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:39:43.808: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569173, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569173, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569173, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569173, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:39:45.819: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569173, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569173, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569173, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569173, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:39:47.810: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569173, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569173, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569173, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569173, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:39:49.811: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569173, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569173, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569173, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569173, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:39:51.815: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569173, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569173, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569173, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569173, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:39:53.816: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569173, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569173, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569173, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569173, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:39:55.809: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569173, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569173, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569173, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569173, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:39:57.808: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569173, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569173, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569173, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569173, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:39:59.808: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569173, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569173, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569173, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569173, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:40:02.028: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569173, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569173, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569173, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569173, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:40:03.816: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569173, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569173, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569173, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569173, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 22 05:40:06.878: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a mutating webhook configuration
STEP: Updating a mutating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that should not be mutated
STEP: Patching a mutating webhook configuration's rules to include the create operation
STEP: Creating a configMap that should be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 05:40:08.313: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2900" for this suite.
STEP: Destroying namespace "webhook-2900-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

â€¢ [SLOW TEST:38.063 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]","total":270,"completed":112,"skipped":2002,"failed":0}
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 05:40:09.086: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-545
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir volume type on tmpfs
Feb 22 05:40:09.708: INFO: Waiting up to 5m0s for pod "pod-5656ae6f-747f-4ed7-a8fd-5f8c2afe2bc6" in namespace "emptydir-545" to be "Succeeded or Failed"
Feb 22 05:40:09.731: INFO: Pod "pod-5656ae6f-747f-4ed7-a8fd-5f8c2afe2bc6": Phase="Pending", Reason="", readiness=false. Elapsed: 23.401303ms
Feb 22 05:40:11.784: INFO: Pod "pod-5656ae6f-747f-4ed7-a8fd-5f8c2afe2bc6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.075977636s
Feb 22 05:40:14.066: INFO: Pod "pod-5656ae6f-747f-4ed7-a8fd-5f8c2afe2bc6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.357960752s
Feb 22 05:40:16.085: INFO: Pod "pod-5656ae6f-747f-4ed7-a8fd-5f8c2afe2bc6": Phase="Pending", Reason="", readiness=false. Elapsed: 6.376866255s
Feb 22 05:40:18.122: INFO: Pod "pod-5656ae6f-747f-4ed7-a8fd-5f8c2afe2bc6": Phase="Pending", Reason="", readiness=false. Elapsed: 8.414111475s
Feb 22 05:40:20.527: INFO: Pod "pod-5656ae6f-747f-4ed7-a8fd-5f8c2afe2bc6": Phase="Pending", Reason="", readiness=false. Elapsed: 10.818936417s
Feb 22 05:40:22.578: INFO: Pod "pod-5656ae6f-747f-4ed7-a8fd-5f8c2afe2bc6": Phase="Pending", Reason="", readiness=false. Elapsed: 12.870409386s
Feb 22 05:40:24.598: INFO: Pod "pod-5656ae6f-747f-4ed7-a8fd-5f8c2afe2bc6": Phase="Pending", Reason="", readiness=false. Elapsed: 14.890378609s
Feb 22 05:40:26.613: INFO: Pod "pod-5656ae6f-747f-4ed7-a8fd-5f8c2afe2bc6": Phase="Pending", Reason="", readiness=false. Elapsed: 16.904849343s
Feb 22 05:40:28.627: INFO: Pod "pod-5656ae6f-747f-4ed7-a8fd-5f8c2afe2bc6": Phase="Pending", Reason="", readiness=false. Elapsed: 18.919342111s
Feb 22 05:40:30.638: INFO: Pod "pod-5656ae6f-747f-4ed7-a8fd-5f8c2afe2bc6": Phase="Pending", Reason="", readiness=false. Elapsed: 20.92955965s
Feb 22 05:40:32.646: INFO: Pod "pod-5656ae6f-747f-4ed7-a8fd-5f8c2afe2bc6": Phase="Pending", Reason="", readiness=false. Elapsed: 22.938267254s
Feb 22 05:40:34.661: INFO: Pod "pod-5656ae6f-747f-4ed7-a8fd-5f8c2afe2bc6": Phase="Pending", Reason="", readiness=false. Elapsed: 24.952805702s
Feb 22 05:40:36.677: INFO: Pod "pod-5656ae6f-747f-4ed7-a8fd-5f8c2afe2bc6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.968990585s
STEP: Saw pod success
Feb 22 05:40:36.677: INFO: Pod "pod-5656ae6f-747f-4ed7-a8fd-5f8c2afe2bc6" satisfied condition "Succeeded or Failed"
Feb 22 05:40:36.691: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com pod pod-5656ae6f-747f-4ed7-a8fd-5f8c2afe2bc6 container test-container: <nil>
STEP: delete the pod
Feb 22 05:40:42.330: INFO: Waiting for pod pod-5656ae6f-747f-4ed7-a8fd-5f8c2afe2bc6 to disappear
Feb 22 05:40:42.382: INFO: Pod pod-5656ae6f-747f-4ed7-a8fd-5f8c2afe2bc6 still exists
Feb 22 05:40:44.383: INFO: Waiting for pod pod-5656ae6f-747f-4ed7-a8fd-5f8c2afe2bc6 to disappear
Feb 22 05:40:44.403: INFO: Pod pod-5656ae6f-747f-4ed7-a8fd-5f8c2afe2bc6 still exists
Feb 22 05:40:46.383: INFO: Waiting for pod pod-5656ae6f-747f-4ed7-a8fd-5f8c2afe2bc6 to disappear
Feb 22 05:40:46.403: INFO: Pod pod-5656ae6f-747f-4ed7-a8fd-5f8c2afe2bc6 still exists
Feb 22 05:40:48.383: INFO: Waiting for pod pod-5656ae6f-747f-4ed7-a8fd-5f8c2afe2bc6 to disappear
Feb 22 05:40:48.429: INFO: Pod pod-5656ae6f-747f-4ed7-a8fd-5f8c2afe2bc6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 05:40:48.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-545" for this suite.

â€¢ [SLOW TEST:39.451 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:42
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":270,"completed":113,"skipped":2008,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 05:40:48.540: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1937
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name projected-secret-test-map-7fcc8e89-4945-4430-94b0-4b61b518efc5
STEP: Creating a pod to test consume secrets
Feb 22 05:40:49.255: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-d88dcb63-7e62-4140-8243-8d5265110055" in namespace "projected-1937" to be "Succeeded or Failed"
Feb 22 05:40:49.274: INFO: Pod "pod-projected-secrets-d88dcb63-7e62-4140-8243-8d5265110055": Phase="Pending", Reason="", readiness=false. Elapsed: 18.982878ms
Feb 22 05:40:51.284: INFO: Pod "pod-projected-secrets-d88dcb63-7e62-4140-8243-8d5265110055": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029365297s
Feb 22 05:40:53.317: INFO: Pod "pod-projected-secrets-d88dcb63-7e62-4140-8243-8d5265110055": Phase="Pending", Reason="", readiness=false. Elapsed: 4.062837925s
Feb 22 05:40:55.347: INFO: Pod "pod-projected-secrets-d88dcb63-7e62-4140-8243-8d5265110055": Phase="Pending", Reason="", readiness=false. Elapsed: 6.092030407s
Feb 22 05:40:57.386: INFO: Pod "pod-projected-secrets-d88dcb63-7e62-4140-8243-8d5265110055": Phase="Pending", Reason="", readiness=false. Elapsed: 8.131220911s
Feb 22 05:40:59.773: INFO: Pod "pod-projected-secrets-d88dcb63-7e62-4140-8243-8d5265110055": Phase="Pending", Reason="", readiness=false. Elapsed: 10.518182188s
Feb 22 05:41:01.884: INFO: Pod "pod-projected-secrets-d88dcb63-7e62-4140-8243-8d5265110055": Phase="Pending", Reason="", readiness=false. Elapsed: 12.629304313s
Feb 22 05:41:05.034: INFO: Pod "pod-projected-secrets-d88dcb63-7e62-4140-8243-8d5265110055": Phase="Pending", Reason="", readiness=false. Elapsed: 15.779472712s
Feb 22 05:41:07.250: INFO: Pod "pod-projected-secrets-d88dcb63-7e62-4140-8243-8d5265110055": Phase="Pending", Reason="", readiness=false. Elapsed: 17.995417895s
Feb 22 05:41:09.277: INFO: Pod "pod-projected-secrets-d88dcb63-7e62-4140-8243-8d5265110055": Phase="Pending", Reason="", readiness=false. Elapsed: 20.022678671s
Feb 22 05:41:11.287: INFO: Pod "pod-projected-secrets-d88dcb63-7e62-4140-8243-8d5265110055": Phase="Pending", Reason="", readiness=false. Elapsed: 22.032591772s
Feb 22 05:41:13.305: INFO: Pod "pod-projected-secrets-d88dcb63-7e62-4140-8243-8d5265110055": Phase="Pending", Reason="", readiness=false. Elapsed: 24.05069753s
Feb 22 05:41:15.333: INFO: Pod "pod-projected-secrets-d88dcb63-7e62-4140-8243-8d5265110055": Phase="Pending", Reason="", readiness=false. Elapsed: 26.078751586s
Feb 22 05:41:17.357: INFO: Pod "pod-projected-secrets-d88dcb63-7e62-4140-8243-8d5265110055": Phase="Pending", Reason="", readiness=false. Elapsed: 28.10237145s
Feb 22 05:41:19.399: INFO: Pod "pod-projected-secrets-d88dcb63-7e62-4140-8243-8d5265110055": Phase="Succeeded", Reason="", readiness=false. Elapsed: 30.144502414s
STEP: Saw pod success
Feb 22 05:41:19.400: INFO: Pod "pod-projected-secrets-d88dcb63-7e62-4140-8243-8d5265110055" satisfied condition "Succeeded or Failed"
Feb 22 05:41:19.437: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com pod pod-projected-secrets-d88dcb63-7e62-4140-8243-8d5265110055 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 22 05:41:26.277: INFO: Waiting for pod pod-projected-secrets-d88dcb63-7e62-4140-8243-8d5265110055 to disappear
Feb 22 05:41:26.319: INFO: Pod pod-projected-secrets-d88dcb63-7e62-4140-8243-8d5265110055 still exists
Feb 22 05:41:28.320: INFO: Waiting for pod pod-projected-secrets-d88dcb63-7e62-4140-8243-8d5265110055 to disappear
Feb 22 05:41:28.346: INFO: Pod pod-projected-secrets-d88dcb63-7e62-4140-8243-8d5265110055 still exists
Feb 22 05:41:30.320: INFO: Waiting for pod pod-projected-secrets-d88dcb63-7e62-4140-8243-8d5265110055 to disappear
Feb 22 05:41:30.329: INFO: Pod pod-projected-secrets-d88dcb63-7e62-4140-8243-8d5265110055 still exists
Feb 22 05:41:32.320: INFO: Waiting for pod pod-projected-secrets-d88dcb63-7e62-4140-8243-8d5265110055 to disappear
Feb 22 05:41:32.331: INFO: Pod pod-projected-secrets-d88dcb63-7e62-4140-8243-8d5265110055 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 05:41:32.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1937" for this suite.

â€¢ [SLOW TEST:43.862 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","total":270,"completed":114,"skipped":2016,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should support configurable pod DNS nameservers [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 05:41:32.426: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-1798
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support configurable pod DNS nameservers [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod with dnsPolicy=None and customized dnsConfig...
Feb 22 05:41:32.930: INFO: Created pod &Pod{ObjectMeta:{dns-1798  dns-1798 /api/v1/namespaces/dns-1798/pods/dns-1798 8aea917e-32a1-43bd-bae2-5fb9d8e5452a 115564 0 2021-02-22 05:41:32 +0000 UTC <nil> <nil> map[] map[kubernetes.io/psp:e2e-test-privileged-psp] [] []  [{e2e.test Update v1 2021-02-22 05:41:32 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 114 103 115 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 67 111 110 102 105 103 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 115 101 114 118 101 114 115 34 58 123 125 44 34 102 58 115 101 97 114 99 104 101 115 34 58 123 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-jn5tn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-jn5tn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-jn5tn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 22 05:41:32.970: INFO: The status of Pod dns-1798 is Pending, waiting for it to be Running (with Ready = true)
Feb 22 05:41:34.981: INFO: The status of Pod dns-1798 is Pending, waiting for it to be Running (with Ready = true)
Feb 22 05:41:36.977: INFO: The status of Pod dns-1798 is Pending, waiting for it to be Running (with Ready = true)
Feb 22 05:41:39.969: INFO: The status of Pod dns-1798 is Pending, waiting for it to be Running (with Ready = true)
Feb 22 05:41:40.981: INFO: The status of Pod dns-1798 is Pending, waiting for it to be Running (with Ready = true)
Feb 22 05:41:42.980: INFO: The status of Pod dns-1798 is Pending, waiting for it to be Running (with Ready = true)
Feb 22 05:41:44.979: INFO: The status of Pod dns-1798 is Pending, waiting for it to be Running (with Ready = true)
Feb 22 05:41:46.991: INFO: The status of Pod dns-1798 is Pending, waiting for it to be Running (with Ready = true)
Feb 22 05:41:48.981: INFO: The status of Pod dns-1798 is Pending, waiting for it to be Running (with Ready = true)
Feb 22 05:41:50.994: INFO: The status of Pod dns-1798 is Pending, waiting for it to be Running (with Ready = true)
Feb 22 05:41:52.987: INFO: The status of Pod dns-1798 is Pending, waiting for it to be Running (with Ready = true)
Feb 22 05:41:54.982: INFO: The status of Pod dns-1798 is Pending, waiting for it to be Running (with Ready = true)
Feb 22 05:41:56.977: INFO: The status of Pod dns-1798 is Pending, waiting for it to be Running (with Ready = true)
Feb 22 05:41:58.987: INFO: The status of Pod dns-1798 is Running (Ready = true)
STEP: Verifying customized DNS suffix list is configured on pod...
Feb 22 05:41:58.988: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-1798 PodName:dns-1798 ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 22 05:41:58.988: INFO: >>> kubeConfig: /root/.kube/config
STEP: Verifying customized DNS server is configured on pod...
Feb 22 05:41:59.203: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-1798 PodName:dns-1798 ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 22 05:41:59.203: INFO: >>> kubeConfig: /root/.kube/config
Feb 22 05:41:59.343: INFO: Deleting pod dns-1798...
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 05:41:59.384: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1798" for this suite.

â€¢ [SLOW TEST:27.010 seconds]
[sig-network] DNS
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should support configurable pod DNS nameservers [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] DNS should support configurable pod DNS nameservers [Conformance]","total":270,"completed":115,"skipped":2053,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 05:41:59.451: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3499
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Feb 22 05:41:59.760: INFO: Waiting up to 5m0s for pod "downwardapi-volume-332808c2-e69d-48e3-82af-bd49df664720" in namespace "projected-3499" to be "Succeeded or Failed"
Feb 22 05:41:59.789: INFO: Pod "downwardapi-volume-332808c2-e69d-48e3-82af-bd49df664720": Phase="Pending", Reason="", readiness=false. Elapsed: 28.81388ms
Feb 22 05:42:01.798: INFO: Pod "downwardapi-volume-332808c2-e69d-48e3-82af-bd49df664720": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03823544s
Feb 22 05:42:03.809: INFO: Pod "downwardapi-volume-332808c2-e69d-48e3-82af-bd49df664720": Phase="Pending", Reason="", readiness=false. Elapsed: 4.048685877s
Feb 22 05:42:05.831: INFO: Pod "downwardapi-volume-332808c2-e69d-48e3-82af-bd49df664720": Phase="Pending", Reason="", readiness=false. Elapsed: 6.07120821s
Feb 22 05:42:07.874: INFO: Pod "downwardapi-volume-332808c2-e69d-48e3-82af-bd49df664720": Phase="Pending", Reason="", readiness=false. Elapsed: 8.114143515s
Feb 22 05:42:09.892: INFO: Pod "downwardapi-volume-332808c2-e69d-48e3-82af-bd49df664720": Phase="Pending", Reason="", readiness=false. Elapsed: 10.131320093s
Feb 22 05:42:11.908: INFO: Pod "downwardapi-volume-332808c2-e69d-48e3-82af-bd49df664720": Phase="Pending", Reason="", readiness=false. Elapsed: 12.14827251s
Feb 22 05:42:13.927: INFO: Pod "downwardapi-volume-332808c2-e69d-48e3-82af-bd49df664720": Phase="Pending", Reason="", readiness=false. Elapsed: 14.166455083s
Feb 22 05:42:15.938: INFO: Pod "downwardapi-volume-332808c2-e69d-48e3-82af-bd49df664720": Phase="Pending", Reason="", readiness=false. Elapsed: 16.177425854s
Feb 22 05:42:17.970: INFO: Pod "downwardapi-volume-332808c2-e69d-48e3-82af-bd49df664720": Phase="Pending", Reason="", readiness=false. Elapsed: 18.210292358s
Feb 22 05:42:19.984: INFO: Pod "downwardapi-volume-332808c2-e69d-48e3-82af-bd49df664720": Phase="Pending", Reason="", readiness=false. Elapsed: 20.223664637s
Feb 22 05:42:21.993: INFO: Pod "downwardapi-volume-332808c2-e69d-48e3-82af-bd49df664720": Phase="Pending", Reason="", readiness=false. Elapsed: 22.232842322s
Feb 22 05:42:24.002: INFO: Pod "downwardapi-volume-332808c2-e69d-48e3-82af-bd49df664720": Phase="Pending", Reason="", readiness=false. Elapsed: 24.241514842s
Feb 22 05:42:26.011: INFO: Pod "downwardapi-volume-332808c2-e69d-48e3-82af-bd49df664720": Phase="Pending", Reason="", readiness=false. Elapsed: 26.250759164s
Feb 22 05:42:28.023: INFO: Pod "downwardapi-volume-332808c2-e69d-48e3-82af-bd49df664720": Phase="Pending", Reason="", readiness=false. Elapsed: 28.263270686s
Feb 22 05:42:30.040: INFO: Pod "downwardapi-volume-332808c2-e69d-48e3-82af-bd49df664720": Phase="Succeeded", Reason="", readiness=false. Elapsed: 30.280125115s
STEP: Saw pod success
Feb 22 05:42:30.040: INFO: Pod "downwardapi-volume-332808c2-e69d-48e3-82af-bd49df664720" satisfied condition "Succeeded or Failed"
Feb 22 05:42:30.050: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com pod downwardapi-volume-332808c2-e69d-48e3-82af-bd49df664720 container client-container: <nil>
STEP: delete the pod
Feb 22 05:42:35.544: INFO: Waiting for pod downwardapi-volume-332808c2-e69d-48e3-82af-bd49df664720 to disappear
Feb 22 05:42:35.650: INFO: Pod downwardapi-volume-332808c2-e69d-48e3-82af-bd49df664720 still exists
Feb 22 05:42:37.674: INFO: Waiting for pod downwardapi-volume-332808c2-e69d-48e3-82af-bd49df664720 to disappear
Feb 22 05:42:37.754: INFO: Pod downwardapi-volume-332808c2-e69d-48e3-82af-bd49df664720 still exists
Feb 22 05:42:39.674: INFO: Waiting for pod downwardapi-volume-332808c2-e69d-48e3-82af-bd49df664720 to disappear
Feb 22 05:42:39.686: INFO: Pod downwardapi-volume-332808c2-e69d-48e3-82af-bd49df664720 still exists
Feb 22 05:42:41.674: INFO: Waiting for pod downwardapi-volume-332808c2-e69d-48e3-82af-bd49df664720 to disappear
Feb 22 05:42:41.686: INFO: Pod downwardapi-volume-332808c2-e69d-48e3-82af-bd49df664720 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 05:42:41.688: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3499" for this suite.

â€¢ [SLOW TEST:42.301 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:36
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]","total":270,"completed":116,"skipped":2073,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 05:42:41.785: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-6751
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Feb 22 05:42:42.283: INFO: >>> kubeConfig: /root/.kube/config
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 05:42:43.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-6751" for this suite.
â€¢{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]","total":270,"completed":117,"skipped":2100,"failed":0}

------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 05:42:43.444: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3366
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 22 05:42:46.947: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb 22 05:42:52.145: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569367, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569367, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569368, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569366, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:42:54.359: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569367, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569367, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569368, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569366, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:42:56.176: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569367, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569367, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569368, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569366, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:42:58.162: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569367, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569367, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569368, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569366, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:43:00.167: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569367, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569367, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569368, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569366, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:43:02.161: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569367, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569367, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569368, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569366, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:43:04.156: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569367, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569367, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569368, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569366, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:43:06.158: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569367, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569367, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569368, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569366, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:43:08.152: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569367, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569367, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569368, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569366, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:43:10.163: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569367, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569367, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569368, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569366, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:43:12.152: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569367, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569367, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569368, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569366, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:43:14.172: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569367, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569367, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569368, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569366, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 22 05:43:17.193: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Creating a dummy validating-webhook-configuration object
STEP: Deleting the validating-webhook-configuration, which should be possible to remove
STEP: Creating a dummy mutating-webhook-configuration object
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 05:43:17.610: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3366" for this suite.
STEP: Destroying namespace "webhook-3366-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

â€¢ [SLOW TEST:34.670 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]","total":270,"completed":118,"skipped":2100,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 05:43:18.118: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7008
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-map-9d5b088b-c392-456e-8343-0738ecd580b1
STEP: Creating a pod to test consume configMaps
Feb 22 05:43:18.746: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-29d0ae49-786e-4224-a80d-bbc185128e9c" in namespace "projected-7008" to be "Succeeded or Failed"
Feb 22 05:43:18.815: INFO: Pod "pod-projected-configmaps-29d0ae49-786e-4224-a80d-bbc185128e9c": Phase="Pending", Reason="", readiness=false. Elapsed: 68.594049ms
Feb 22 05:43:20.826: INFO: Pod "pod-projected-configmaps-29d0ae49-786e-4224-a80d-bbc185128e9c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.079847759s
Feb 22 05:43:22.860: INFO: Pod "pod-projected-configmaps-29d0ae49-786e-4224-a80d-bbc185128e9c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.113541482s
Feb 22 05:43:24.905: INFO: Pod "pod-projected-configmaps-29d0ae49-786e-4224-a80d-bbc185128e9c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.159147473s
Feb 22 05:43:26.916: INFO: Pod "pod-projected-configmaps-29d0ae49-786e-4224-a80d-bbc185128e9c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.169887425s
Feb 22 05:43:28.926: INFO: Pod "pod-projected-configmaps-29d0ae49-786e-4224-a80d-bbc185128e9c": Phase="Pending", Reason="", readiness=false. Elapsed: 10.180028855s
Feb 22 05:43:30.935: INFO: Pod "pod-projected-configmaps-29d0ae49-786e-4224-a80d-bbc185128e9c": Phase="Pending", Reason="", readiness=false. Elapsed: 12.188985983s
Feb 22 05:43:32.956: INFO: Pod "pod-projected-configmaps-29d0ae49-786e-4224-a80d-bbc185128e9c": Phase="Pending", Reason="", readiness=false. Elapsed: 14.209591606s
Feb 22 05:43:34.964: INFO: Pod "pod-projected-configmaps-29d0ae49-786e-4224-a80d-bbc185128e9c": Phase="Pending", Reason="", readiness=false. Elapsed: 16.218240836s
Feb 22 05:43:36.974: INFO: Pod "pod-projected-configmaps-29d0ae49-786e-4224-a80d-bbc185128e9c": Phase="Pending", Reason="", readiness=false. Elapsed: 18.227616971s
Feb 22 05:43:38.982: INFO: Pod "pod-projected-configmaps-29d0ae49-786e-4224-a80d-bbc185128e9c": Phase="Pending", Reason="", readiness=false. Elapsed: 20.235807649s
Feb 22 05:43:40.999: INFO: Pod "pod-projected-configmaps-29d0ae49-786e-4224-a80d-bbc185128e9c": Phase="Pending", Reason="", readiness=false. Elapsed: 22.252761886s
Feb 22 05:43:43.008: INFO: Pod "pod-projected-configmaps-29d0ae49-786e-4224-a80d-bbc185128e9c": Phase="Pending", Reason="", readiness=false. Elapsed: 24.26161986s
Feb 22 05:43:45.019: INFO: Pod "pod-projected-configmaps-29d0ae49-786e-4224-a80d-bbc185128e9c": Phase="Pending", Reason="", readiness=false. Elapsed: 26.273054086s
Feb 22 05:43:47.029: INFO: Pod "pod-projected-configmaps-29d0ae49-786e-4224-a80d-bbc185128e9c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 28.283157107s
STEP: Saw pod success
Feb 22 05:43:47.030: INFO: Pod "pod-projected-configmaps-29d0ae49-786e-4224-a80d-bbc185128e9c" satisfied condition "Succeeded or Failed"
Feb 22 05:43:47.040: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com pod pod-projected-configmaps-29d0ae49-786e-4224-a80d-bbc185128e9c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 22 05:43:53.181: INFO: Waiting for pod pod-projected-configmaps-29d0ae49-786e-4224-a80d-bbc185128e9c to disappear
Feb 22 05:43:53.189: INFO: Pod pod-projected-configmaps-29d0ae49-786e-4224-a80d-bbc185128e9c still exists
Feb 22 05:43:55.189: INFO: Waiting for pod pod-projected-configmaps-29d0ae49-786e-4224-a80d-bbc185128e9c to disappear
Feb 22 05:43:55.202: INFO: Pod pod-projected-configmaps-29d0ae49-786e-4224-a80d-bbc185128e9c still exists
Feb 22 05:43:57.189: INFO: Waiting for pod pod-projected-configmaps-29d0ae49-786e-4224-a80d-bbc185128e9c to disappear
Feb 22 05:43:57.202: INFO: Pod pod-projected-configmaps-29d0ae49-786e-4224-a80d-bbc185128e9c no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 05:43:57.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7008" for this suite.

â€¢ [SLOW TEST:39.137 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:36
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":270,"completed":119,"skipped":2124,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 05:43:57.256: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-8251
STEP: Waiting for a default service account to be provisioned in namespace
[It] should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: fetching the /apis discovery document
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/apiextensions.k8s.io discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 05:43:57.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-8251" for this suite.
â€¢{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]","total":270,"completed":120,"skipped":2149,"failed":0}

------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 05:43:57.597: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-7554
STEP: Waiting for a default service account to be provisioned in namespace
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: set up a multi version CRD
Feb 22 05:43:57.860: INFO: >>> kubeConfig: /root/.kube/config
STEP: mark a version not serverd
STEP: check the unserved version gets removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 05:44:51.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7554" for this suite.

â€¢ [SLOW TEST:53.504 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]","total":270,"completed":121,"skipped":2149,"failed":0}
SSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 05:44:51.102: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3052
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating the pod
Feb 22 05:45:20.060: INFO: Successfully updated pod "labelsupdatef6577251-f0ba-411a-978b-c949e0a712c5"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 05:45:22.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3052" for this suite.

â€¢ [SLOW TEST:31.058 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:37
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]","total":270,"completed":122,"skipped":2153,"failed":0}
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 05:45:22.162: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6795
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0644 on node default medium
Feb 22 05:45:22.405: INFO: Waiting up to 5m0s for pod "pod-bd85bbcb-c47c-405a-9d15-c28de9e3579b" in namespace "emptydir-6795" to be "Succeeded or Failed"
Feb 22 05:45:22.422: INFO: Pod "pod-bd85bbcb-c47c-405a-9d15-c28de9e3579b": Phase="Pending", Reason="", readiness=false. Elapsed: 16.64105ms
Feb 22 05:45:24.436: INFO: Pod "pod-bd85bbcb-c47c-405a-9d15-c28de9e3579b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030872543s
Feb 22 05:45:26.444: INFO: Pod "pod-bd85bbcb-c47c-405a-9d15-c28de9e3579b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.03898635s
Feb 22 05:45:28.461: INFO: Pod "pod-bd85bbcb-c47c-405a-9d15-c28de9e3579b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.056197925s
Feb 22 05:45:30.469: INFO: Pod "pod-bd85bbcb-c47c-405a-9d15-c28de9e3579b": Phase="Pending", Reason="", readiness=false. Elapsed: 8.063794023s
Feb 22 05:45:32.475: INFO: Pod "pod-bd85bbcb-c47c-405a-9d15-c28de9e3579b": Phase="Pending", Reason="", readiness=false. Elapsed: 10.069673854s
Feb 22 05:45:34.481: INFO: Pod "pod-bd85bbcb-c47c-405a-9d15-c28de9e3579b": Phase="Pending", Reason="", readiness=false. Elapsed: 12.076116864s
Feb 22 05:45:36.492: INFO: Pod "pod-bd85bbcb-c47c-405a-9d15-c28de9e3579b": Phase="Pending", Reason="", readiness=false. Elapsed: 14.087367166s
Feb 22 05:45:38.499: INFO: Pod "pod-bd85bbcb-c47c-405a-9d15-c28de9e3579b": Phase="Pending", Reason="", readiness=false. Elapsed: 16.093994595s
Feb 22 05:45:40.506: INFO: Pod "pod-bd85bbcb-c47c-405a-9d15-c28de9e3579b": Phase="Pending", Reason="", readiness=false. Elapsed: 18.101021105s
Feb 22 05:45:42.512: INFO: Pod "pod-bd85bbcb-c47c-405a-9d15-c28de9e3579b": Phase="Pending", Reason="", readiness=false. Elapsed: 20.107168248s
Feb 22 05:45:44.522: INFO: Pod "pod-bd85bbcb-c47c-405a-9d15-c28de9e3579b": Phase="Pending", Reason="", readiness=false. Elapsed: 22.116645963s
Feb 22 05:45:46.530: INFO: Pod "pod-bd85bbcb-c47c-405a-9d15-c28de9e3579b": Phase="Pending", Reason="", readiness=false. Elapsed: 24.125205369s
Feb 22 05:45:48.541: INFO: Pod "pod-bd85bbcb-c47c-405a-9d15-c28de9e3579b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.136405827s
STEP: Saw pod success
Feb 22 05:45:48.541: INFO: Pod "pod-bd85bbcb-c47c-405a-9d15-c28de9e3579b" satisfied condition "Succeeded or Failed"
Feb 22 05:45:48.554: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com pod pod-bd85bbcb-c47c-405a-9d15-c28de9e3579b container test-container: <nil>
STEP: delete the pod
Feb 22 05:45:56.301: INFO: Waiting for pod pod-bd85bbcb-c47c-405a-9d15-c28de9e3579b to disappear
Feb 22 05:45:56.323: INFO: Pod pod-bd85bbcb-c47c-405a-9d15-c28de9e3579b still exists
Feb 22 05:45:58.323: INFO: Waiting for pod pod-bd85bbcb-c47c-405a-9d15-c28de9e3579b to disappear
Feb 22 05:45:58.367: INFO: Pod pod-bd85bbcb-c47c-405a-9d15-c28de9e3579b still exists
Feb 22 05:46:00.323: INFO: Waiting for pod pod-bd85bbcb-c47c-405a-9d15-c28de9e3579b to disappear
Feb 22 05:46:00.349: INFO: Pod pod-bd85bbcb-c47c-405a-9d15-c28de9e3579b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 05:46:00.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6795" for this suite.

â€¢ [SLOW TEST:38.350 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:42
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","total":270,"completed":123,"skipped":2155,"failed":0}
SSSSS
------------------------------
[sig-apps] Job 
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 05:46:00.513: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-6473
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: Orphaning one of the Job's Pods
Feb 22 05:46:35.426: INFO: Successfully updated pod "adopt-release-kltvl"
STEP: Checking that the Job readopts the Pod
Feb 22 05:46:35.426: INFO: Waiting up to 15m0s for pod "adopt-release-kltvl" in namespace "job-6473" to be "adopted"
Feb 22 05:46:35.471: INFO: Pod "adopt-release-kltvl": Phase="Running", Reason="", readiness=true. Elapsed: 44.806257ms
Feb 22 05:46:37.476: INFO: Pod "adopt-release-kltvl": Phase="Running", Reason="", readiness=true. Elapsed: 2.050600474s
Feb 22 05:46:37.477: INFO: Pod "adopt-release-kltvl" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod
Feb 22 05:46:38.015: INFO: Successfully updated pod "adopt-release-kltvl"
STEP: Checking that the Job releases the Pod
Feb 22 05:46:38.015: INFO: Waiting up to 15m0s for pod "adopt-release-kltvl" in namespace "job-6473" to be "released"
Feb 22 05:46:38.059: INFO: Pod "adopt-release-kltvl": Phase="Running", Reason="", readiness=true. Elapsed: 43.738984ms
Feb 22 05:46:40.106: INFO: Pod "adopt-release-kltvl": Phase="Running", Reason="", readiness=true. Elapsed: 2.090770404s
Feb 22 05:46:40.106: INFO: Pod "adopt-release-kltvl" satisfied condition "released"
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 05:46:40.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-6473" for this suite.

â€¢ [SLOW TEST:39.699 seconds]
[sig-apps] Job
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]","total":270,"completed":124,"skipped":2160,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 05:46:40.213: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-4930
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 22 05:46:41.180: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb 22 05:46:43.203: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569601, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569601, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569601, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569601, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:46:45.210: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569601, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569601, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569601, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569601, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:46:47.222: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569601, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569601, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569601, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569601, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:46:49.259: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569601, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569601, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569601, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569601, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:46:51.230: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569601, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569601, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569601, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569601, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:46:53.213: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569601, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569601, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569601, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569601, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:46:55.215: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569601, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569601, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569601, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569601, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:46:57.213: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569601, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569601, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569601, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569601, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:46:59.210: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569601, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569601, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569601, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569601, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:47:01.228: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569601, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569601, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569601, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569601, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:47:03.231: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569601, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569601, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569601, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569601, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:47:05.210: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569601, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569601, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569601, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569601, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:47:07.266: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569601, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569601, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569601, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569601, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:47:09.239: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569601, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569601, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569601, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749569601, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 22 05:47:12.274: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod
STEP: 'kubectl attach' the pod, should be denied by the webhook
Feb 22 05:47:40.548: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config attach --namespace=webhook-4930 to-be-attached-pod -i -c=container1'
Feb 22 05:47:40.966: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 05:47:40.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4930" for this suite.
STEP: Destroying namespace "webhook-4930-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

â€¢ [SLOW TEST:61.133 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]","total":270,"completed":125,"skipped":2178,"failed":0}
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 05:47:41.347: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-2464
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-e5dcbd07-285f-43bf-81d1-f30c36dfd749
STEP: Creating a pod to test consume secrets
Feb 22 05:47:41.675: INFO: Waiting up to 5m0s for pod "pod-secrets-9d991cfa-5432-4fb5-a93d-0779f0f2fc7a" in namespace "secrets-2464" to be "Succeeded or Failed"
Feb 22 05:47:41.713: INFO: Pod "pod-secrets-9d991cfa-5432-4fb5-a93d-0779f0f2fc7a": Phase="Pending", Reason="", readiness=false. Elapsed: 38.312097ms
Feb 22 05:47:43.721: INFO: Pod "pod-secrets-9d991cfa-5432-4fb5-a93d-0779f0f2fc7a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.046734991s
Feb 22 05:47:45.727: INFO: Pod "pod-secrets-9d991cfa-5432-4fb5-a93d-0779f0f2fc7a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.051872788s
Feb 22 05:47:47.755: INFO: Pod "pod-secrets-9d991cfa-5432-4fb5-a93d-0779f0f2fc7a": Phase="Pending", Reason="", readiness=false. Elapsed: 6.079926352s
Feb 22 05:47:49.766: INFO: Pod "pod-secrets-9d991cfa-5432-4fb5-a93d-0779f0f2fc7a": Phase="Pending", Reason="", readiness=false. Elapsed: 8.091553295s
Feb 22 05:47:51.783: INFO: Pod "pod-secrets-9d991cfa-5432-4fb5-a93d-0779f0f2fc7a": Phase="Pending", Reason="", readiness=false. Elapsed: 10.108806094s
Feb 22 05:47:53.789: INFO: Pod "pod-secrets-9d991cfa-5432-4fb5-a93d-0779f0f2fc7a": Phase="Pending", Reason="", readiness=false. Elapsed: 12.114042881s
Feb 22 05:47:55.807: INFO: Pod "pod-secrets-9d991cfa-5432-4fb5-a93d-0779f0f2fc7a": Phase="Pending", Reason="", readiness=false. Elapsed: 14.132613651s
Feb 22 05:47:57.813: INFO: Pod "pod-secrets-9d991cfa-5432-4fb5-a93d-0779f0f2fc7a": Phase="Pending", Reason="", readiness=false. Elapsed: 16.138392422s
Feb 22 05:47:59.832: INFO: Pod "pod-secrets-9d991cfa-5432-4fb5-a93d-0779f0f2fc7a": Phase="Pending", Reason="", readiness=false. Elapsed: 18.157160558s
Feb 22 05:48:01.839: INFO: Pod "pod-secrets-9d991cfa-5432-4fb5-a93d-0779f0f2fc7a": Phase="Pending", Reason="", readiness=false. Elapsed: 20.164533845s
Feb 22 05:48:03.846: INFO: Pod "pod-secrets-9d991cfa-5432-4fb5-a93d-0779f0f2fc7a": Phase="Pending", Reason="", readiness=false. Elapsed: 22.171586064s
Feb 22 05:48:05.868: INFO: Pod "pod-secrets-9d991cfa-5432-4fb5-a93d-0779f0f2fc7a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.193185552s
STEP: Saw pod success
Feb 22 05:48:05.868: INFO: Pod "pod-secrets-9d991cfa-5432-4fb5-a93d-0779f0f2fc7a" satisfied condition "Succeeded or Failed"
Feb 22 05:48:05.876: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com pod pod-secrets-9d991cfa-5432-4fb5-a93d-0779f0f2fc7a container secret-volume-test: <nil>
STEP: delete the pod
Feb 22 05:48:06.005: INFO: Waiting for pod pod-secrets-9d991cfa-5432-4fb5-a93d-0779f0f2fc7a to disappear
Feb 22 05:48:06.024: INFO: Pod pod-secrets-9d991cfa-5432-4fb5-a93d-0779f0f2fc7a still exists
Feb 22 05:48:08.024: INFO: Waiting for pod pod-secrets-9d991cfa-5432-4fb5-a93d-0779f0f2fc7a to disappear
Feb 22 05:48:08.045: INFO: Pod pod-secrets-9d991cfa-5432-4fb5-a93d-0779f0f2fc7a still exists
Feb 22 05:48:10.024: INFO: Waiting for pod pod-secrets-9d991cfa-5432-4fb5-a93d-0779f0f2fc7a to disappear
Feb 22 05:48:10.032: INFO: Pod pod-secrets-9d991cfa-5432-4fb5-a93d-0779f0f2fc7a still exists
Feb 22 05:48:12.024: INFO: Waiting for pod pod-secrets-9d991cfa-5432-4fb5-a93d-0779f0f2fc7a to disappear
Feb 22 05:48:12.032: INFO: Pod pod-secrets-9d991cfa-5432-4fb5-a93d-0779f0f2fc7a still exists
Feb 22 05:48:14.024: INFO: Waiting for pod pod-secrets-9d991cfa-5432-4fb5-a93d-0779f0f2fc7a to disappear
Feb 22 05:48:14.035: INFO: Pod pod-secrets-9d991cfa-5432-4fb5-a93d-0779f0f2fc7a still exists
Feb 22 05:48:16.024: INFO: Waiting for pod pod-secrets-9d991cfa-5432-4fb5-a93d-0779f0f2fc7a to disappear
Feb 22 05:48:16.030: INFO: Pod pod-secrets-9d991cfa-5432-4fb5-a93d-0779f0f2fc7a no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 05:48:16.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2464" for this suite.

â€¢ [SLOW TEST:34.726 seconds]
[sig-storage] Secrets
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:36
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]","total":270,"completed":126,"skipped":2179,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 05:48:16.074: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-5273
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
Feb 22 05:48:17.204: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 05:48:17.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5273" for this suite.
â€¢{"msg":"PASSED [sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]","total":270,"completed":127,"skipped":2190,"failed":0}
SSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 05:48:17.248: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-7555
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 05:48:51.669: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-7555" for this suite.

â€¢ [SLOW TEST:34.503 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Docker Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]","total":270,"completed":128,"skipped":2202,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 05:48:51.753: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-3945
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Feb 22 05:49:42.374: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 22 05:49:42.408: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 22 05:49:44.411: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 22 05:49:44.421: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 22 05:49:46.410: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 22 05:49:46.423: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 22 05:49:48.410: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 22 05:49:48.422: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 22 05:49:50.411: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 22 05:49:50.423: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 22 05:49:52.410: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 22 05:49:52.421: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 22 05:49:54.411: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 22 05:49:54.421: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 22 05:49:56.410: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 22 05:49:56.420: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 22 05:49:58.411: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 22 05:49:58.422: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 22 05:50:00.411: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 22 05:50:00.429: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 22 05:50:02.412: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 22 05:50:02.452: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 05:50:02.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-3945" for this suite.

â€¢ [SLOW TEST:70.920 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  when create a pod with lifecycle hook
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]","total":270,"completed":129,"skipped":2216,"failed":0}
S
------------------------------
[sig-cli] Kubectl client Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 05:50:02.696: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4265
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating Agnhost RC
Feb 22 05:50:03.365: INFO: namespace kubectl-4265
Feb 22 05:50:03.366: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config create -f - --namespace=kubectl-4265'
Feb 22 05:50:05.631: INFO: stderr: ""
Feb 22 05:50:05.631: INFO: stdout: "replicationcontroller/agnhost-master created\n"
STEP: Waiting for Agnhost master to start.
Feb 22 05:50:06.686: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 05:50:06.686: INFO: Found 0 / 1
Feb 22 05:50:07.652: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 05:50:07.652: INFO: Found 0 / 1
Feb 22 05:50:08.723: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 05:50:08.723: INFO: Found 0 / 1
Feb 22 05:50:09.683: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 05:50:09.683: INFO: Found 0 / 1
Feb 22 05:50:10.645: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 05:50:10.646: INFO: Found 0 / 1
Feb 22 05:50:11.658: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 05:50:11.658: INFO: Found 0 / 1
Feb 22 05:50:12.641: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 05:50:12.641: INFO: Found 0 / 1
Feb 22 05:50:13.692: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 05:50:13.692: INFO: Found 0 / 1
Feb 22 05:50:14.640: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 05:50:14.641: INFO: Found 0 / 1
Feb 22 05:50:15.656: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 05:50:15.656: INFO: Found 0 / 1
Feb 22 05:50:16.724: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 05:50:16.724: INFO: Found 0 / 1
Feb 22 05:50:17.764: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 05:50:17.765: INFO: Found 0 / 1
Feb 22 05:50:18.642: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 05:50:18.642: INFO: Found 0 / 1
Feb 22 05:50:19.651: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 05:50:19.651: INFO: Found 0 / 1
Feb 22 05:50:20.641: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 05:50:20.641: INFO: Found 0 / 1
Feb 22 05:50:21.647: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 05:50:21.647: INFO: Found 0 / 1
Feb 22 05:50:22.643: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 05:50:22.643: INFO: Found 0 / 1
Feb 22 05:50:23.641: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 05:50:23.641: INFO: Found 0 / 1
Feb 22 05:50:24.663: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 05:50:24.663: INFO: Found 0 / 1
Feb 22 05:50:25.641: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 05:50:25.641: INFO: Found 0 / 1
Feb 22 05:50:26.645: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 05:50:26.645: INFO: Found 0 / 1
Feb 22 05:50:27.642: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 05:50:27.642: INFO: Found 0 / 1
Feb 22 05:50:28.641: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 05:50:28.641: INFO: Found 0 / 1
Feb 22 05:50:29.641: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 05:50:29.641: INFO: Found 0 / 1
Feb 22 05:50:30.639: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 05:50:30.639: INFO: Found 0 / 1
Feb 22 05:50:31.641: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 05:50:31.641: INFO: Found 0 / 1
Feb 22 05:50:32.642: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 05:50:32.642: INFO: Found 1 / 1
Feb 22 05:50:32.642: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 22 05:50:32.664: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 05:50:32.665: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 22 05:50:32.665: INFO: wait on agnhost-master startup in kubectl-4265 
Feb 22 05:50:32.665: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config logs agnhost-master-58pgx agnhost-master --namespace=kubectl-4265'
Feb 22 05:50:32.919: INFO: stderr: ""
Feb 22 05:50:32.919: INFO: stdout: "Paused\n"
STEP: exposing RC
Feb 22 05:50:32.919: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config expose rc agnhost-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-4265'
Feb 22 05:50:33.247: INFO: stderr: ""
Feb 22 05:50:33.248: INFO: stdout: "service/rm2 exposed\n"
Feb 22 05:50:33.308: INFO: Service rm2 in namespace kubectl-4265 found.
STEP: exposing service
Feb 22 05:50:35.344: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-4265'
Feb 22 05:50:35.713: INFO: stderr: ""
Feb 22 05:50:35.713: INFO: stdout: "service/rm3 exposed\n"
Feb 22 05:50:35.785: INFO: Service rm3 in namespace kubectl-4265 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 05:50:37.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4265" for this suite.

â€¢ [SLOW TEST:35.196 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl expose
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1119
    should create services for rc  [Conformance]
    /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl expose should create services for rc  [Conformance]","total":270,"completed":130,"skipped":2217,"failed":0}
S
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 05:50:37.889: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-1784
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod pod-subpath-test-projected-v4h2
STEP: Creating a pod to test atomic-volume-subpath
Feb 22 05:50:38.367: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-v4h2" in namespace "subpath-1784" to be "Succeeded or Failed"
Feb 22 05:50:38.399: INFO: Pod "pod-subpath-test-projected-v4h2": Phase="Pending", Reason="", readiness=false. Elapsed: 31.787959ms
Feb 22 05:50:40.424: INFO: Pod "pod-subpath-test-projected-v4h2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.056147884s
Feb 22 05:50:42.812: INFO: Pod "pod-subpath-test-projected-v4h2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.444434708s
Feb 22 05:50:44.832: INFO: Pod "pod-subpath-test-projected-v4h2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.465043086s
Feb 22 05:50:46.845: INFO: Pod "pod-subpath-test-projected-v4h2": Phase="Pending", Reason="", readiness=false. Elapsed: 8.477751106s
Feb 22 05:50:48.857: INFO: Pod "pod-subpath-test-projected-v4h2": Phase="Pending", Reason="", readiness=false. Elapsed: 10.489258366s
Feb 22 05:50:50.886: INFO: Pod "pod-subpath-test-projected-v4h2": Phase="Pending", Reason="", readiness=false. Elapsed: 12.519011645s
Feb 22 05:50:52.899: INFO: Pod "pod-subpath-test-projected-v4h2": Phase="Pending", Reason="", readiness=false. Elapsed: 14.532070829s
Feb 22 05:50:54.914: INFO: Pod "pod-subpath-test-projected-v4h2": Phase="Pending", Reason="", readiness=false. Elapsed: 16.546124117s
Feb 22 05:50:56.923: INFO: Pod "pod-subpath-test-projected-v4h2": Phase="Pending", Reason="", readiness=false. Elapsed: 18.555201897s
Feb 22 05:50:58.941: INFO: Pod "pod-subpath-test-projected-v4h2": Phase="Pending", Reason="", readiness=false. Elapsed: 20.573341067s
Feb 22 05:51:00.947: INFO: Pod "pod-subpath-test-projected-v4h2": Phase="Pending", Reason="", readiness=false. Elapsed: 22.579510284s
Feb 22 05:51:02.954: INFO: Pod "pod-subpath-test-projected-v4h2": Phase="Pending", Reason="", readiness=false. Elapsed: 24.586780921s
Feb 22 05:51:04.962: INFO: Pod "pod-subpath-test-projected-v4h2": Phase="Running", Reason="", readiness=true. Elapsed: 26.594893848s
Feb 22 05:51:06.969: INFO: Pod "pod-subpath-test-projected-v4h2": Phase="Running", Reason="", readiness=true. Elapsed: 28.601947877s
Feb 22 05:51:08.978: INFO: Pod "pod-subpath-test-projected-v4h2": Phase="Running", Reason="", readiness=true. Elapsed: 30.611064852s
Feb 22 05:51:10.987: INFO: Pod "pod-subpath-test-projected-v4h2": Phase="Running", Reason="", readiness=true. Elapsed: 32.619484839s
Feb 22 05:51:13.001: INFO: Pod "pod-subpath-test-projected-v4h2": Phase="Running", Reason="", readiness=true. Elapsed: 34.633731638s
Feb 22 05:51:15.008: INFO: Pod "pod-subpath-test-projected-v4h2": Phase="Running", Reason="", readiness=true. Elapsed: 36.640551123s
Feb 22 05:51:17.018: INFO: Pod "pod-subpath-test-projected-v4h2": Phase="Running", Reason="", readiness=true. Elapsed: 38.650470504s
Feb 22 05:51:19.028: INFO: Pod "pod-subpath-test-projected-v4h2": Phase="Running", Reason="", readiness=true. Elapsed: 40.660107433s
Feb 22 05:51:21.037: INFO: Pod "pod-subpath-test-projected-v4h2": Phase="Running", Reason="", readiness=true. Elapsed: 42.669362059s
Feb 22 05:51:23.096: INFO: Pod "pod-subpath-test-projected-v4h2": Phase="Running", Reason="", readiness=true. Elapsed: 44.728380935s
Feb 22 05:51:25.133: INFO: Pod "pod-subpath-test-projected-v4h2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 46.76601394s
STEP: Saw pod success
Feb 22 05:51:25.134: INFO: Pod "pod-subpath-test-projected-v4h2" satisfied condition "Succeeded or Failed"
Feb 22 05:51:25.145: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com pod pod-subpath-test-projected-v4h2 container test-container-subpath-projected-v4h2: <nil>
STEP: delete the pod
Feb 22 05:51:31.492: INFO: Waiting for pod pod-subpath-test-projected-v4h2 to disappear
Feb 22 05:51:31.524: INFO: Pod pod-subpath-test-projected-v4h2 still exists
Feb 22 05:51:33.524: INFO: Waiting for pod pod-subpath-test-projected-v4h2 to disappear
Feb 22 05:51:33.534: INFO: Pod pod-subpath-test-projected-v4h2 still exists
Feb 22 05:51:35.525: INFO: Waiting for pod pod-subpath-test-projected-v4h2 to disappear
Feb 22 05:51:35.533: INFO: Pod pod-subpath-test-projected-v4h2 still exists
Feb 22 05:51:37.524: INFO: Waiting for pod pod-subpath-test-projected-v4h2 to disappear
Feb 22 05:51:37.531: INFO: Pod pod-subpath-test-projected-v4h2 still exists
Feb 22 05:51:39.524: INFO: Waiting for pod pod-subpath-test-projected-v4h2 to disappear
Feb 22 05:51:39.535: INFO: Pod pod-subpath-test-projected-v4h2 still exists
Feb 22 05:51:41.525: INFO: Waiting for pod pod-subpath-test-projected-v4h2 to disappear
Feb 22 05:51:41.530: INFO: Pod pod-subpath-test-projected-v4h2 no longer exists
STEP: Deleting pod pod-subpath-test-projected-v4h2
Feb 22 05:51:41.531: INFO: Deleting pod "pod-subpath-test-projected-v4h2" in namespace "subpath-1784"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 05:51:41.538: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1784" for this suite.

â€¢ [SLOW TEST:63.715 seconds]
[sig-storage] Subpath
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [LinuxOnly] [Conformance]","total":270,"completed":131,"skipped":2218,"failed":0}
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 05:51:41.608: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-8187
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:91
Feb 22 05:51:41.914: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 22 05:51:41.971: INFO: Waiting for terminating namespaces to be deleted...
Feb 22 05:51:41.995: INFO: 
Logging pods the kubelet thinks is on node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com before test
Feb 22 05:51:42.036: INFO: nginx-private from test-image-pull-secrets-ns started at 2021-02-22 03:11:22 +0000 UTC (1 container statuses recorded)
Feb 22 05:51:42.037: INFO: 	Container nginx-private-container ready: true, restart count 0
Feb 22 05:51:42.037: INFO: test-docker-registry from test-private-image-registry-ns started at 2021-02-22 03:23:54 +0000 UTC (1 container statuses recorded)
Feb 22 05:51:42.037: INFO: 	Container test-docker-registry ready: true, restart count 0
Feb 22 05:51:42.038: INFO: helloworld from test-kube-events-ns started at 2021-02-22 03:14:06 +0000 UTC (1 container statuses recorded)
Feb 22 05:51:42.038: INFO: 	Container hello ready: true, restart count 0
Feb 22 05:51:42.038: INFO: schedext-test-node-selector-1 from test-node-selector started at 2021-02-22 03:16:36 +0000 UTC (1 container statuses recorded)
Feb 22 05:51:42.039: INFO: 	Container hello ready: true, restart count 0
Feb 22 05:51:42.040: INFO: schedext-test-affinity-3 from test-pod-affinity started at 2021-02-22 03:18:02 +0000 UTC (1 container statuses recorded)
Feb 22 05:51:42.040: INFO: 	Container hello ready: true, restart count 0
Feb 22 05:51:42.040: INFO: wcp-sanity-busybox-7bf494fc58-tlpw6 from test-update-workload-ns started at 2021-02-22 03:28:50 +0000 UTC (1 container statuses recorded)
Feb 22 05:51:42.040: INFO: 	Container wcp-sanity-busybox-container ready: true, restart count 0
Feb 22 05:51:42.040: INFO: helloworld from test-telemetry started at 2021-02-22 03:31:02 +0000 UTC (1 container statuses recorded)
Feb 22 05:51:42.040: INFO: 	Container hello ready: true, restart count 0
Feb 22 05:51:42.040: INFO: hello-web-1-5f76cbcd98-vs4bx from test-network-policy started at 2021-02-22 04:27:53 +0000 UTC (1 container statuses recorded)
Feb 22 05:51:42.040: INFO: 	Container hello-app ready: true, restart count 0
Feb 22 05:51:42.040: INFO: 
Logging pods the kubelet thinks is on node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com before test
Feb 22 05:51:42.057: INFO: hello-web-2-dcbfdb96d-pcvm7 from test-network-policy started at 2021-02-22 04:27:55 +0000 UTC (1 container statuses recorded)
Feb 22 05:51:42.057: INFO: 	Container hello-app ready: true, restart count 0
Feb 22 05:51:42.057: INFO: wcp-sanity-busybox-7bf494fc58-rcpr6 from test-update-workload-ns started at 2021-02-22 04:28:23 +0000 UTC (1 container statuses recorded)
Feb 22 05:51:42.057: INFO: 	Container wcp-sanity-busybox-container ready: true, restart count 0
Feb 22 05:51:42.057: INFO: 
Logging pods the kubelet thinks is on node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com before test
Feb 22 05:51:42.078: INFO: podwithpersistentvolume from storage-policy-test started at 2021-02-22 03:27:14 +0000 UTC (1 container statuses recorded)
Feb 22 05:51:42.078: INFO: 	Container hello ready: true, restart count 0
Feb 22 05:51:42.078: INFO: wcp-sanity-busybox-7bf494fc58-npc5m from test-update-workload-ns started at 2021-02-22 03:28:52 +0000 UTC (1 container statuses recorded)
Feb 22 05:51:42.078: INFO: 	Container wcp-sanity-busybox-container ready: true, restart count 0
Feb 22 05:51:42.078: INFO: hello-web-5f76cbcd98-9f9j4 from test-cluster-ip-service started at 2021-02-22 04:27:54 +0000 UTC (1 container statuses recorded)
Feb 22 05:51:42.078: INFO: 	Container hello-app ready: true, restart count 0
Feb 22 05:51:42.079: INFO: wcp-sanity-busybox-7bf494fc58-7sn7q from test-dataprovider-podvms-ns started at 2021-02-22 03:08:43 +0000 UTC (1 container statuses recorded)
Feb 22 05:51:42.079: INFO: 	Container wcp-sanity-busybox-container ready: true, restart count 0
Feb 22 05:51:42.079: INFO: wcp-sanity-busybox-7bf494fc58-pln4w from test-dataprovider-podvms-ns started at 2021-02-22 03:08:42 +0000 UTC (1 container statuses recorded)
Feb 22 05:51:42.080: INFO: 	Container wcp-sanity-busybox-container ready: true, restart count 0
Feb 22 05:51:42.080: INFO: schedext-test-affinity-1 from test-pod-affinity started at 2021-02-22 03:17:26 +0000 UTC (1 container statuses recorded)
Feb 22 05:51:42.080: INFO: 	Container hello ready: true, restart count 0
Feb 22 05:51:42.080: INFO: schedext-test-affinity-2 from test-pod-affinity started at 2021-02-22 03:17:50 +0000 UTC (1 container statuses recorded)
Feb 22 05:51:42.080: INFO: 	Container hello ready: true, restart count 0
Feb 22 05:51:42.080: INFO: busybox from test-pod-external-nw-access started at 2021-02-22 03:22:58 +0000 UTC (1 container statuses recorded)
Feb 22 05:51:42.081: INFO: 	Container busybox ready: true, restart count 0
Feb 22 05:51:42.081: INFO: curl-pod from test-cluster-ip-service started at 2021-02-22 03:04:01 +0000 UTC (1 container statuses recorded)
Feb 22 05:51:42.081: INFO: 	Container curl-container ready: true, restart count 0
Feb 22 05:51:42.081: INFO: curl-pod from test-network-policy started at 2021-02-22 03:15:49 +0000 UTC (1 container statuses recorded)
Feb 22 05:51:42.081: INFO: 	Container curl-container ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-256bfdb9-be97-44f8-bf40-7660e036ba02 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-256bfdb9-be97-44f8-bf40-7660e036ba02 off the node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com
STEP: verifying the node doesn't have the label kubernetes.io/e2e-256bfdb9-be97-44f8-bf40-7660e036ba02
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 05:52:24.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-8187" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:82

â€¢ [SLOW TEST:42.876 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching  [Conformance]","total":270,"completed":132,"skipped":2220,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 05:52:24.512: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-864
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0777 on tmpfs
Feb 22 05:52:24.944: INFO: Waiting up to 5m0s for pod "pod-7b35178f-27dd-4807-9863-eddac387e25a" in namespace "emptydir-864" to be "Succeeded or Failed"
Feb 22 05:52:24.955: INFO: Pod "pod-7b35178f-27dd-4807-9863-eddac387e25a": Phase="Pending", Reason="", readiness=false. Elapsed: 10.612053ms
Feb 22 05:52:26.962: INFO: Pod "pod-7b35178f-27dd-4807-9863-eddac387e25a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017779814s
Feb 22 05:52:28.981: INFO: Pod "pod-7b35178f-27dd-4807-9863-eddac387e25a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.037131995s
Feb 22 05:52:30.997: INFO: Pod "pod-7b35178f-27dd-4807-9863-eddac387e25a": Phase="Pending", Reason="", readiness=false. Elapsed: 6.053085899s
Feb 22 05:52:33.014: INFO: Pod "pod-7b35178f-27dd-4807-9863-eddac387e25a": Phase="Pending", Reason="", readiness=false. Elapsed: 8.069560539s
Feb 22 05:52:35.020: INFO: Pod "pod-7b35178f-27dd-4807-9863-eddac387e25a": Phase="Pending", Reason="", readiness=false. Elapsed: 10.076000591s
Feb 22 05:52:37.029: INFO: Pod "pod-7b35178f-27dd-4807-9863-eddac387e25a": Phase="Pending", Reason="", readiness=false. Elapsed: 12.085134192s
Feb 22 05:52:39.038: INFO: Pod "pod-7b35178f-27dd-4807-9863-eddac387e25a": Phase="Pending", Reason="", readiness=false. Elapsed: 14.093356917s
Feb 22 05:52:41.048: INFO: Pod "pod-7b35178f-27dd-4807-9863-eddac387e25a": Phase="Pending", Reason="", readiness=false. Elapsed: 16.103549584s
Feb 22 05:52:43.055: INFO: Pod "pod-7b35178f-27dd-4807-9863-eddac387e25a": Phase="Pending", Reason="", readiness=false. Elapsed: 18.110671578s
Feb 22 05:52:45.064: INFO: Pod "pod-7b35178f-27dd-4807-9863-eddac387e25a": Phase="Pending", Reason="", readiness=false. Elapsed: 20.119823355s
Feb 22 05:52:47.071: INFO: Pod "pod-7b35178f-27dd-4807-9863-eddac387e25a": Phase="Pending", Reason="", readiness=false. Elapsed: 22.126500526s
Feb 22 05:52:49.098: INFO: Pod "pod-7b35178f-27dd-4807-9863-eddac387e25a": Phase="Pending", Reason="", readiness=false. Elapsed: 24.153448346s
Feb 22 05:52:51.168: INFO: Pod "pod-7b35178f-27dd-4807-9863-eddac387e25a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.223931255s
STEP: Saw pod success
Feb 22 05:52:51.168: INFO: Pod "pod-7b35178f-27dd-4807-9863-eddac387e25a" satisfied condition "Succeeded or Failed"
Feb 22 05:52:51.180: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com pod pod-7b35178f-27dd-4807-9863-eddac387e25a container test-container: <nil>
STEP: delete the pod
Feb 22 05:52:58.484: INFO: Waiting for pod pod-7b35178f-27dd-4807-9863-eddac387e25a to disappear
Feb 22 05:52:58.505: INFO: Pod pod-7b35178f-27dd-4807-9863-eddac387e25a still exists
Feb 22 05:53:00.506: INFO: Waiting for pod pod-7b35178f-27dd-4807-9863-eddac387e25a to disappear
Feb 22 05:53:00.521: INFO: Pod pod-7b35178f-27dd-4807-9863-eddac387e25a still exists
Feb 22 05:53:02.506: INFO: Waiting for pod pod-7b35178f-27dd-4807-9863-eddac387e25a to disappear
Feb 22 05:53:02.512: INFO: Pod pod-7b35178f-27dd-4807-9863-eddac387e25a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 05:53:02.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-864" for this suite.

â€¢ [SLOW TEST:38.044 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:42
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":270,"completed":133,"skipped":2275,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 05:53:02.565: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-1128
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a job
STEP: Ensuring job reaches completions
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 05:54:56.902: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-1128" for this suite.

â€¢ [SLOW TEST:114.451 seconds]
[sig-apps] Job
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]","total":270,"completed":134,"skipped":2289,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 05:54:57.016: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-73
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test substitution in container's command
Feb 22 05:54:57.472: INFO: Waiting up to 5m0s for pod "var-expansion-f3cb2527-3747-4117-a348-5a8d8c7d1c02" in namespace "var-expansion-73" to be "Succeeded or Failed"
Feb 22 05:54:57.486: INFO: Pod "var-expansion-f3cb2527-3747-4117-a348-5a8d8c7d1c02": Phase="Pending", Reason="", readiness=false. Elapsed: 13.039499ms
Feb 22 05:54:59.494: INFO: Pod "var-expansion-f3cb2527-3747-4117-a348-5a8d8c7d1c02": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0215927s
Feb 22 05:55:01.533: INFO: Pod "var-expansion-f3cb2527-3747-4117-a348-5a8d8c7d1c02": Phase="Pending", Reason="", readiness=false. Elapsed: 4.060094802s
Feb 22 05:55:03.552: INFO: Pod "var-expansion-f3cb2527-3747-4117-a348-5a8d8c7d1c02": Phase="Pending", Reason="", readiness=false. Elapsed: 6.079145675s
Feb 22 05:55:05.566: INFO: Pod "var-expansion-f3cb2527-3747-4117-a348-5a8d8c7d1c02": Phase="Pending", Reason="", readiness=false. Elapsed: 8.093436353s
Feb 22 05:55:08.733: INFO: Pod "var-expansion-f3cb2527-3747-4117-a348-5a8d8c7d1c02": Phase="Pending", Reason="", readiness=false. Elapsed: 11.260403621s
Feb 22 05:55:10.851: INFO: Pod "var-expansion-f3cb2527-3747-4117-a348-5a8d8c7d1c02": Phase="Pending", Reason="", readiness=false. Elapsed: 13.378764697s
Feb 22 05:55:13.030: INFO: Pod "var-expansion-f3cb2527-3747-4117-a348-5a8d8c7d1c02": Phase="Pending", Reason="", readiness=false. Elapsed: 15.557421329s
Feb 22 05:55:15.055: INFO: Pod "var-expansion-f3cb2527-3747-4117-a348-5a8d8c7d1c02": Phase="Pending", Reason="", readiness=false. Elapsed: 17.582764622s
Feb 22 05:55:17.064: INFO: Pod "var-expansion-f3cb2527-3747-4117-a348-5a8d8c7d1c02": Phase="Pending", Reason="", readiness=false. Elapsed: 19.591493288s
Feb 22 05:55:19.072: INFO: Pod "var-expansion-f3cb2527-3747-4117-a348-5a8d8c7d1c02": Phase="Pending", Reason="", readiness=false. Elapsed: 21.59947086s
Feb 22 05:55:21.111: INFO: Pod "var-expansion-f3cb2527-3747-4117-a348-5a8d8c7d1c02": Phase="Pending", Reason="", readiness=false. Elapsed: 23.638169725s
Feb 22 05:55:23.118: INFO: Pod "var-expansion-f3cb2527-3747-4117-a348-5a8d8c7d1c02": Phase="Pending", Reason="", readiness=false. Elapsed: 25.645821826s
Feb 22 05:55:25.129: INFO: Pod "var-expansion-f3cb2527-3747-4117-a348-5a8d8c7d1c02": Phase="Pending", Reason="", readiness=false. Elapsed: 27.656433413s
Feb 22 05:55:27.139: INFO: Pod "var-expansion-f3cb2527-3747-4117-a348-5a8d8c7d1c02": Phase="Pending", Reason="", readiness=false. Elapsed: 29.666821587s
Feb 22 05:55:29.155: INFO: Pod "var-expansion-f3cb2527-3747-4117-a348-5a8d8c7d1c02": Phase="Pending", Reason="", readiness=false. Elapsed: 31.682743754s
Feb 22 05:55:31.164: INFO: Pod "var-expansion-f3cb2527-3747-4117-a348-5a8d8c7d1c02": Phase="Pending", Reason="", readiness=false. Elapsed: 33.691688496s
Feb 22 05:55:33.173: INFO: Pod "var-expansion-f3cb2527-3747-4117-a348-5a8d8c7d1c02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 35.700473987s
STEP: Saw pod success
Feb 22 05:55:33.173: INFO: Pod "var-expansion-f3cb2527-3747-4117-a348-5a8d8c7d1c02" satisfied condition "Succeeded or Failed"
Feb 22 05:55:33.180: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com pod var-expansion-f3cb2527-3747-4117-a348-5a8d8c7d1c02 container dapi-container: <nil>
STEP: delete the pod
Feb 22 05:55:39.804: INFO: Waiting for pod var-expansion-f3cb2527-3747-4117-a348-5a8d8c7d1c02 to disappear
Feb 22 05:55:39.824: INFO: Pod var-expansion-f3cb2527-3747-4117-a348-5a8d8c7d1c02 still exists
Feb 22 05:55:41.825: INFO: Waiting for pod var-expansion-f3cb2527-3747-4117-a348-5a8d8c7d1c02 to disappear
Feb 22 05:55:41.834: INFO: Pod var-expansion-f3cb2527-3747-4117-a348-5a8d8c7d1c02 still exists
Feb 22 05:55:43.825: INFO: Waiting for pod var-expansion-f3cb2527-3747-4117-a348-5a8d8c7d1c02 to disappear
Feb 22 05:55:43.846: INFO: Pod var-expansion-f3cb2527-3747-4117-a348-5a8d8c7d1c02 still exists
Feb 22 05:55:45.825: INFO: Waiting for pod var-expansion-f3cb2527-3747-4117-a348-5a8d8c7d1c02 to disappear
Feb 22 05:55:45.860: INFO: Pod var-expansion-f3cb2527-3747-4117-a348-5a8d8c7d1c02 still exists
Feb 22 05:55:47.825: INFO: Waiting for pod var-expansion-f3cb2527-3747-4117-a348-5a8d8c7d1c02 to disappear
Feb 22 05:55:47.833: INFO: Pod var-expansion-f3cb2527-3747-4117-a348-5a8d8c7d1c02 still exists
Feb 22 05:55:49.825: INFO: Waiting for pod var-expansion-f3cb2527-3747-4117-a348-5a8d8c7d1c02 to disappear
Feb 22 05:55:49.832: INFO: Pod var-expansion-f3cb2527-3747-4117-a348-5a8d8c7d1c02 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 05:55:49.834: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-73" for this suite.

â€¢ [SLOW TEST:52.875 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]","total":270,"completed":135,"skipped":2337,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 05:55:49.906: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-4173
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 22 05:55:51.399: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Feb 22 05:55:53.473: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570151, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570151, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570151, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570151, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:55:55.511: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570151, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570151, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570151, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570151, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:55:57.511: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570151, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570151, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570151, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570151, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:55:59.497: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570151, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570151, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570151, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570151, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:56:01.498: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570151, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570151, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570151, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570151, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:56:03.481: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570151, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570151, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570151, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570151, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:56:05.483: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570151, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570151, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570151, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570151, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:56:07.485: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570151, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570151, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570151, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570151, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:56:09.482: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570151, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570151, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570151, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570151, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:56:11.481: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570151, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570151, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570151, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570151, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:56:13.481: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570151, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570151, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570151, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570151, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:56:15.481: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570151, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570151, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570151, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570151, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:56:17.483: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570151, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570151, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570151, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570151, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 22 05:56:20.628: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that should be mutated
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that should not be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 05:56:21.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4173" for this suite.
STEP: Destroying namespace "webhook-4173-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

â€¢ [SLOW TEST:32.507 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]","total":270,"completed":136,"skipped":2349,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 05:56:22.444: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2508
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-map-852e68c6-bdcb-4586-8454-ed75c2400aa8
STEP: Creating a pod to test consume configMaps
Feb 22 05:56:22.913: INFO: Waiting up to 5m0s for pod "pod-configmaps-f014c576-236d-4183-89b0-adfd9ffac5ca" in namespace "configmap-2508" to be "Succeeded or Failed"
Feb 22 05:56:22.934: INFO: Pod "pod-configmaps-f014c576-236d-4183-89b0-adfd9ffac5ca": Phase="Pending", Reason="", readiness=false. Elapsed: 21.089362ms
Feb 22 05:56:24.960: INFO: Pod "pod-configmaps-f014c576-236d-4183-89b0-adfd9ffac5ca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.046903103s
Feb 22 05:56:27.017: INFO: Pod "pod-configmaps-f014c576-236d-4183-89b0-adfd9ffac5ca": Phase="Pending", Reason="", readiness=false. Elapsed: 4.103793864s
Feb 22 05:56:29.032: INFO: Pod "pod-configmaps-f014c576-236d-4183-89b0-adfd9ffac5ca": Phase="Pending", Reason="", readiness=false. Elapsed: 6.118904804s
Feb 22 05:56:31.042: INFO: Pod "pod-configmaps-f014c576-236d-4183-89b0-adfd9ffac5ca": Phase="Pending", Reason="", readiness=false. Elapsed: 8.128510916s
Feb 22 05:56:33.050: INFO: Pod "pod-configmaps-f014c576-236d-4183-89b0-adfd9ffac5ca": Phase="Pending", Reason="", readiness=false. Elapsed: 10.137283836s
Feb 22 05:56:35.059: INFO: Pod "pod-configmaps-f014c576-236d-4183-89b0-adfd9ffac5ca": Phase="Pending", Reason="", readiness=false. Elapsed: 12.146339194s
Feb 22 05:56:37.070: INFO: Pod "pod-configmaps-f014c576-236d-4183-89b0-adfd9ffac5ca": Phase="Pending", Reason="", readiness=false. Elapsed: 14.157151701s
Feb 22 05:56:39.077: INFO: Pod "pod-configmaps-f014c576-236d-4183-89b0-adfd9ffac5ca": Phase="Pending", Reason="", readiness=false. Elapsed: 16.164370055s
Feb 22 05:56:41.102: INFO: Pod "pod-configmaps-f014c576-236d-4183-89b0-adfd9ffac5ca": Phase="Pending", Reason="", readiness=false. Elapsed: 18.18870484s
Feb 22 05:56:43.109: INFO: Pod "pod-configmaps-f014c576-236d-4183-89b0-adfd9ffac5ca": Phase="Pending", Reason="", readiness=false. Elapsed: 20.196363913s
Feb 22 05:56:45.121: INFO: Pod "pod-configmaps-f014c576-236d-4183-89b0-adfd9ffac5ca": Phase="Pending", Reason="", readiness=false. Elapsed: 22.208407573s
Feb 22 05:56:47.167: INFO: Pod "pod-configmaps-f014c576-236d-4183-89b0-adfd9ffac5ca": Phase="Pending", Reason="", readiness=false. Elapsed: 24.25381775s
Feb 22 05:56:49.186: INFO: Pod "pod-configmaps-f014c576-236d-4183-89b0-adfd9ffac5ca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.27267805s
STEP: Saw pod success
Feb 22 05:56:49.186: INFO: Pod "pod-configmaps-f014c576-236d-4183-89b0-adfd9ffac5ca" satisfied condition "Succeeded or Failed"
Feb 22 05:56:49.204: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com pod pod-configmaps-f014c576-236d-4183-89b0-adfd9ffac5ca container configmap-volume-test: <nil>
STEP: delete the pod
Feb 22 05:56:49.390: INFO: Waiting for pod pod-configmaps-f014c576-236d-4183-89b0-adfd9ffac5ca to disappear
Feb 22 05:56:49.417: INFO: Pod pod-configmaps-f014c576-236d-4183-89b0-adfd9ffac5ca still exists
Feb 22 05:56:51.418: INFO: Waiting for pod pod-configmaps-f014c576-236d-4183-89b0-adfd9ffac5ca to disappear
Feb 22 05:56:51.436: INFO: Pod pod-configmaps-f014c576-236d-4183-89b0-adfd9ffac5ca still exists
Feb 22 05:56:53.418: INFO: Waiting for pod pod-configmaps-f014c576-236d-4183-89b0-adfd9ffac5ca to disappear
Feb 22 05:56:53.427: INFO: Pod pod-configmaps-f014c576-236d-4183-89b0-adfd9ffac5ca still exists
Feb 22 05:56:55.417: INFO: Waiting for pod pod-configmaps-f014c576-236d-4183-89b0-adfd9ffac5ca to disappear
Feb 22 05:56:55.426: INFO: Pod pod-configmaps-f014c576-236d-4183-89b0-adfd9ffac5ca still exists
Feb 22 05:56:57.418: INFO: Waiting for pod pod-configmaps-f014c576-236d-4183-89b0-adfd9ffac5ca to disappear
Feb 22 05:56:57.445: INFO: Pod pod-configmaps-f014c576-236d-4183-89b0-adfd9ffac5ca still exists
Feb 22 05:56:59.417: INFO: Waiting for pod pod-configmaps-f014c576-236d-4183-89b0-adfd9ffac5ca to disappear
Feb 22 05:56:59.425: INFO: Pod pod-configmaps-f014c576-236d-4183-89b0-adfd9ffac5ca no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 05:56:59.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2508" for this suite.

â€¢ [SLOW TEST:37.067 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:36
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","total":270,"completed":137,"skipped":2398,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 05:56:59.536: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-1493
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:91
Feb 22 05:56:59.799: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 22 05:56:59.825: INFO: Waiting for terminating namespaces to be deleted...
Feb 22 05:56:59.848: INFO: 
Logging pods the kubelet thinks is on node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com before test
Feb 22 05:56:59.904: INFO: nginx-private from test-image-pull-secrets-ns started at 2021-02-22 03:11:22 +0000 UTC (1 container statuses recorded)
Feb 22 05:56:59.904: INFO: 	Container nginx-private-container ready: true, restart count 0
Feb 22 05:56:59.904: INFO: test-docker-registry from test-private-image-registry-ns started at 2021-02-22 03:23:54 +0000 UTC (1 container statuses recorded)
Feb 22 05:56:59.904: INFO: 	Container test-docker-registry ready: true, restart count 0
Feb 22 05:56:59.904: INFO: helloworld from test-kube-events-ns started at 2021-02-22 03:14:06 +0000 UTC (1 container statuses recorded)
Feb 22 05:56:59.904: INFO: 	Container hello ready: true, restart count 0
Feb 22 05:56:59.904: INFO: schedext-test-node-selector-1 from test-node-selector started at 2021-02-22 03:16:36 +0000 UTC (1 container statuses recorded)
Feb 22 05:56:59.904: INFO: 	Container hello ready: true, restart count 0
Feb 22 05:56:59.904: INFO: schedext-test-affinity-3 from test-pod-affinity started at 2021-02-22 03:18:02 +0000 UTC (1 container statuses recorded)
Feb 22 05:56:59.904: INFO: 	Container hello ready: true, restart count 0
Feb 22 05:56:59.904: INFO: wcp-sanity-busybox-7bf494fc58-tlpw6 from test-update-workload-ns started at 2021-02-22 03:28:50 +0000 UTC (1 container statuses recorded)
Feb 22 05:56:59.904: INFO: 	Container wcp-sanity-busybox-container ready: true, restart count 0
Feb 22 05:56:59.904: INFO: helloworld from test-telemetry started at 2021-02-22 03:31:02 +0000 UTC (1 container statuses recorded)
Feb 22 05:56:59.904: INFO: 	Container hello ready: true, restart count 0
Feb 22 05:56:59.904: INFO: hello-web-1-5f76cbcd98-vs4bx from test-network-policy started at 2021-02-22 04:27:53 +0000 UTC (1 container statuses recorded)
Feb 22 05:56:59.904: INFO: 	Container hello-app ready: true, restart count 0
Feb 22 05:56:59.904: INFO: 
Logging pods the kubelet thinks is on node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com before test
Feb 22 05:56:59.923: INFO: hello-web-2-dcbfdb96d-pcvm7 from test-network-policy started at 2021-02-22 04:27:55 +0000 UTC (1 container statuses recorded)
Feb 22 05:56:59.923: INFO: 	Container hello-app ready: true, restart count 0
Feb 22 05:56:59.923: INFO: wcp-sanity-busybox-7bf494fc58-rcpr6 from test-update-workload-ns started at 2021-02-22 04:28:23 +0000 UTC (1 container statuses recorded)
Feb 22 05:56:59.923: INFO: 	Container wcp-sanity-busybox-container ready: true, restart count 0
Feb 22 05:56:59.923: INFO: 
Logging pods the kubelet thinks is on node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com before test
Feb 22 05:56:59.958: INFO: wcp-sanity-busybox-7bf494fc58-npc5m from test-update-workload-ns started at 2021-02-22 03:28:52 +0000 UTC (1 container statuses recorded)
Feb 22 05:56:59.958: INFO: 	Container wcp-sanity-busybox-container ready: true, restart count 0
Feb 22 05:56:59.958: INFO: hello-web-5f76cbcd98-9f9j4 from test-cluster-ip-service started at 2021-02-22 04:27:54 +0000 UTC (1 container statuses recorded)
Feb 22 05:56:59.958: INFO: 	Container hello-app ready: true, restart count 0
Feb 22 05:56:59.958: INFO: wcp-sanity-busybox-7bf494fc58-7sn7q from test-dataprovider-podvms-ns started at 2021-02-22 03:08:43 +0000 UTC (1 container statuses recorded)
Feb 22 05:56:59.958: INFO: 	Container wcp-sanity-busybox-container ready: true, restart count 0
Feb 22 05:56:59.958: INFO: wcp-sanity-busybox-7bf494fc58-pln4w from test-dataprovider-podvms-ns started at 2021-02-22 03:08:42 +0000 UTC (1 container statuses recorded)
Feb 22 05:56:59.958: INFO: 	Container wcp-sanity-busybox-container ready: true, restart count 0
Feb 22 05:56:59.958: INFO: podwithpersistentvolume from storage-policy-test started at 2021-02-22 03:27:14 +0000 UTC (1 container statuses recorded)
Feb 22 05:56:59.958: INFO: 	Container hello ready: true, restart count 0
Feb 22 05:56:59.958: INFO: schedext-test-affinity-2 from test-pod-affinity started at 2021-02-22 03:17:50 +0000 UTC (1 container statuses recorded)
Feb 22 05:56:59.958: INFO: 	Container hello ready: true, restart count 0
Feb 22 05:56:59.958: INFO: busybox from test-pod-external-nw-access started at 2021-02-22 03:22:58 +0000 UTC (1 container statuses recorded)
Feb 22 05:56:59.958: INFO: 	Container busybox ready: true, restart count 0
Feb 22 05:56:59.958: INFO: curl-pod from test-cluster-ip-service started at 2021-02-22 03:04:01 +0000 UTC (1 container statuses recorded)
Feb 22 05:56:59.958: INFO: 	Container curl-container ready: true, restart count 0
Feb 22 05:56:59.958: INFO: curl-pod from test-network-policy started at 2021-02-22 03:15:49 +0000 UTC (1 container statuses recorded)
Feb 22 05:56:59.958: INFO: 	Container curl-container ready: true, restart count 0
Feb 22 05:56:59.958: INFO: schedext-test-affinity-1 from test-pod-affinity started at 2021-02-22 03:17:26 +0000 UTC (1 container statuses recorded)
Feb 22 05:56:59.958: INFO: 	Container hello ready: true, restart count 0
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-040c17d9-6300-4db5-b4e3-2889f99c3535 90
STEP: Trying to create a pod(pod1) with hostport 54321 and hostIP 127.0.0.1 and expect scheduled
STEP: Trying to create another pod(pod2) with hostport 54321 but hostIP 127.0.0.2 on the node which pod1 resides and expect scheduled
STEP: Trying to create a third pod(pod3) with hostport 54321, hostIP 127.0.0.2 but use UDP protocol on the node which pod2 resides
STEP: removing the label kubernetes.io/e2e-040c17d9-6300-4db5-b4e3-2889f99c3535 off the node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com
STEP: verifying the node doesn't have the label kubernetes.io/e2e-040c17d9-6300-4db5-b4e3-2889f99c3535
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 05:58:49.208: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-1493" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:82

â€¢ [SLOW TEST:109.851 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]","total":270,"completed":138,"skipped":2445,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 05:58:49.422: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5156
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Feb 22 05:58:49.940: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2dec7430-99c0-44c6-8051-ad04833407b1" in namespace "projected-5156" to be "Succeeded or Failed"
Feb 22 05:58:49.955: INFO: Pod "downwardapi-volume-2dec7430-99c0-44c6-8051-ad04833407b1": Phase="Pending", Reason="", readiness=false. Elapsed: 15.055819ms
Feb 22 05:58:51.969: INFO: Pod "downwardapi-volume-2dec7430-99c0-44c6-8051-ad04833407b1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0286807s
Feb 22 05:58:53.979: INFO: Pod "downwardapi-volume-2dec7430-99c0-44c6-8051-ad04833407b1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.039019087s
Feb 22 05:58:56.086: INFO: Pod "downwardapi-volume-2dec7430-99c0-44c6-8051-ad04833407b1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.145369852s
Feb 22 05:58:58.118: INFO: Pod "downwardapi-volume-2dec7430-99c0-44c6-8051-ad04833407b1": Phase="Pending", Reason="", readiness=false. Elapsed: 8.17768457s
Feb 22 05:59:00.139: INFO: Pod "downwardapi-volume-2dec7430-99c0-44c6-8051-ad04833407b1": Phase="Pending", Reason="", readiness=false. Elapsed: 10.198360145s
Feb 22 05:59:02.150: INFO: Pod "downwardapi-volume-2dec7430-99c0-44c6-8051-ad04833407b1": Phase="Pending", Reason="", readiness=false. Elapsed: 12.209846572s
Feb 22 05:59:04.171: INFO: Pod "downwardapi-volume-2dec7430-99c0-44c6-8051-ad04833407b1": Phase="Pending", Reason="", readiness=false. Elapsed: 14.230920391s
Feb 22 05:59:06.180: INFO: Pod "downwardapi-volume-2dec7430-99c0-44c6-8051-ad04833407b1": Phase="Pending", Reason="", readiness=false. Elapsed: 16.239894802s
Feb 22 05:59:08.233: INFO: Pod "downwardapi-volume-2dec7430-99c0-44c6-8051-ad04833407b1": Phase="Pending", Reason="", readiness=false. Elapsed: 18.292584018s
Feb 22 05:59:10.259: INFO: Pod "downwardapi-volume-2dec7430-99c0-44c6-8051-ad04833407b1": Phase="Pending", Reason="", readiness=false. Elapsed: 20.318281381s
Feb 22 05:59:12.278: INFO: Pod "downwardapi-volume-2dec7430-99c0-44c6-8051-ad04833407b1": Phase="Pending", Reason="", readiness=false. Elapsed: 22.338008785s
Feb 22 05:59:14.288: INFO: Pod "downwardapi-volume-2dec7430-99c0-44c6-8051-ad04833407b1": Phase="Pending", Reason="", readiness=false. Elapsed: 24.347746779s
Feb 22 05:59:16.353: INFO: Pod "downwardapi-volume-2dec7430-99c0-44c6-8051-ad04833407b1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.412896022s
STEP: Saw pod success
Feb 22 05:59:16.353: INFO: Pod "downwardapi-volume-2dec7430-99c0-44c6-8051-ad04833407b1" satisfied condition "Succeeded or Failed"
Feb 22 05:59:16.394: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com pod downwardapi-volume-2dec7430-99c0-44c6-8051-ad04833407b1 container client-container: <nil>
STEP: delete the pod
Feb 22 05:59:23.136: INFO: Waiting for pod downwardapi-volume-2dec7430-99c0-44c6-8051-ad04833407b1 to disappear
Feb 22 05:59:23.148: INFO: Pod downwardapi-volume-2dec7430-99c0-44c6-8051-ad04833407b1 still exists
Feb 22 05:59:25.148: INFO: Waiting for pod downwardapi-volume-2dec7430-99c0-44c6-8051-ad04833407b1 to disappear
Feb 22 05:59:25.156: INFO: Pod downwardapi-volume-2dec7430-99c0-44c6-8051-ad04833407b1 still exists
Feb 22 05:59:27.148: INFO: Waiting for pod downwardapi-volume-2dec7430-99c0-44c6-8051-ad04833407b1 to disappear
Feb 22 05:59:27.155: INFO: Pod downwardapi-volume-2dec7430-99c0-44c6-8051-ad04833407b1 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 05:59:27.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5156" for this suite.

â€¢ [SLOW TEST:37.767 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:36
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]","total":270,"completed":139,"skipped":2504,"failed":0}
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 05:59:27.216: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3673
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 22 05:59:28.436: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb 22 05:59:30.492: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570368, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570368, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570368, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570368, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:59:32.503: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570368, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570368, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570368, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570368, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:59:34.530: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570368, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570368, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570368, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570368, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:59:36.503: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570368, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570368, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570368, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570368, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:59:38.499: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570368, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570368, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570368, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570368, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:59:40.503: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570368, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570368, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570368, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570368, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:59:42.503: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570368, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570368, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570368, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570368, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:59:44.506: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570368, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570368, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570368, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570368, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:59:46.507: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570368, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570368, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570368, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570368, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:59:48.501: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570368, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570368, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570368, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570368, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:59:50.500: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570368, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570368, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570368, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570368, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:59:52.499: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570368, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570368, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570368, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570368, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:59:54.500: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570368, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570368, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570368, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570368, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:59:56.501: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570368, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570368, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570368, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570368, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 05:59:58.502: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570368, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570368, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570368, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570368, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 22 06:00:01.640: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Feb 22 06:00:01.654: INFO: >>> kubeConfig: /root/.kube/config
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-1756-crds.webhook.example.com via the AdmissionRegistration API
Feb 22 06:00:04.544: INFO: Waiting for webhook configuration to be ready...
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:00:07.890: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3673" for this suite.
STEP: Destroying namespace "webhook-3673-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

â€¢ [SLOW TEST:45.177 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]","total":270,"completed":140,"skipped":2506,"failed":0}
S
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:00:12.393: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-512
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating service endpoint-test2 in namespace services-512
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-512 to expose endpoints map[]
Feb 22 06:00:16.181: INFO: Get endpoints failed (657.222935ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Feb 22 06:00:17.356: INFO: successfully validated that service endpoint-test2 in namespace services-512 exposes endpoints map[] (1.832215955s elapsed)
STEP: Creating pod pod1 in namespace services-512
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-512 to expose endpoints map[pod1:[80]]
Feb 22 06:00:22.190: INFO: Unexpected endpoints: found map[], expected map[pod1:[80]] (4.553525764s elapsed, will retry)
Feb 22 06:00:27.454: INFO: Unexpected endpoints: found map[], expected map[pod1:[80]] (9.818077663s elapsed, will retry)
Feb 22 06:00:32.841: INFO: Unexpected endpoints: found map[], expected map[pod1:[80]] (15.204950391s elapsed, will retry)
Feb 22 06:00:37.954: INFO: Unexpected endpoints: found map[], expected map[pod1:[80]] (20.317892184s elapsed, will retry)
Feb 22 06:00:43.076: INFO: Unexpected endpoints: found map[], expected map[pod1:[80]] (25.44022621s elapsed, will retry)
Feb 22 06:00:48.195: INFO: Unexpected endpoints: found map[], expected map[pod1:[80]] (30.558670461s elapsed, will retry)
Feb 22 06:00:53.283: INFO: Unexpected endpoints: found map[], expected map[pod1:[80]] (35.646716559s elapsed, will retry)
Feb 22 06:00:57.427: INFO: successfully validated that service endpoint-test2 in namespace services-512 exposes endpoints map[pod1:[80]] (39.791431356s elapsed)
STEP: Creating pod pod2 in namespace services-512
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-512 to expose endpoints map[pod1:[80] pod2:[80]]
Feb 22 06:01:01.746: INFO: Unexpected endpoints: found map[25f0f910-03c5-4489-bd94-fd0565d5ff09:[80]], expected map[pod1:[80] pod2:[80]] (4.267045893s elapsed, will retry)
Feb 22 06:01:08.135: INFO: Unexpected endpoints: found map[25f0f910-03c5-4489-bd94-fd0565d5ff09:[80]], expected map[pod1:[80] pod2:[80]] (10.656675621s elapsed, will retry)
Feb 22 06:01:13.436: INFO: Unexpected endpoints: found map[25f0f910-03c5-4489-bd94-fd0565d5ff09:[80]], expected map[pod1:[80] pod2:[80]] (15.957560572s elapsed, will retry)
Feb 22 06:01:18.652: INFO: Unexpected endpoints: found map[25f0f910-03c5-4489-bd94-fd0565d5ff09:[80]], expected map[pod1:[80] pod2:[80]] (21.173789355s elapsed, will retry)
Feb 22 06:01:24.216: INFO: Unexpected endpoints: found map[25f0f910-03c5-4489-bd94-fd0565d5ff09:[80]], expected map[pod1:[80] pod2:[80]] (26.737101014s elapsed, will retry)
Feb 22 06:01:29.657: INFO: successfully validated that service endpoint-test2 in namespace services-512 exposes endpoints map[pod1:[80] pod2:[80]] (32.178256648s elapsed)
STEP: Deleting pod pod1 in namespace services-512
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-512 to expose endpoints map[pod2:[80]]
Feb 22 06:01:29.813: INFO: successfully validated that service endpoint-test2 in namespace services-512 exposes endpoints map[pod2:[80]] (52.034689ms elapsed)
STEP: Deleting pod pod2 in namespace services-512
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-512 to expose endpoints map[]
Feb 22 06:01:30.944: INFO: successfully validated that service endpoint-test2 in namespace services-512 exposes endpoints map[] (1.079887665s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:01:31.181: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-512" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702

â€¢ [SLOW TEST:78.993 seconds]
[sig-network] Services
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Services should serve a basic endpoint from pods  [Conformance]","total":270,"completed":141,"skipped":2507,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:01:31.416: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3189
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Feb 22 06:01:31.989: INFO: Waiting up to 5m0s for pod "downwardapi-volume-39d5c186-3615-4d44-89aa-7c625a1c0204" in namespace "projected-3189" to be "Succeeded or Failed"
Feb 22 06:01:32.198: INFO: Pod "downwardapi-volume-39d5c186-3615-4d44-89aa-7c625a1c0204": Phase="Pending", Reason="", readiness=false. Elapsed: 208.436839ms
Feb 22 06:01:34.229: INFO: Pod "downwardapi-volume-39d5c186-3615-4d44-89aa-7c625a1c0204": Phase="Pending", Reason="", readiness=false. Elapsed: 2.239316837s
Feb 22 06:01:36.236: INFO: Pod "downwardapi-volume-39d5c186-3615-4d44-89aa-7c625a1c0204": Phase="Pending", Reason="", readiness=false. Elapsed: 4.246470543s
Feb 22 06:01:38.288: INFO: Pod "downwardapi-volume-39d5c186-3615-4d44-89aa-7c625a1c0204": Phase="Pending", Reason="", readiness=false. Elapsed: 6.298973239s
Feb 22 06:01:40.298: INFO: Pod "downwardapi-volume-39d5c186-3615-4d44-89aa-7c625a1c0204": Phase="Pending", Reason="", readiness=false. Elapsed: 8.308456448s
Feb 22 06:01:42.309: INFO: Pod "downwardapi-volume-39d5c186-3615-4d44-89aa-7c625a1c0204": Phase="Pending", Reason="", readiness=false. Elapsed: 10.319055412s
Feb 22 06:01:44.381: INFO: Pod "downwardapi-volume-39d5c186-3615-4d44-89aa-7c625a1c0204": Phase="Pending", Reason="", readiness=false. Elapsed: 12.391906513s
Feb 22 06:01:46.395: INFO: Pod "downwardapi-volume-39d5c186-3615-4d44-89aa-7c625a1c0204": Phase="Pending", Reason="", readiness=false. Elapsed: 14.40597138s
Feb 22 06:01:48.455: INFO: Pod "downwardapi-volume-39d5c186-3615-4d44-89aa-7c625a1c0204": Phase="Pending", Reason="", readiness=false. Elapsed: 16.465357981s
Feb 22 06:01:51.322: INFO: Pod "downwardapi-volume-39d5c186-3615-4d44-89aa-7c625a1c0204": Phase="Pending", Reason="", readiness=false. Elapsed: 19.332643272s
Feb 22 06:01:53.408: INFO: Pod "downwardapi-volume-39d5c186-3615-4d44-89aa-7c625a1c0204": Phase="Pending", Reason="", readiness=false. Elapsed: 21.418114481s
Feb 22 06:01:55.420: INFO: Pod "downwardapi-volume-39d5c186-3615-4d44-89aa-7c625a1c0204": Phase="Pending", Reason="", readiness=false. Elapsed: 23.430519934s
Feb 22 06:01:57.555: INFO: Pod "downwardapi-volume-39d5c186-3615-4d44-89aa-7c625a1c0204": Phase="Pending", Reason="", readiness=false. Elapsed: 25.56563262s
Feb 22 06:01:59.597: INFO: Pod "downwardapi-volume-39d5c186-3615-4d44-89aa-7c625a1c0204": Phase="Pending", Reason="", readiness=false. Elapsed: 27.607183849s
Feb 22 06:02:01.620: INFO: Pod "downwardapi-volume-39d5c186-3615-4d44-89aa-7c625a1c0204": Phase="Pending", Reason="", readiness=false. Elapsed: 29.630044115s
Feb 22 06:02:03.670: INFO: Pod "downwardapi-volume-39d5c186-3615-4d44-89aa-7c625a1c0204": Phase="Pending", Reason="", readiness=false. Elapsed: 31.680465263s
Feb 22 06:02:05.683: INFO: Pod "downwardapi-volume-39d5c186-3615-4d44-89aa-7c625a1c0204": Phase="Succeeded", Reason="", readiness=false. Elapsed: 33.693098125s
STEP: Saw pod success
Feb 22 06:02:05.684: INFO: Pod "downwardapi-volume-39d5c186-3615-4d44-89aa-7c625a1c0204" satisfied condition "Succeeded or Failed"
Feb 22 06:02:05.695: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com pod downwardapi-volume-39d5c186-3615-4d44-89aa-7c625a1c0204 container client-container: <nil>
STEP: delete the pod
Feb 22 06:02:05.847: INFO: Waiting for pod downwardapi-volume-39d5c186-3615-4d44-89aa-7c625a1c0204 to disappear
Feb 22 06:02:05.862: INFO: Pod downwardapi-volume-39d5c186-3615-4d44-89aa-7c625a1c0204 still exists
Feb 22 06:02:07.864: INFO: Waiting for pod downwardapi-volume-39d5c186-3615-4d44-89aa-7c625a1c0204 to disappear
Feb 22 06:02:07.879: INFO: Pod downwardapi-volume-39d5c186-3615-4d44-89aa-7c625a1c0204 still exists
Feb 22 06:02:09.864: INFO: Waiting for pod downwardapi-volume-39d5c186-3615-4d44-89aa-7c625a1c0204 to disappear
Feb 22 06:02:09.890: INFO: Pod downwardapi-volume-39d5c186-3615-4d44-89aa-7c625a1c0204 still exists
Feb 22 06:02:11.864: INFO: Waiting for pod downwardapi-volume-39d5c186-3615-4d44-89aa-7c625a1c0204 to disappear
Feb 22 06:02:11.873: INFO: Pod downwardapi-volume-39d5c186-3615-4d44-89aa-7c625a1c0204 still exists
Feb 22 06:02:13.864: INFO: Waiting for pod downwardapi-volume-39d5c186-3615-4d44-89aa-7c625a1c0204 to disappear
Feb 22 06:02:13.878: INFO: Pod downwardapi-volume-39d5c186-3615-4d44-89aa-7c625a1c0204 still exists
Feb 22 06:02:15.864: INFO: Waiting for pod downwardapi-volume-39d5c186-3615-4d44-89aa-7c625a1c0204 to disappear
Feb 22 06:02:15.882: INFO: Pod downwardapi-volume-39d5c186-3615-4d44-89aa-7c625a1c0204 still exists
Feb 22 06:02:17.864: INFO: Waiting for pod downwardapi-volume-39d5c186-3615-4d44-89aa-7c625a1c0204 to disappear
Feb 22 06:02:17.877: INFO: Pod downwardapi-volume-39d5c186-3615-4d44-89aa-7c625a1c0204 still exists
Feb 22 06:02:19.864: INFO: Waiting for pod downwardapi-volume-39d5c186-3615-4d44-89aa-7c625a1c0204 to disappear
Feb 22 06:02:19.879: INFO: Pod downwardapi-volume-39d5c186-3615-4d44-89aa-7c625a1c0204 still exists
Feb 22 06:02:21.864: INFO: Waiting for pod downwardapi-volume-39d5c186-3615-4d44-89aa-7c625a1c0204 to disappear
Feb 22 06:02:21.874: INFO: Pod downwardapi-volume-39d5c186-3615-4d44-89aa-7c625a1c0204 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:02:21.877: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3189" for this suite.

â€¢ [SLOW TEST:50.553 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:36
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]","total":270,"completed":142,"skipped":2525,"failed":0}
SSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:02:21.979: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4559
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Feb 22 06:02:22.529: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config version'
Feb 22 06:02:22.912: INFO: stderr: ""
Feb 22 06:02:22.912: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"18\", GitVersion:\"v1.18.10+wcp.2\", GitCommit:\"616ce1cdb02a0616875491e96578db5280a50124\", GitTreeState:\"clean\", BuildDate:\"2020-12-12T17:17:16Z\", GoVersion:\"go1.13.15\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"18\", GitVersion:\"v1.18.10+wcp.2\", GitCommit:\"616ce1cdb02a0616875491e96578db5280a50124\", GitTreeState:\"clean\", BuildDate:\"2020-12-12T17:14:42Z\", GoVersion:\"go1.13.15\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:02:22.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4559" for this suite.
â€¢{"msg":"PASSED [sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]","total":270,"completed":143,"skipped":2532,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:02:22.988: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-7610
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Discovering how many secrets are in namespace by default
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Secret
STEP: Ensuring resource quota status captures secret creation
STEP: Deleting a secret
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:02:40.585: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7610" for this suite.

â€¢ [SLOW TEST:17.646 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]","total":270,"completed":144,"skipped":2539,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:02:40.637: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-1627
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Feb 22 06:02:51.829: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:02:51.829: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1627" for this suite.

â€¢ [SLOW TEST:11.537 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]","total":270,"completed":145,"skipped":2546,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation 
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:02:52.193: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename tables
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in tables-7899
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:47
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:02:52.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-7899" for this suite.
â€¢{"msg":"PASSED [sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]","total":270,"completed":146,"skipped":2570,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:02:52.786: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-438
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Feb 22 06:02:53.236: INFO: The status of Pod test-webserver-3cbf5d61-d646-4be3-86a0-29a4e61eb19d is Pending, waiting for it to be Running (with Ready = true)
Feb 22 06:02:55.248: INFO: The status of Pod test-webserver-3cbf5d61-d646-4be3-86a0-29a4e61eb19d is Pending, waiting for it to be Running (with Ready = true)
Feb 22 06:02:57.292: INFO: The status of Pod test-webserver-3cbf5d61-d646-4be3-86a0-29a4e61eb19d is Pending, waiting for it to be Running (with Ready = true)
Feb 22 06:02:59.263: INFO: The status of Pod test-webserver-3cbf5d61-d646-4be3-86a0-29a4e61eb19d is Pending, waiting for it to be Running (with Ready = true)
Feb 22 06:03:01.256: INFO: The status of Pod test-webserver-3cbf5d61-d646-4be3-86a0-29a4e61eb19d is Pending, waiting for it to be Running (with Ready = true)
Feb 22 06:03:03.346: INFO: The status of Pod test-webserver-3cbf5d61-d646-4be3-86a0-29a4e61eb19d is Pending, waiting for it to be Running (with Ready = true)
Feb 22 06:03:05.367: INFO: The status of Pod test-webserver-3cbf5d61-d646-4be3-86a0-29a4e61eb19d is Pending, waiting for it to be Running (with Ready = true)
Feb 22 06:03:07.257: INFO: The status of Pod test-webserver-3cbf5d61-d646-4be3-86a0-29a4e61eb19d is Pending, waiting for it to be Running (with Ready = true)
Feb 22 06:03:09.375: INFO: The status of Pod test-webserver-3cbf5d61-d646-4be3-86a0-29a4e61eb19d is Pending, waiting for it to be Running (with Ready = true)
Feb 22 06:03:11.281: INFO: The status of Pod test-webserver-3cbf5d61-d646-4be3-86a0-29a4e61eb19d is Pending, waiting for it to be Running (with Ready = true)
Feb 22 06:03:13.264: INFO: The status of Pod test-webserver-3cbf5d61-d646-4be3-86a0-29a4e61eb19d is Pending, waiting for it to be Running (with Ready = true)
Feb 22 06:03:15.271: INFO: The status of Pod test-webserver-3cbf5d61-d646-4be3-86a0-29a4e61eb19d is Pending, waiting for it to be Running (with Ready = true)
Feb 22 06:03:17.249: INFO: The status of Pod test-webserver-3cbf5d61-d646-4be3-86a0-29a4e61eb19d is Pending, waiting for it to be Running (with Ready = true)
Feb 22 06:03:19.309: INFO: The status of Pod test-webserver-3cbf5d61-d646-4be3-86a0-29a4e61eb19d is Pending, waiting for it to be Running (with Ready = true)
Feb 22 06:03:21.249: INFO: The status of Pod test-webserver-3cbf5d61-d646-4be3-86a0-29a4e61eb19d is Pending, waiting for it to be Running (with Ready = true)
Feb 22 06:03:23.257: INFO: The status of Pod test-webserver-3cbf5d61-d646-4be3-86a0-29a4e61eb19d is Pending, waiting for it to be Running (with Ready = true)
Feb 22 06:03:25.326: INFO: The status of Pod test-webserver-3cbf5d61-d646-4be3-86a0-29a4e61eb19d is Pending, waiting for it to be Running (with Ready = true)
Feb 22 06:03:27.277: INFO: The status of Pod test-webserver-3cbf5d61-d646-4be3-86a0-29a4e61eb19d is Pending, waiting for it to be Running (with Ready = true)
Feb 22 06:03:29.259: INFO: The status of Pod test-webserver-3cbf5d61-d646-4be3-86a0-29a4e61eb19d is Pending, waiting for it to be Running (with Ready = true)
Feb 22 06:03:31.251: INFO: The status of Pod test-webserver-3cbf5d61-d646-4be3-86a0-29a4e61eb19d is Running (Ready = false)
Feb 22 06:03:33.256: INFO: The status of Pod test-webserver-3cbf5d61-d646-4be3-86a0-29a4e61eb19d is Running (Ready = false)
Feb 22 06:03:35.257: INFO: The status of Pod test-webserver-3cbf5d61-d646-4be3-86a0-29a4e61eb19d is Running (Ready = false)
Feb 22 06:03:37.249: INFO: The status of Pod test-webserver-3cbf5d61-d646-4be3-86a0-29a4e61eb19d is Running (Ready = false)
Feb 22 06:03:39.246: INFO: The status of Pod test-webserver-3cbf5d61-d646-4be3-86a0-29a4e61eb19d is Running (Ready = false)
Feb 22 06:03:41.244: INFO: The status of Pod test-webserver-3cbf5d61-d646-4be3-86a0-29a4e61eb19d is Running (Ready = false)
Feb 22 06:03:43.244: INFO: The status of Pod test-webserver-3cbf5d61-d646-4be3-86a0-29a4e61eb19d is Running (Ready = false)
Feb 22 06:03:45.253: INFO: The status of Pod test-webserver-3cbf5d61-d646-4be3-86a0-29a4e61eb19d is Running (Ready = false)
Feb 22 06:03:47.264: INFO: The status of Pod test-webserver-3cbf5d61-d646-4be3-86a0-29a4e61eb19d is Running (Ready = true)
Feb 22 06:03:47.279: INFO: Container started at 2021-02-22 06:03:29 +0000 UTC, pod became ready at 2021-02-22 06:03:46 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:03:47.282: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-438" for this suite.

â€¢ [SLOW TEST:54.600 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]","total":270,"completed":147,"skipped":2587,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:03:47.404: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7900
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-04435835-c98c-477e-abb5-90bc4caf7cf9
STEP: Creating a pod to test consume configMaps
Feb 22 06:03:47.831: INFO: Waiting up to 5m0s for pod "pod-configmaps-113aaf83-e66a-4ca4-bb9e-646d28ac3147" in namespace "configmap-7900" to be "Succeeded or Failed"
Feb 22 06:03:47.853: INFO: Pod "pod-configmaps-113aaf83-e66a-4ca4-bb9e-646d28ac3147": Phase="Pending", Reason="", readiness=false. Elapsed: 21.819023ms
Feb 22 06:03:49.868: INFO: Pod "pod-configmaps-113aaf83-e66a-4ca4-bb9e-646d28ac3147": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036939511s
Feb 22 06:03:51.879: INFO: Pod "pod-configmaps-113aaf83-e66a-4ca4-bb9e-646d28ac3147": Phase="Pending", Reason="", readiness=false. Elapsed: 4.047514713s
Feb 22 06:03:53.939: INFO: Pod "pod-configmaps-113aaf83-e66a-4ca4-bb9e-646d28ac3147": Phase="Pending", Reason="", readiness=false. Elapsed: 6.108206555s
Feb 22 06:03:55.964: INFO: Pod "pod-configmaps-113aaf83-e66a-4ca4-bb9e-646d28ac3147": Phase="Pending", Reason="", readiness=false. Elapsed: 8.132453542s
Feb 22 06:03:57.984: INFO: Pod "pod-configmaps-113aaf83-e66a-4ca4-bb9e-646d28ac3147": Phase="Pending", Reason="", readiness=false. Elapsed: 10.152442968s
Feb 22 06:03:59.999: INFO: Pod "pod-configmaps-113aaf83-e66a-4ca4-bb9e-646d28ac3147": Phase="Pending", Reason="", readiness=false. Elapsed: 12.168122628s
Feb 22 06:04:02.011: INFO: Pod "pod-configmaps-113aaf83-e66a-4ca4-bb9e-646d28ac3147": Phase="Pending", Reason="", readiness=false. Elapsed: 14.179403342s
Feb 22 06:04:04.044: INFO: Pod "pod-configmaps-113aaf83-e66a-4ca4-bb9e-646d28ac3147": Phase="Pending", Reason="", readiness=false. Elapsed: 16.212591885s
Feb 22 06:04:06.052: INFO: Pod "pod-configmaps-113aaf83-e66a-4ca4-bb9e-646d28ac3147": Phase="Pending", Reason="", readiness=false. Elapsed: 18.22065561s
Feb 22 06:04:08.059: INFO: Pod "pod-configmaps-113aaf83-e66a-4ca4-bb9e-646d28ac3147": Phase="Pending", Reason="", readiness=false. Elapsed: 20.227951106s
Feb 22 06:04:10.116: INFO: Pod "pod-configmaps-113aaf83-e66a-4ca4-bb9e-646d28ac3147": Phase="Pending", Reason="", readiness=false. Elapsed: 22.28520416s
Feb 22 06:04:12.128: INFO: Pod "pod-configmaps-113aaf83-e66a-4ca4-bb9e-646d28ac3147": Phase="Pending", Reason="", readiness=false. Elapsed: 24.296845951s
Feb 22 06:04:14.134: INFO: Pod "pod-configmaps-113aaf83-e66a-4ca4-bb9e-646d28ac3147": Phase="Pending", Reason="", readiness=false. Elapsed: 26.302940351s
Feb 22 06:04:16.142: INFO: Pod "pod-configmaps-113aaf83-e66a-4ca4-bb9e-646d28ac3147": Phase="Pending", Reason="", readiness=false. Elapsed: 28.311239268s
Feb 22 06:04:18.152: INFO: Pod "pod-configmaps-113aaf83-e66a-4ca4-bb9e-646d28ac3147": Phase="Succeeded", Reason="", readiness=false. Elapsed: 30.320782596s
STEP: Saw pod success
Feb 22 06:04:18.152: INFO: Pod "pod-configmaps-113aaf83-e66a-4ca4-bb9e-646d28ac3147" satisfied condition "Succeeded or Failed"
Feb 22 06:04:18.159: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com pod pod-configmaps-113aaf83-e66a-4ca4-bb9e-646d28ac3147 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 22 06:04:25.337: INFO: Waiting for pod pod-configmaps-113aaf83-e66a-4ca4-bb9e-646d28ac3147 to disappear
Feb 22 06:04:25.379: INFO: Pod pod-configmaps-113aaf83-e66a-4ca4-bb9e-646d28ac3147 still exists
Feb 22 06:04:27.380: INFO: Waiting for pod pod-configmaps-113aaf83-e66a-4ca4-bb9e-646d28ac3147 to disappear
Feb 22 06:04:27.393: INFO: Pod pod-configmaps-113aaf83-e66a-4ca4-bb9e-646d28ac3147 still exists
Feb 22 06:04:29.380: INFO: Waiting for pod pod-configmaps-113aaf83-e66a-4ca4-bb9e-646d28ac3147 to disappear
Feb 22 06:04:29.391: INFO: Pod pod-configmaps-113aaf83-e66a-4ca4-bb9e-646d28ac3147 still exists
Feb 22 06:04:31.380: INFO: Waiting for pod pod-configmaps-113aaf83-e66a-4ca4-bb9e-646d28ac3147 to disappear
Feb 22 06:04:31.390: INFO: Pod pod-configmaps-113aaf83-e66a-4ca4-bb9e-646d28ac3147 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:04:31.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7900" for this suite.

â€¢ [SLOW TEST:44.026 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:36
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":270,"completed":148,"skipped":2611,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:04:31.454: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9093
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap configmap-9093/configmap-test-33e81526-2a5f-4ca1-9331-0287cde076f6
STEP: Creating a pod to test consume configMaps
Feb 22 06:04:31.894: INFO: Waiting up to 5m0s for pod "pod-configmaps-03f881a0-ed9d-4e83-98b4-9136a3035622" in namespace "configmap-9093" to be "Succeeded or Failed"
Feb 22 06:04:31.965: INFO: Pod "pod-configmaps-03f881a0-ed9d-4e83-98b4-9136a3035622": Phase="Pending", Reason="", readiness=false. Elapsed: 70.216444ms
Feb 22 06:04:33.972: INFO: Pod "pod-configmaps-03f881a0-ed9d-4e83-98b4-9136a3035622": Phase="Pending", Reason="", readiness=false. Elapsed: 2.077317217s
Feb 22 06:04:36.014: INFO: Pod "pod-configmaps-03f881a0-ed9d-4e83-98b4-9136a3035622": Phase="Pending", Reason="", readiness=false. Elapsed: 4.11924228s
Feb 22 06:04:38.025: INFO: Pod "pod-configmaps-03f881a0-ed9d-4e83-98b4-9136a3035622": Phase="Pending", Reason="", readiness=false. Elapsed: 6.130256733s
Feb 22 06:04:40.065: INFO: Pod "pod-configmaps-03f881a0-ed9d-4e83-98b4-9136a3035622": Phase="Pending", Reason="", readiness=false. Elapsed: 8.170229622s
Feb 22 06:04:42.293: INFO: Pod "pod-configmaps-03f881a0-ed9d-4e83-98b4-9136a3035622": Phase="Pending", Reason="", readiness=false. Elapsed: 10.398680164s
Feb 22 06:04:44.305: INFO: Pod "pod-configmaps-03f881a0-ed9d-4e83-98b4-9136a3035622": Phase="Pending", Reason="", readiness=false. Elapsed: 12.410413118s
Feb 22 06:04:46.393: INFO: Pod "pod-configmaps-03f881a0-ed9d-4e83-98b4-9136a3035622": Phase="Pending", Reason="", readiness=false. Elapsed: 14.498652774s
Feb 22 06:04:48.442: INFO: Pod "pod-configmaps-03f881a0-ed9d-4e83-98b4-9136a3035622": Phase="Pending", Reason="", readiness=false. Elapsed: 16.547164126s
Feb 22 06:04:50.450: INFO: Pod "pod-configmaps-03f881a0-ed9d-4e83-98b4-9136a3035622": Phase="Pending", Reason="", readiness=false. Elapsed: 18.555866958s
Feb 22 06:04:52.463: INFO: Pod "pod-configmaps-03f881a0-ed9d-4e83-98b4-9136a3035622": Phase="Pending", Reason="", readiness=false. Elapsed: 20.568623197s
Feb 22 06:04:54.471: INFO: Pod "pod-configmaps-03f881a0-ed9d-4e83-98b4-9136a3035622": Phase="Pending", Reason="", readiness=false. Elapsed: 22.576435459s
Feb 22 06:04:56.479: INFO: Pod "pod-configmaps-03f881a0-ed9d-4e83-98b4-9136a3035622": Phase="Pending", Reason="", readiness=false. Elapsed: 24.584505674s
Feb 22 06:04:58.489: INFO: Pod "pod-configmaps-03f881a0-ed9d-4e83-98b4-9136a3035622": Phase="Pending", Reason="", readiness=false. Elapsed: 26.594295714s
Feb 22 06:05:00.503: INFO: Pod "pod-configmaps-03f881a0-ed9d-4e83-98b4-9136a3035622": Phase="Succeeded", Reason="", readiness=false. Elapsed: 28.608086724s
STEP: Saw pod success
Feb 22 06:05:00.503: INFO: Pod "pod-configmaps-03f881a0-ed9d-4e83-98b4-9136a3035622" satisfied condition "Succeeded or Failed"
Feb 22 06:05:00.524: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com pod pod-configmaps-03f881a0-ed9d-4e83-98b4-9136a3035622 container env-test: <nil>
STEP: delete the pod
Feb 22 06:05:08.134: INFO: Waiting for pod pod-configmaps-03f881a0-ed9d-4e83-98b4-9136a3035622 to disappear
Feb 22 06:05:08.173: INFO: Pod pod-configmaps-03f881a0-ed9d-4e83-98b4-9136a3035622 still exists
Feb 22 06:05:10.174: INFO: Waiting for pod pod-configmaps-03f881a0-ed9d-4e83-98b4-9136a3035622 to disappear
Feb 22 06:05:10.184: INFO: Pod pod-configmaps-03f881a0-ed9d-4e83-98b4-9136a3035622 still exists
Feb 22 06:05:12.174: INFO: Waiting for pod pod-configmaps-03f881a0-ed9d-4e83-98b4-9136a3035622 to disappear
Feb 22 06:05:12.195: INFO: Pod pod-configmaps-03f881a0-ed9d-4e83-98b4-9136a3035622 still exists
Feb 22 06:05:14.173: INFO: Waiting for pod pod-configmaps-03f881a0-ed9d-4e83-98b4-9136a3035622 to disappear
Feb 22 06:05:14.182: INFO: Pod pod-configmaps-03f881a0-ed9d-4e83-98b4-9136a3035622 still exists
Feb 22 06:05:16.174: INFO: Waiting for pod pod-configmaps-03f881a0-ed9d-4e83-98b4-9136a3035622 to disappear
Feb 22 06:05:16.182: INFO: Pod pod-configmaps-03f881a0-ed9d-4e83-98b4-9136a3035622 still exists
Feb 22 06:05:18.174: INFO: Waiting for pod pod-configmaps-03f881a0-ed9d-4e83-98b4-9136a3035622 to disappear
Feb 22 06:05:18.181: INFO: Pod pod-configmaps-03f881a0-ed9d-4e83-98b4-9136a3035622 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:05:18.181: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9093" for this suite.

â€¢ [SLOW TEST:46.773 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:34
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]","total":270,"completed":149,"skipped":2646,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:05:18.232: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-7555
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Feb 22 06:05:49.274: INFO: Successfully updated pod "pod-update-66bba7ad-47a9-4b41-9d62-2bfda04ef6e0"
STEP: verifying the updated pod is in kubernetes
Feb 22 06:05:49.380: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:05:49.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7555" for this suite.

â€¢ [SLOW TEST:31.260 seconds]
[k8s.io] Pods
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Pods should be updated [NodeConformance] [Conformance]","total":270,"completed":150,"skipped":2692,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:05:49.505: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-1265
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicaSet
STEP: Ensuring resource quota status captures replicaset creation
STEP: Deleting a ReplicaSet
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:06:01.295: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1265" for this suite.

â€¢ [SLOW TEST:11.859 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]","total":270,"completed":151,"skipped":2706,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:06:01.368: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-6835
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Feb 22 06:06:11.871: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:06:11.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6835" for this suite.

â€¢ [SLOW TEST:10.586 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]","total":270,"completed":152,"skipped":2719,"failed":0}
SSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:06:11.958: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-5014
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
Feb 22 06:06:12.283: INFO: PodSpec: initContainers in spec.initContainers
Feb 22 06:10:05.201: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-60c3aeb4-70ff-413b-bd5f-797bf52c63af", GenerateName:"", Namespace:"init-container-5014", SelfLink:"/api/v1/namespaces/init-container-5014/pods/pod-init-60c3aeb4-70ff-413b-bd5f-797bf52c63af", UID:"6824867f-5fc9-469b-8ca1-86e08d26860c", ResourceVersion:"134580", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63749570772, loc:(*time.Location)(0x7b501e0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"282710746"}, Annotations:map[string]string{"attachment_id":"9dd50380-7d89-4a24-95c1-228a5d0c038d", "kubernetes.io/psp":"e2e-test-privileged-psp", "mac":"04:50:56:00:28:19", "vlan":"None", "vmware-system-ephemeral-disk-uuid":"6000C29e-dbcb-daee-1af5-a1d0e5baec47", "vmware-system-image-references":"{\"init1\":\"busybox-c954c04429e8f5873d6cf81884df42470d97ef3b-v3668\",\"init2\":\"busybox-c954c04429e8f5873d6cf81884df42470d97ef3b-v3668\",\"run1\":\"pause-54467452d21a00c28aa4cce37d0850173b528ca6-v39401\"}", "vmware-system-vm-moid":"vm-632:6b180790-afb7-40a7-b1c1-16f00c9b6783", "vmware-system-vm-uuid":"502f08f2-2214-fede-0fbf-7259b81ad0b2"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string{"lifecycle-controller/system.vmware.com"}, ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:(*v1.Time)(0xc003028ec0), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003028f60)}, v1.ManagedFieldsEntry{Manager:"nsx-ncp-75bf644549-ps9h2", Operation:"Update", APIVersion:"v1", Time:(*v1.Time)(0xc003028fa0), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003029160)}, v1.ManagedFieldsEntry{Manager:"image-controller", Operation:"Update", APIVersion:"v1", Time:(*v1.Time)(0xc0030292a0), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003029300)}, v1.ManagedFieldsEntry{Manager:"scheduler-extender", Operation:"Update", APIVersion:"v1", Time:(*v1.Time)(0xc003029320), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003029340)}, v1.ManagedFieldsEntry{Manager:"spherelet", Operation:"Update", APIVersion:"v1", Time:(*v1.Time)(0xc003029360), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003029540)}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-csjwk", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0020f0100), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"mirror.gcr.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-csjwk", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"mirror.gcr.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-csjwk", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.2", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-csjwk", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc006628388), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"sc2-rdops-vm05-dhcp-174-51.eng.vmware.com", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc001eee150), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc006628410)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc006628430)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc006628438), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00662843c), PreemptionPolicy:(*v1.PreemptionPolicy)(nil), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570773, loc:(*time.Location)(0x7b501e0)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570895, loc:(*time.Location)(0x7b501e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570895, loc:(*time.Location)(0x7b501e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749570895, loc:(*time.Location)(0x7b501e0)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.192.174.51", PodIP:"172.26.1.210", PodIPs:[]v1.PodIP{v1.PodIP{IP:"172.26.1.210"}}, StartTime:(*v1.Time)(0xc003029560), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0030295a0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001eee230)}, Ready:false, RestartCount:3, Image:"mirror.gcr.io/library/busybox:1.29", ImageID:"busybox-c954c04429e8f5873d6cf81884df42470d97ef3b-v3668", ContainerID:"d541e077-803f-41a9-bd16-da2dc3654ba6", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc003029620), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"mirror.gcr.io/library/busybox:1.29", ImageID:"busybox-c954c04429e8f5873d6cf81884df42470d97ef3b-v3668", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc003029580), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.2", ImageID:"pause-54467452d21a00c28aa4cce37d0850173b528ca6-v39401", ContainerID:"", Started:(*bool)(nil)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:10:05.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-5014" for this suite.

â€¢ [SLOW TEST:233.782 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]","total":270,"completed":153,"skipped":2731,"failed":0}
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:10:05.751: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9647
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-map-c0169840-f144-4607-9da5-749d4cde0257
STEP: Creating a pod to test consume configMaps
Feb 22 06:10:06.934: INFO: Waiting up to 5m0s for pod "pod-configmaps-6b81bc22-b039-471a-a49d-bddb24930c83" in namespace "configmap-9647" to be "Succeeded or Failed"
Feb 22 06:10:06.969: INFO: Pod "pod-configmaps-6b81bc22-b039-471a-a49d-bddb24930c83": Phase="Pending", Reason="", readiness=false. Elapsed: 35.210122ms
Feb 22 06:10:08.978: INFO: Pod "pod-configmaps-6b81bc22-b039-471a-a49d-bddb24930c83": Phase="Pending", Reason="", readiness=false. Elapsed: 2.044557257s
Feb 22 06:10:10.996: INFO: Pod "pod-configmaps-6b81bc22-b039-471a-a49d-bddb24930c83": Phase="Pending", Reason="", readiness=false. Elapsed: 4.062565821s
Feb 22 06:10:13.026: INFO: Pod "pod-configmaps-6b81bc22-b039-471a-a49d-bddb24930c83": Phase="Pending", Reason="", readiness=false. Elapsed: 6.092264254s
Feb 22 06:10:15.038: INFO: Pod "pod-configmaps-6b81bc22-b039-471a-a49d-bddb24930c83": Phase="Pending", Reason="", readiness=false. Elapsed: 8.104051446s
Feb 22 06:10:17.102: INFO: Pod "pod-configmaps-6b81bc22-b039-471a-a49d-bddb24930c83": Phase="Pending", Reason="", readiness=false. Elapsed: 10.167736389s
Feb 22 06:10:19.127: INFO: Pod "pod-configmaps-6b81bc22-b039-471a-a49d-bddb24930c83": Phase="Pending", Reason="", readiness=false. Elapsed: 12.192942927s
Feb 22 06:10:21.143: INFO: Pod "pod-configmaps-6b81bc22-b039-471a-a49d-bddb24930c83": Phase="Pending", Reason="", readiness=false. Elapsed: 14.209657889s
Feb 22 06:10:23.158: INFO: Pod "pod-configmaps-6b81bc22-b039-471a-a49d-bddb24930c83": Phase="Pending", Reason="", readiness=false. Elapsed: 16.224067562s
Feb 22 06:10:25.185: INFO: Pod "pod-configmaps-6b81bc22-b039-471a-a49d-bddb24930c83": Phase="Pending", Reason="", readiness=false. Elapsed: 18.250976669s
Feb 22 06:10:27.196: INFO: Pod "pod-configmaps-6b81bc22-b039-471a-a49d-bddb24930c83": Phase="Pending", Reason="", readiness=false. Elapsed: 20.261804768s
Feb 22 06:10:29.202: INFO: Pod "pod-configmaps-6b81bc22-b039-471a-a49d-bddb24930c83": Phase="Pending", Reason="", readiness=false. Elapsed: 22.268085847s
Feb 22 06:10:31.207: INFO: Pod "pod-configmaps-6b81bc22-b039-471a-a49d-bddb24930c83": Phase="Pending", Reason="", readiness=false. Elapsed: 24.273384929s
Feb 22 06:10:33.231: INFO: Pod "pod-configmaps-6b81bc22-b039-471a-a49d-bddb24930c83": Phase="Pending", Reason="", readiness=false. Elapsed: 26.297598566s
Feb 22 06:10:35.252: INFO: Pod "pod-configmaps-6b81bc22-b039-471a-a49d-bddb24930c83": Phase="Pending", Reason="", readiness=false. Elapsed: 28.318125832s
Feb 22 06:10:37.279: INFO: Pod "pod-configmaps-6b81bc22-b039-471a-a49d-bddb24930c83": Phase="Succeeded", Reason="", readiness=false. Elapsed: 30.345602829s
STEP: Saw pod success
Feb 22 06:10:37.280: INFO: Pod "pod-configmaps-6b81bc22-b039-471a-a49d-bddb24930c83" satisfied condition "Succeeded or Failed"
Feb 22 06:10:37.294: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com pod pod-configmaps-6b81bc22-b039-471a-a49d-bddb24930c83 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 22 06:10:43.541: INFO: Waiting for pod pod-configmaps-6b81bc22-b039-471a-a49d-bddb24930c83 to disappear
Feb 22 06:10:43.556: INFO: Pod pod-configmaps-6b81bc22-b039-471a-a49d-bddb24930c83 still exists
Feb 22 06:10:45.557: INFO: Waiting for pod pod-configmaps-6b81bc22-b039-471a-a49d-bddb24930c83 to disappear
Feb 22 06:10:45.566: INFO: Pod pod-configmaps-6b81bc22-b039-471a-a49d-bddb24930c83 still exists
Feb 22 06:10:47.557: INFO: Waiting for pod pod-configmaps-6b81bc22-b039-471a-a49d-bddb24930c83 to disappear
Feb 22 06:10:47.568: INFO: Pod pod-configmaps-6b81bc22-b039-471a-a49d-bddb24930c83 still exists
Feb 22 06:10:49.558: INFO: Waiting for pod pod-configmaps-6b81bc22-b039-471a-a49d-bddb24930c83 to disappear
Feb 22 06:10:49.584: INFO: Pod pod-configmaps-6b81bc22-b039-471a-a49d-bddb24930c83 still exists
Feb 22 06:10:51.557: INFO: Waiting for pod pod-configmaps-6b81bc22-b039-471a-a49d-bddb24930c83 to disappear
Feb 22 06:10:51.622: INFO: Pod pod-configmaps-6b81bc22-b039-471a-a49d-bddb24930c83 still exists
Feb 22 06:10:53.557: INFO: Waiting for pod pod-configmaps-6b81bc22-b039-471a-a49d-bddb24930c83 to disappear
Feb 22 06:10:53.584: INFO: Pod pod-configmaps-6b81bc22-b039-471a-a49d-bddb24930c83 still exists
Feb 22 06:10:55.558: INFO: Waiting for pod pod-configmaps-6b81bc22-b039-471a-a49d-bddb24930c83 to disappear
Feb 22 06:10:55.684: INFO: Pod pod-configmaps-6b81bc22-b039-471a-a49d-bddb24930c83 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:10:55.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9647" for this suite.

â€¢ [SLOW TEST:50.413 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:36
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":270,"completed":154,"skipped":2737,"failed":0}
SSSS
------------------------------
[sig-network] Services 
  should find a service from listing all namespaces [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:10:56.193: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-3611
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should find a service from listing all namespaces [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: fetching services
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:10:57.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3611" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702
â€¢{"msg":"PASSED [sig-network] Services should find a service from listing all namespaces [Conformance]","total":270,"completed":155,"skipped":2741,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:10:58.494: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-9287
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Feb 22 06:11:02.368: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9287 /api/v1/namespaces/watch-9287/configmaps/e2e-watch-test-configmap-a adf4a4be-e39c-476e-acdb-e3100a7c36cb 135177 0 2021-02-22 06:11:01 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2021-02-22 06:11:01 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Feb 22 06:11:02.372: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9287 /api/v1/namespaces/watch-9287/configmaps/e2e-watch-test-configmap-a adf4a4be-e39c-476e-acdb-e3100a7c36cb 135177 0 2021-02-22 06:11:01 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2021-02-22 06:11:01 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Feb 22 06:11:12.433: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9287 /api/v1/namespaces/watch-9287/configmaps/e2e-watch-test-configmap-a adf4a4be-e39c-476e-acdb-e3100a7c36cb 135322 0 2021-02-22 06:11:01 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2021-02-22 06:11:12 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Feb 22 06:11:12.433: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9287 /api/v1/namespaces/watch-9287/configmaps/e2e-watch-test-configmap-a adf4a4be-e39c-476e-acdb-e3100a7c36cb 135322 0 2021-02-22 06:11:01 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2021-02-22 06:11:12 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Feb 22 06:11:22.538: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9287 /api/v1/namespaces/watch-9287/configmaps/e2e-watch-test-configmap-a adf4a4be-e39c-476e-acdb-e3100a7c36cb 135416 0 2021-02-22 06:11:01 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2021-02-22 06:11:22 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Feb 22 06:11:22.539: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9287 /api/v1/namespaces/watch-9287/configmaps/e2e-watch-test-configmap-a adf4a4be-e39c-476e-acdb-e3100a7c36cb 135416 0 2021-02-22 06:11:01 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2021-02-22 06:11:22 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Feb 22 06:11:32.575: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9287 /api/v1/namespaces/watch-9287/configmaps/e2e-watch-test-configmap-a adf4a4be-e39c-476e-acdb-e3100a7c36cb 135508 0 2021-02-22 06:11:01 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2021-02-22 06:11:22 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Feb 22 06:11:32.575: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9287 /api/v1/namespaces/watch-9287/configmaps/e2e-watch-test-configmap-a adf4a4be-e39c-476e-acdb-e3100a7c36cb 135508 0 2021-02-22 06:11:01 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2021-02-22 06:11:22 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Feb 22 06:11:42.600: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9287 /api/v1/namespaces/watch-9287/configmaps/e2e-watch-test-configmap-b cbee8912-a1e4-4f11-b222-28ffaaa0fa23 135603 0 2021-02-22 06:11:42 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2021-02-22 06:11:42 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Feb 22 06:11:42.600: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9287 /api/v1/namespaces/watch-9287/configmaps/e2e-watch-test-configmap-b cbee8912-a1e4-4f11-b222-28ffaaa0fa23 135603 0 2021-02-22 06:11:42 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2021-02-22 06:11:42 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Feb 22 06:11:52.630: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9287 /api/v1/namespaces/watch-9287/configmaps/e2e-watch-test-configmap-b cbee8912-a1e4-4f11-b222-28ffaaa0fa23 135698 0 2021-02-22 06:11:42 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2021-02-22 06:11:42 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Feb 22 06:11:52.630: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9287 /api/v1/namespaces/watch-9287/configmaps/e2e-watch-test-configmap-b cbee8912-a1e4-4f11-b222-28ffaaa0fa23 135698 0 2021-02-22 06:11:42 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2021-02-22 06:11:42 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:12:02.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-9287" for this suite.

â€¢ [SLOW TEST:64.190 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]","total":270,"completed":156,"skipped":2764,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:12:02.708: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-1109
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1109.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-1109.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1109.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-1109.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 22 06:12:39.435: INFO: DNS probes using dns-test-062e18ba-a1d1-42cd-8b27-a7d808a0e0ae succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1109.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-1109.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1109.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-1109.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 22 06:13:10.090: INFO: DNS probes using dns-test-064b7adb-9717-41bf-8432-077cf07b0733 succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1109.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-1109.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1109.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-1109.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 22 06:13:41.904: INFO: DNS probes using dns-test-b4a56618-cfe6-4615-93ac-a8266b94b2c8 succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:13:42.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1109" for this suite.

â€¢ [SLOW TEST:100.084 seconds]
[sig-network] DNS
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for ExternalName services [Conformance]","total":270,"completed":157,"skipped":2818,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:13:42.813: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6343
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-5fd11136-f5ac-45b9-949a-4c4cae33909f
STEP: Creating a pod to test consume configMaps
Feb 22 06:13:43.303: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-8419c957-d63c-4359-ad42-1ffabaa6a26e" in namespace "projected-6343" to be "Succeeded or Failed"
Feb 22 06:13:43.342: INFO: Pod "pod-projected-configmaps-8419c957-d63c-4359-ad42-1ffabaa6a26e": Phase="Pending", Reason="", readiness=false. Elapsed: 39.091068ms
Feb 22 06:13:45.740: INFO: Pod "pod-projected-configmaps-8419c957-d63c-4359-ad42-1ffabaa6a26e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.437014009s
Feb 22 06:13:47.862: INFO: Pod "pod-projected-configmaps-8419c957-d63c-4359-ad42-1ffabaa6a26e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.558146826s
Feb 22 06:13:49.907: INFO: Pod "pod-projected-configmaps-8419c957-d63c-4359-ad42-1ffabaa6a26e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.603291643s
Feb 22 06:13:51.934: INFO: Pod "pod-projected-configmaps-8419c957-d63c-4359-ad42-1ffabaa6a26e": Phase="Pending", Reason="", readiness=false. Elapsed: 8.630242941s
Feb 22 06:13:53.990: INFO: Pod "pod-projected-configmaps-8419c957-d63c-4359-ad42-1ffabaa6a26e": Phase="Pending", Reason="", readiness=false. Elapsed: 10.686466196s
Feb 22 06:13:56.260: INFO: Pod "pod-projected-configmaps-8419c957-d63c-4359-ad42-1ffabaa6a26e": Phase="Pending", Reason="", readiness=false. Elapsed: 12.956478053s
Feb 22 06:13:58.277: INFO: Pod "pod-projected-configmaps-8419c957-d63c-4359-ad42-1ffabaa6a26e": Phase="Pending", Reason="", readiness=false. Elapsed: 14.97328654s
Feb 22 06:14:00.289: INFO: Pod "pod-projected-configmaps-8419c957-d63c-4359-ad42-1ffabaa6a26e": Phase="Pending", Reason="", readiness=false. Elapsed: 16.985555152s
Feb 22 06:14:02.317: INFO: Pod "pod-projected-configmaps-8419c957-d63c-4359-ad42-1ffabaa6a26e": Phase="Pending", Reason="", readiness=false. Elapsed: 19.013698007s
Feb 22 06:14:04.330: INFO: Pod "pod-projected-configmaps-8419c957-d63c-4359-ad42-1ffabaa6a26e": Phase="Pending", Reason="", readiness=false. Elapsed: 21.026160507s
Feb 22 06:14:06.348: INFO: Pod "pod-projected-configmaps-8419c957-d63c-4359-ad42-1ffabaa6a26e": Phase="Pending", Reason="", readiness=false. Elapsed: 23.04456358s
Feb 22 06:14:08.357: INFO: Pod "pod-projected-configmaps-8419c957-d63c-4359-ad42-1ffabaa6a26e": Phase="Pending", Reason="", readiness=false. Elapsed: 25.053693395s
Feb 22 06:14:10.368: INFO: Pod "pod-projected-configmaps-8419c957-d63c-4359-ad42-1ffabaa6a26e": Phase="Pending", Reason="", readiness=false. Elapsed: 27.06509965s
Feb 22 06:14:12.400: INFO: Pod "pod-projected-configmaps-8419c957-d63c-4359-ad42-1ffabaa6a26e": Phase="Pending", Reason="", readiness=false. Elapsed: 29.096303662s
Feb 22 06:14:14.427: INFO: Pod "pod-projected-configmaps-8419c957-d63c-4359-ad42-1ffabaa6a26e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 31.123872363s
STEP: Saw pod success
Feb 22 06:14:14.427: INFO: Pod "pod-projected-configmaps-8419c957-d63c-4359-ad42-1ffabaa6a26e" satisfied condition "Succeeded or Failed"
Feb 22 06:14:14.452: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com pod pod-projected-configmaps-8419c957-d63c-4359-ad42-1ffabaa6a26e container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 22 06:14:21.011: INFO: Waiting for pod pod-projected-configmaps-8419c957-d63c-4359-ad42-1ffabaa6a26e to disappear
Feb 22 06:14:21.033: INFO: Pod pod-projected-configmaps-8419c957-d63c-4359-ad42-1ffabaa6a26e still exists
Feb 22 06:14:23.033: INFO: Waiting for pod pod-projected-configmaps-8419c957-d63c-4359-ad42-1ffabaa6a26e to disappear
Feb 22 06:14:23.046: INFO: Pod pod-projected-configmaps-8419c957-d63c-4359-ad42-1ffabaa6a26e still exists
Feb 22 06:14:25.033: INFO: Waiting for pod pod-projected-configmaps-8419c957-d63c-4359-ad42-1ffabaa6a26e to disappear
Feb 22 06:14:25.043: INFO: Pod pod-projected-configmaps-8419c957-d63c-4359-ad42-1ffabaa6a26e no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:14:25.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6343" for this suite.

â€¢ [SLOW TEST:42.300 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:36
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","total":270,"completed":158,"skipped":2832,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:14:25.136: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1293
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0644 on tmpfs
Feb 22 06:14:25.589: INFO: Waiting up to 5m0s for pod "pod-3c3c4792-8276-479c-8a0c-274ae04f70ef" in namespace "emptydir-1293" to be "Succeeded or Failed"
Feb 22 06:14:25.600: INFO: Pod "pod-3c3c4792-8276-479c-8a0c-274ae04f70ef": Phase="Pending", Reason="", readiness=false. Elapsed: 10.713214ms
Feb 22 06:14:27.606: INFO: Pod "pod-3c3c4792-8276-479c-8a0c-274ae04f70ef": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016625238s
Feb 22 06:14:29.817: INFO: Pod "pod-3c3c4792-8276-479c-8a0c-274ae04f70ef": Phase="Pending", Reason="", readiness=false. Elapsed: 4.227285594s
Feb 22 06:14:31.835: INFO: Pod "pod-3c3c4792-8276-479c-8a0c-274ae04f70ef": Phase="Pending", Reason="", readiness=false. Elapsed: 6.245784993s
Feb 22 06:14:33.853: INFO: Pod "pod-3c3c4792-8276-479c-8a0c-274ae04f70ef": Phase="Pending", Reason="", readiness=false. Elapsed: 8.26340381s
Feb 22 06:14:35.863: INFO: Pod "pod-3c3c4792-8276-479c-8a0c-274ae04f70ef": Phase="Pending", Reason="", readiness=false. Elapsed: 10.273833814s
Feb 22 06:14:37.900: INFO: Pod "pod-3c3c4792-8276-479c-8a0c-274ae04f70ef": Phase="Pending", Reason="", readiness=false. Elapsed: 12.310769001s
Feb 22 06:14:39.922: INFO: Pod "pod-3c3c4792-8276-479c-8a0c-274ae04f70ef": Phase="Pending", Reason="", readiness=false. Elapsed: 14.332053047s
Feb 22 06:14:41.931: INFO: Pod "pod-3c3c4792-8276-479c-8a0c-274ae04f70ef": Phase="Pending", Reason="", readiness=false. Elapsed: 16.341078402s
Feb 22 06:14:43.952: INFO: Pod "pod-3c3c4792-8276-479c-8a0c-274ae04f70ef": Phase="Pending", Reason="", readiness=false. Elapsed: 18.362735717s
Feb 22 06:14:45.963: INFO: Pod "pod-3c3c4792-8276-479c-8a0c-274ae04f70ef": Phase="Pending", Reason="", readiness=false. Elapsed: 20.373917536s
Feb 22 06:14:47.976: INFO: Pod "pod-3c3c4792-8276-479c-8a0c-274ae04f70ef": Phase="Pending", Reason="", readiness=false. Elapsed: 22.386600028s
Feb 22 06:14:49.984: INFO: Pod "pod-3c3c4792-8276-479c-8a0c-274ae04f70ef": Phase="Pending", Reason="", readiness=false. Elapsed: 24.394088251s
Feb 22 06:14:51.998: INFO: Pod "pod-3c3c4792-8276-479c-8a0c-274ae04f70ef": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.408701239s
STEP: Saw pod success
Feb 22 06:14:51.998: INFO: Pod "pod-3c3c4792-8276-479c-8a0c-274ae04f70ef" satisfied condition "Succeeded or Failed"
Feb 22 06:14:52.008: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com pod pod-3c3c4792-8276-479c-8a0c-274ae04f70ef container test-container: <nil>
STEP: delete the pod
Feb 22 06:14:52.121: INFO: Waiting for pod pod-3c3c4792-8276-479c-8a0c-274ae04f70ef to disappear
Feb 22 06:14:52.143: INFO: Pod pod-3c3c4792-8276-479c-8a0c-274ae04f70ef still exists
Feb 22 06:14:54.143: INFO: Waiting for pod pod-3c3c4792-8276-479c-8a0c-274ae04f70ef to disappear
Feb 22 06:14:54.155: INFO: Pod pod-3c3c4792-8276-479c-8a0c-274ae04f70ef still exists
Feb 22 06:14:56.143: INFO: Waiting for pod pod-3c3c4792-8276-479c-8a0c-274ae04f70ef to disappear
Feb 22 06:14:56.153: INFO: Pod pod-3c3c4792-8276-479c-8a0c-274ae04f70ef still exists
Feb 22 06:14:58.143: INFO: Waiting for pod pod-3c3c4792-8276-479c-8a0c-274ae04f70ef to disappear
Feb 22 06:14:58.160: INFO: Pod pod-3c3c4792-8276-479c-8a0c-274ae04f70ef still exists
Feb 22 06:15:00.145: INFO: Waiting for pod pod-3c3c4792-8276-479c-8a0c-274ae04f70ef to disappear
Feb 22 06:15:00.158: INFO: Pod pod-3c3c4792-8276-479c-8a0c-274ae04f70ef still exists
Feb 22 06:15:02.144: INFO: Waiting for pod pod-3c3c4792-8276-479c-8a0c-274ae04f70ef to disappear
Feb 22 06:15:02.151: INFO: Pod pod-3c3c4792-8276-479c-8a0c-274ae04f70ef still exists
Feb 22 06:15:04.144: INFO: Waiting for pod pod-3c3c4792-8276-479c-8a0c-274ae04f70ef to disappear
Feb 22 06:15:04.162: INFO: Pod pod-3c3c4792-8276-479c-8a0c-274ae04f70ef still exists
Feb 22 06:15:06.143: INFO: Waiting for pod pod-3c3c4792-8276-479c-8a0c-274ae04f70ef to disappear
Feb 22 06:15:06.166: INFO: Pod pod-3c3c4792-8276-479c-8a0c-274ae04f70ef still exists
Feb 22 06:15:08.143: INFO: Waiting for pod pod-3c3c4792-8276-479c-8a0c-274ae04f70ef to disappear
Feb 22 06:15:08.158: INFO: Pod pod-3c3c4792-8276-479c-8a0c-274ae04f70ef still exists
Feb 22 06:15:10.144: INFO: Waiting for pod pod-3c3c4792-8276-479c-8a0c-274ae04f70ef to disappear
Feb 22 06:15:10.165: INFO: Pod pod-3c3c4792-8276-479c-8a0c-274ae04f70ef still exists
Feb 22 06:15:12.143: INFO: Waiting for pod pod-3c3c4792-8276-479c-8a0c-274ae04f70ef to disappear
Feb 22 06:15:12.209: INFO: Pod pod-3c3c4792-8276-479c-8a0c-274ae04f70ef still exists
Feb 22 06:15:14.143: INFO: Waiting for pod pod-3c3c4792-8276-479c-8a0c-274ae04f70ef to disappear
Feb 22 06:15:14.149: INFO: Pod pod-3c3c4792-8276-479c-8a0c-274ae04f70ef no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:15:14.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1293" for this suite.

â€¢ [SLOW TEST:49.063 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:42
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":270,"completed":159,"skipped":2844,"failed":0}
SSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:15:14.198: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-2754
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Feb 22 06:15:14.572: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2754 /api/v1/namespaces/watch-2754/configmaps/e2e-watch-test-label-changed 4874a6e3-fb37-4cb6-96ac-787a1ec6af63 137914 0 2021-02-22 06:15:14 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2021-02-22 06:15:14 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Feb 22 06:15:14.577: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2754 /api/v1/namespaces/watch-2754/configmaps/e2e-watch-test-label-changed 4874a6e3-fb37-4cb6-96ac-787a1ec6af63 137915 0 2021-02-22 06:15:14 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2021-02-22 06:15:14 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Feb 22 06:15:14.580: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2754 /api/v1/namespaces/watch-2754/configmaps/e2e-watch-test-label-changed 4874a6e3-fb37-4cb6-96ac-787a1ec6af63 137916 0 2021-02-22 06:15:14 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2021-02-22 06:15:14 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Feb 22 06:15:24.737: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2754 /api/v1/namespaces/watch-2754/configmaps/e2e-watch-test-label-changed 4874a6e3-fb37-4cb6-96ac-787a1ec6af63 138037 0 2021-02-22 06:15:14 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2021-02-22 06:15:24 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Feb 22 06:15:24.738: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2754 /api/v1/namespaces/watch-2754/configmaps/e2e-watch-test-label-changed 4874a6e3-fb37-4cb6-96ac-787a1ec6af63 138038 0 2021-02-22 06:15:14 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2021-02-22 06:15:24 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
Feb 22 06:15:24.738: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2754 /api/v1/namespaces/watch-2754/configmaps/e2e-watch-test-label-changed 4874a6e3-fb37-4cb6-96ac-787a1ec6af63 138039 0 2021-02-22 06:15:14 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2021-02-22 06:15:24 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:15:24.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2754" for this suite.

â€¢ [SLOW TEST:10.592 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]","total":270,"completed":160,"skipped":2847,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:15:24.791: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-4889
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 22 06:15:25.942: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb 22 06:15:27.964: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571326, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571326, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571326, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571325, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:15:30.006: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571326, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571326, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571326, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571325, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:15:31.998: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571326, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571326, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571326, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571325, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:15:33.972: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571326, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571326, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571326, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571325, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:15:35.990: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571326, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571326, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571326, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571325, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:15:38.248: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571326, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571326, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571326, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571325, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:15:39.975: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571326, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571326, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571326, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571325, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:15:41.974: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571326, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571326, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571326, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571325, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:15:43.989: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571326, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571326, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571326, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571325, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:15:45.974: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571326, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571326, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571326, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571325, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:15:47.973: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571326, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571326, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571326, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571325, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:15:49.990: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571326, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571326, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571326, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571325, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:15:51.985: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571326, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571326, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571326, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571325, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 22 06:15:55.053: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: fetching the /apis discovery document
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/admissionregistration.k8s.io discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:15:55.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4889" for this suite.
STEP: Destroying namespace "webhook-4889-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

â€¢ [SLOW TEST:30.764 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]","total":270,"completed":161,"skipped":2872,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:15:55.568: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-7691
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicationController
STEP: Ensuring resource quota status captures replication controller creation
STEP: Deleting a ReplicationController
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:16:07.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7691" for this suite.

â€¢ [SLOW TEST:11.796 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]","total":270,"completed":162,"skipped":2885,"failed":0}
SSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:16:07.365: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-9044
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Feb 22 06:16:07.666: INFO: Creating ReplicaSet my-hostname-basic-2199d819-a605-47bd-be3f-7b3978532c94
Feb 22 06:16:07.842: INFO: Pod name my-hostname-basic-2199d819-a605-47bd-be3f-7b3978532c94: Found 0 pods out of 1
Feb 22 06:16:12.853: INFO: Pod name my-hostname-basic-2199d819-a605-47bd-be3f-7b3978532c94: Found 1 pods out of 1
Feb 22 06:16:12.853: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-2199d819-a605-47bd-be3f-7b3978532c94" is running
Feb 22 06:16:34.879: INFO: Pod "my-hostname-basic-2199d819-a605-47bd-be3f-7b3978532c94-wjvmx" is running (conditions: [{Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2021-02-22 06:16:07 +0000 UTC Reason: Message:}])
Feb 22 06:16:34.880: INFO: Trying to dial the pod
Feb 22 06:16:39.942: INFO: Controller my-hostname-basic-2199d819-a605-47bd-be3f-7b3978532c94: Got expected result from replica 1 [my-hostname-basic-2199d819-a605-47bd-be3f-7b3978532c94-wjvmx]: "my-hostname-basic-2199d819-a605-47bd-be3f-7b3978532c94-wjvmx", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:16:39.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-9044" for this suite.

â€¢ [SLOW TEST:32.626 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet should serve a basic image on each replica with a public image  [Conformance]","total":270,"completed":163,"skipped":2888,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:16:40.056: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-9132
STEP: Waiting for a default service account to be provisioned in namespace
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Feb 22 06:16:40.352: INFO: >>> kubeConfig: /root/.kube/config
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:16:41.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-9132" for this suite.
â€¢{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]","total":270,"completed":164,"skipped":2952,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:16:41.913: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6435
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward api env vars
Feb 22 06:16:42.358: INFO: Waiting up to 5m0s for pod "downward-api-c09cd057-b6aa-4e66-824a-89cacd858315" in namespace "downward-api-6435" to be "Succeeded or Failed"
Feb 22 06:16:42.393: INFO: Pod "downward-api-c09cd057-b6aa-4e66-824a-89cacd858315": Phase="Pending", Reason="", readiness=false. Elapsed: 34.443464ms
Feb 22 06:16:44.789: INFO: Pod "downward-api-c09cd057-b6aa-4e66-824a-89cacd858315": Phase="Pending", Reason="", readiness=false. Elapsed: 2.430563912s
Feb 22 06:16:46.818: INFO: Pod "downward-api-c09cd057-b6aa-4e66-824a-89cacd858315": Phase="Pending", Reason="", readiness=false. Elapsed: 4.459894691s
Feb 22 06:16:49.223: INFO: Pod "downward-api-c09cd057-b6aa-4e66-824a-89cacd858315": Phase="Pending", Reason="", readiness=false. Elapsed: 6.865116991s
Feb 22 06:16:51.270: INFO: Pod "downward-api-c09cd057-b6aa-4e66-824a-89cacd858315": Phase="Pending", Reason="", readiness=false. Elapsed: 8.911986868s
Feb 22 06:16:53.292: INFO: Pod "downward-api-c09cd057-b6aa-4e66-824a-89cacd858315": Phase="Pending", Reason="", readiness=false. Elapsed: 10.933879484s
Feb 22 06:16:55.302: INFO: Pod "downward-api-c09cd057-b6aa-4e66-824a-89cacd858315": Phase="Pending", Reason="", readiness=false. Elapsed: 12.943314976s
Feb 22 06:16:57.309: INFO: Pod "downward-api-c09cd057-b6aa-4e66-824a-89cacd858315": Phase="Pending", Reason="", readiness=false. Elapsed: 14.951186237s
Feb 22 06:16:59.315: INFO: Pod "downward-api-c09cd057-b6aa-4e66-824a-89cacd858315": Phase="Pending", Reason="", readiness=false. Elapsed: 16.957111588s
Feb 22 06:17:01.322: INFO: Pod "downward-api-c09cd057-b6aa-4e66-824a-89cacd858315": Phase="Pending", Reason="", readiness=false. Elapsed: 18.963501641s
Feb 22 06:17:03.329: INFO: Pod "downward-api-c09cd057-b6aa-4e66-824a-89cacd858315": Phase="Pending", Reason="", readiness=false. Elapsed: 20.970516392s
Feb 22 06:17:05.350: INFO: Pod "downward-api-c09cd057-b6aa-4e66-824a-89cacd858315": Phase="Pending", Reason="", readiness=false. Elapsed: 22.991788294s
Feb 22 06:17:07.360: INFO: Pod "downward-api-c09cd057-b6aa-4e66-824a-89cacd858315": Phase="Pending", Reason="", readiness=false. Elapsed: 25.001678701s
Feb 22 06:17:09.398: INFO: Pod "downward-api-c09cd057-b6aa-4e66-824a-89cacd858315": Phase="Pending", Reason="", readiness=false. Elapsed: 27.040143596s
Feb 22 06:17:11.411: INFO: Pod "downward-api-c09cd057-b6aa-4e66-824a-89cacd858315": Phase="Succeeded", Reason="", readiness=false. Elapsed: 29.052306893s
STEP: Saw pod success
Feb 22 06:17:11.411: INFO: Pod "downward-api-c09cd057-b6aa-4e66-824a-89cacd858315" satisfied condition "Succeeded or Failed"
Feb 22 06:17:11.420: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com pod downward-api-c09cd057-b6aa-4e66-824a-89cacd858315 container dapi-container: <nil>
STEP: delete the pod
Feb 22 06:17:17.878: INFO: Waiting for pod downward-api-c09cd057-b6aa-4e66-824a-89cacd858315 to disappear
Feb 22 06:17:17.905: INFO: Pod downward-api-c09cd057-b6aa-4e66-824a-89cacd858315 still exists
Feb 22 06:17:19.905: INFO: Waiting for pod downward-api-c09cd057-b6aa-4e66-824a-89cacd858315 to disappear
Feb 22 06:17:19.915: INFO: Pod downward-api-c09cd057-b6aa-4e66-824a-89cacd858315 still exists
Feb 22 06:17:21.905: INFO: Waiting for pod downward-api-c09cd057-b6aa-4e66-824a-89cacd858315 to disappear
Feb 22 06:17:21.913: INFO: Pod downward-api-c09cd057-b6aa-4e66-824a-89cacd858315 still exists
Feb 22 06:17:23.905: INFO: Waiting for pod downward-api-c09cd057-b6aa-4e66-824a-89cacd858315 to disappear
Feb 22 06:17:23.912: INFO: Pod downward-api-c09cd057-b6aa-4e66-824a-89cacd858315 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:17:23.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6435" for this suite.

â€¢ [SLOW TEST:42.033 seconds]
[sig-node] Downward API
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:34
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]","total":270,"completed":165,"skipped":3031,"failed":0}
SSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:17:23.946: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-819
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Feb 22 06:17:24.255: INFO: >>> kubeConfig: /root/.kube/config
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:17:56.504: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-819" for this suite.

â€¢ [SLOW TEST:32.618 seconds]
[k8s.io] Pods
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Pods should support remote command execution over websockets [NodeConformance] [Conformance]","total":270,"completed":166,"skipped":3034,"failed":0}
SSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:17:56.566: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-4943
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Feb 22 06:18:25.569: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:18:25.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-4943" for this suite.

â€¢ [SLOW TEST:29.154 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  blackbox test
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:40
    on terminated container
    /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:133
      should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":270,"completed":167,"skipped":3041,"failed":0}
SSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:18:25.721: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-1405
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod test-webserver-8efdaaee-52b7-4b76-8b0b-8a35b3744eee in namespace container-probe-1405
Feb 22 06:18:52.252: INFO: Started pod test-webserver-8efdaaee-52b7-4b76-8b0b-8a35b3744eee in namespace container-probe-1405
STEP: checking the pod's current state and verifying that restartCount is present
Feb 22 06:18:52.266: INFO: Initial restart count of pod test-webserver-8efdaaee-52b7-4b76-8b0b-8a35b3744eee is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:22:54.100: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1405" for this suite.

â€¢ [SLOW TEST:268.547 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","total":270,"completed":168,"skipped":3046,"failed":0}
SSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:22:54.286: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-2562
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 22 06:22:55.930: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Feb 22 06:22:57.988: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571776, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571776, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571776, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571775, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:23:00.028: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571776, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571776, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571776, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571775, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:23:02.030: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571776, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571776, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571776, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571775, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:23:04.001: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571776, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571776, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571776, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571775, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:23:06.412: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571776, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571776, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571776, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571775, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:23:10.002: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571776, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571776, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571776, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571775, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:23:12.198: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571776, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571776, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571776, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571775, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:23:14.026: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571776, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571776, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571776, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571775, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:23:16.013: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571776, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571776, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571776, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571775, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:23:18.016: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571776, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571776, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571776, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571775, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:23:20.007: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571776, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571776, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571776, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571775, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:23:22.013: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571776, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571776, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571776, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571775, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:23:23.999: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571776, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571776, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571776, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571775, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:23:25.999: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571776, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571776, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571776, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571775, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:23:28.000: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571776, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571776, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571776, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571775, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:23:29.999: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571776, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571776, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571776, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749571775, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 22 06:23:33.156: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a validating webhook configuration
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Updating a validating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Patching a validating webhook configuration's rules to include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:23:33.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2562" for this suite.
STEP: Destroying namespace "webhook-2562-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

â€¢ [SLOW TEST:39.960 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]","total":270,"completed":169,"skipped":3055,"failed":0}
SSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:23:34.253: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-6838
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:74
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Feb 22 06:23:34.741: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Feb 22 06:23:39.788: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 22 06:24:01.852: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
Feb 22 06:24:34.059: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-6838 /apis/apps/v1/namespaces/deployment-6838/deployments/test-cleanup-deployment d261202c-72ec-4b3c-92bc-800e5858b2ad 143861 1 2021-02-22 06:24:01 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[deployment.kubernetes.io/revision:1] [] []  [{e2e.test Update apps/v1 2021-02-22 06:24:01 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 112 114 111 103 114 101 115 115 68 101 97 100 108 105 110 101 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 118 105 115 105 111 110 72 105 115 116 111 114 121 76 105 109 105 116 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 116 114 97 116 101 103 121 34 58 123 34 102 58 114 111 108 108 105 110 103 85 112 100 97 116 101 34 58 123 34 46 34 58 123 125 44 34 102 58 109 97 120 83 117 114 103 101 34 58 123 125 44 34 102 58 109 97 120 85 110 97 118 97 105 108 97 98 108 101 34 58 123 125 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2021-02-22 06:24:32 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 65 118 97 105 108 97 98 108 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 80 114 111 103 114 101 115 115 105 110 103 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 112 100 97 116 101 100 82 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc006673d48 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2021-02-22 06:24:02 +0000 UTC,LastTransitionTime:2021-02-22 06:24:02 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-cleanup-deployment-b4867b47f" has successfully progressed.,LastUpdateTime:2021-02-22 06:24:32 +0000 UTC,LastTransitionTime:2021-02-22 06:24:02 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Feb 22 06:24:34.091: INFO: New ReplicaSet "test-cleanup-deployment-b4867b47f" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:{test-cleanup-deployment-b4867b47f  deployment-6838 /apis/apps/v1/namespaces/deployment-6838/replicasets/test-cleanup-deployment-b4867b47f d6af8dc9-0c80-495d-8bbb-9f745f6b3cdb 143849 1 2021-02-22 06:24:01 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:b4867b47f] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment d261202c-72ec-4b3c-92bc-800e5858b2ad 0xc00432e1e0 0xc00432e1e1}] []  [{kube-controller-manager Update apps/v1 2021-02-22 06:24:31 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 100 50 54 49 50 48 50 99 45 55 50 101 99 45 52 98 51 99 45 57 50 98 99 45 56 48 48 101 53 56 53 56 98 50 97 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: b4867b47f,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:b4867b47f] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00432e258 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Feb 22 06:24:34.124: INFO: Pod "test-cleanup-deployment-b4867b47f-rjg4j" is available:
&Pod{ObjectMeta:{test-cleanup-deployment-b4867b47f-rjg4j test-cleanup-deployment-b4867b47f- deployment-6838 /api/v1/namespaces/deployment-6838/pods/test-cleanup-deployment-b4867b47f-rjg4j ce0aa415-51be-4075-9c63-4481eeee9140 143846 0 2021-02-22 06:24:02 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:b4867b47f] map[attachment_id:9a7892b9-3946-4e12-82ba-9e8fcf793096 kubernetes.io/psp:e2e-test-privileged-psp mac:04:50:56:00:28:0d vlan:None vmware-system-ephemeral-disk-uuid:6000C29c-594e-3877-7e50-c293fa905240 vmware-system-image-references:{"agnhost":"agnhost-4c5d323a799f707178acf281f8da2d9a581ad331-v12206"} vmware-system-vm-moid:vm-667:6b180790-afb7-40a7-b1c1-16f00c9b6783 vmware-system-vm-uuid:502f2967-966a-e22a-62cf-e3bdf8ea0b02] [{apps/v1 ReplicaSet test-cleanup-deployment-b4867b47f d6af8dc9-0c80-495d-8bbb-9f745f6b3cdb 0xc004089127 0xc004089128}] [lifecycle-controller/system.vmware.com]  [{image-controller Update v1 2021-02-22 06:24:02 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 105 109 97 103 101 45 114 101 102 101 114 101 110 99 101 115 34 58 123 125 125 125 125],}} {kube-controller-manager Update v1 2021-02-22 06:24:02 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 100 54 97 102 56 100 99 57 45 48 99 56 48 45 52 57 53 100 45 56 98 98 98 45 57 102 55 52 53 102 54 98 51 99 100 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {nsx-ncp-75bf644549-ps9h2 Update v1 2021-02-22 06:24:03 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 97 116 116 97 99 104 109 101 110 116 95 105 100 34 58 123 125 44 34 102 58 109 97 99 34 58 123 125 44 34 102 58 118 108 97 110 34 58 123 125 125 125 125],}} {scheduler-extender Update v1 2021-02-22 06:24:23 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 101 112 104 101 109 101 114 97 108 45 100 105 115 107 45 117 117 105 100 34 58 123 125 44 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 118 109 45 109 111 105 100 34 58 123 125 44 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 118 109 45 117 117 105 100 34 58 123 125 125 44 34 102 58 102 105 110 97 108 105 122 101 114 115 34 58 123 34 46 34 58 123 125 44 34 118 58 92 34 108 105 102 101 99 121 99 108 101 45 99 111 110 116 114 111 108 108 101 114 47 115 121 115 116 101 109 46 118 109 119 97 114 101 46 99 111 109 92 34 34 58 123 125 125 125 125],}} {spherelet Update v1 2021-02-22 06:24:31 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 102 58 101 110 118 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 95 52 52 51 95 84 67 80 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 95 52 52 51 95 84 67 80 95 65 68 68 82 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 95 52 52 51 95 84 67 80 95 80 79 82 84 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 95 52 52 51 95 84 67 80 95 80 82 79 84 79 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 83 69 82 86 73 67 69 95 72 79 83 84 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 83 69 82 86 73 67 69 95 80 79 82 84 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 83 69 82 86 73 67 69 95 80 79 82 84 95 72 84 84 80 83 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 55 50 46 50 54 46 49 46 50 50 55 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-tnjp7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-tnjp7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-tnjp7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:sc2-rdops-vm05-dhcp-174-51.eng.vmware.com,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 06:24:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 06:24:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 06:24:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 06:24:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.192.174.51,PodIP:172.26.1.227,StartTime:2021-02-22 06:24:30 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2021-02-22 06:24:32 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,ImageID:agnhost-4c5d323a799f707178acf281f8da2d9a581ad331-v12206,ContainerID:da39e605-38f3-4056-9517-4f7698d96670,Started:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.26.1.227,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:24:34.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6838" for this suite.

â€¢ [SLOW TEST:59.917 seconds]
[sig-apps] Deployment
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should delete old replica sets [Conformance]","total":270,"completed":170,"skipped":3060,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:24:34.209: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-2759
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod pod-subpath-test-configmap-vhkb
STEP: Creating a pod to test atomic-volume-subpath
Feb 22 06:24:34.641: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-vhkb" in namespace "subpath-2759" to be "Succeeded or Failed"
Feb 22 06:24:34.668: INFO: Pod "pod-subpath-test-configmap-vhkb": Phase="Pending", Reason="", readiness=false. Elapsed: 25.827346ms
Feb 22 06:24:36.677: INFO: Pod "pod-subpath-test-configmap-vhkb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035130537s
Feb 22 06:24:38.692: INFO: Pod "pod-subpath-test-configmap-vhkb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.050488656s
Feb 22 06:24:40.857: INFO: Pod "pod-subpath-test-configmap-vhkb": Phase="Pending", Reason="", readiness=false. Elapsed: 6.214862564s
Feb 22 06:24:42.881: INFO: Pod "pod-subpath-test-configmap-vhkb": Phase="Pending", Reason="", readiness=false. Elapsed: 8.238954052s
Feb 22 06:24:44.934: INFO: Pod "pod-subpath-test-configmap-vhkb": Phase="Pending", Reason="", readiness=false. Elapsed: 10.292028805s
Feb 22 06:24:46.951: INFO: Pod "pod-subpath-test-configmap-vhkb": Phase="Pending", Reason="", readiness=false. Elapsed: 12.309493286s
Feb 22 06:24:48.961: INFO: Pod "pod-subpath-test-configmap-vhkb": Phase="Pending", Reason="", readiness=false. Elapsed: 14.319284804s
Feb 22 06:24:50.971: INFO: Pod "pod-subpath-test-configmap-vhkb": Phase="Pending", Reason="", readiness=false. Elapsed: 16.329403244s
Feb 22 06:24:52.984: INFO: Pod "pod-subpath-test-configmap-vhkb": Phase="Pending", Reason="", readiness=false. Elapsed: 18.342519529s
Feb 22 06:24:54.996: INFO: Pod "pod-subpath-test-configmap-vhkb": Phase="Pending", Reason="", readiness=false. Elapsed: 20.353988963s
Feb 22 06:24:57.016: INFO: Pod "pod-subpath-test-configmap-vhkb": Phase="Pending", Reason="", readiness=false. Elapsed: 22.374033492s
Feb 22 06:24:59.022: INFO: Pod "pod-subpath-test-configmap-vhkb": Phase="Pending", Reason="", readiness=false. Elapsed: 24.380351045s
Feb 22 06:25:01.039: INFO: Pod "pod-subpath-test-configmap-vhkb": Phase="Running", Reason="", readiness=true. Elapsed: 26.396581028s
Feb 22 06:25:03.080: INFO: Pod "pod-subpath-test-configmap-vhkb": Phase="Running", Reason="", readiness=true. Elapsed: 28.437833858s
Feb 22 06:25:05.133: INFO: Pod "pod-subpath-test-configmap-vhkb": Phase="Running", Reason="", readiness=true. Elapsed: 30.491518836s
Feb 22 06:25:07.153: INFO: Pod "pod-subpath-test-configmap-vhkb": Phase="Running", Reason="", readiness=true. Elapsed: 32.511430366s
Feb 22 06:25:09.180: INFO: Pod "pod-subpath-test-configmap-vhkb": Phase="Running", Reason="", readiness=true. Elapsed: 34.537981194s
Feb 22 06:25:11.190: INFO: Pod "pod-subpath-test-configmap-vhkb": Phase="Running", Reason="", readiness=true. Elapsed: 36.547840476s
Feb 22 06:25:13.201: INFO: Pod "pod-subpath-test-configmap-vhkb": Phase="Running", Reason="", readiness=true. Elapsed: 38.55945914s
Feb 22 06:25:15.218: INFO: Pod "pod-subpath-test-configmap-vhkb": Phase="Running", Reason="", readiness=true. Elapsed: 40.576108659s
Feb 22 06:25:17.236: INFO: Pod "pod-subpath-test-configmap-vhkb": Phase="Running", Reason="", readiness=true. Elapsed: 42.594506102s
Feb 22 06:25:19.249: INFO: Pod "pod-subpath-test-configmap-vhkb": Phase="Running", Reason="", readiness=true. Elapsed: 44.606856675s
Feb 22 06:25:21.261: INFO: Pod "pod-subpath-test-configmap-vhkb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 46.618700059s
STEP: Saw pod success
Feb 22 06:25:21.262: INFO: Pod "pod-subpath-test-configmap-vhkb" satisfied condition "Succeeded or Failed"
Feb 22 06:25:21.270: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com pod pod-subpath-test-configmap-vhkb container test-container-subpath-configmap-vhkb: <nil>
STEP: delete the pod
Feb 22 06:25:21.389: INFO: Waiting for pod pod-subpath-test-configmap-vhkb to disappear
Feb 22 06:25:21.408: INFO: Pod pod-subpath-test-configmap-vhkb still exists
Feb 22 06:25:23.409: INFO: Waiting for pod pod-subpath-test-configmap-vhkb to disappear
Feb 22 06:25:23.421: INFO: Pod pod-subpath-test-configmap-vhkb still exists
Feb 22 06:25:25.409: INFO: Waiting for pod pod-subpath-test-configmap-vhkb to disappear
Feb 22 06:25:25.428: INFO: Pod pod-subpath-test-configmap-vhkb still exists
Feb 22 06:25:27.409: INFO: Waiting for pod pod-subpath-test-configmap-vhkb to disappear
Feb 22 06:25:27.429: INFO: Pod pod-subpath-test-configmap-vhkb still exists
Feb 22 06:25:29.409: INFO: Waiting for pod pod-subpath-test-configmap-vhkb to disappear
Feb 22 06:25:29.432: INFO: Pod pod-subpath-test-configmap-vhkb still exists
Feb 22 06:25:31.409: INFO: Waiting for pod pod-subpath-test-configmap-vhkb to disappear
Feb 22 06:25:31.418: INFO: Pod pod-subpath-test-configmap-vhkb still exists
Feb 22 06:25:33.409: INFO: Waiting for pod pod-subpath-test-configmap-vhkb to disappear
Feb 22 06:25:33.462: INFO: Pod pod-subpath-test-configmap-vhkb still exists
Feb 22 06:25:35.409: INFO: Waiting for pod pod-subpath-test-configmap-vhkb to disappear
Feb 22 06:25:35.422: INFO: Pod pod-subpath-test-configmap-vhkb still exists
Feb 22 06:25:37.409: INFO: Waiting for pod pod-subpath-test-configmap-vhkb to disappear
Feb 22 06:25:37.420: INFO: Pod pod-subpath-test-configmap-vhkb still exists
Feb 22 06:25:39.409: INFO: Waiting for pod pod-subpath-test-configmap-vhkb to disappear
Feb 22 06:25:39.420: INFO: Pod pod-subpath-test-configmap-vhkb still exists
Feb 22 06:25:41.409: INFO: Waiting for pod pod-subpath-test-configmap-vhkb to disappear
Feb 22 06:25:41.417: INFO: Pod pod-subpath-test-configmap-vhkb no longer exists
STEP: Deleting pod pod-subpath-test-configmap-vhkb
Feb 22 06:25:41.419: INFO: Deleting pod "pod-subpath-test-configmap-vhkb" in namespace "subpath-2759"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:25:41.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2759" for this suite.

â€¢ [SLOW TEST:67.343 seconds]
[sig-storage] Subpath
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]","total":270,"completed":171,"skipped":3091,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:25:41.557: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7686
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Feb 22 06:25:42.059: INFO: Waiting up to 5m0s for pod "downwardapi-volume-96e8581b-d5ae-4aa5-afa4-eb4a4e3c521d" in namespace "downward-api-7686" to be "Succeeded or Failed"
Feb 22 06:25:42.089: INFO: Pod "downwardapi-volume-96e8581b-d5ae-4aa5-afa4-eb4a4e3c521d": Phase="Pending", Reason="", readiness=false. Elapsed: 28.780974ms
Feb 22 06:25:44.100: INFO: Pod "downwardapi-volume-96e8581b-d5ae-4aa5-afa4-eb4a4e3c521d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040069179s
Feb 22 06:25:46.113: INFO: Pod "downwardapi-volume-96e8581b-d5ae-4aa5-afa4-eb4a4e3c521d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.053200445s
Feb 22 06:25:48.123: INFO: Pod "downwardapi-volume-96e8581b-d5ae-4aa5-afa4-eb4a4e3c521d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.063213989s
Feb 22 06:25:50.134: INFO: Pod "downwardapi-volume-96e8581b-d5ae-4aa5-afa4-eb4a4e3c521d": Phase="Pending", Reason="", readiness=false. Elapsed: 8.07468633s
Feb 22 06:25:52.165: INFO: Pod "downwardapi-volume-96e8581b-d5ae-4aa5-afa4-eb4a4e3c521d": Phase="Pending", Reason="", readiness=false. Elapsed: 10.104870539s
Feb 22 06:25:54.189: INFO: Pod "downwardapi-volume-96e8581b-d5ae-4aa5-afa4-eb4a4e3c521d": Phase="Pending", Reason="", readiness=false. Elapsed: 12.129247726s
Feb 22 06:25:56.197: INFO: Pod "downwardapi-volume-96e8581b-d5ae-4aa5-afa4-eb4a4e3c521d": Phase="Pending", Reason="", readiness=false. Elapsed: 14.136811935s
Feb 22 06:25:58.209: INFO: Pod "downwardapi-volume-96e8581b-d5ae-4aa5-afa4-eb4a4e3c521d": Phase="Pending", Reason="", readiness=false. Elapsed: 16.148903505s
Feb 22 06:26:00.222: INFO: Pod "downwardapi-volume-96e8581b-d5ae-4aa5-afa4-eb4a4e3c521d": Phase="Pending", Reason="", readiness=false. Elapsed: 18.162296702s
Feb 22 06:26:02.236: INFO: Pod "downwardapi-volume-96e8581b-d5ae-4aa5-afa4-eb4a4e3c521d": Phase="Pending", Reason="", readiness=false. Elapsed: 20.176769005s
Feb 22 06:26:04.252: INFO: Pod "downwardapi-volume-96e8581b-d5ae-4aa5-afa4-eb4a4e3c521d": Phase="Pending", Reason="", readiness=false. Elapsed: 22.192755071s
Feb 22 06:26:06.500: INFO: Pod "downwardapi-volume-96e8581b-d5ae-4aa5-afa4-eb4a4e3c521d": Phase="Pending", Reason="", readiness=false. Elapsed: 24.440701578s
Feb 22 06:26:09.409: INFO: Pod "downwardapi-volume-96e8581b-d5ae-4aa5-afa4-eb4a4e3c521d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 27.348933003s
STEP: Saw pod success
Feb 22 06:26:09.419: INFO: Pod "downwardapi-volume-96e8581b-d5ae-4aa5-afa4-eb4a4e3c521d" satisfied condition "Succeeded or Failed"
Feb 22 06:26:10.099: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com pod downwardapi-volume-96e8581b-d5ae-4aa5-afa4-eb4a4e3c521d container client-container: <nil>
STEP: delete the pod
Feb 22 06:26:18.392: INFO: Waiting for pod downwardapi-volume-96e8581b-d5ae-4aa5-afa4-eb4a4e3c521d to disappear
Feb 22 06:26:18.448: INFO: Pod downwardapi-volume-96e8581b-d5ae-4aa5-afa4-eb4a4e3c521d still exists
Feb 22 06:26:20.449: INFO: Waiting for pod downwardapi-volume-96e8581b-d5ae-4aa5-afa4-eb4a4e3c521d to disappear
Feb 22 06:26:20.459: INFO: Pod downwardapi-volume-96e8581b-d5ae-4aa5-afa4-eb4a4e3c521d still exists
Feb 22 06:26:22.449: INFO: Waiting for pod downwardapi-volume-96e8581b-d5ae-4aa5-afa4-eb4a4e3c521d to disappear
Feb 22 06:26:22.457: INFO: Pod downwardapi-volume-96e8581b-d5ae-4aa5-afa4-eb4a4e3c521d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:26:22.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7686" for this suite.

â€¢ [SLOW TEST:40.972 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:37
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]","total":270,"completed":172,"skipped":3101,"failed":0}
SSSSSS
------------------------------
[k8s.io] Security Context when creating containers with AllowPrivilegeEscalation 
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:26:22.555: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-7443
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:41
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Feb 22 06:26:23.141: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-98951b1b-9525-4ab5-b4c4-f6eef3c73636" in namespace "security-context-test-7443" to be "Succeeded or Failed"
Feb 22 06:26:23.152: INFO: Pod "alpine-nnp-false-98951b1b-9525-4ab5-b4c4-f6eef3c73636": Phase="Pending", Reason="", readiness=false. Elapsed: 10.633636ms
Feb 22 06:26:25.165: INFO: Pod "alpine-nnp-false-98951b1b-9525-4ab5-b4c4-f6eef3c73636": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023678504s
Feb 22 06:26:27.176: INFO: Pod "alpine-nnp-false-98951b1b-9525-4ab5-b4c4-f6eef3c73636": Phase="Pending", Reason="", readiness=false. Elapsed: 4.034794021s
Feb 22 06:26:29.198: INFO: Pod "alpine-nnp-false-98951b1b-9525-4ab5-b4c4-f6eef3c73636": Phase="Pending", Reason="", readiness=false. Elapsed: 6.056271543s
Feb 22 06:26:31.206: INFO: Pod "alpine-nnp-false-98951b1b-9525-4ab5-b4c4-f6eef3c73636": Phase="Pending", Reason="", readiness=false. Elapsed: 8.06428125s
Feb 22 06:26:33.219: INFO: Pod "alpine-nnp-false-98951b1b-9525-4ab5-b4c4-f6eef3c73636": Phase="Pending", Reason="", readiness=false. Elapsed: 10.077266647s
Feb 22 06:26:35.229: INFO: Pod "alpine-nnp-false-98951b1b-9525-4ab5-b4c4-f6eef3c73636": Phase="Pending", Reason="", readiness=false. Elapsed: 12.087252894s
Feb 22 06:26:37.239: INFO: Pod "alpine-nnp-false-98951b1b-9525-4ab5-b4c4-f6eef3c73636": Phase="Pending", Reason="", readiness=false. Elapsed: 14.097200263s
Feb 22 06:26:39.265: INFO: Pod "alpine-nnp-false-98951b1b-9525-4ab5-b4c4-f6eef3c73636": Phase="Pending", Reason="", readiness=false. Elapsed: 16.123422877s
Feb 22 06:26:41.279: INFO: Pod "alpine-nnp-false-98951b1b-9525-4ab5-b4c4-f6eef3c73636": Phase="Pending", Reason="", readiness=false. Elapsed: 18.137752796s
Feb 22 06:26:43.288: INFO: Pod "alpine-nnp-false-98951b1b-9525-4ab5-b4c4-f6eef3c73636": Phase="Pending", Reason="", readiness=false. Elapsed: 20.146701041s
Feb 22 06:26:45.327: INFO: Pod "alpine-nnp-false-98951b1b-9525-4ab5-b4c4-f6eef3c73636": Phase="Pending", Reason="", readiness=false. Elapsed: 22.18598946s
Feb 22 06:26:47.338: INFO: Pod "alpine-nnp-false-98951b1b-9525-4ab5-b4c4-f6eef3c73636": Phase="Pending", Reason="", readiness=false. Elapsed: 24.196648987s
Feb 22 06:26:49.345: INFO: Pod "alpine-nnp-false-98951b1b-9525-4ab5-b4c4-f6eef3c73636": Phase="Pending", Reason="", readiness=false. Elapsed: 26.20368725s
Feb 22 06:26:51.364: INFO: Pod "alpine-nnp-false-98951b1b-9525-4ab5-b4c4-f6eef3c73636": Phase="Pending", Reason="", readiness=false. Elapsed: 28.222871998s
Feb 22 06:26:53.372: INFO: Pod "alpine-nnp-false-98951b1b-9525-4ab5-b4c4-f6eef3c73636": Phase="Pending", Reason="", readiness=false. Elapsed: 30.230695369s
Feb 22 06:26:55.396: INFO: Pod "alpine-nnp-false-98951b1b-9525-4ab5-b4c4-f6eef3c73636": Phase="Pending", Reason="", readiness=false. Elapsed: 32.254522523s
Feb 22 06:26:57.444: INFO: Pod "alpine-nnp-false-98951b1b-9525-4ab5-b4c4-f6eef3c73636": Phase="Pending", Reason="", readiness=false. Elapsed: 34.30253473s
Feb 22 06:26:59.454: INFO: Pod "alpine-nnp-false-98951b1b-9525-4ab5-b4c4-f6eef3c73636": Phase="Pending", Reason="", readiness=false. Elapsed: 36.312218056s
Feb 22 06:27:01.486: INFO: Pod "alpine-nnp-false-98951b1b-9525-4ab5-b4c4-f6eef3c73636": Phase="Pending", Reason="", readiness=false. Elapsed: 38.344926403s
Feb 22 06:27:03.633: INFO: Pod "alpine-nnp-false-98951b1b-9525-4ab5-b4c4-f6eef3c73636": Phase="Pending", Reason="", readiness=false. Elapsed: 40.491901356s
Feb 22 06:27:05.687: INFO: Pod "alpine-nnp-false-98951b1b-9525-4ab5-b4c4-f6eef3c73636": Phase="Pending", Reason="", readiness=false. Elapsed: 42.545459825s
Feb 22 06:27:07.793: INFO: Pod "alpine-nnp-false-98951b1b-9525-4ab5-b4c4-f6eef3c73636": Phase="Pending", Reason="", readiness=false. Elapsed: 44.651992067s
Feb 22 06:27:09.811: INFO: Pod "alpine-nnp-false-98951b1b-9525-4ab5-b4c4-f6eef3c73636": Phase="Pending", Reason="", readiness=false. Elapsed: 46.669236209s
Feb 22 06:27:11.849: INFO: Pod "alpine-nnp-false-98951b1b-9525-4ab5-b4c4-f6eef3c73636": Phase="Pending", Reason="", readiness=false. Elapsed: 48.707143441s
Feb 22 06:27:13.862: INFO: Pod "alpine-nnp-false-98951b1b-9525-4ab5-b4c4-f6eef3c73636": Phase="Pending", Reason="", readiness=false. Elapsed: 50.720776458s
Feb 22 06:27:15.879: INFO: Pod "alpine-nnp-false-98951b1b-9525-4ab5-b4c4-f6eef3c73636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 52.7379196s
Feb 22 06:27:15.880: INFO: Pod "alpine-nnp-false-98951b1b-9525-4ab5-b4c4-f6eef3c73636" satisfied condition "Succeeded or Failed"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:27:22.070: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-7443" for this suite.

â€¢ [SLOW TEST:59.596 seconds]
[k8s.io] Security Context
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  when creating containers with AllowPrivilegeEscalation
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:291
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]","total":270,"completed":173,"skipped":3107,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:27:22.171: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-1711
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-4638
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-3173
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:28:23.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-1711" for this suite.
STEP: Destroying namespace "nsdeletetest-4638" for this suite.
Feb 22 06:28:23.285: INFO: Namespace nsdeletetest-4638 was already deleted
STEP: Destroying namespace "nsdeletetest-3173" for this suite.

â€¢ [SLOW TEST:61.141 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]","total":270,"completed":174,"skipped":3118,"failed":0}
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should deny crd creation [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:28:23.314: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3277
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 22 06:28:24.251: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb 22 06:28:26.278: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572104, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572104, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572104, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572104, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:28:28.316: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572104, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572104, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572104, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572104, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:28:30.295: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572104, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572104, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572104, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572104, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:28:32.307: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572104, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572104, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572104, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572104, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:28:34.287: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572104, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572104, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572104, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572104, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:28:36.290: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572104, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572104, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572104, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572104, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:28:38.301: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572104, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572104, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572104, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572104, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:28:40.286: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572104, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572104, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572104, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572104, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:28:42.310: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572104, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572104, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572104, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572104, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:28:44.753: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572104, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572104, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572104, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572104, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:28:46.288: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572104, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572104, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572104, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572104, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:28:48.295: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572104, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572104, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572104, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572104, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:28:50.349: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572104, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572104, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572104, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572104, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 22 06:28:53.429: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the crd webhook via the AdmissionRegistration API
STEP: Creating a custom resource definition that should be denied by the webhook
Feb 22 06:28:53.667: INFO: >>> kubeConfig: /root/.kube/config
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:28:53.837: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3277" for this suite.
STEP: Destroying namespace "webhook-3277-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

â€¢ [SLOW TEST:31.182 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]","total":270,"completed":175,"skipped":3118,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:28:54.580: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-584
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Starting the proxy
Feb 22 06:28:54.973: INFO: Asynchronously running '/usr/bin/kubectl kubectl --kubeconfig=/root/.kube/config proxy --unix-socket=/tmp/kubectl-proxy-unix344524345/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:28:55.234: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-584" for this suite.
â€¢{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support --unix-socket=/path  [Conformance]","total":270,"completed":176,"skipped":3140,"failed":0}
SSS
------------------------------
[sig-cli] Kubectl client Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:28:55.305: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9568
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating all guestbook components
Feb 22 06:28:56.237: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-slave
  labels:
    app: agnhost
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: agnhost
    role: slave
    tier: backend

Feb 22 06:28:56.238: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config create -f - --namespace=kubectl-9568'
Feb 22 06:29:01.005: INFO: stderr: ""
Feb 22 06:29:01.016: INFO: stdout: "service/agnhost-slave created\n"
Feb 22 06:29:01.040: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-master
  labels:
    app: agnhost
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: agnhost
    role: master
    tier: backend

Feb 22 06:29:01.052: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config create -f - --namespace=kubectl-9568'
Feb 22 06:29:05.107: INFO: stderr: ""
Feb 22 06:29:05.107: INFO: stdout: "service/agnhost-master created\n"
Feb 22 06:29:05.111: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Feb 22 06:29:05.111: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config create -f - --namespace=kubectl-9568'
Feb 22 06:29:06.569: INFO: stderr: ""
Feb 22 06:29:06.569: INFO: stdout: "service/frontend created\n"
Feb 22 06:29:06.579: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: guestbook-frontend
        image: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12
        args: [ "guestbook", "--backend-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 80

Feb 22 06:29:06.581: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config create -f - --namespace=kubectl-9568'
Feb 22 06:29:09.058: INFO: stderr: ""
Feb 22 06:29:09.058: INFO: stdout: "deployment.apps/frontend created\n"
Feb 22 06:29:09.061: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: agnhost
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12
        args: [ "guestbook", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Feb 22 06:29:09.061: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config create -f - --namespace=kubectl-9568'
Feb 22 06:29:10.635: INFO: stderr: ""
Feb 22 06:29:10.635: INFO: stdout: "deployment.apps/agnhost-master created\n"
Feb 22 06:29:10.637: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: agnhost
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12
        args: [ "guestbook", "--slaveof", "agnhost-master", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Feb 22 06:29:10.637: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config create -f - --namespace=kubectl-9568'
Feb 22 06:29:11.895: INFO: stderr: ""
Feb 22 06:29:11.895: INFO: stdout: "deployment.apps/agnhost-slave created\n"
STEP: validating guestbook app
Feb 22 06:29:11.896: INFO: Waiting for all frontend pods to be Running.
Feb 22 06:30:06.954: INFO: Waiting for frontend to serve content.
Feb 22 06:30:07.147: INFO: Trying to add a new entry to the guestbook.
Feb 22 06:30:07.385: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Feb 22 06:30:07.582: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config delete --grace-period=0 --force -f - --namespace=kubectl-9568'
Feb 22 06:30:08.156: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 22 06:30:08.156: INFO: stdout: "service \"agnhost-slave\" force deleted\n"
STEP: using delete to clean up resources
Feb 22 06:30:08.158: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config delete --grace-period=0 --force -f - --namespace=kubectl-9568'
Feb 22 06:30:08.942: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 22 06:30:08.942: INFO: stdout: "service \"agnhost-master\" force deleted\n"
STEP: using delete to clean up resources
Feb 22 06:30:08.942: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config delete --grace-period=0 --force -f - --namespace=kubectl-9568'
Feb 22 06:30:09.546: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 22 06:30:09.546: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Feb 22 06:30:09.547: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config delete --grace-period=0 --force -f - --namespace=kubectl-9568'
Feb 22 06:30:10.165: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 22 06:30:10.165: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Feb 22 06:30:10.165: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config delete --grace-period=0 --force -f - --namespace=kubectl-9568'
Feb 22 06:30:11.302: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 22 06:30:11.302: INFO: stdout: "deployment.apps \"agnhost-master\" force deleted\n"
STEP: using delete to clean up resources
Feb 22 06:30:11.302: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config delete --grace-period=0 --force -f - --namespace=kubectl-9568'
Feb 22 06:30:11.689: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 22 06:30:11.689: INFO: stdout: "deployment.apps \"agnhost-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:30:11.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9568" for this suite.

â€¢ [SLOW TEST:76.587 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Guestbook application
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:310
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Guestbook application should create and stop a working application  [Conformance]","total":270,"completed":177,"skipped":3143,"failed":0}
SSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:30:11.920: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-635
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test override all
Feb 22 06:30:12.756: INFO: Waiting up to 5m0s for pod "client-containers-8b588144-50e5-4d07-9a8d-16d715184faa" in namespace "containers-635" to be "Succeeded or Failed"
Feb 22 06:30:12.792: INFO: Pod "client-containers-8b588144-50e5-4d07-9a8d-16d715184faa": Phase="Pending", Reason="", readiness=false. Elapsed: 35.252299ms
Feb 22 06:30:14.804: INFO: Pod "client-containers-8b588144-50e5-4d07-9a8d-16d715184faa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.047851578s
Feb 22 06:30:16.812: INFO: Pod "client-containers-8b588144-50e5-4d07-9a8d-16d715184faa": Phase="Pending", Reason="", readiness=false. Elapsed: 4.055406374s
Feb 22 06:30:18.831: INFO: Pod "client-containers-8b588144-50e5-4d07-9a8d-16d715184faa": Phase="Pending", Reason="", readiness=false. Elapsed: 6.074533384s
Feb 22 06:30:20.841: INFO: Pod "client-containers-8b588144-50e5-4d07-9a8d-16d715184faa": Phase="Pending", Reason="", readiness=false. Elapsed: 8.085116604s
Feb 22 06:30:22.864: INFO: Pod "client-containers-8b588144-50e5-4d07-9a8d-16d715184faa": Phase="Pending", Reason="", readiness=false. Elapsed: 10.107178967s
Feb 22 06:30:24.873: INFO: Pod "client-containers-8b588144-50e5-4d07-9a8d-16d715184faa": Phase="Pending", Reason="", readiness=false. Elapsed: 12.116943759s
Feb 22 06:30:26.885: INFO: Pod "client-containers-8b588144-50e5-4d07-9a8d-16d715184faa": Phase="Pending", Reason="", readiness=false. Elapsed: 14.128193559s
Feb 22 06:30:29.701: INFO: Pod "client-containers-8b588144-50e5-4d07-9a8d-16d715184faa": Phase="Pending", Reason="", readiness=false. Elapsed: 16.944177979s
Feb 22 06:30:31.867: INFO: Pod "client-containers-8b588144-50e5-4d07-9a8d-16d715184faa": Phase="Pending", Reason="", readiness=false. Elapsed: 19.111015968s
Feb 22 06:30:33.944: INFO: Pod "client-containers-8b588144-50e5-4d07-9a8d-16d715184faa": Phase="Pending", Reason="", readiness=false. Elapsed: 21.187778435s
Feb 22 06:30:35.961: INFO: Pod "client-containers-8b588144-50e5-4d07-9a8d-16d715184faa": Phase="Pending", Reason="", readiness=false. Elapsed: 23.20466435s
Feb 22 06:30:37.983: INFO: Pod "client-containers-8b588144-50e5-4d07-9a8d-16d715184faa": Phase="Pending", Reason="", readiness=false. Elapsed: 25.226320199s
Feb 22 06:30:40.000: INFO: Pod "client-containers-8b588144-50e5-4d07-9a8d-16d715184faa": Phase="Pending", Reason="", readiness=false. Elapsed: 27.243467454s
Feb 22 06:30:42.012: INFO: Pod "client-containers-8b588144-50e5-4d07-9a8d-16d715184faa": Phase="Running", Reason="", readiness=true. Elapsed: 29.255127899s
Feb 22 06:30:44.022: INFO: Pod "client-containers-8b588144-50e5-4d07-9a8d-16d715184faa": Phase="Running", Reason="", readiness=true. Elapsed: 31.266020302s
Feb 22 06:30:46.030: INFO: Pod "client-containers-8b588144-50e5-4d07-9a8d-16d715184faa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 33.273147422s
STEP: Saw pod success
Feb 22 06:30:46.030: INFO: Pod "client-containers-8b588144-50e5-4d07-9a8d-16d715184faa" satisfied condition "Succeeded or Failed"
Feb 22 06:30:46.039: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com pod client-containers-8b588144-50e5-4d07-9a8d-16d715184faa container test-container: <nil>
STEP: delete the pod
Feb 22 06:30:46.140: INFO: Waiting for pod client-containers-8b588144-50e5-4d07-9a8d-16d715184faa to disappear
Feb 22 06:30:46.168: INFO: Pod client-containers-8b588144-50e5-4d07-9a8d-16d715184faa still exists
Feb 22 06:30:48.171: INFO: Waiting for pod client-containers-8b588144-50e5-4d07-9a8d-16d715184faa to disappear
Feb 22 06:30:48.187: INFO: Pod client-containers-8b588144-50e5-4d07-9a8d-16d715184faa still exists
Feb 22 06:30:50.169: INFO: Waiting for pod client-containers-8b588144-50e5-4d07-9a8d-16d715184faa to disappear
Feb 22 06:30:50.202: INFO: Pod client-containers-8b588144-50e5-4d07-9a8d-16d715184faa still exists
Feb 22 06:30:52.169: INFO: Waiting for pod client-containers-8b588144-50e5-4d07-9a8d-16d715184faa to disappear
Feb 22 06:30:52.188: INFO: Pod client-containers-8b588144-50e5-4d07-9a8d-16d715184faa still exists
Feb 22 06:30:54.169: INFO: Waiting for pod client-containers-8b588144-50e5-4d07-9a8d-16d715184faa to disappear
Feb 22 06:30:54.180: INFO: Pod client-containers-8b588144-50e5-4d07-9a8d-16d715184faa still exists
Feb 22 06:30:56.169: INFO: Waiting for pod client-containers-8b588144-50e5-4d07-9a8d-16d715184faa to disappear
Feb 22 06:30:56.181: INFO: Pod client-containers-8b588144-50e5-4d07-9a8d-16d715184faa still exists
Feb 22 06:30:58.169: INFO: Waiting for pod client-containers-8b588144-50e5-4d07-9a8d-16d715184faa to disappear
Feb 22 06:30:58.179: INFO: Pod client-containers-8b588144-50e5-4d07-9a8d-16d715184faa still exists
Feb 22 06:31:00.170: INFO: Waiting for pod client-containers-8b588144-50e5-4d07-9a8d-16d715184faa to disappear
Feb 22 06:31:00.240: INFO: Pod client-containers-8b588144-50e5-4d07-9a8d-16d715184faa no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:31:00.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-635" for this suite.

â€¢ [SLOW TEST:48.481 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Docker Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]","total":270,"completed":178,"skipped":3154,"failed":0}
SS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:31:00.400: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename aggregator
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in aggregator-1263
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:76
Feb 22 06:31:00.896: INFO: >>> kubeConfig: /root/.kube/config
[It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the sample API server.
Feb 22 06:31:01.927: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Feb 22 06:31:04.356: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572261, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:31:06.396: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572261, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:31:08.402: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572261, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:31:10.372: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572261, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:31:12.368: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572261, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:31:14.370: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572261, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:31:16.364: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572261, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:31:18.367: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572261, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:31:20.366: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572261, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:31:22.363: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572261, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:31:24.672: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572261, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:31:26.364: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572261, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:31:28.370: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572261, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:31:30.364: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572261, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:31:32.374: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572261, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:31:34.365: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572261, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:31:36.368: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572261, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:31:38.367: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572261, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:31:40.362: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572261, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:31:42.388: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572261, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:31:44.363: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572261, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:31:46.371: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572261, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:31:48.372: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572261, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:31:50.363: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572261, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:31:52.364: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572261, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:31:54.368: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572261, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:31:56.441: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572262, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572261, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:32:02.189: INFO: Waited 3.760438972s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:67
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:32:04.387: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-1263" for this suite.

â€¢ [SLOW TEST:64.049 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]","total":270,"completed":179,"skipped":3156,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:32:04.478: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-4199
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Feb 22 06:32:04.845: INFO: >>> kubeConfig: /root/.kube/config
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Feb 22 06:32:23.055: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-4199 create -f -'
Feb 22 06:32:25.501: INFO: stderr: ""
Feb 22 06:32:25.501: INFO: stdout: "e2e-test-crd-publish-openapi-4413-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Feb 22 06:32:25.501: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-4199 delete e2e-test-crd-publish-openapi-4413-crds test-cr'
Feb 22 06:32:25.680: INFO: stderr: ""
Feb 22 06:32:25.680: INFO: stdout: "e2e-test-crd-publish-openapi-4413-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Feb 22 06:32:25.680: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-4199 apply -f -'
Feb 22 06:32:26.691: INFO: stderr: ""
Feb 22 06:32:26.691: INFO: stdout: "e2e-test-crd-publish-openapi-4413-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Feb 22 06:32:26.691: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config --namespace=crd-publish-openapi-4199 delete e2e-test-crd-publish-openapi-4413-crds test-cr'
Feb 22 06:32:26.885: INFO: stderr: ""
Feb 22 06:32:26.885: INFO: stdout: "e2e-test-crd-publish-openapi-4413-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Feb 22 06:32:26.885: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config explain e2e-test-crd-publish-openapi-4413-crds'
Feb 22 06:32:27.463: INFO: stderr: ""
Feb 22 06:32:27.463: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-4413-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:32:37.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4199" for this suite.

â€¢ [SLOW TEST:33.238 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]","total":270,"completed":180,"skipped":3198,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should honor timeout [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:32:37.725: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-2908
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 22 06:32:39.425: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb 22 06:32:41.451: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572359, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572359, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572359, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572359, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:32:43.464: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572359, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572359, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572359, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572359, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:32:45.460: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572359, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572359, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572359, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572359, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:32:47.469: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572359, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572359, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572359, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572359, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:32:49.460: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572359, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572359, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572359, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572359, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:32:51.491: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572359, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572359, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572359, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572359, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:32:53.477: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572359, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572359, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572359, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572359, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:32:55.459: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572359, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572359, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572359, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572359, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:32:57.462: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572359, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572359, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572359, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572359, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:32:59.957: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572359, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572359, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572359, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572359, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:33:01.670: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572359, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572359, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572359, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572359, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:33:03.600: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572359, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572359, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572359, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572359, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:33:05.463: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572359, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572359, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572359, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572359, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 22 06:33:08.535: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Setting timeout (1s) shorter than webhook latency (5s)
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s)
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is longer than webhook latency
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is empty (defaulted to 10s in v1)
STEP: Registering slow webhook via the AdmissionRegistration API
Feb 22 06:33:16.210: INFO: Waiting for webhook configuration to be ready...
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:33:21.419: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2908" for this suite.
STEP: Destroying namespace "webhook-2908-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

â€¢ [SLOW TEST:44.574 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]","total":270,"completed":181,"skipped":3205,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:33:22.324: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1369
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Feb 22 06:33:22.811: INFO: Waiting up to 5m0s for pod "downwardapi-volume-413e251d-1c76-47ff-b105-b5720d08eab6" in namespace "projected-1369" to be "Succeeded or Failed"
Feb 22 06:33:22.837: INFO: Pod "downwardapi-volume-413e251d-1c76-47ff-b105-b5720d08eab6": Phase="Pending", Reason="", readiness=false. Elapsed: 25.319946ms
Feb 22 06:33:24.915: INFO: Pod "downwardapi-volume-413e251d-1c76-47ff-b105-b5720d08eab6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.103588378s
Feb 22 06:33:26.936: INFO: Pod "downwardapi-volume-413e251d-1c76-47ff-b105-b5720d08eab6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.124316243s
Feb 22 06:33:28.955: INFO: Pod "downwardapi-volume-413e251d-1c76-47ff-b105-b5720d08eab6": Phase="Pending", Reason="", readiness=false. Elapsed: 6.143061612s
Feb 22 06:33:30.997: INFO: Pod "downwardapi-volume-413e251d-1c76-47ff-b105-b5720d08eab6": Phase="Pending", Reason="", readiness=false. Elapsed: 8.185740844s
Feb 22 06:33:33.022: INFO: Pod "downwardapi-volume-413e251d-1c76-47ff-b105-b5720d08eab6": Phase="Pending", Reason="", readiness=false. Elapsed: 10.210049144s
Feb 22 06:33:35.053: INFO: Pod "downwardapi-volume-413e251d-1c76-47ff-b105-b5720d08eab6": Phase="Pending", Reason="", readiness=false. Elapsed: 12.241756072s
Feb 22 06:33:37.069: INFO: Pod "downwardapi-volume-413e251d-1c76-47ff-b105-b5720d08eab6": Phase="Pending", Reason="", readiness=false. Elapsed: 14.257463903s
Feb 22 06:33:39.118: INFO: Pod "downwardapi-volume-413e251d-1c76-47ff-b105-b5720d08eab6": Phase="Pending", Reason="", readiness=false. Elapsed: 16.306620793s
Feb 22 06:33:41.128: INFO: Pod "downwardapi-volume-413e251d-1c76-47ff-b105-b5720d08eab6": Phase="Pending", Reason="", readiness=false. Elapsed: 18.315862435s
Feb 22 06:33:43.136: INFO: Pod "downwardapi-volume-413e251d-1c76-47ff-b105-b5720d08eab6": Phase="Pending", Reason="", readiness=false. Elapsed: 20.324480547s
Feb 22 06:33:45.145: INFO: Pod "downwardapi-volume-413e251d-1c76-47ff-b105-b5720d08eab6": Phase="Pending", Reason="", readiness=false. Elapsed: 22.333709641s
Feb 22 06:33:47.156: INFO: Pod "downwardapi-volume-413e251d-1c76-47ff-b105-b5720d08eab6": Phase="Pending", Reason="", readiness=false. Elapsed: 24.344716872s
Feb 22 06:33:49.172: INFO: Pod "downwardapi-volume-413e251d-1c76-47ff-b105-b5720d08eab6": Phase="Pending", Reason="", readiness=false. Elapsed: 26.360295548s
Feb 22 06:33:51.180: INFO: Pod "downwardapi-volume-413e251d-1c76-47ff-b105-b5720d08eab6": Phase="Pending", Reason="", readiness=false. Elapsed: 28.368547555s
Feb 22 06:33:53.204: INFO: Pod "downwardapi-volume-413e251d-1c76-47ff-b105-b5720d08eab6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 30.391941604s
STEP: Saw pod success
Feb 22 06:33:53.204: INFO: Pod "downwardapi-volume-413e251d-1c76-47ff-b105-b5720d08eab6" satisfied condition "Succeeded or Failed"
Feb 22 06:33:53.235: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com pod downwardapi-volume-413e251d-1c76-47ff-b105-b5720d08eab6 container client-container: <nil>
STEP: delete the pod
Feb 22 06:33:58.817: INFO: Waiting for pod downwardapi-volume-413e251d-1c76-47ff-b105-b5720d08eab6 to disappear
Feb 22 06:33:58.898: INFO: Pod downwardapi-volume-413e251d-1c76-47ff-b105-b5720d08eab6 still exists
Feb 22 06:34:00.899: INFO: Waiting for pod downwardapi-volume-413e251d-1c76-47ff-b105-b5720d08eab6 to disappear
Feb 22 06:34:00.909: INFO: Pod downwardapi-volume-413e251d-1c76-47ff-b105-b5720d08eab6 still exists
Feb 22 06:34:02.899: INFO: Waiting for pod downwardapi-volume-413e251d-1c76-47ff-b105-b5720d08eab6 to disappear
Feb 22 06:34:02.910: INFO: Pod downwardapi-volume-413e251d-1c76-47ff-b105-b5720d08eab6 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:34:02.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1369" for this suite.

â€¢ [SLOW TEST:40.640 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:36
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]","total":270,"completed":182,"skipped":3218,"failed":0}
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:34:02.975: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4190
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: validating api versions
Feb 22 06:34:03.323: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config api-versions'
Feb 22 06:34:03.647: INFO: stderr: ""
Feb 22 06:34:03.647: INFO: stdout: "acme.cert-manager.io/v1alpha2\nacme.cert-manager.io/v1alpha3\naddons.cluster.x-k8s.io/v1alpha3\nadmissionregistration.k8s.io/v1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\nappplatform.wcp.vmware.com/v1alpha1\nappplatform.wcp.vmware.com/v1beta1\napps/v1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\nbootstrap.cluster.x-k8s.io/v1alpha2\nbootstrap.cluster.x-k8s.io/v1alpha3\ncert-manager.io/v1alpha2\ncert-manager.io/v1alpha3\ncertificates.k8s.io/v1beta1\ncluster.x-k8s.io/v1alpha2\ncluster.x-k8s.io/v1alpha3\ncns.vmware.com/v1alpha1\ncontrolplane.cluster.x-k8s.io/v1alpha3\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\ncrd.projectcalico.org/v1\ndiscovery.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nexp.cluster.x-k8s.io/v1alpha3\nextensions/v1beta1\nimagecontroller.vmware.com/v1\ninfrastructure.cluster.vmware.com/v1alpha2\ninfrastructure.cluster.vmware.com/v1alpha3\ninstallers.tmc.cloud.vmware.com/v1alpha1\nk8s.cni.cncf.io/v1\nlicenseoperator.vmware.com/v1alpha1\nnetoperator.vmware.com/v1alpha1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnetworking.x-k8s.io/v1alpha1pre1\nnode.k8s.io/v1beta1\nnsx.vmware.com/v1\npolicy/v1beta1\npsp.wcp.vmware.com/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nregistryagent.vmware.com/v1alpha1\nrun.tanzu.vmware.com/v1alpha1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\nvmoperator.vmware.com/v1alpha1\nvmware.com/v1alpha1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:34:03.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4190" for this suite.
â€¢{"msg":"PASSED [sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]","total":270,"completed":183,"skipped":3228,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:34:03.727: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-6944
STEP: Waiting for a default service account to be provisioned in namespace
[It] listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Feb 22 06:34:04.021: INFO: >>> kubeConfig: /root/.kube/config
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:34:34.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-6944" for this suite.

â€¢ [SLOW TEST:31.362 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:48
    listing custom resource definition objects works  [Conformance]
    /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]","total":270,"completed":184,"skipped":3241,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:34:35.090: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-2234
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 22 06:34:38.374: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb 22 06:34:41.102: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572478, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572478, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572478, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572478, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:34:43.293: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572478, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572478, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572478, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572478, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:34:45.163: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572478, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572478, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572478, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572478, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:34:47.118: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572478, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572478, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572478, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572478, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:34:49.121: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572478, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572478, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572478, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572478, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:34:51.109: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572478, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572478, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572478, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572478, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:34:53.109: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572478, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572478, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572478, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572478, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:34:55.114: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572478, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572478, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572478, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572478, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:34:57.108: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572478, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572478, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572478, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572478, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:34:59.109: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572478, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572478, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572478, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572478, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:35:01.116: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572478, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572478, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572478, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572478, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:35:03.112: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572478, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572478, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572478, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572478, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:35:05.112: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572478, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572478, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572478, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572478, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 06:35:07.461: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572478, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572478, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572478, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749572478, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 22 06:35:10.435: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Feb 22 06:35:10.538: INFO: >>> kubeConfig: /root/.kube/config
STEP: Registering the custom resource webhook via the AdmissionRegistration API
Feb 22 06:35:11.702: INFO: Waiting for webhook configuration to be ready...
STEP: Creating a custom resource that should be denied by the webhook
STEP: Creating a custom resource whose deletion would be denied by the webhook
STEP: Updating the custom resource with disallowed data should be denied
STEP: Deleting the custom resource should be denied
STEP: Remove the offending key and value from the custom resource data
STEP: Deleting the updated custom resource should be successful
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:35:13.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2234" for this suite.
STEP: Destroying namespace "webhook-2234-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

â€¢ [SLOW TEST:43.008 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]","total":270,"completed":185,"skipped":3249,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:35:18.117: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6756
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating the pod
Feb 22 06:35:49.563: INFO: Successfully updated pod "annotationupdate1dff60ab-719a-42a1-a228-d3a571d03c20"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:35:51.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6756" for this suite.

â€¢ [SLOW TEST:33.579 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:36
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]","total":270,"completed":186,"skipped":3262,"failed":0}
SSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:35:51.724: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-6798
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:74
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Feb 22 06:35:52.062: INFO: Creating deployment "webserver-deployment"
Feb 22 06:35:52.088: INFO: Waiting for observed generation 1
Feb 22 06:35:54.135: INFO: Waiting for all required pods to come up
Feb 22 06:35:54.162: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running
Feb 22 06:36:46.284: INFO: Waiting for deployment "webserver-deployment" to complete
Feb 22 06:36:46.321: INFO: Updating deployment "webserver-deployment" with a non-existent image
Feb 22 06:36:46.376: INFO: Updating deployment webserver-deployment
Feb 22 06:36:46.376: INFO: Waiting for observed generation 2
Feb 22 06:36:48.455: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Feb 22 06:36:48.474: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Feb 22 06:36:48.509: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Feb 22 06:36:48.602: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Feb 22 06:36:48.602: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Feb 22 06:36:48.614: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Feb 22 06:36:48.641: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Feb 22 06:36:48.641: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Feb 22 06:36:48.702: INFO: Updating deployment webserver-deployment
Feb 22 06:36:48.702: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Feb 22 06:36:48.822: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Feb 22 06:36:48.959: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
Feb 22 06:36:49.629: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-6798 /apis/apps/v1/namespaces/deployment-6798/deployments/webserver-deployment ac687fbc-d390-44b3-9669-ef1cdbd3bd9d 152317 3 2021-02-22 06:35:52 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2021-02-22 06:36:48 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 112 114 111 103 114 101 115 115 68 101 97 100 108 105 110 101 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 118 105 115 105 111 110 72 105 115 116 111 114 121 76 105 109 105 116 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 116 114 97 116 101 103 121 34 58 123 34 102 58 114 111 108 108 105 110 103 85 112 100 97 116 101 34 58 123 34 46 34 58 123 125 44 34 102 58 109 97 120 83 117 114 103 101 34 58 123 125 44 34 102 58 109 97 120 85 110 97 118 97 105 108 97 98 108 101 34 58 123 125 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2021-02-22 06:36:49 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 65 118 97 105 108 97 98 108 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 80 114 111 103 114 101 115 115 105 110 103 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 110 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 112 100 97 116 101 100 82 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc008bb75a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-6676bcd6d4" is progressing.,LastUpdateTime:2021-02-22 06:36:47 +0000 UTC,LastTransitionTime:2021-02-22 06:35:52 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2021-02-22 06:36:48 +0000 UTC,LastTransitionTime:2021-02-22 06:36:48 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Feb 22 06:36:50.038: INFO: New ReplicaSet "webserver-deployment-6676bcd6d4" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-6676bcd6d4  deployment-6798 /apis/apps/v1/namespaces/deployment-6798/replicasets/webserver-deployment-6676bcd6d4 4be7b8c2-e00e-47bc-a24c-a981c1fd2358 152305 3 2021-02-22 06:36:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment ac687fbc-d390-44b3-9669-ef1cdbd3bd9d 0xc0021046a7 0xc0021046a8}] []  [{kube-controller-manager Update apps/v1 2021-02-22 06:36:48 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 97 99 54 56 55 102 98 99 45 100 51 57 48 45 52 52 98 51 45 57 54 54 57 45 101 102 49 99 100 98 100 51 98 100 57 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 6676bcd6d4,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc002104a38 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Feb 22 06:36:50.038: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Feb 22 06:36:50.040: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-79c655c588  deployment-6798 /apis/apps/v1/namespaces/deployment-6798/replicasets/webserver-deployment-79c655c588 2d4a3051-a859-4bf3-8ca3-d132a375274d 152303 3 2021-02-22 06:35:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:79c655c588] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment ac687fbc-d390-44b3-9669-ef1cdbd3bd9d 0xc002104b37 0xc002104b38}] []  [{kube-controller-manager Update apps/v1 2021-02-22 06:36:48 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 97 99 54 56 55 102 98 99 45 100 51 57 48 45 52 52 98 51 45 57 54 54 57 45 101 102 49 99 100 98 100 51 98 100 57 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 79c655c588,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:79c655c588] map[] [] []  []} {[] [] [{httpd mirror.gcr.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc002104e28 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Feb 22 06:36:50.617: INFO: Pod "webserver-deployment-6676bcd6d4-846jr" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-846jr webserver-deployment-6676bcd6d4- deployment-6798 /api/v1/namespaces/deployment-6798/pods/webserver-deployment-6676bcd6d4-846jr be43cea9-f786-4e16-8db3-ee12c2f5d37f 152345 0 2021-02-22 06:36:49 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 4be7b8c2-e00e-47bc-a24c-a981c1fd2358 0xc0007421c7 0xc0007421c8}] []  [{kube-controller-manager Update v1 2021-02-22 06:36:49 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 52 98 101 55 98 56 99 50 45 101 48 48 101 45 52 55 98 99 45 97 50 52 99 45 97 57 56 49 99 49 102 100 50 51 53 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-6l5rr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-6l5rr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-6l5rr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 22 06:36:50.632: INFO: Pod "webserver-deployment-6676bcd6d4-8cp9x" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-8cp9x webserver-deployment-6676bcd6d4- deployment-6798 /api/v1/namespaces/deployment-6798/pods/webserver-deployment-6676bcd6d4-8cp9x f4c47b00-e7b2-4ffd-9b00-ff58151e0130 152335 0 2021-02-22 06:36:49 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 4be7b8c2-e00e-47bc-a24c-a981c1fd2358 0xc000742480 0xc000742481}] []  [{kube-controller-manager Update v1 2021-02-22 06:36:49 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 52 98 101 55 98 56 99 50 45 101 48 48 101 45 52 55 98 99 45 97 50 52 99 45 97 57 56 49 99 49 102 100 50 51 53 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-6l5rr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-6l5rr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-6l5rr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:sc2-rdops-vm05-dhcp-163-39.eng.vmware.com,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 06:36:49 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 22 06:36:50.637: INFO: Pod "webserver-deployment-6676bcd6d4-99v9c" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-99v9c webserver-deployment-6676bcd6d4- deployment-6798 /api/v1/namespaces/deployment-6798/pods/webserver-deployment-6676bcd6d4-99v9c 886e56c6-e7d5-4913-9aa3-2e07ef8ca85b 152318 0 2021-02-22 06:36:48 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 4be7b8c2-e00e-47bc-a24c-a981c1fd2358 0xc000742740 0xc000742741}] []  [{kube-controller-manager Update v1 2021-02-22 06:36:48 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 52 98 101 55 98 56 99 50 45 101 48 48 101 45 52 55 98 99 45 97 50 52 99 45 97 57 56 49 99 49 102 100 50 51 53 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-6l5rr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-6l5rr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-6l5rr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:sc2-rdops-vm05-dhcp-163-39.eng.vmware.com,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 06:36:49 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 22 06:36:50.638: INFO: Pod "webserver-deployment-6676bcd6d4-bql8n" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-bql8n webserver-deployment-6676bcd6d4- deployment-6798 /api/v1/namespaces/deployment-6798/pods/webserver-deployment-6676bcd6d4-bql8n 17c1fd4f-f454-42e1-9d52-9316558ce72e 152346 0 2021-02-22 06:36:49 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 4be7b8c2-e00e-47bc-a24c-a981c1fd2358 0xc000742b20 0xc000742b21}] []  [{kube-controller-manager Update v1 2021-02-22 06:36:49 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 52 98 101 55 98 56 99 50 45 101 48 48 101 45 52 55 98 99 45 97 50 52 99 45 97 57 56 49 99 49 102 100 50 51 53 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-6l5rr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-6l5rr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-6l5rr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:sc2-rdops-vm05-dhcp-163-39.eng.vmware.com,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 06:36:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 22 06:36:50.647: INFO: Pod "webserver-deployment-6676bcd6d4-ct29v" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-ct29v webserver-deployment-6676bcd6d4- deployment-6798 /api/v1/namespaces/deployment-6798/pods/webserver-deployment-6676bcd6d4-ct29v 5ee1cd2e-bf5a-4308-a7b1-a6b9fdfcc962 152300 0 2021-02-22 06:36:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[attachment_id:c5968067-d1fd-4b77-bef1-8384b4609cb1 kubernetes.io/psp:e2e-test-privileged-psp mac:04:50:56:00:28:28 vlan:None vmware-system-image-references:{"httpd":"webserver-ea8d19c56b2978338502181157e293b3d96a2b18-v68050"}] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 4be7b8c2-e00e-47bc-a24c-a981c1fd2358 0xc000742dd7 0xc000742dd8}] []  [{kube-controller-manager Update v1 2021-02-22 06:36:46 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 52 98 101 55 98 56 99 50 45 101 48 48 101 45 52 55 98 99 45 97 50 52 99 45 97 57 56 49 99 49 102 100 50 51 53 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {image-controller Update v1 2021-02-22 06:36:47 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 105 109 97 103 101 45 114 101 102 101 114 101 110 99 101 115 34 58 123 125 125 125 125],}} {nsx-ncp-75bf644549-ps9h2 Update v1 2021-02-22 06:36:48 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 97 116 116 97 99 104 109 101 110 116 95 105 100 34 58 123 125 44 34 102 58 109 97 99 34 58 123 125 44 34 102 58 118 108 97 110 34 58 123 125 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-6l5rr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-6l5rr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-6l5rr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:sc2-rdops-vm05-dhcp-179-105.eng.vmware.com,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 06:36:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 22 06:36:50.649: INFO: Pod "webserver-deployment-6676bcd6d4-dmrhl" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-dmrhl webserver-deployment-6676bcd6d4- deployment-6798 /api/v1/namespaces/deployment-6798/pods/webserver-deployment-6676bcd6d4-dmrhl fa22a98b-8629-48e9-b3b6-ec4775467103 152341 0 2021-02-22 06:36:49 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 4be7b8c2-e00e-47bc-a24c-a981c1fd2358 0xc000743110 0xc000743111}] []  [{kube-controller-manager Update v1 2021-02-22 06:36:49 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 52 98 101 55 98 56 99 50 45 101 48 48 101 45 52 55 98 99 45 97 50 52 99 45 97 57 56 49 99 49 102 100 50 51 53 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-6l5rr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-6l5rr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-6l5rr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:sc2-rdops-vm05-dhcp-179-105.eng.vmware.com,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 06:36:49 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 22 06:36:50.651: INFO: Pod "webserver-deployment-6676bcd6d4-l56tj" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-l56tj webserver-deployment-6676bcd6d4- deployment-6798 /api/v1/namespaces/deployment-6798/pods/webserver-deployment-6676bcd6d4-l56tj 45d08c8e-81f3-43df-b3a3-645350d4d66b 152274 0 2021-02-22 06:36:47 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 4be7b8c2-e00e-47bc-a24c-a981c1fd2358 0xc0007434d0 0xc0007434d1}] []  [{kube-controller-manager Update v1 2021-02-22 06:36:47 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 52 98 101 55 98 56 99 50 45 101 48 48 101 45 52 55 98 99 45 97 50 52 99 45 97 57 56 49 99 49 102 100 50 51 53 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-6l5rr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-6l5rr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-6l5rr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:sc2-rdops-vm05-dhcp-179-105.eng.vmware.com,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 06:36:47 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 22 06:36:50.656: INFO: Pod "webserver-deployment-6676bcd6d4-mxtq7" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-mxtq7 webserver-deployment-6676bcd6d4- deployment-6798 /api/v1/namespaces/deployment-6798/pods/webserver-deployment-6676bcd6d4-mxtq7 fd58ab92-6c4b-4ae9-80b1-dd8e121c8777 152325 0 2021-02-22 06:36:49 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 4be7b8c2-e00e-47bc-a24c-a981c1fd2358 0xc0005c29e0 0xc0005c29e1}] []  [{kube-controller-manager Update v1 2021-02-22 06:36:49 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 52 98 101 55 98 56 99 50 45 101 48 48 101 45 52 55 98 99 45 97 50 52 99 45 97 57 56 49 99 49 102 100 50 51 53 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-6l5rr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-6l5rr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-6l5rr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 22 06:36:50.657: INFO: Pod "webserver-deployment-6676bcd6d4-pl8pt" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-pl8pt webserver-deployment-6676bcd6d4- deployment-6798 /api/v1/namespaces/deployment-6798/pods/webserver-deployment-6676bcd6d4-pl8pt d73a0343-9c55-4c25-b76e-522c14bf622e 152343 0 2021-02-22 06:36:49 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 4be7b8c2-e00e-47bc-a24c-a981c1fd2358 0xc0005c2f80 0xc0005c2f81}] []  [{kube-controller-manager Update v1 2021-02-22 06:36:49 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 52 98 101 55 98 56 99 50 45 101 48 48 101 45 52 55 98 99 45 97 50 52 99 45 97 57 56 49 99 49 102 100 50 51 53 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-6l5rr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-6l5rr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-6l5rr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:sc2-rdops-vm05-dhcp-174-51.eng.vmware.com,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 06:36:49 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 22 06:36:50.658: INFO: Pod "webserver-deployment-6676bcd6d4-qqft2" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-qqft2 webserver-deployment-6676bcd6d4- deployment-6798 /api/v1/namespaces/deployment-6798/pods/webserver-deployment-6676bcd6d4-qqft2 92c52695-61a7-4339-a6a1-e776dad62248 152324 0 2021-02-22 06:36:49 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 4be7b8c2-e00e-47bc-a24c-a981c1fd2358 0xc0005c3130 0xc0005c3131}] []  [{kube-controller-manager Update v1 2021-02-22 06:36:49 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 52 98 101 55 98 56 99 50 45 101 48 48 101 45 52 55 98 99 45 97 50 52 99 45 97 57 56 49 99 49 102 100 50 51 53 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-6l5rr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-6l5rr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-6l5rr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 22 06:36:50.660: INFO: Pod "webserver-deployment-6676bcd6d4-tdwrv" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-tdwrv webserver-deployment-6676bcd6d4- deployment-6798 /api/v1/namespaces/deployment-6798/pods/webserver-deployment-6676bcd6d4-tdwrv ab6c493a-fe5f-4fa7-a2c9-9880247f8554 152301 0 2021-02-22 06:36:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[attachment_id:dd6faf9c-1104-42ed-995d-53ebfa3d6788 kubernetes.io/psp:e2e-test-privileged-psp mac:04:50:56:00:28:27 vlan:None vmware-system-image-references:{"httpd":"webserver-ea8d19c56b2978338502181157e293b3d96a2b18-v16322"}] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 4be7b8c2-e00e-47bc-a24c-a981c1fd2358 0xc0005c3377 0xc0005c3378}] []  [{kube-controller-manager Update v1 2021-02-22 06:36:46 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 52 98 101 55 98 56 99 50 45 101 48 48 101 45 52 55 98 99 45 97 50 52 99 45 97 57 56 49 99 49 102 100 50 51 53 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {image-controller Update v1 2021-02-22 06:36:47 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 105 109 97 103 101 45 114 101 102 101 114 101 110 99 101 115 34 58 123 125 125 125 125],}} {nsx-ncp-75bf644549-ps9h2 Update v1 2021-02-22 06:36:48 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 97 116 116 97 99 104 109 101 110 116 95 105 100 34 58 123 125 44 34 102 58 109 97 99 34 58 123 125 44 34 102 58 118 108 97 110 34 58 123 125 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-6l5rr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-6l5rr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-6l5rr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:sc2-rdops-vm05-dhcp-179-105.eng.vmware.com,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 06:36:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 22 06:36:50.662: INFO: Pod "webserver-deployment-6676bcd6d4-zflqs" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-zflqs webserver-deployment-6676bcd6d4- deployment-6798 /api/v1/namespaces/deployment-6798/pods/webserver-deployment-6676bcd6d4-zflqs 88e645e6-015e-411d-bf14-ccae33dd9ac2 152266 0 2021-02-22 06:36:46 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[kubernetes.io/psp:e2e-test-privileged-psp vmware-system-image-references:{"httpd":"webserver-ea8d19c56b2978338502181157e293b3d96a2b18-v16571"}] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 4be7b8c2-e00e-47bc-a24c-a981c1fd2358 0xc0005c3800 0xc0005c3801}] []  [{kube-controller-manager Update v1 2021-02-22 06:36:46 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 52 98 101 55 98 56 99 50 45 101 48 48 101 45 52 55 98 99 45 97 50 52 99 45 97 57 56 49 99 49 102 100 50 51 53 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {image-controller Update v1 2021-02-22 06:36:47 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 105 109 97 103 101 45 114 101 102 101 114 101 110 99 101 115 34 58 123 125 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-6l5rr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-6l5rr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-6l5rr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:sc2-rdops-vm05-dhcp-179-105.eng.vmware.com,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 06:36:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 22 06:36:50.665: INFO: Pod "webserver-deployment-6676bcd6d4-zrzql" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-zrzql webserver-deployment-6676bcd6d4- deployment-6798 /api/v1/namespaces/deployment-6798/pods/webserver-deployment-6676bcd6d4-zrzql d43bc9a8-9667-40b9-9e4c-c1187789a94e 152265 0 2021-02-22 06:36:47 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 4be7b8c2-e00e-47bc-a24c-a981c1fd2358 0xc001662040 0xc001662041}] []  [{kube-controller-manager Update v1 2021-02-22 06:36:47 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 52 98 101 55 98 56 99 50 45 101 48 48 101 45 52 55 98 99 45 97 50 52 99 45 97 57 56 49 99 49 102 100 50 51 53 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-6l5rr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-6l5rr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-6l5rr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:sc2-rdops-vm05-dhcp-163-39.eng.vmware.com,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 06:36:47 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 22 06:36:50.666: INFO: Pod "webserver-deployment-79c655c588-6xn2v" is not available:
&Pod{ObjectMeta:{webserver-deployment-79c655c588-6xn2v webserver-deployment-79c655c588- deployment-6798 /api/v1/namespaces/deployment-6798/pods/webserver-deployment-79c655c588-6xn2v f9e47035-f53e-4099-b3c8-5f5a2e98c823 152333 0 2021-02-22 06:36:49 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:79c655c588] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-79c655c588 2d4a3051-a859-4bf3-8ca3-d132a375274d 0xc001662170 0xc001662171}] []  [{kube-controller-manager Update v1 2021-02-22 06:36:49 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 50 100 52 97 51 48 53 49 45 97 56 53 57 45 52 98 102 51 45 56 99 97 51 45 100 49 51 50 97 51 55 53 50 55 52 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-6l5rr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-6l5rr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:mirror.gcr.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-6l5rr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 22 06:36:50.681: INFO: Pod "webserver-deployment-79c655c588-99rrc" is available:
&Pod{ObjectMeta:{webserver-deployment-79c655c588-99rrc webserver-deployment-79c655c588- deployment-6798 /api/v1/namespaces/deployment-6798/pods/webserver-deployment-79c655c588-99rrc 5a07b362-122c-4e97-994f-3dd96beadcf5 152231 0 2021-02-22 06:35:52 +0000 UTC 2021-02-22 06:36:46 +0000 UTC 0xc001662250 map[name:httpd pod-template-hash:79c655c588] map[attachment_id:8f348014-790c-40c5-ae21-61dc13fde0e9 kubernetes.io/psp:e2e-test-privileged-psp mac:04:50:56:00:28:1e vlan:None vmware-system-ephemeral-disk-uuid:6000C29c-323c-673a-940a-e44783cac8a8 vmware-system-image-references:{"httpd":"httpd-d22d0e2cfeeaa0c1d2773814f5199d564ac0eae2-v4616"} vmware-system-vm-moid:vm-715:6b180790-afb7-40a7-b1c1-16f00c9b6783 vmware-system-vm-uuid:502fcf52-7794-1ca9-4826-b7e70bf50c2e] [{apps/v1 ReplicaSet webserver-deployment-79c655c588 2d4a3051-a859-4bf3-8ca3-d132a375274d 0xc00166228f 0xc0016622a0}] [lifecycle-controller/system.vmware.com]  [{kube-controller-manager Update v1 2021-02-22 06:35:52 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 50 100 52 97 51 48 53 49 45 97 56 53 57 45 52 98 102 51 45 56 99 97 51 45 100 49 51 50 97 51 55 53 50 55 52 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {nsx-ncp-75bf644549-ps9h2 Update v1 2021-02-22 06:36:02 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 97 116 116 97 99 104 109 101 110 116 95 105 100 34 58 123 125 44 34 102 58 109 97 99 34 58 123 125 44 34 102 58 118 108 97 110 34 58 123 125 125 125 125],}} {image-controller Update v1 2021-02-22 06:36:06 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 105 109 97 103 101 45 114 101 102 101 114 101 110 99 101 115 34 58 123 125 125 125 125],}} {scheduler-extender Update v1 2021-02-22 06:36:30 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 101 112 104 101 109 101 114 97 108 45 100 105 115 107 45 117 117 105 100 34 58 123 125 44 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 118 109 45 109 111 105 100 34 58 123 125 44 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 118 109 45 117 117 105 100 34 58 123 125 125 44 34 102 58 102 105 110 97 108 105 122 101 114 115 34 58 123 34 46 34 58 123 125 44 34 118 58 92 34 108 105 102 101 99 121 99 108 101 45 99 111 110 116 114 111 108 108 101 114 47 115 121 115 116 101 109 46 118 109 119 97 114 101 46 99 111 109 92 34 34 58 123 125 125 125 125],}} {spherelet Update v1 2021-02-22 06:36:45 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 102 58 101 110 118 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 95 52 52 51 95 84 67 80 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 95 52 52 51 95 84 67 80 95 65 68 68 82 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 95 52 52 51 95 84 67 80 95 80 79 82 84 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 95 52 52 51 95 84 67 80 95 80 82 79 84 79 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 83 69 82 86 73 67 69 95 72 79 83 84 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 83 69 82 86 73 67 69 95 80 79 82 84 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 83 69 82 86 73 67 69 95 80 79 82 84 95 72 84 84 80 83 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 55 50 46 50 54 46 49 46 50 49 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-6l5rr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-6l5rr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:mirror.gcr.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-6l5rr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:sc2-rdops-vm05-dhcp-174-51.eng.vmware.com,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 06:35:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 06:36:47 +0000 UTC,Reason:,Message:,},PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 06:36:47 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 06:36:47 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.192.174.51,PodIP:172.26.1.214,StartTime:2021-02-22 06:36:41 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2021-02-22 06:36:42 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:mirror.gcr.io/library/httpd:2.4.38-alpine,ImageID:httpd-d22d0e2cfeeaa0c1d2773814f5199d564ac0eae2-v4616,ContainerID:dac6ecb7-3335-4110-8cac-90f2ef417dbc,Started:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.26.1.214,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 22 06:36:50.686: INFO: Pod "webserver-deployment-79c655c588-9jft6" is available:
&Pod{ObjectMeta:{webserver-deployment-79c655c588-9jft6 webserver-deployment-79c655c588- deployment-6798 /api/v1/namespaces/deployment-6798/pods/webserver-deployment-79c655c588-9jft6 3791b283-954f-4d79-9cf7-9c9a47b4a3dd 152185 0 2021-02-22 06:35:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:79c655c588] map[attachment_id:ad37d719-774e-429b-ae2f-b59c8dd56efd kubernetes.io/psp:e2e-test-privileged-psp mac:04:50:56:00:28:1f vlan:None vmware-system-ephemeral-disk-uuid:6000C299-bbd8-2611-0ebb-3177aa726539 vmware-system-image-references:{"httpd":"httpd-d22d0e2cfeeaa0c1d2773814f5199d564ac0eae2-v4616"} vmware-system-vm-moid:vm-713:6b180790-afb7-40a7-b1c1-16f00c9b6783 vmware-system-vm-uuid:502f38df-845d-3542-4ac4-b4dd8e46f5a4] [{apps/v1 ReplicaSet webserver-deployment-79c655c588 2d4a3051-a859-4bf3-8ca3-d132a375274d 0xc0016633df 0xc001663520}] [lifecycle-controller/system.vmware.com]  [{kube-controller-manager Update v1 2021-02-22 06:35:52 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 50 100 52 97 51 48 53 49 45 97 56 53 57 45 52 98 102 51 45 56 99 97 51 45 100 49 51 50 97 51 55 53 50 55 52 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {nsx-ncp-75bf644549-ps9h2 Update v1 2021-02-22 06:36:02 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 97 116 116 97 99 104 109 101 110 116 95 105 100 34 58 123 125 44 34 102 58 109 97 99 34 58 123 125 44 34 102 58 118 108 97 110 34 58 123 125 125 125 125],}} {image-controller Update v1 2021-02-22 06:36:07 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 105 109 97 103 101 45 114 101 102 101 114 101 110 99 101 115 34 58 123 125 125 125 125],}} {scheduler-extender Update v1 2021-02-22 06:36:30 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 101 112 104 101 109 101 114 97 108 45 100 105 115 107 45 117 117 105 100 34 58 123 125 44 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 118 109 45 109 111 105 100 34 58 123 125 44 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 118 109 45 117 117 105 100 34 58 123 125 125 44 34 102 58 102 105 110 97 108 105 122 101 114 115 34 58 123 34 46 34 58 123 125 44 34 118 58 92 34 108 105 102 101 99 121 99 108 101 45 99 111 110 116 114 111 108 108 101 114 47 115 121 115 116 101 109 46 118 109 119 97 114 101 46 99 111 109 92 34 34 58 123 125 125 125 125],}} {spherelet Update v1 2021-02-22 06:36:44 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 102 58 101 110 118 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 95 52 52 51 95 84 67 80 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 95 52 52 51 95 84 67 80 95 65 68 68 82 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 95 52 52 51 95 84 67 80 95 80 79 82 84 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 95 52 52 51 95 84 67 80 95 80 82 79 84 79 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 83 69 82 86 73 67 69 95 72 79 83 84 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 83 69 82 86 73 67 69 95 80 79 82 84 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 83 69 82 86 73 67 69 95 80 79 82 84 95 72 84 84 80 83 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 55 50 46 50 54 46 49 46 50 49 53 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-6l5rr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-6l5rr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:mirror.gcr.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-6l5rr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:sc2-rdops-vm05-dhcp-174-51.eng.vmware.com,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 06:35:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 06:36:46 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 06:36:46 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 06:36:40 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.192.174.51,PodIP:172.26.1.215,StartTime:2021-02-22 06:36:39 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2021-02-22 06:36:41 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:mirror.gcr.io/library/httpd:2.4.38-alpine,ImageID:httpd-d22d0e2cfeeaa0c1d2773814f5199d564ac0eae2-v4616,ContainerID:c02f03f2-64c4-4b69-a1b3-df1e78af781f,Started:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.26.1.215,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 22 06:36:50.692: INFO: Pod "webserver-deployment-79c655c588-9jhgh" is not available:
&Pod{ObjectMeta:{webserver-deployment-79c655c588-9jhgh webserver-deployment-79c655c588- deployment-6798 /api/v1/namespaces/deployment-6798/pods/webserver-deployment-79c655c588-9jhgh 17e24e68-d5c9-45c0-8e8e-d827999b3fb0 152331 0 2021-02-22 06:36:49 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:79c655c588] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-79c655c588 2d4a3051-a859-4bf3-8ca3-d132a375274d 0xc001f501c7 0xc001f501c8}] []  [{kube-controller-manager Update v1 2021-02-22 06:36:49 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 50 100 52 97 51 48 53 49 45 97 56 53 57 45 52 98 102 51 45 56 99 97 51 45 100 49 51 50 97 51 55 53 50 55 52 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-6l5rr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-6l5rr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:mirror.gcr.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-6l5rr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 22 06:36:50.694: INFO: Pod "webserver-deployment-79c655c588-9lj7c" is available:
&Pod{ObjectMeta:{webserver-deployment-79c655c588-9lj7c webserver-deployment-79c655c588- deployment-6798 /api/v1/namespaces/deployment-6798/pods/webserver-deployment-79c655c588-9lj7c c3484bb6-5ae6-4026-8ae6-7179fc343ba5 152003 0 2021-02-22 06:35:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:79c655c588] map[attachment_id:5b70d258-dfdb-451b-893e-b2c90d42d7db kubernetes.io/psp:e2e-test-privileged-psp mac:04:50:56:00:28:20 vlan:None vmware-system-ephemeral-disk-uuid:6000C290-bed5-5109-8090-5fd05320152f vmware-system-image-references:{"httpd":"httpd-d22d0e2cfeeaa0c1d2773814f5199d564ac0eae2-v4616"} vmware-system-vm-moid:vm-710:6b180790-afb7-40a7-b1c1-16f00c9b6783 vmware-system-vm-uuid:502f6d23-bece-b7e5-ed38-b8508f41d131] [{apps/v1 ReplicaSet webserver-deployment-79c655c588 2d4a3051-a859-4bf3-8ca3-d132a375274d 0xc001f504f7 0xc001f504f8}] [lifecycle-controller/system.vmware.com]  [{kube-controller-manager Update v1 2021-02-22 06:35:52 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 50 100 52 97 51 48 53 49 45 97 56 53 57 45 52 98 102 51 45 56 99 97 51 45 100 49 51 50 97 51 55 53 50 55 52 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {nsx-ncp-75bf644549-ps9h2 Update v1 2021-02-22 06:36:02 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 97 116 116 97 99 104 109 101 110 116 95 105 100 34 58 123 125 44 34 102 58 109 97 99 34 58 123 125 44 34 102 58 118 108 97 110 34 58 123 125 125 125 125],}} {image-controller Update v1 2021-02-22 06:36:06 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 105 109 97 103 101 45 114 101 102 101 114 101 110 99 101 115 34 58 123 125 125 125 125],}} {scheduler-extender Update v1 2021-02-22 06:36:19 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 101 112 104 101 109 101 114 97 108 45 100 105 115 107 45 117 117 105 100 34 58 123 125 44 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 118 109 45 109 111 105 100 34 58 123 125 44 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 118 109 45 117 117 105 100 34 58 123 125 125 44 34 102 58 102 105 110 97 108 105 122 101 114 115 34 58 123 34 46 34 58 123 125 44 34 118 58 92 34 108 105 102 101 99 121 99 108 101 45 99 111 110 116 114 111 108 108 101 114 47 115 121 115 116 101 109 46 118 109 119 97 114 101 46 99 111 109 92 34 34 58 123 125 125 125 125],}} {spherelet Update v1 2021-02-22 06:36:29 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 102 58 101 110 118 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 95 52 52 51 95 84 67 80 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 95 52 52 51 95 84 67 80 95 65 68 68 82 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 95 52 52 51 95 84 67 80 95 80 79 82 84 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 95 52 52 51 95 84 67 80 95 80 82 79 84 79 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 83 69 82 86 73 67 69 95 72 79 83 84 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 83 69 82 86 73 67 69 95 80 79 82 84 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 83 69 82 86 73 67 69 95 80 79 82 84 95 72 84 84 80 83 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 55 50 46 50 54 46 49 46 50 49 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-6l5rr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-6l5rr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:mirror.gcr.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-6l5rr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:sc2-rdops-vm05-dhcp-163-39.eng.vmware.com,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 06:35:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 06:36:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 06:36:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 06:36:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.192.163.39,PodIP:172.26.1.216,StartTime:2021-02-22 06:36:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2021-02-22 06:36:29 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:mirror.gcr.io/library/httpd:2.4.38-alpine,ImageID:httpd-d22d0e2cfeeaa0c1d2773814f5199d564ac0eae2-v4616,ContainerID:31d2a317-6291-423d-b836-34eaa4265b9f,Started:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.26.1.216,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 22 06:36:50.703: INFO: Pod "webserver-deployment-79c655c588-gjc2t" is available:
&Pod{ObjectMeta:{webserver-deployment-79c655c588-gjc2t webserver-deployment-79c655c588- deployment-6798 /api/v1/namespaces/deployment-6798/pods/webserver-deployment-79c655c588-gjc2t 0099f967-da8e-4447-9abe-f13a18ae46d8 152189 0 2021-02-22 06:35:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:79c655c588] map[attachment_id:4b70e9c4-6e7c-48a3-bf7b-64728bf1b6c1 kubernetes.io/psp:e2e-test-privileged-psp mac:04:50:56:00:28:19 vlan:None vmware-system-ephemeral-disk-uuid:6000C298-a24f-3258-69c7-39b55e703347 vmware-system-image-references:{"httpd":"httpd-d22d0e2cfeeaa0c1d2773814f5199d564ac0eae2-v4616"} vmware-system-vm-moid:vm-709:6b180790-afb7-40a7-b1c1-16f00c9b6783 vmware-system-vm-uuid:502f5adc-1d53-94fe-37e8-eda44618e1d0] [{apps/v1 ReplicaSet webserver-deployment-79c655c588 2d4a3051-a859-4bf3-8ca3-d132a375274d 0xc001f50b2f 0xc001f50b40}] [lifecycle-controller/system.vmware.com]  [{kube-controller-manager Update v1 2021-02-22 06:35:52 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 50 100 52 97 51 48 53 49 45 97 56 53 57 45 52 98 102 51 45 56 99 97 51 45 100 49 51 50 97 51 55 53 50 55 52 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {nsx-ncp-75bf644549-ps9h2 Update v1 2021-02-22 06:36:02 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 97 116 116 97 99 104 109 101 110 116 95 105 100 34 58 123 125 44 34 102 58 109 97 99 34 58 123 125 44 34 102 58 118 108 97 110 34 58 123 125 125 125 125],}} {image-controller Update v1 2021-02-22 06:36:07 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 105 109 97 103 101 45 114 101 102 101 114 101 110 99 101 115 34 58 123 125 125 125 125],}} {scheduler-extender Update v1 2021-02-22 06:36:30 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 101 112 104 101 109 101 114 97 108 45 100 105 115 107 45 117 117 105 100 34 58 123 125 44 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 118 109 45 109 111 105 100 34 58 123 125 44 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 118 109 45 117 117 105 100 34 58 123 125 125 44 34 102 58 102 105 110 97 108 105 122 101 114 115 34 58 123 34 46 34 58 123 125 44 34 118 58 92 34 108 105 102 101 99 121 99 108 101 45 99 111 110 116 114 111 108 108 101 114 47 115 121 115 116 101 109 46 118 109 119 97 114 101 46 99 111 109 92 34 34 58 123 125 125 125 125],}} {spherelet Update v1 2021-02-22 06:36:45 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 102 58 101 110 118 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 95 52 52 51 95 84 67 80 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 95 52 52 51 95 84 67 80 95 65 68 68 82 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 95 52 52 51 95 84 67 80 95 80 79 82 84 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 95 52 52 51 95 84 67 80 95 80 82 79 84 79 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 83 69 82 86 73 67 69 95 72 79 83 84 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 83 69 82 86 73 67 69 95 80 79 82 84 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 83 69 82 86 73 67 69 95 80 79 82 84 95 72 84 84 80 83 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 55 50 46 50 54 46 49 46 50 49 50 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-6l5rr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-6l5rr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:mirror.gcr.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-6l5rr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:sc2-rdops-vm05-dhcp-174-51.eng.vmware.com,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 06:35:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 06:36:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 06:36:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 06:36:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.192.174.51,PodIP:172.26.1.212,StartTime:2021-02-22 06:36:42 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2021-02-22 06:36:44 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:mirror.gcr.io/library/httpd:2.4.38-alpine,ImageID:httpd-d22d0e2cfeeaa0c1d2773814f5199d564ac0eae2-v4616,ContainerID:d6603e58-7c94-4d78-a7e5-cf5fb8f8e82e,Started:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.26.1.212,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 22 06:36:50.709: INFO: Pod "webserver-deployment-79c655c588-hxbq7" is available:
&Pod{ObjectMeta:{webserver-deployment-79c655c588-hxbq7 webserver-deployment-79c655c588- deployment-6798 /api/v1/namespaces/deployment-6798/pods/webserver-deployment-79c655c588-hxbq7 001139a2-57ca-454e-8972-c71a070ce791 152232 0 2021-02-22 06:35:52 +0000 UTC 2021-02-22 06:36:46 +0000 UTC 0xc001f50de8 map[name:httpd pod-template-hash:79c655c588] map[attachment_id:d525b152-38b2-4dfc-ada2-af5ea0e454bb kubernetes.io/psp:e2e-test-privileged-psp mac:04:50:56:00:28:12 vlan:None vmware-system-ephemeral-disk-uuid:6000C295-cd8d-8f0f-d99f-915e27a65a72 vmware-system-image-references:{"httpd":"httpd-d22d0e2cfeeaa0c1d2773814f5199d564ac0eae2-v4616"} vmware-system-vm-moid:vm-708:6b180790-afb7-40a7-b1c1-16f00c9b6783 vmware-system-vm-uuid:502ff226-91de-24bb-252e-62aef1babf16] [{apps/v1 ReplicaSet webserver-deployment-79c655c588 2d4a3051-a859-4bf3-8ca3-d132a375274d 0xc001f50e37 0xc001f50e38}] [lifecycle-controller/system.vmware.com]  [{image-controller Update v1 2021-02-22 06:35:52 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 105 109 97 103 101 45 114 101 102 101 114 101 110 99 101 115 34 58 123 125 125 125 125],}} {kube-controller-manager Update v1 2021-02-22 06:35:52 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 50 100 52 97 51 48 53 49 45 97 56 53 57 45 52 98 102 51 45 56 99 97 51 45 100 49 51 50 97 51 55 53 50 55 52 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {nsx-ncp-75bf644549-ps9h2 Update v1 2021-02-22 06:36:02 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 97 116 116 97 99 104 109 101 110 116 95 105 100 34 58 123 125 44 34 102 58 109 97 99 34 58 123 125 44 34 102 58 118 108 97 110 34 58 123 125 125 125 125],}} {scheduler-extender Update v1 2021-02-22 06:36:30 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 101 112 104 101 109 101 114 97 108 45 100 105 115 107 45 117 117 105 100 34 58 123 125 44 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 118 109 45 109 111 105 100 34 58 123 125 44 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 118 109 45 117 117 105 100 34 58 123 125 125 44 34 102 58 102 105 110 97 108 105 122 101 114 115 34 58 123 34 46 34 58 123 125 44 34 118 58 92 34 108 105 102 101 99 121 99 108 101 45 99 111 110 116 114 111 108 108 101 114 47 115 121 115 116 101 109 46 118 109 119 97 114 101 46 99 111 109 92 34 34 58 123 125 125 125 125],}} {spherelet Update v1 2021-02-22 06:36:45 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 102 58 101 110 118 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 95 52 52 51 95 84 67 80 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 95 52 52 51 95 84 67 80 95 65 68 68 82 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 95 52 52 51 95 84 67 80 95 80 79 82 84 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 95 52 52 51 95 84 67 80 95 80 82 79 84 79 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 83 69 82 86 73 67 69 95 72 79 83 84 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 83 69 82 86 73 67 69 95 80 79 82 84 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 83 69 82 86 73 67 69 95 80 79 82 84 95 72 84 84 80 83 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 55 50 46 50 54 46 49 46 50 49 48 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-6l5rr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-6l5rr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:mirror.gcr.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-6l5rr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:sc2-rdops-vm05-dhcp-174-51.eng.vmware.com,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 06:35:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 06:36:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 06:36:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 06:36:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.192.174.51,PodIP:172.26.1.210,StartTime:2021-02-22 06:36:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2021-02-22 06:36:45 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:mirror.gcr.io/library/httpd:2.4.38-alpine,ImageID:httpd-d22d0e2cfeeaa0c1d2773814f5199d564ac0eae2-v4616,ContainerID:b50a235b-2ad7-491b-9183-09b6c250e297,Started:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.26.1.210,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 22 06:36:50.710: INFO: Pod "webserver-deployment-79c655c588-hz8zz" is available:
&Pod{ObjectMeta:{webserver-deployment-79c655c588-hz8zz webserver-deployment-79c655c588- deployment-6798 /api/v1/namespaces/deployment-6798/pods/webserver-deployment-79c655c588-hz8zz f77845b6-cfce-40c9-aabe-9daf3a424e19 152009 0 2021-02-22 06:35:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:79c655c588] map[attachment_id:bd778165-07dc-491f-83ef-304b6168435b kubernetes.io/psp:e2e-test-privileged-psp mac:04:50:56:00:28:25 vlan:None vmware-system-ephemeral-disk-uuid:6000C29a-e014-731e-622f-68e3f63c7bec vmware-system-image-references:{"httpd":"httpd-d22d0e2cfeeaa0c1d2773814f5199d564ac0eae2-v4616"} vmware-system-vm-moid:vm-712:6b180790-afb7-40a7-b1c1-16f00c9b6783 vmware-system-vm-uuid:502f2164-7445-a9bd-d535-18d76716d2e4] [{apps/v1 ReplicaSet webserver-deployment-79c655c588 2d4a3051-a859-4bf3-8ca3-d132a375274d 0xc001f5172f 0xc001f517f0}] [lifecycle-controller/system.vmware.com]  [{kube-controller-manager Update v1 2021-02-22 06:35:52 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 50 100 52 97 51 48 53 49 45 97 56 53 57 45 52 98 102 51 45 56 99 97 51 45 100 49 51 50 97 51 55 53 50 55 52 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {nsx-ncp-75bf644549-ps9h2 Update v1 2021-02-22 06:36:02 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 97 116 116 97 99 104 109 101 110 116 95 105 100 34 58 123 125 44 34 102 58 109 97 99 34 58 123 125 44 34 102 58 118 108 97 110 34 58 123 125 125 125 125],}} {image-controller Update v1 2021-02-22 06:36:06 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 105 109 97 103 101 45 114 101 102 101 114 101 110 99 101 115 34 58 123 125 125 125 125],}} {scheduler-extender Update v1 2021-02-22 06:36:16 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 101 112 104 101 109 101 114 97 108 45 100 105 115 107 45 117 117 105 100 34 58 123 125 44 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 118 109 45 109 111 105 100 34 58 123 125 44 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 118 109 45 117 117 105 100 34 58 123 125 125 44 34 102 58 102 105 110 97 108 105 122 101 114 115 34 58 123 34 46 34 58 123 125 44 34 118 58 92 34 108 105 102 101 99 121 99 108 101 45 99 111 110 116 114 111 108 108 101 114 47 115 121 115 116 101 109 46 118 109 119 97 114 101 46 99 111 109 92 34 34 58 123 125 125 125 125],}} {spherelet Update v1 2021-02-22 06:36:29 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 102 58 101 110 118 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 95 52 52 51 95 84 67 80 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 95 52 52 51 95 84 67 80 95 65 68 68 82 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 95 52 52 51 95 84 67 80 95 80 79 82 84 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 95 52 52 51 95 84 67 80 95 80 82 79 84 79 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 83 69 82 86 73 67 69 95 72 79 83 84 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 83 69 82 86 73 67 69 95 80 79 82 84 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 83 69 82 86 73 67 69 95 80 79 82 84 95 72 84 84 80 83 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 55 50 46 50 54 46 49 46 50 49 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-6l5rr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-6l5rr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:mirror.gcr.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-6l5rr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:sc2-rdops-vm05-dhcp-179-105.eng.vmware.com,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 06:35:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 06:36:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 06:36:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 06:36:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.192.179.105,PodIP:172.26.1.218,StartTime:2021-02-22 06:36:25 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2021-02-22 06:36:28 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:mirror.gcr.io/library/httpd:2.4.38-alpine,ImageID:httpd-d22d0e2cfeeaa0c1d2773814f5199d564ac0eae2-v4616,ContainerID:2cae936e-dcd3-4b95-9d3c-f3ebdeb902bc,Started:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.26.1.218,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 22 06:36:50.721: INFO: Pod "webserver-deployment-79c655c588-kp62t" is available:
&Pod{ObjectMeta:{webserver-deployment-79c655c588-kp62t webserver-deployment-79c655c588- deployment-6798 /api/v1/namespaces/deployment-6798/pods/webserver-deployment-79c655c588-kp62t 1cdbed72-882a-4d7e-8f42-023cd109b6d0 152008 0 2021-02-22 06:35:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:79c655c588] map[attachment_id:a9d36337-1391-4d0f-86a4-6f492388cd38 kubernetes.io/psp:e2e-test-privileged-psp mac:04:50:56:00:28:26 vlan:None vmware-system-ephemeral-disk-uuid:6000C299-a838-8dac-8dde-16ce435065e4 vmware-system-image-references:{"httpd":"httpd-d22d0e2cfeeaa0c1d2773814f5199d564ac0eae2-v4616"} vmware-system-vm-moid:vm-711:6b180790-afb7-40a7-b1c1-16f00c9b6783 vmware-system-vm-uuid:502f96d6-ebbc-7f4e-72bc-f558ff025d9d] [{apps/v1 ReplicaSet webserver-deployment-79c655c588 2d4a3051-a859-4bf3-8ca3-d132a375274d 0xc001f51c2f 0xc001f51c40}] [lifecycle-controller/system.vmware.com]  [{kube-controller-manager Update v1 2021-02-22 06:35:52 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 50 100 52 97 51 48 53 49 45 97 56 53 57 45 52 98 102 51 45 56 99 97 51 45 100 49 51 50 97 51 55 53 50 55 52 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {nsx-ncp-75bf644549-ps9h2 Update v1 2021-02-22 06:36:03 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 97 116 116 97 99 104 109 101 110 116 95 105 100 34 58 123 125 44 34 102 58 109 97 99 34 58 123 125 44 34 102 58 118 108 97 110 34 58 123 125 125 125 125],}} {image-controller Update v1 2021-02-22 06:36:07 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 105 109 97 103 101 45 114 101 102 101 114 101 110 99 101 115 34 58 123 125 125 125 125],}} {scheduler-extender Update v1 2021-02-22 06:36:19 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 101 112 104 101 109 101 114 97 108 45 100 105 115 107 45 117 117 105 100 34 58 123 125 44 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 118 109 45 109 111 105 100 34 58 123 125 44 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 118 109 45 117 117 105 100 34 58 123 125 125 44 34 102 58 102 105 110 97 108 105 122 101 114 115 34 58 123 34 46 34 58 123 125 44 34 118 58 92 34 108 105 102 101 99 121 99 108 101 45 99 111 110 116 114 111 108 108 101 114 47 115 121 115 116 101 109 46 118 109 119 97 114 101 46 99 111 109 92 34 34 58 123 125 125 125 125],}} {spherelet Update v1 2021-02-22 06:36:29 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 102 58 101 110 118 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 95 52 52 51 95 84 67 80 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 95 52 52 51 95 84 67 80 95 65 68 68 82 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 95 52 52 51 95 84 67 80 95 80 79 82 84 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 95 52 52 51 95 84 67 80 95 80 82 79 84 79 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 83 69 82 86 73 67 69 95 72 79 83 84 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 83 69 82 86 73 67 69 95 80 79 82 84 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 83 69 82 86 73 67 69 95 80 79 82 84 95 72 84 84 80 83 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 55 50 46 50 54 46 49 46 50 49 57 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-6l5rr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-6l5rr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:mirror.gcr.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-6l5rr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:sc2-rdops-vm05-dhcp-163-39.eng.vmware.com,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 06:35:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 06:36:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 06:36:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 06:36:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.192.163.39,PodIP:172.26.1.219,StartTime:2021-02-22 06:36:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2021-02-22 06:36:29 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:mirror.gcr.io/library/httpd:2.4.38-alpine,ImageID:httpd-d22d0e2cfeeaa0c1d2773814f5199d564ac0eae2-v4616,ContainerID:3d517bb6-3005-40b2-9f8e-6790192f5165,Started:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.26.1.219,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 22 06:36:50.748: INFO: Pod "webserver-deployment-79c655c588-ljrmz" is not available:
&Pod{ObjectMeta:{webserver-deployment-79c655c588-ljrmz webserver-deployment-79c655c588- deployment-6798 /api/v1/namespaces/deployment-6798/pods/webserver-deployment-79c655c588-ljrmz c8503eca-f4b2-41c1-ab28-7478530d698f 152328 0 2021-02-22 06:36:49 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:79c655c588] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-79c655c588 2d4a3051-a859-4bf3-8ca3-d132a375274d 0xc001f51e27 0xc001f51e28}] []  [{kube-controller-manager Update v1 2021-02-22 06:36:49 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 50 100 52 97 51 48 53 49 45 97 56 53 57 45 52 98 102 51 45 56 99 97 51 45 100 49 51 50 97 51 55 53 50 55 52 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-6l5rr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-6l5rr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:mirror.gcr.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-6l5rr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 22 06:36:50.752: INFO: Pod "webserver-deployment-79c655c588-r22kj" is available:
&Pod{ObjectMeta:{webserver-deployment-79c655c588-r22kj webserver-deployment-79c655c588- deployment-6798 /api/v1/namespaces/deployment-6798/pods/webserver-deployment-79c655c588-r22kj e0344add-22ed-4a12-ad20-a00137233f96 152131 0 2021-02-22 06:35:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:79c655c588] map[attachment_id:7a066d06-6603-4255-a8d9-f58835954d8b kubernetes.io/psp:e2e-test-privileged-psp mac:04:50:56:00:28:1c vlan:None vmware-system-ephemeral-disk-uuid:6000C29a-e315-099b-a8d0-5d1ed5277a82 vmware-system-image-references:{"httpd":"httpd-d22d0e2cfeeaa0c1d2773814f5199d564ac0eae2-v4616"} vmware-system-vm-moid:vm-707:6b180790-afb7-40a7-b1c1-16f00c9b6783 vmware-system-vm-uuid:502f2ff0-5322-bb57-49df-9c57e424e952] [{apps/v1 ReplicaSet webserver-deployment-79c655c588 2d4a3051-a859-4bf3-8ca3-d132a375274d 0xc001f51f47 0xc001f51f48}] [lifecycle-controller/system.vmware.com]  [{kube-controller-manager Update v1 2021-02-22 06:35:52 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 50 100 52 97 51 48 53 49 45 97 56 53 57 45 52 98 102 51 45 56 99 97 51 45 100 49 51 50 97 51 55 53 50 55 52 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {nsx-ncp-75bf644549-ps9h2 Update v1 2021-02-22 06:36:01 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 97 116 116 97 99 104 109 101 110 116 95 105 100 34 58 123 125 44 34 102 58 109 97 99 34 58 123 125 44 34 102 58 118 108 97 110 34 58 123 125 125 125 125],}} {image-controller Update v1 2021-02-22 06:36:05 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 105 109 97 103 101 45 114 101 102 101 114 101 110 99 101 115 34 58 123 125 125 125 125],}} {scheduler-extender Update v1 2021-02-22 06:36:28 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 101 112 104 101 109 101 114 97 108 45 100 105 115 107 45 117 117 105 100 34 58 123 125 44 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 118 109 45 109 111 105 100 34 58 123 125 44 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 118 109 45 117 117 105 100 34 58 123 125 125 44 34 102 58 102 105 110 97 108 105 122 101 114 115 34 58 123 34 46 34 58 123 125 44 34 118 58 92 34 108 105 102 101 99 121 99 108 101 45 99 111 110 116 114 111 108 108 101 114 47 115 121 115 116 101 109 46 118 109 119 97 114 101 46 99 111 109 92 34 34 58 123 125 125 125 125],}} {spherelet Update v1 2021-02-22 06:36:39 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 102 58 101 110 118 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 95 52 52 51 95 84 67 80 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 95 52 52 51 95 84 67 80 95 65 68 68 82 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 95 52 52 51 95 84 67 80 95 80 79 82 84 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 95 52 52 51 95 84 67 80 95 80 82 79 84 79 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 83 69 82 86 73 67 69 95 72 79 83 84 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 83 69 82 86 73 67 69 95 80 79 82 84 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 83 69 82 86 73 67 69 95 80 79 82 84 95 72 84 84 80 83 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 55 50 46 50 54 46 49 46 50 49 51 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-6l5rr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-6l5rr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:mirror.gcr.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-6l5rr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:sc2-rdops-vm05-dhcp-174-51.eng.vmware.com,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 06:35:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 06:36:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 06:36:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 06:36:40 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.192.174.51,PodIP:172.26.1.213,StartTime:2021-02-22 06:36:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2021-02-22 06:36:39 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:mirror.gcr.io/library/httpd:2.4.38-alpine,ImageID:httpd-d22d0e2cfeeaa0c1d2773814f5199d564ac0eae2-v4616,ContainerID:e0746624-e036-4247-bb3c-81d56ec60f36,Started:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.26.1.213,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 22 06:36:50.755: INFO: Pod "webserver-deployment-79c655c588-rd8j5" is available:
&Pod{ObjectMeta:{webserver-deployment-79c655c588-rd8j5 webserver-deployment-79c655c588- deployment-6798 /api/v1/namespaces/deployment-6798/pods/webserver-deployment-79c655c588-rd8j5 808d5f96-5f5a-4a4f-bf1c-bc5c228a834c 152195 0 2021-02-22 06:35:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:79c655c588] map[attachment_id:23754708-4657-4794-b3b2-2c4db5dc4625 kubernetes.io/psp:e2e-test-privileged-psp mac:04:50:56:00:28:18 vlan:None vmware-system-ephemeral-disk-uuid:6000C296-22ba-14fd-085f-95aacaad6034 vmware-system-image-references:{"httpd":"httpd-d22d0e2cfeeaa0c1d2773814f5199d564ac0eae2-v40751"} vmware-system-vm-moid:vm-706:6b180790-afb7-40a7-b1c1-16f00c9b6783 vmware-system-vm-uuid:502f3ad0-b807-0316-261f-3d7376aa0463] [{apps/v1 ReplicaSet webserver-deployment-79c655c588 2d4a3051-a859-4bf3-8ca3-d132a375274d 0xc001a460ff 0xc001a46110}] [lifecycle-controller/system.vmware.com]  [{kube-controller-manager Update v1 2021-02-22 06:35:52 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 50 100 52 97 51 48 53 49 45 97 56 53 57 45 52 98 102 51 45 56 99 97 51 45 100 49 51 50 97 51 55 53 50 55 52 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {image-controller Update v1 2021-02-22 06:35:53 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 105 109 97 103 101 45 114 101 102 101 114 101 110 99 101 115 34 58 123 125 125 125 125],}} {nsx-ncp-75bf644549-ps9h2 Update v1 2021-02-22 06:36:01 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 97 116 116 97 99 104 109 101 110 116 95 105 100 34 58 123 125 44 34 102 58 109 97 99 34 58 123 125 44 34 102 58 118 108 97 110 34 58 123 125 125 125 125],}} {scheduler-extender Update v1 2021-02-22 06:36:30 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 101 112 104 101 109 101 114 97 108 45 100 105 115 107 45 117 117 105 100 34 58 123 125 44 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 118 109 45 109 111 105 100 34 58 123 125 44 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 118 109 45 117 117 105 100 34 58 123 125 125 44 34 102 58 102 105 110 97 108 105 122 101 114 115 34 58 123 34 46 34 58 123 125 44 34 118 58 92 34 108 105 102 101 99 121 99 108 101 45 99 111 110 116 114 111 108 108 101 114 47 115 121 115 116 101 109 46 118 109 119 97 114 101 46 99 111 109 92 34 34 58 123 125 125 125 125],}} {spherelet Update v1 2021-02-22 06:36:45 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 102 58 101 110 118 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 95 52 52 51 95 84 67 80 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 95 52 52 51 95 84 67 80 95 65 68 68 82 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 95 52 52 51 95 84 67 80 95 80 79 82 84 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 95 52 52 51 95 84 67 80 95 80 82 79 84 79 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 83 69 82 86 73 67 69 95 72 79 83 84 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 83 69 82 86 73 67 69 95 80 79 82 84 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 83 69 82 86 73 67 69 95 80 79 82 84 95 72 84 84 80 83 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 55 50 46 50 54 46 49 46 50 49 49 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-6l5rr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-6l5rr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:mirror.gcr.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-6l5rr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:sc2-rdops-vm05-dhcp-174-51.eng.vmware.com,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 06:35:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 06:36:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 06:36:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 06:36:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.192.174.51,PodIP:172.26.1.211,StartTime:2021-02-22 06:36:41 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2021-02-22 06:36:43 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:mirror.gcr.io/library/httpd:2.4.38-alpine,ImageID:httpd-d22d0e2cfeeaa0c1d2773814f5199d564ac0eae2-v40751,ContainerID:b43d9f82-104a-40b6-8b6f-6cd83061f89e,Started:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.26.1.211,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 22 06:36:50.757: INFO: Pod "webserver-deployment-79c655c588-vkhp6" is not available:
&Pod{ObjectMeta:{webserver-deployment-79c655c588-vkhp6 webserver-deployment-79c655c588- deployment-6798 /api/v1/namespaces/deployment-6798/pods/webserver-deployment-79c655c588-vkhp6 8d1f9cc2-65f4-42d0-9885-5119446d15a8 152327 0 2021-02-22 06:36:48 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:79c655c588] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-79c655c588 2d4a3051-a859-4bf3-8ca3-d132a375274d 0xc001a462f7 0xc001a462f8}] []  [{kube-controller-manager Update v1 2021-02-22 06:36:48 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 50 100 52 97 51 48 53 49 45 97 56 53 57 45 52 98 102 51 45 56 99 97 51 45 100 49 51 50 97 51 55 53 50 55 52 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-6l5rr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-6l5rr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:mirror.gcr.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-6l5rr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:sc2-rdops-vm05-dhcp-174-51.eng.vmware.com,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 06:36:49 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 22 06:36:50.759: INFO: Pod "webserver-deployment-79c655c588-vr9p9" is not available:
&Pod{ObjectMeta:{webserver-deployment-79c655c588-vr9p9 webserver-deployment-79c655c588- deployment-6798 /api/v1/namespaces/deployment-6798/pods/webserver-deployment-79c655c588-vr9p9 d9b68230-5bd0-4739-a56a-c7bff5605b3a 152342 0 2021-02-22 06:36:48 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:79c655c588] map[kubernetes.io/psp:e2e-test-privileged-psp vmware-system-image-references:{"httpd":"httpd-d22d0e2cfeeaa0c1d2773814f5199d564ac0eae2-v4616"}] [{apps/v1 ReplicaSet webserver-deployment-79c655c588 2d4a3051-a859-4bf3-8ca3-d132a375274d 0xc001a46410 0xc001a46411}] []  [{kube-controller-manager Update v1 2021-02-22 06:36:48 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 50 100 52 97 51 48 53 49 45 97 56 53 57 45 52 98 102 51 45 56 99 97 51 45 100 49 51 50 97 51 55 53 50 55 52 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {image-controller Update v1 2021-02-22 06:36:49 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 105 109 97 103 101 45 114 101 102 101 114 101 110 99 101 115 34 58 123 125 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-6l5rr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-6l5rr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:mirror.gcr.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-6l5rr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:sc2-rdops-vm05-dhcp-179-105.eng.vmware.com,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 06:36:49 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 22 06:36:50.763: INFO: Pod "webserver-deployment-79c655c588-w5lb6" is not available:
&Pod{ObjectMeta:{webserver-deployment-79c655c588-w5lb6 webserver-deployment-79c655c588- deployment-6798 /api/v1/namespaces/deployment-6798/pods/webserver-deployment-79c655c588-w5lb6 3043e072-11bd-4ab6-9e7c-d752685fca6b 152339 0 2021-02-22 06:36:48 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:79c655c588] map[kubernetes.io/psp:e2e-test-privileged-psp vmware-system-image-references:{"httpd":"httpd-d22d0e2cfeeaa0c1d2773814f5199d564ac0eae2-v4616"}] [{apps/v1 ReplicaSet webserver-deployment-79c655c588 2d4a3051-a859-4bf3-8ca3-d132a375274d 0xc001a466a0 0xc001a466a1}] []  [{kube-controller-manager Update v1 2021-02-22 06:36:48 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 50 100 52 97 51 48 53 49 45 97 56 53 57 45 52 98 102 51 45 56 99 97 51 45 100 49 51 50 97 51 55 53 50 55 52 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {image-controller Update v1 2021-02-22 06:36:49 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 105 109 97 103 101 45 114 101 102 101 114 101 110 99 101 115 34 58 123 125 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-6l5rr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-6l5rr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:mirror.gcr.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-6l5rr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:sc2-rdops-vm05-dhcp-174-51.eng.vmware.com,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 06:36:49 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 22 06:36:50.764: INFO: Pod "webserver-deployment-79c655c588-xwsg8" is available:
&Pod{ObjectMeta:{webserver-deployment-79c655c588-xwsg8 webserver-deployment-79c655c588- deployment-6798 /api/v1/namespaces/deployment-6798/pods/webserver-deployment-79c655c588-xwsg8 a500a1d7-082c-48f4-96ec-277d0861f592 152187 0 2021-02-22 06:35:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:79c655c588] map[attachment_id:742ccdf7-7e94-45e0-8821-d9d32fecd23e kubernetes.io/psp:e2e-test-privileged-psp mac:04:50:56:00:28:21 vlan:None vmware-system-ephemeral-disk-uuid:6000C296-6ec3-397b-237d-2b186cc1efd5 vmware-system-image-references:{"httpd":"httpd-d22d0e2cfeeaa0c1d2773814f5199d564ac0eae2-v4616"} vmware-system-vm-moid:vm-714:6b180790-afb7-40a7-b1c1-16f00c9b6783 vmware-system-vm-uuid:502fc5f3-c759-5bc0-c281-350ad0e4d7cf] [{apps/v1 ReplicaSet webserver-deployment-79c655c588 2d4a3051-a859-4bf3-8ca3-d132a375274d 0xc001a46877 0xc001a46878}] [lifecycle-controller/system.vmware.com]  [{kube-controller-manager Update v1 2021-02-22 06:35:52 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 50 100 52 97 51 48 53 49 45 97 56 53 57 45 52 98 102 51 45 56 99 97 51 45 100 49 51 50 97 51 55 53 50 55 52 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {nsx-ncp-75bf644549-ps9h2 Update v1 2021-02-22 06:36:03 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 97 116 116 97 99 104 109 101 110 116 95 105 100 34 58 123 125 44 34 102 58 109 97 99 34 58 123 125 44 34 102 58 118 108 97 110 34 58 123 125 125 125 125],}} {image-controller Update v1 2021-02-22 06:36:06 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 105 109 97 103 101 45 114 101 102 101 114 101 110 99 101 115 34 58 123 125 125 125 125],}} {scheduler-extender Update v1 2021-02-22 06:36:30 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 101 112 104 101 109 101 114 97 108 45 100 105 115 107 45 117 117 105 100 34 58 123 125 44 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 118 109 45 109 111 105 100 34 58 123 125 44 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 118 109 45 117 117 105 100 34 58 123 125 125 44 34 102 58 102 105 110 97 108 105 122 101 114 115 34 58 123 34 46 34 58 123 125 44 34 118 58 92 34 108 105 102 101 99 121 99 108 101 45 99 111 110 116 114 111 108 108 101 114 47 115 121 115 116 101 109 46 118 109 119 97 114 101 46 99 111 109 92 34 34 58 123 125 125 125 125],}} {spherelet Update v1 2021-02-22 06:36:44 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 102 58 101 110 118 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 95 52 52 51 95 84 67 80 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 95 52 52 51 95 84 67 80 95 65 68 68 82 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 95 52 52 51 95 84 67 80 95 80 79 82 84 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 95 52 52 51 95 84 67 80 95 80 82 79 84 79 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 83 69 82 86 73 67 69 95 72 79 83 84 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 83 69 82 86 73 67 69 95 80 79 82 84 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 83 69 82 86 73 67 69 95 80 79 82 84 95 72 84 84 80 83 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 55 50 46 50 54 46 49 46 50 49 55 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-6l5rr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-6l5rr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:mirror.gcr.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-6l5rr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:sc2-rdops-vm05-dhcp-174-51.eng.vmware.com,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 06:35:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 06:36:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 06:36:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 06:36:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.192.174.51,PodIP:172.26.1.217,StartTime:2021-02-22 06:36:40 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2021-02-22 06:36:42 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:mirror.gcr.io/library/httpd:2.4.38-alpine,ImageID:httpd-d22d0e2cfeeaa0c1d2773814f5199d564ac0eae2-v4616,ContainerID:ffdd71a6-31f3-4890-9c7b-15d6b147b8ee,Started:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.26.1.217,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 22 06:36:50.768: INFO: Pod "webserver-deployment-79c655c588-zklbx" is not available:
&Pod{ObjectMeta:{webserver-deployment-79c655c588-zklbx webserver-deployment-79c655c588- deployment-6798 /api/v1/namespaces/deployment-6798/pods/webserver-deployment-79c655c588-zklbx 20303e99-5a54-40f0-99b0-49b025cde6bd 152332 0 2021-02-22 06:36:49 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:79c655c588] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-79c655c588 2d4a3051-a859-4bf3-8ca3-d132a375274d 0xc001a46b97 0xc001a46b98}] []  [{kube-controller-manager Update v1 2021-02-22 06:36:49 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 50 100 52 97 51 48 53 49 45 97 56 53 57 45 52 98 102 51 45 56 99 97 51 45 100 49 51 50 97 51 55 53 50 55 52 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-6l5rr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-6l5rr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:mirror.gcr.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-6l5rr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:36:50.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6798" for this suite.

â€¢ [SLOW TEST:60.566 seconds]
[sig-apps] Deployment
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should support proportional scaling [Conformance]","total":270,"completed":187,"skipped":3269,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:36:52.319: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-876
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward api env vars
Feb 22 06:36:53.255: INFO: Waiting up to 5m0s for pod "downward-api-b12ac9f0-5f2d-40d7-a3c7-a4e2ea6bc55f" in namespace "downward-api-876" to be "Succeeded or Failed"
Feb 22 06:36:53.270: INFO: Pod "downward-api-b12ac9f0-5f2d-40d7-a3c7-a4e2ea6bc55f": Phase="Pending", Reason="", readiness=false. Elapsed: 15.140738ms
Feb 22 06:36:55.286: INFO: Pod "downward-api-b12ac9f0-5f2d-40d7-a3c7-a4e2ea6bc55f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031660919s
Feb 22 06:36:57.426: INFO: Pod "downward-api-b12ac9f0-5f2d-40d7-a3c7-a4e2ea6bc55f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.17166704s
Feb 22 06:36:59.675: INFO: Pod "downward-api-b12ac9f0-5f2d-40d7-a3c7-a4e2ea6bc55f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.420165982s
Feb 22 06:37:01.721: INFO: Pod "downward-api-b12ac9f0-5f2d-40d7-a3c7-a4e2ea6bc55f": Phase="Pending", Reason="", readiness=false. Elapsed: 8.46609926s
Feb 22 06:37:03.820: INFO: Pod "downward-api-b12ac9f0-5f2d-40d7-a3c7-a4e2ea6bc55f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.565551997s
Feb 22 06:37:06.013: INFO: Pod "downward-api-b12ac9f0-5f2d-40d7-a3c7-a4e2ea6bc55f": Phase="Pending", Reason="", readiness=false. Elapsed: 12.758344655s
Feb 22 06:37:08.792: INFO: Pod "downward-api-b12ac9f0-5f2d-40d7-a3c7-a4e2ea6bc55f": Phase="Pending", Reason="", readiness=false. Elapsed: 15.536775144s
Feb 22 06:37:12.957: INFO: Pod "downward-api-b12ac9f0-5f2d-40d7-a3c7-a4e2ea6bc55f": Phase="Pending", Reason="", readiness=false. Elapsed: 19.701888044s
Feb 22 06:37:15.509: INFO: Pod "downward-api-b12ac9f0-5f2d-40d7-a3c7-a4e2ea6bc55f": Phase="Pending", Reason="", readiness=false. Elapsed: 22.253789647s
Feb 22 06:37:17.796: INFO: Pod "downward-api-b12ac9f0-5f2d-40d7-a3c7-a4e2ea6bc55f": Phase="Pending", Reason="", readiness=false. Elapsed: 24.541771453s
Feb 22 06:37:19.997: INFO: Pod "downward-api-b12ac9f0-5f2d-40d7-a3c7-a4e2ea6bc55f": Phase="Pending", Reason="", readiness=false. Elapsed: 26.742640459s
Feb 22 06:37:22.104: INFO: Pod "downward-api-b12ac9f0-5f2d-40d7-a3c7-a4e2ea6bc55f": Phase="Pending", Reason="", readiness=false. Elapsed: 28.84929984s
Feb 22 06:37:31.992: INFO: Pod "downward-api-b12ac9f0-5f2d-40d7-a3c7-a4e2ea6bc55f": Phase="Pending", Reason="", readiness=false. Elapsed: 38.73729949s
Feb 22 06:37:34.024: INFO: Pod "downward-api-b12ac9f0-5f2d-40d7-a3c7-a4e2ea6bc55f": Phase="Pending", Reason="", readiness=false. Elapsed: 40.769360856s
Feb 22 06:37:36.364: INFO: Pod "downward-api-b12ac9f0-5f2d-40d7-a3c7-a4e2ea6bc55f": Phase="Pending", Reason="", readiness=false. Elapsed: 43.109005059s
Feb 22 06:37:38.391: INFO: Pod "downward-api-b12ac9f0-5f2d-40d7-a3c7-a4e2ea6bc55f": Phase="Pending", Reason="", readiness=false. Elapsed: 45.136550735s
Feb 22 06:37:40.493: INFO: Pod "downward-api-b12ac9f0-5f2d-40d7-a3c7-a4e2ea6bc55f": Phase="Pending", Reason="", readiness=false. Elapsed: 47.237799412s
Feb 22 06:37:42.892: INFO: Pod "downward-api-b12ac9f0-5f2d-40d7-a3c7-a4e2ea6bc55f": Phase="Pending", Reason="", readiness=false. Elapsed: 49.63725486s
Feb 22 06:37:44.948: INFO: Pod "downward-api-b12ac9f0-5f2d-40d7-a3c7-a4e2ea6bc55f": Phase="Pending", Reason="", readiness=false. Elapsed: 51.692879536s
Feb 22 06:37:46.995: INFO: Pod "downward-api-b12ac9f0-5f2d-40d7-a3c7-a4e2ea6bc55f": Phase="Pending", Reason="", readiness=false. Elapsed: 53.740042379s
Feb 22 06:37:49.083: INFO: Pod "downward-api-b12ac9f0-5f2d-40d7-a3c7-a4e2ea6bc55f": Phase="Pending", Reason="", readiness=false. Elapsed: 55.828164186s
Feb 22 06:37:51.413: INFO: Pod "downward-api-b12ac9f0-5f2d-40d7-a3c7-a4e2ea6bc55f": Phase="Pending", Reason="", readiness=false. Elapsed: 58.158132573s
Feb 22 06:37:53.464: INFO: Pod "downward-api-b12ac9f0-5f2d-40d7-a3c7-a4e2ea6bc55f": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.208891535s
Feb 22 06:37:55.529: INFO: Pod "downward-api-b12ac9f0-5f2d-40d7-a3c7-a4e2ea6bc55f": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.274495272s
Feb 22 06:37:57.538: INFO: Pod "downward-api-b12ac9f0-5f2d-40d7-a3c7-a4e2ea6bc55f": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.283349552s
Feb 22 06:37:59.592: INFO: Pod "downward-api-b12ac9f0-5f2d-40d7-a3c7-a4e2ea6bc55f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 1m6.33694082s
STEP: Saw pod success
Feb 22 06:37:59.594: INFO: Pod "downward-api-b12ac9f0-5f2d-40d7-a3c7-a4e2ea6bc55f" satisfied condition "Succeeded or Failed"
Feb 22 06:37:59.615: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com pod downward-api-b12ac9f0-5f2d-40d7-a3c7-a4e2ea6bc55f container dapi-container: <nil>
STEP: delete the pod
Feb 22 06:38:05.984: INFO: Waiting for pod downward-api-b12ac9f0-5f2d-40d7-a3c7-a4e2ea6bc55f to disappear
Feb 22 06:38:06.010: INFO: Pod downward-api-b12ac9f0-5f2d-40d7-a3c7-a4e2ea6bc55f still exists
Feb 22 06:38:08.012: INFO: Waiting for pod downward-api-b12ac9f0-5f2d-40d7-a3c7-a4e2ea6bc55f to disappear
Feb 22 06:38:08.030: INFO: Pod downward-api-b12ac9f0-5f2d-40d7-a3c7-a4e2ea6bc55f still exists
Feb 22 06:38:10.011: INFO: Waiting for pod downward-api-b12ac9f0-5f2d-40d7-a3c7-a4e2ea6bc55f to disappear
Feb 22 06:38:10.020: INFO: Pod downward-api-b12ac9f0-5f2d-40d7-a3c7-a4e2ea6bc55f still exists
Feb 22 06:38:12.011: INFO: Waiting for pod downward-api-b12ac9f0-5f2d-40d7-a3c7-a4e2ea6bc55f to disappear
Feb 22 06:38:12.046: INFO: Pod downward-api-b12ac9f0-5f2d-40d7-a3c7-a4e2ea6bc55f no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:38:12.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-876" for this suite.

â€¢ [SLOW TEST:79.844 seconds]
[sig-node] Downward API
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:34
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]","total":270,"completed":188,"skipped":3291,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:38:12.168: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-1138
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name secret-emptykey-test-826cb1d7-ca73-4686-8183-e3200ec84850
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:38:12.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1138" for this suite.
â€¢{"msg":"PASSED [sig-api-machinery] Secrets should fail to create secret due to empty secret key [Conformance]","total":270,"completed":189,"skipped":3299,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:38:12.627: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-338
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Feb 22 06:38:12.862: INFO: >>> kubeConfig: /root/.kube/config
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:38:47.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-338" for this suite.

â€¢ [SLOW TEST:34.809 seconds]
[k8s.io] Pods
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]","total":270,"completed":190,"skipped":3337,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:38:47.439: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-6689
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Feb 22 06:39:34.326: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:39:34.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-6689" for this suite.

â€¢ [SLOW TEST:47.419 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  blackbox test
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:40
    on terminated container
    /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:133
      should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":270,"completed":191,"skipped":3351,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:39:34.889: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1040
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-map-a9dcba87-311d-4768-b6ba-bded6b619564
STEP: Creating a pod to test consume configMaps
Feb 22 06:39:55.794: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a6a38070-9c48-4295-8fb1-e3f036cdb66d" in namespace "projected-1040" to be "Succeeded or Failed"
Feb 22 06:39:55.836: INFO: Pod "pod-projected-configmaps-a6a38070-9c48-4295-8fb1-e3f036cdb66d": Phase="Pending", Reason="", readiness=false. Elapsed: 41.949019ms
Feb 22 06:39:57.891: INFO: Pod "pod-projected-configmaps-a6a38070-9c48-4295-8fb1-e3f036cdb66d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.096606396s
Feb 22 06:39:59.927: INFO: Pod "pod-projected-configmaps-a6a38070-9c48-4295-8fb1-e3f036cdb66d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.133177106s
Feb 22 06:40:02.054: INFO: Pod "pod-projected-configmaps-a6a38070-9c48-4295-8fb1-e3f036cdb66d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.25947233s
Feb 22 06:40:04.077: INFO: Pod "pod-projected-configmaps-a6a38070-9c48-4295-8fb1-e3f036cdb66d": Phase="Pending", Reason="", readiness=false. Elapsed: 8.283042577s
Feb 22 06:40:06.142: INFO: Pod "pod-projected-configmaps-a6a38070-9c48-4295-8fb1-e3f036cdb66d": Phase="Pending", Reason="", readiness=false. Elapsed: 10.347445718s
Feb 22 06:40:08.197: INFO: Pod "pod-projected-configmaps-a6a38070-9c48-4295-8fb1-e3f036cdb66d": Phase="Pending", Reason="", readiness=false. Elapsed: 12.403116705s
Feb 22 06:40:10.218: INFO: Pod "pod-projected-configmaps-a6a38070-9c48-4295-8fb1-e3f036cdb66d": Phase="Pending", Reason="", readiness=false. Elapsed: 14.424161213s
Feb 22 06:40:12.236: INFO: Pod "pod-projected-configmaps-a6a38070-9c48-4295-8fb1-e3f036cdb66d": Phase="Pending", Reason="", readiness=false. Elapsed: 16.442161708s
Feb 22 06:40:14.269: INFO: Pod "pod-projected-configmaps-a6a38070-9c48-4295-8fb1-e3f036cdb66d": Phase="Pending", Reason="", readiness=false. Elapsed: 18.475031577s
Feb 22 06:40:16.290: INFO: Pod "pod-projected-configmaps-a6a38070-9c48-4295-8fb1-e3f036cdb66d": Phase="Pending", Reason="", readiness=false. Elapsed: 20.495396503s
Feb 22 06:40:18.348: INFO: Pod "pod-projected-configmaps-a6a38070-9c48-4295-8fb1-e3f036cdb66d": Phase="Pending", Reason="", readiness=false. Elapsed: 22.553351875s
Feb 22 06:40:20.362: INFO: Pod "pod-projected-configmaps-a6a38070-9c48-4295-8fb1-e3f036cdb66d": Phase="Pending", Reason="", readiness=false. Elapsed: 24.567744281s
Feb 22 06:40:22.382: INFO: Pod "pod-projected-configmaps-a6a38070-9c48-4295-8fb1-e3f036cdb66d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.587581024s
STEP: Saw pod success
Feb 22 06:40:22.382: INFO: Pod "pod-projected-configmaps-a6a38070-9c48-4295-8fb1-e3f036cdb66d" satisfied condition "Succeeded or Failed"
Feb 22 06:40:22.440: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com pod pod-projected-configmaps-a6a38070-9c48-4295-8fb1-e3f036cdb66d container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 22 06:40:29.381: INFO: Waiting for pod pod-projected-configmaps-a6a38070-9c48-4295-8fb1-e3f036cdb66d to disappear
Feb 22 06:40:29.412: INFO: Pod pod-projected-configmaps-a6a38070-9c48-4295-8fb1-e3f036cdb66d still exists
Feb 22 06:40:31.412: INFO: Waiting for pod pod-projected-configmaps-a6a38070-9c48-4295-8fb1-e3f036cdb66d to disappear
Feb 22 06:40:31.430: INFO: Pod pod-projected-configmaps-a6a38070-9c48-4295-8fb1-e3f036cdb66d still exists
Feb 22 06:40:33.412: INFO: Waiting for pod pod-projected-configmaps-a6a38070-9c48-4295-8fb1-e3f036cdb66d to disappear
Feb 22 06:40:33.425: INFO: Pod pod-projected-configmaps-a6a38070-9c48-4295-8fb1-e3f036cdb66d no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:40:33.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1040" for this suite.

â€¢ [SLOW TEST:58.665 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:36
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","total":270,"completed":192,"skipped":3378,"failed":0}
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should have a working scale subresource [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:40:33.557: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-5613
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-5613
[It] should have a working scale subresource [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating statefulset ss in namespace statefulset-5613
Feb 22 06:40:34.083: INFO: Found 0 stateful pods, waiting for 1
Feb 22 06:40:44.478: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
Feb 22 06:40:54.134: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
Feb 22 06:41:04.111: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Feb 22 06:41:04.202: INFO: Deleting all statefulset in ns statefulset-5613
Feb 22 06:41:04.215: INFO: Scaling statefulset ss to 0
Feb 22 06:41:24.399: INFO: Waiting for statefulset status.replicas updated to 0
Feb 22 06:41:24.416: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:41:24.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5613" for this suite.

â€¢ [SLOW TEST:51.058 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
    should have a working scale subresource [Conformance]
    /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]","total":270,"completed":193,"skipped":3378,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:41:24.655: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6394
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Feb 22 06:41:25.098: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config create -f - --namespace=kubectl-6394'
Feb 22 06:41:26.365: INFO: stderr: ""
Feb 22 06:41:26.365: INFO: stdout: "replicationcontroller/agnhost-master created\n"
Feb 22 06:41:26.365: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config create -f - --namespace=kubectl-6394'
Feb 22 06:41:27.495: INFO: stderr: ""
Feb 22 06:41:27.495: INFO: stdout: "service/agnhost-master created\n"
STEP: Waiting for Agnhost master to start.
Feb 22 06:41:28.514: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 06:41:28.514: INFO: Found 0 / 1
Feb 22 06:41:29.539: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 06:41:29.539: INFO: Found 0 / 1
Feb 22 06:41:30.506: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 06:41:30.506: INFO: Found 0 / 1
Feb 22 06:41:31.515: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 06:41:31.515: INFO: Found 0 / 1
Feb 22 06:41:32.507: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 06:41:32.507: INFO: Found 0 / 1
Feb 22 06:41:33.528: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 06:41:33.528: INFO: Found 0 / 1
Feb 22 06:41:34.506: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 06:41:34.506: INFO: Found 0 / 1
Feb 22 06:41:35.508: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 06:41:35.508: INFO: Found 0 / 1
Feb 22 06:41:36.505: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 06:41:36.505: INFO: Found 0 / 1
Feb 22 06:41:37.857: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 06:41:37.859: INFO: Found 0 / 1
Feb 22 06:41:38.754: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 06:41:38.754: INFO: Found 0 / 1
Feb 22 06:41:39.647: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 06:41:39.647: INFO: Found 0 / 1
Feb 22 06:41:40.541: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 06:41:40.541: INFO: Found 0 / 1
Feb 22 06:41:41.505: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 06:41:41.505: INFO: Found 0 / 1
Feb 22 06:41:42.509: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 06:41:42.509: INFO: Found 0 / 1
Feb 22 06:41:43.621: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 06:41:43.621: INFO: Found 0 / 1
Feb 22 06:41:44.508: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 06:41:44.508: INFO: Found 0 / 1
Feb 22 06:41:45.518: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 06:41:45.518: INFO: Found 0 / 1
Feb 22 06:41:46.506: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 06:41:46.507: INFO: Found 0 / 1
Feb 22 06:41:47.713: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 06:41:47.713: INFO: Found 0 / 1
Feb 22 06:41:48.562: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 06:41:48.562: INFO: Found 0 / 1
Feb 22 06:41:49.507: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 06:41:49.507: INFO: Found 0 / 1
Feb 22 06:41:50.509: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 06:41:50.509: INFO: Found 0 / 1
Feb 22 06:41:51.548: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 06:41:51.548: INFO: Found 0 / 1
Feb 22 06:41:52.517: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 06:41:52.517: INFO: Found 0 / 1
Feb 22 06:41:53.567: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 06:41:53.567: INFO: Found 0 / 1
Feb 22 06:41:54.509: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 06:41:54.510: INFO: Found 1 / 1
Feb 22 06:41:54.510: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 22 06:41:54.527: INFO: Selector matched 1 pods for map[app:agnhost]
Feb 22 06:41:54.528: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 22 06:41:54.529: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config describe pod agnhost-master-v8pqt --namespace=kubectl-6394'
Feb 22 06:41:55.117: INFO: stderr: ""
Feb 22 06:41:55.118: INFO: stdout: "Name:         agnhost-master-v8pqt\nNamespace:    kubectl-6394\nPriority:     0\nNode:         sc2-rdops-vm05-dhcp-174-51.eng.vmware.com/10.192.174.51\nStart Time:   Mon, 22 Feb 2021 06:41:48 +0000\nLabels:       app=agnhost\n              role=master\nAnnotations:  attachment_id: a55e0e03-cfb2-4458-b44a-9426660ea45a\n              kubernetes.io/psp: e2e-test-privileged-psp\n              mac: 04:50:56:00:28:12\n              vlan: None\n              vmware-system-ephemeral-disk-uuid: 6000C29c-2010-1936-499e-95676f1d9cfb\n              vmware-system-image-references: {\"agnhost-master\":\"agnhost-4c5d323a799f707178acf281f8da2d9a581ad331-v57809\"}\n              vmware-system-vm-moid: vm-756:6b180790-afb7-40a7-b1c1-16f00c9b6783\n              vmware-system-vm-uuid: 502f22f9-ba81-a523-1fd4-01f3907f5f9f\nStatus:       Running\nIP:           172.26.1.210\nIPs:\n  IP:           172.26.1.210\nControlled By:  ReplicationController/agnhost-master\nContainers:\n  agnhost-master:\n    Container ID:   0b7c5685-f35e-4aa2-b0e6-fec2f9f1918d\n    Image:          us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12\n    Image ID:       agnhost-4c5d323a799f707178acf281f8da2d9a581ad331-v57809\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Mon, 22 Feb 2021 06:41:50 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-mc8bn (ro)\nConditions:\n  Type              Status\n  PodScheduled      True \n  Ready             True \n  Initialized       True \n  ContainersReady   True \nVolumes:\n  default-token-mc8bn:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-mc8bn\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason                        Age   From               Message\n  ----    ------                        ----  ----               -------\n  Normal  Scheduled                     28s   default-scheduler  Successfully assigned kubectl-6394/agnhost-master-v8pqt to sc2-rdops-vm05-dhcp-174-51.eng.vmware.com\n  Normal  Image                         29s   image-controller   Image agnhost-4c5d323a799f707178acf281f8da2d9a581ad331-v57809 bound successfully\n  Normal  SuccessfulRealizeNSXResource  15s   nsx-container-ncp  Successfully realized NSX resource for Pod\n  Normal  Pulling                       12s   kubelet            Waiting for Image kubectl-6394/agnhost-4c5d323a799f707178acf281f8da2d9a581ad331-v57809\n  Normal  Pulled                        12s   kubelet            Image kubectl-6394/agnhost-4c5d323a799f707178acf281f8da2d9a581ad331-v57809 is ready\n  Normal  Created                       2s    kubelet            Created container agnhost-master\n  Normal  Started                       2s    kubelet            Started container agnhost-master\n  Normal  SuccessfulMountVolume         2s    kubelet            Successfully mounted volume default-token-mc8bn\n"
Feb 22 06:41:55.119: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config describe rc agnhost-master --namespace=kubectl-6394'
Feb 22 06:41:55.621: INFO: stderr: ""
Feb 22 06:41:55.621: INFO: stdout: "Name:         agnhost-master\nNamespace:    kubectl-6394\nSelector:     app=agnhost,role=master\nLabels:       app=agnhost\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=master\n  Containers:\n   agnhost-master:\n    Image:        us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  29s   replication-controller  Created pod: agnhost-master-v8pqt\n"
Feb 22 06:41:55.621: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config describe service agnhost-master --namespace=kubectl-6394'
Feb 22 06:41:55.927: INFO: stderr: ""
Feb 22 06:41:55.927: INFO: stdout: "Name:              agnhost-master\nNamespace:         kubectl-6394\nLabels:            app=agnhost\n                   role=master\nAnnotations:       <none>\nSelector:          app=agnhost,role=master\nType:              ClusterIP\nIP:                172.24.65.179\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         172.26.1.210:6379\nSession Affinity:  None\nEvents:            <none>\n"
Feb 22 06:41:55.959: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config describe node 422f888355a48498536ab68056030072'
Feb 22 06:41:56.563: INFO: stderr: ""
Feb 22 06:41:56.564: INFO: stdout: "Name:               422f888355a48498536ab68056030072\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=422f888355a48498536ab68056030072\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/master=\nAnnotations:        kubeadm.alpha.kubernetes.io/cri-socket: /run/containerd/containerd.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Mon, 22 Feb 2021 02:39:47 +0000\nTaints:             node-role.kubernetes.io/master:NoSchedule\nUnschedulable:      false\nLease:\n  HolderIdentity:  422f888355a48498536ab68056030072\n  AcquireTime:     <unset>\n  RenewTime:       Mon, 22 Feb 2021 06:41:47 +0000\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Mon, 22 Feb 2021 06:40:12 +0000   Mon, 22 Feb 2021 02:39:47 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Mon, 22 Feb 2021 06:40:12 +0000   Mon, 22 Feb 2021 02:39:47 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Mon, 22 Feb 2021 06:40:12 +0000   Mon, 22 Feb 2021 02:39:47 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Mon, 22 Feb 2021 06:40:12 +0000   Mon, 22 Feb 2021 02:54:30 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  172.26.0.2\n  Hostname:    422f888355a48498536ab68056030072\nCapacity:\n  cpu:                2\n  ephemeral-storage:  32881404Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             8139040Ki\n  pods:               110\nAllocatable:\n  cpu:                2\n  ephemeral-storage:  32881404Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             8139040Ki\n  pods:               110\nSystem Info:\n  Machine ID:                                32038c9d510d449b8de77cd12337280b\n  System UUID:                               83882f42-a455-9884-536a-b68056030072\n  Boot ID:                                   757dc53a-3596-47c3-94e2-20b908c9b595\n  Kernel Version:                            4.19.164-3.ph3-esx\n  OS Image:                                  VMware Photon OS/Linux\n  Operating System:                          linux\n  Architecture:                              amd64\n  Container Runtime Version:                 containerd://1.3.3\n  Kubelet Version:                           v1.18.10+wcp.2\n  Kube-Proxy Version:                        v1.18.10+wcp.2\nNon-terminated Pods:                         (35 in total)\n  Namespace                                  Name                                                               CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                                  ----                                                               ------------  ----------  ---------------  -------------  ---\n  kube-system                                coredns-5dc469f6f-t8c8s                                            100m (5%)     0 (0%)      70Mi (0%)        170Mi (2%)     3h59m\n  kube-system                                csr-signer-422f888355a48498536ab68056030072                        0 (0%)        0 (0%)      0 (0%)           0 (0%)         3h59m\n  kube-system                                docker-registry-422f888355a48498536ab68056030072                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         4h\n  kube-system                                etcd-422f888355a48498536ab68056030072                              0 (0%)        0 (0%)      0 (0%)           0 (0%)         4h\n  kube-system                                kube-apiserver-422f888355a48498536ab68056030072                    250m (12%)    0 (0%)      0 (0%)           0 (0%)         3h48m\n  kube-system                                kube-controller-manager-422f888355a48498536ab68056030072           200m (10%)    0 (0%)      0 (0%)           0 (0%)         3h59m\n  kube-system                                kube-proxy-9b49t                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         3h59m\n  kube-system                                kube-scheduler-422f888355a48498536ab68056030072                    100m (5%)     0 (0%)      0 (0%)           0 (0%)         174m\n  kube-system                                kubectl-plugin-vsphere-422f888355a48498536ab68056030072            0 (0%)        0 (0%)      0 (0%)           0 (0%)         4h\n  kube-system                                wcp-authproxy-422f888355a48498536ab68056030072                     0 (0%)        0 (0%)      0 (0%)           0 (0%)         3h52m\n  kube-system                                wcp-fip-422f888355a48498536ab68056030072                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         4h\n  vmware-system-appplatform-operator-system  vmware-system-appplatform-operator-mgr-0                           100m (5%)     800m (40%)  20Mi (0%)        200Mi (2%)     4h\n  vmware-system-appplatform-operator-system  vmware-system-psp-operator-mgr-bd448c899-l2dj5                     100m (5%)     800m (40%)  20Mi (0%)        200Mi (2%)     3h53m\n  vmware-system-capw                         capi-controller-manager-dfd9d6447-jxx5x                            20m (1%)      500m (25%)  150Mi (1%)       1200Mi (15%)   3h54m\n  vmware-system-capw                         capi-kubeadm-bootstrap-controller-manager-69cff4b44b-psxzc         20m (1%)      500m (25%)  150Mi (1%)       1200Mi (15%)   3h54m\n  vmware-system-capw                         capi-kubeadm-bootstrap-webhook-5b7df9dd86-bwxxs                    20m (1%)      500m (25%)  150Mi (1%)       1200Mi (15%)   3h54m\n  vmware-system-capw                         capi-kubeadm-control-plane-controller-manager-558fb7d468-fzx7c     20m (1%)      500m (25%)  150Mi (1%)       1200Mi (15%)   3h54m\n  vmware-system-capw                         capi-kubeadm-control-plane-webhook-75dcd4c988-ds9v6                20m (1%)      500m (25%)  150Mi (1%)       1200Mi (15%)   3h54m\n  vmware-system-capw                         capi-webhook-69dd568bcc-98hsq                                      20m (1%)      500m (25%)  150Mi (1%)       1200Mi (15%)   3h54m\n  vmware-system-capw                         capw-controller-manager-55f69b8994-2vw7n                           20m (1%)      350m (17%)  150Mi (1%)       800Mi (10%)    3h54m\n  vmware-system-capw                         capw-webhook-7c699b6dc5-vrdmk                                      20m (1%)      350m (17%)  150Mi (1%)       800Mi (10%)    3h54m\n  vmware-system-cert-manager                 cert-manager-6bfcdd64d7-lx6dm                                      0 (0%)        0 (0%)      0 (0%)           0 (0%)         3h59m\n  vmware-system-cert-manager                 cert-manager-cainjector-d6d65789-bqpzj                             0 (0%)        0 (0%)      0 (0%)           0 (0%)         3h59m\n  vmware-system-cert-manager                 cert-manager-webhook-6458d865dc-jzrq9                              0 (0%)        0 (0%)      0 (0%)           0 (0%)         3h59m\n  vmware-system-csi                          vsphere-csi-controller-599b696656-8582v                            0 (0%)        0 (0%)      0 (0%)           0 (0%)         3h52m\n  vmware-system-kubeimage                    image-controller-648894d4f4-lmvfm                                  0 (0%)        0 (0%)      0 (0%)           0 (0%)         4h\n  vmware-system-license-operator             vmware-system-license-operator-controller-manager-56db59d6ttmkp    100m (5%)     150m (7%)   20Mi (0%)        300Mi (3%)     3h52m\n  vmware-system-logging                      fluentbit-w6v45                                                    100m (5%)     500m (25%)  0 (0%)           0 (0%)         4h\n  vmware-system-nsop                         vmware-system-nsop-controller-manager-78dcd47c85-q2z6q             100m (5%)     100m (5%)   20Mi (0%)        100Mi (1%)     3h52m\n  vmware-system-nsx                          nsx-ncp-75bf644549-ps9h2                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         4h\n  vmware-system-registry                     vmware-registry-controller-manager-6f788c669-pqwc9                 200m (10%)    200m (10%)  150Mi (1%)       350Mi (4%)     4h\n  vmware-system-tkg                          vmware-system-tkg-controller-manager-7788d5cb55-9kpj2              110m (5%)     400m (20%)  120Mi (1%)       460Mi (5%)     3h53m\n  vmware-system-tkg                          vmware-system-tkg-webhook-c7cd4d7f6-f92s6                          20m (1%)      400m (20%)  90Mi (1%)        120Mi (1%)     3h53m\n  vmware-system-ucs                          upgrade-compatibility-service-9b97cb576-bmxxh                      100m (5%)     1 (50%)     20Mi (0%)        30Mi (0%)      3h59m\n  vmware-system-vmop                         vmware-system-vmop-controller-manager-65585cb69-q6hlz              100m (5%)     250m (12%)  75Mi (0%)        300Mi (3%)     3h53m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests      Limits\n  --------           --------      ------\n  cpu                1840m (92%)   8300m (415%)\n  memory             1805Mi (22%)  11030Mi (138%)\n  ephemeral-storage  0 (0%)        0 (0%)\n  hugepages-1Gi      0 (0%)        0 (0%)\n  hugepages-2Mi      0 (0%)        0 (0%)\nEvents:              <none>\n"
Feb 22 06:41:56.565: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config describe namespace kubectl-6394'
Feb 22 06:41:56.807: INFO: stderr: ""
Feb 22 06:41:56.807: INFO: stdout: "Name:         kubectl-6394\nLabels:       e2e-framework=kubectl\n              e2e-run=49da0b2e-ba34-411c-817a-d046574ac55a\nAnnotations:  ls_id-0: 24db986e-3a7c-4d9b-8e6b-2a410ac69607\n              ncp/extpoolid: domain-c9:6b180790-afb7-40a7-b1c1-16f00c9b6783-ippool-192-168-124-1-192-168-124-254\n              ncp/router_id: t1_35a8fa06-835c-4ae0-8a82-11611d3448b2_rtr\n              ncp/snat_ip: 192.168.124.30\n              ncp/subnet-0: 172.26.1.208/28\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:41:56.810: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6394" for this suite.

â€¢ [SLOW TEST:32.229 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl describe
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:978
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods  [Conformance]","total":270,"completed":194,"skipped":3418,"failed":0}
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:41:56.908: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1457
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0777 on node default medium
Feb 22 06:41:57.382: INFO: Waiting up to 5m0s for pod "pod-5d3befc5-16d5-4626-b53d-0562dcc8e6a3" in namespace "emptydir-1457" to be "Succeeded or Failed"
Feb 22 06:41:57.406: INFO: Pod "pod-5d3befc5-16d5-4626-b53d-0562dcc8e6a3": Phase="Pending", Reason="", readiness=false. Elapsed: 23.702629ms
Feb 22 06:41:59.448: INFO: Pod "pod-5d3befc5-16d5-4626-b53d-0562dcc8e6a3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.06514867s
Feb 22 06:42:01.581: INFO: Pod "pod-5d3befc5-16d5-4626-b53d-0562dcc8e6a3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.198376845s
Feb 22 06:42:03.607: INFO: Pod "pod-5d3befc5-16d5-4626-b53d-0562dcc8e6a3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.224183565s
Feb 22 06:42:05.769: INFO: Pod "pod-5d3befc5-16d5-4626-b53d-0562dcc8e6a3": Phase="Pending", Reason="", readiness=false. Elapsed: 8.386058005s
Feb 22 06:42:07.793: INFO: Pod "pod-5d3befc5-16d5-4626-b53d-0562dcc8e6a3": Phase="Pending", Reason="", readiness=false. Elapsed: 10.410836764s
Feb 22 06:42:09.805: INFO: Pod "pod-5d3befc5-16d5-4626-b53d-0562dcc8e6a3": Phase="Pending", Reason="", readiness=false. Elapsed: 12.422861762s
Feb 22 06:42:11.818: INFO: Pod "pod-5d3befc5-16d5-4626-b53d-0562dcc8e6a3": Phase="Pending", Reason="", readiness=false. Elapsed: 14.435511874s
Feb 22 06:42:13.828: INFO: Pod "pod-5d3befc5-16d5-4626-b53d-0562dcc8e6a3": Phase="Pending", Reason="", readiness=false. Elapsed: 16.44581219s
Feb 22 06:42:15.845: INFO: Pod "pod-5d3befc5-16d5-4626-b53d-0562dcc8e6a3": Phase="Pending", Reason="", readiness=false. Elapsed: 18.462977384s
Feb 22 06:42:17.852: INFO: Pod "pod-5d3befc5-16d5-4626-b53d-0562dcc8e6a3": Phase="Pending", Reason="", readiness=false. Elapsed: 20.469659848s
Feb 22 06:42:19.861: INFO: Pod "pod-5d3befc5-16d5-4626-b53d-0562dcc8e6a3": Phase="Pending", Reason="", readiness=false. Elapsed: 22.478619702s
Feb 22 06:42:21.877: INFO: Pod "pod-5d3befc5-16d5-4626-b53d-0562dcc8e6a3": Phase="Pending", Reason="", readiness=false. Elapsed: 24.494547196s
Feb 22 06:42:23.887: INFO: Pod "pod-5d3befc5-16d5-4626-b53d-0562dcc8e6a3": Phase="Pending", Reason="", readiness=false. Elapsed: 26.504005252s
Feb 22 06:42:25.905: INFO: Pod "pod-5d3befc5-16d5-4626-b53d-0562dcc8e6a3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 28.522500056s
STEP: Saw pod success
Feb 22 06:42:25.905: INFO: Pod "pod-5d3befc5-16d5-4626-b53d-0562dcc8e6a3" satisfied condition "Succeeded or Failed"
Feb 22 06:42:25.934: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com pod pod-5d3befc5-16d5-4626-b53d-0562dcc8e6a3 container test-container: <nil>
STEP: delete the pod
Feb 22 06:42:32.936: INFO: Waiting for pod pod-5d3befc5-16d5-4626-b53d-0562dcc8e6a3 to disappear
Feb 22 06:42:32.963: INFO: Pod pod-5d3befc5-16d5-4626-b53d-0562dcc8e6a3 still exists
Feb 22 06:42:34.963: INFO: Waiting for pod pod-5d3befc5-16d5-4626-b53d-0562dcc8e6a3 to disappear
Feb 22 06:42:34.979: INFO: Pod pod-5d3befc5-16d5-4626-b53d-0562dcc8e6a3 still exists
Feb 22 06:42:36.963: INFO: Waiting for pod pod-5d3befc5-16d5-4626-b53d-0562dcc8e6a3 to disappear
Feb 22 06:42:37.007: INFO: Pod pod-5d3befc5-16d5-4626-b53d-0562dcc8e6a3 still exists
Feb 22 06:42:38.964: INFO: Waiting for pod pod-5d3befc5-16d5-4626-b53d-0562dcc8e6a3 to disappear
Feb 22 06:42:38.976: INFO: Pod pod-5d3befc5-16d5-4626-b53d-0562dcc8e6a3 still exists
Feb 22 06:42:40.963: INFO: Waiting for pod pod-5d3befc5-16d5-4626-b53d-0562dcc8e6a3 to disappear
Feb 22 06:42:41.014: INFO: Pod pod-5d3befc5-16d5-4626-b53d-0562dcc8e6a3 still exists
Feb 22 06:42:42.963: INFO: Waiting for pod pod-5d3befc5-16d5-4626-b53d-0562dcc8e6a3 to disappear
Feb 22 06:42:42.971: INFO: Pod pod-5d3befc5-16d5-4626-b53d-0562dcc8e6a3 still exists
Feb 22 06:42:44.963: INFO: Waiting for pod pod-5d3befc5-16d5-4626-b53d-0562dcc8e6a3 to disappear
Feb 22 06:42:44.977: INFO: Pod pod-5d3befc5-16d5-4626-b53d-0562dcc8e6a3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:42:44.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1457" for this suite.

â€¢ [SLOW TEST:48.112 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:42
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","total":270,"completed":195,"skipped":3425,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:42:45.033: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-7031
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
Feb 22 06:42:45.348: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:43:15.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-7031" for this suite.

â€¢ [SLOW TEST:30.898 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]","total":270,"completed":196,"skipped":3487,"failed":0}
SSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:43:15.938: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-4953
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
Feb 22 06:43:16.809: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:46:34.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4953" for this suite.

â€¢ [SLOW TEST:199.179 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]","total":270,"completed":197,"skipped":3490,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:46:35.142: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7058
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap that has name configmap-test-emptyKey-ac320035-3df4-4c63-8680-462c2851ffbf
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:46:35.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7058" for this suite.
â€¢{"msg":"PASSED [sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]","total":270,"completed":198,"skipped":3512,"failed":0}

------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:46:35.545: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-2541
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secret-namespace-7736
STEP: Creating secret with name secret-test-13c8fd21-9aa8-4996-aebf-ced6b757208c
STEP: Creating a pod to test consume secrets
Feb 22 06:46:36.385: INFO: Waiting up to 5m0s for pod "pod-secrets-b532ad53-16af-45e1-8c2d-85e8eaefae56" in namespace "secrets-2541" to be "Succeeded or Failed"
Feb 22 06:46:36.397: INFO: Pod "pod-secrets-b532ad53-16af-45e1-8c2d-85e8eaefae56": Phase="Pending", Reason="", readiness=false. Elapsed: 11.93189ms
Feb 22 06:46:38.409: INFO: Pod "pod-secrets-b532ad53-16af-45e1-8c2d-85e8eaefae56": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024000843s
Feb 22 06:46:40.432: INFO: Pod "pod-secrets-b532ad53-16af-45e1-8c2d-85e8eaefae56": Phase="Pending", Reason="", readiness=false. Elapsed: 4.046648937s
Feb 22 06:46:42.462: INFO: Pod "pod-secrets-b532ad53-16af-45e1-8c2d-85e8eaefae56": Phase="Pending", Reason="", readiness=false. Elapsed: 6.076840102s
Feb 22 06:46:44.488: INFO: Pod "pod-secrets-b532ad53-16af-45e1-8c2d-85e8eaefae56": Phase="Pending", Reason="", readiness=false. Elapsed: 8.102695723s
Feb 22 06:46:46.510: INFO: Pod "pod-secrets-b532ad53-16af-45e1-8c2d-85e8eaefae56": Phase="Pending", Reason="", readiness=false. Elapsed: 10.124774916s
Feb 22 06:46:48.522: INFO: Pod "pod-secrets-b532ad53-16af-45e1-8c2d-85e8eaefae56": Phase="Pending", Reason="", readiness=false. Elapsed: 12.137470144s
Feb 22 06:46:50.537: INFO: Pod "pod-secrets-b532ad53-16af-45e1-8c2d-85e8eaefae56": Phase="Pending", Reason="", readiness=false. Elapsed: 14.15241431s
Feb 22 06:46:52.570: INFO: Pod "pod-secrets-b532ad53-16af-45e1-8c2d-85e8eaefae56": Phase="Pending", Reason="", readiness=false. Elapsed: 16.184987741s
Feb 22 06:46:54.577: INFO: Pod "pod-secrets-b532ad53-16af-45e1-8c2d-85e8eaefae56": Phase="Pending", Reason="", readiness=false. Elapsed: 18.192530427s
Feb 22 06:46:56.591: INFO: Pod "pod-secrets-b532ad53-16af-45e1-8c2d-85e8eaefae56": Phase="Pending", Reason="", readiness=false. Elapsed: 20.206508625s
Feb 22 06:46:58.601: INFO: Pod "pod-secrets-b532ad53-16af-45e1-8c2d-85e8eaefae56": Phase="Pending", Reason="", readiness=false. Elapsed: 22.215625939s
Feb 22 06:47:00.613: INFO: Pod "pod-secrets-b532ad53-16af-45e1-8c2d-85e8eaefae56": Phase="Pending", Reason="", readiness=false. Elapsed: 24.227900082s
Feb 22 06:47:02.623: INFO: Pod "pod-secrets-b532ad53-16af-45e1-8c2d-85e8eaefae56": Phase="Pending", Reason="", readiness=false. Elapsed: 26.237577104s
Feb 22 06:47:04.646: INFO: Pod "pod-secrets-b532ad53-16af-45e1-8c2d-85e8eaefae56": Phase="Pending", Reason="", readiness=false. Elapsed: 28.261168693s
Feb 22 06:47:06.685: INFO: Pod "pod-secrets-b532ad53-16af-45e1-8c2d-85e8eaefae56": Phase="Succeeded", Reason="", readiness=false. Elapsed: 30.300167894s
STEP: Saw pod success
Feb 22 06:47:06.685: INFO: Pod "pod-secrets-b532ad53-16af-45e1-8c2d-85e8eaefae56" satisfied condition "Succeeded or Failed"
Feb 22 06:47:06.709: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com pod pod-secrets-b532ad53-16af-45e1-8c2d-85e8eaefae56 container secret-volume-test: <nil>
STEP: delete the pod
Feb 22 06:47:13.581: INFO: Waiting for pod pod-secrets-b532ad53-16af-45e1-8c2d-85e8eaefae56 to disappear
Feb 22 06:47:13.611: INFO: Pod pod-secrets-b532ad53-16af-45e1-8c2d-85e8eaefae56 still exists
Feb 22 06:47:15.612: INFO: Waiting for pod pod-secrets-b532ad53-16af-45e1-8c2d-85e8eaefae56 to disappear
Feb 22 06:47:15.622: INFO: Pod pod-secrets-b532ad53-16af-45e1-8c2d-85e8eaefae56 still exists
Feb 22 06:47:17.612: INFO: Waiting for pod pod-secrets-b532ad53-16af-45e1-8c2d-85e8eaefae56 to disappear
Feb 22 06:47:17.632: INFO: Pod pod-secrets-b532ad53-16af-45e1-8c2d-85e8eaefae56 still exists
Feb 22 06:47:19.612: INFO: Waiting for pod pod-secrets-b532ad53-16af-45e1-8c2d-85e8eaefae56 to disappear
Feb 22 06:47:19.622: INFO: Pod pod-secrets-b532ad53-16af-45e1-8c2d-85e8eaefae56 still exists
Feb 22 06:47:21.612: INFO: Waiting for pod pod-secrets-b532ad53-16af-45e1-8c2d-85e8eaefae56 to disappear
Feb 22 06:47:21.620: INFO: Pod pod-secrets-b532ad53-16af-45e1-8c2d-85e8eaefae56 still exists
Feb 22 06:47:23.612: INFO: Waiting for pod pod-secrets-b532ad53-16af-45e1-8c2d-85e8eaefae56 to disappear
Feb 22 06:47:23.627: INFO: Pod pod-secrets-b532ad53-16af-45e1-8c2d-85e8eaefae56 still exists
Feb 22 06:47:25.612: INFO: Waiting for pod pod-secrets-b532ad53-16af-45e1-8c2d-85e8eaefae56 to disappear
Feb 22 06:47:25.637: INFO: Pod pod-secrets-b532ad53-16af-45e1-8c2d-85e8eaefae56 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:47:25.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2541" for this suite.
STEP: Destroying namespace "secret-namespace-7736" for this suite.

â€¢ [SLOW TEST:50.199 seconds]
[sig-storage] Secrets
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:36
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]","total":270,"completed":199,"skipped":3512,"failed":0}
SS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:47:25.745: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-3700
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a service externalname-service with the type=ExternalName in namespace services-3700
STEP: changing the ExternalName service to type=ClusterIP
STEP: creating replication controller externalname-service in namespace services-3700
Feb 22 06:48:02.425: INFO: Creating new exec pod
Feb 22 06:48:27.497: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=services-3700 execpod8fsps -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Feb 22 06:48:29.431: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Feb 22 06:48:29.431: INFO: stdout: ""
Feb 22 06:48:29.436: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=services-3700 execpod8fsps -- /bin/sh -x -c nc -zv -t -w 2 172.24.234.178 80'
Feb 22 06:48:29.936: INFO: stderr: "+ nc -zv -t -w 2 172.24.234.178 80\nConnection to 172.24.234.178 80 port [tcp/http] succeeded!\n"
Feb 22 06:48:29.936: INFO: stdout: ""
Feb 22 06:48:29.936: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:48:30.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3700" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702

â€¢ [SLOW TEST:64.668 seconds]
[sig-network] Services
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]","total":270,"completed":200,"skipped":3514,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:48:30.426: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8262
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name projected-secret-test-44462001-a56a-4c2f-bf47-f2822155adda
STEP: Creating a pod to test consume secrets
Feb 22 06:48:30.999: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-0014c13f-eec6-4209-a0fa-b7be85ed1809" in namespace "projected-8262" to be "Succeeded or Failed"
Feb 22 06:48:31.010: INFO: Pod "pod-projected-secrets-0014c13f-eec6-4209-a0fa-b7be85ed1809": Phase="Pending", Reason="", readiness=false. Elapsed: 10.322128ms
Feb 22 06:48:33.024: INFO: Pod "pod-projected-secrets-0014c13f-eec6-4209-a0fa-b7be85ed1809": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024076792s
Feb 22 06:48:35.070: INFO: Pod "pod-projected-secrets-0014c13f-eec6-4209-a0fa-b7be85ed1809": Phase="Pending", Reason="", readiness=false. Elapsed: 4.070367923s
Feb 22 06:48:37.114: INFO: Pod "pod-projected-secrets-0014c13f-eec6-4209-a0fa-b7be85ed1809": Phase="Pending", Reason="", readiness=false. Elapsed: 6.114781104s
Feb 22 06:48:39.150: INFO: Pod "pod-projected-secrets-0014c13f-eec6-4209-a0fa-b7be85ed1809": Phase="Pending", Reason="", readiness=false. Elapsed: 8.150622902s
Feb 22 06:48:41.182: INFO: Pod "pod-projected-secrets-0014c13f-eec6-4209-a0fa-b7be85ed1809": Phase="Pending", Reason="", readiness=false. Elapsed: 10.182812136s
Feb 22 06:48:43.268: INFO: Pod "pod-projected-secrets-0014c13f-eec6-4209-a0fa-b7be85ed1809": Phase="Pending", Reason="", readiness=false. Elapsed: 12.268502966s
Feb 22 06:48:45.286: INFO: Pod "pod-projected-secrets-0014c13f-eec6-4209-a0fa-b7be85ed1809": Phase="Pending", Reason="", readiness=false. Elapsed: 14.286382954s
Feb 22 06:48:47.303: INFO: Pod "pod-projected-secrets-0014c13f-eec6-4209-a0fa-b7be85ed1809": Phase="Pending", Reason="", readiness=false. Elapsed: 16.303148901s
Feb 22 06:48:49.329: INFO: Pod "pod-projected-secrets-0014c13f-eec6-4209-a0fa-b7be85ed1809": Phase="Pending", Reason="", readiness=false. Elapsed: 18.330025025s
Feb 22 06:48:51.342: INFO: Pod "pod-projected-secrets-0014c13f-eec6-4209-a0fa-b7be85ed1809": Phase="Pending", Reason="", readiness=false. Elapsed: 20.34237868s
Feb 22 06:48:53.353: INFO: Pod "pod-projected-secrets-0014c13f-eec6-4209-a0fa-b7be85ed1809": Phase="Pending", Reason="", readiness=false. Elapsed: 22.353636486s
Feb 22 06:48:55.361: INFO: Pod "pod-projected-secrets-0014c13f-eec6-4209-a0fa-b7be85ed1809": Phase="Pending", Reason="", readiness=false. Elapsed: 24.361909278s
Feb 22 06:48:57.370: INFO: Pod "pod-projected-secrets-0014c13f-eec6-4209-a0fa-b7be85ed1809": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.370939742s
STEP: Saw pod success
Feb 22 06:48:57.371: INFO: Pod "pod-projected-secrets-0014c13f-eec6-4209-a0fa-b7be85ed1809" satisfied condition "Succeeded or Failed"
Feb 22 06:48:57.384: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com pod pod-projected-secrets-0014c13f-eec6-4209-a0fa-b7be85ed1809 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 22 06:48:57.503: INFO: Waiting for pod pod-projected-secrets-0014c13f-eec6-4209-a0fa-b7be85ed1809 to disappear
Feb 22 06:48:57.576: INFO: Pod pod-projected-secrets-0014c13f-eec6-4209-a0fa-b7be85ed1809 still exists
Feb 22 06:48:59.576: INFO: Waiting for pod pod-projected-secrets-0014c13f-eec6-4209-a0fa-b7be85ed1809 to disappear
Feb 22 06:48:59.771: INFO: Pod pod-projected-secrets-0014c13f-eec6-4209-a0fa-b7be85ed1809 still exists
Feb 22 06:49:01.576: INFO: Waiting for pod pod-projected-secrets-0014c13f-eec6-4209-a0fa-b7be85ed1809 to disappear
Feb 22 06:49:01.583: INFO: Pod pod-projected-secrets-0014c13f-eec6-4209-a0fa-b7be85ed1809 still exists
Feb 22 06:49:03.576: INFO: Waiting for pod pod-projected-secrets-0014c13f-eec6-4209-a0fa-b7be85ed1809 to disappear
Feb 22 06:49:03.584: INFO: Pod pod-projected-secrets-0014c13f-eec6-4209-a0fa-b7be85ed1809 still exists
Feb 22 06:49:05.576: INFO: Waiting for pod pod-projected-secrets-0014c13f-eec6-4209-a0fa-b7be85ed1809 to disappear
Feb 22 06:49:05.583: INFO: Pod pod-projected-secrets-0014c13f-eec6-4209-a0fa-b7be85ed1809 still exists
Feb 22 06:49:07.576: INFO: Waiting for pod pod-projected-secrets-0014c13f-eec6-4209-a0fa-b7be85ed1809 to disappear
Feb 22 06:49:07.590: INFO: Pod pod-projected-secrets-0014c13f-eec6-4209-a0fa-b7be85ed1809 still exists
Feb 22 06:49:09.576: INFO: Waiting for pod pod-projected-secrets-0014c13f-eec6-4209-a0fa-b7be85ed1809 to disappear
Feb 22 06:49:09.581: INFO: Pod pod-projected-secrets-0014c13f-eec6-4209-a0fa-b7be85ed1809 still exists
Feb 22 06:49:11.577: INFO: Waiting for pod pod-projected-secrets-0014c13f-eec6-4209-a0fa-b7be85ed1809 to disappear
Feb 22 06:49:11.585: INFO: Pod pod-projected-secrets-0014c13f-eec6-4209-a0fa-b7be85ed1809 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:49:11.585: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8262" for this suite.

â€¢ [SLOW TEST:41.216 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":270,"completed":201,"skipped":3557,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:49:11.645: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-4262
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4262.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-4262.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4262.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-4262.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4262.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-4262.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4262.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-4262.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4262.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-4262.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4262.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-4262.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4262.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 124.245.24.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.24.245.124_udp@PTR;check="$$(dig +tcp +noall +answer +search 124.245.24.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.24.245.124_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4262.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-4262.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4262.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-4262.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4262.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-4262.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4262.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-4262.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4262.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-4262.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4262.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-4262.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4262.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 124.245.24.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.24.245.124_udp@PTR;check="$$(dig +tcp +noall +answer +search 124.245.24.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.24.245.124_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 22 06:49:48.301: INFO: Unable to read wheezy_udp@dns-test-service.dns-4262.svc.cluster.local from pod dns-4262/dns-test-cd49f672-6860-4163-b910-69b8e16f1e54: the server could not find the requested resource (get pods dns-test-cd49f672-6860-4163-b910-69b8e16f1e54)
Feb 22 06:49:48.325: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4262.svc.cluster.local from pod dns-4262/dns-test-cd49f672-6860-4163-b910-69b8e16f1e54: the server could not find the requested resource (get pods dns-test-cd49f672-6860-4163-b910-69b8e16f1e54)
Feb 22 06:49:48.338: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4262.svc.cluster.local from pod dns-4262/dns-test-cd49f672-6860-4163-b910-69b8e16f1e54: the server could not find the requested resource (get pods dns-test-cd49f672-6860-4163-b910-69b8e16f1e54)
Feb 22 06:49:48.357: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4262.svc.cluster.local from pod dns-4262/dns-test-cd49f672-6860-4163-b910-69b8e16f1e54: the server could not find the requested resource (get pods dns-test-cd49f672-6860-4163-b910-69b8e16f1e54)
Feb 22 06:49:48.722: INFO: Lookups using dns-4262/dns-test-cd49f672-6860-4163-b910-69b8e16f1e54 failed for: [wheezy_udp@dns-test-service.dns-4262.svc.cluster.local wheezy_tcp@dns-test-service.dns-4262.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4262.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4262.svc.cluster.local]

Feb 22 06:49:54.012: INFO: DNS probes using dns-4262/dns-test-cd49f672-6860-4163-b910-69b8e16f1e54 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:49:54.313: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4262" for this suite.

â€¢ [SLOW TEST:42.713 seconds]
[sig-network] DNS
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for services  [Conformance]","total":270,"completed":202,"skipped":3589,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:49:54.363: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-2219
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Feb 22 06:50:56.998: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 22 06:50:57.029: INFO: Pod pod-with-prestop-http-hook still exists
Feb 22 06:50:59.029: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 22 06:50:59.042: INFO: Pod pod-with-prestop-http-hook still exists
Feb 22 06:51:01.030: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 22 06:51:01.054: INFO: Pod pod-with-prestop-http-hook still exists
Feb 22 06:51:03.052: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 22 06:51:03.072: INFO: Pod pod-with-prestop-http-hook still exists
Feb 22 06:51:05.029: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 22 06:51:05.047: INFO: Pod pod-with-prestop-http-hook still exists
Feb 22 06:51:07.029: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 22 06:51:07.072: INFO: Pod pod-with-prestop-http-hook still exists
Feb 22 06:51:09.029: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 22 06:51:09.043: INFO: Pod pod-with-prestop-http-hook still exists
Feb 22 06:51:11.029: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 22 06:51:11.038: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:51:11.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-2219" for this suite.

â€¢ [SLOW TEST:76.795 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  when create a pod with lifecycle hook
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]","total":270,"completed":203,"skipped":3641,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:51:11.173: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9001
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating the pod
Feb 22 06:51:34.193: INFO: Successfully updated pod "annotationupdate7cb97947-7d6a-4d06-9fb2-d03516e828da"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:51:36.285: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9001" for this suite.

â€¢ [SLOW TEST:25.157 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:37
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]","total":270,"completed":204,"skipped":3655,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:51:36.349: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7219
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Update Demo
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:271
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a replication controller
Feb 22 06:51:36.797: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config create -f - --namespace=kubectl-7219'
Feb 22 06:51:38.979: INFO: stderr: ""
Feb 22 06:51:38.979: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 22 06:51:38.980: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7219'
Feb 22 06:51:39.481: INFO: stderr: ""
Feb 22 06:51:39.481: INFO: stdout: "update-demo-nautilus-dzx9s update-demo-nautilus-nhr9b "
Feb 22 06:51:39.481: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods update-demo-nautilus-dzx9s -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7219'
Feb 22 06:51:39.883: INFO: stderr: ""
Feb 22 06:51:39.883: INFO: stdout: ""
Feb 22 06:51:39.883: INFO: update-demo-nautilus-dzx9s is created but not running
Feb 22 06:51:44.884: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7219'
Feb 22 06:51:45.321: INFO: stderr: ""
Feb 22 06:51:45.321: INFO: stdout: "update-demo-nautilus-dzx9s update-demo-nautilus-nhr9b "
Feb 22 06:51:45.321: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods update-demo-nautilus-dzx9s -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7219'
Feb 22 06:51:45.585: INFO: stderr: ""
Feb 22 06:51:45.585: INFO: stdout: ""
Feb 22 06:51:45.585: INFO: update-demo-nautilus-dzx9s is created but not running
Feb 22 06:51:50.586: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7219'
Feb 22 06:51:50.819: INFO: stderr: ""
Feb 22 06:51:50.819: INFO: stdout: "update-demo-nautilus-dzx9s update-demo-nautilus-nhr9b "
Feb 22 06:51:50.819: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods update-demo-nautilus-dzx9s -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7219'
Feb 22 06:51:50.994: INFO: stderr: ""
Feb 22 06:51:50.994: INFO: stdout: ""
Feb 22 06:51:50.994: INFO: update-demo-nautilus-dzx9s is created but not running
Feb 22 06:51:55.995: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7219'
Feb 22 06:51:56.384: INFO: stderr: ""
Feb 22 06:51:56.384: INFO: stdout: "update-demo-nautilus-dzx9s update-demo-nautilus-nhr9b "
Feb 22 06:51:56.384: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods update-demo-nautilus-dzx9s -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7219'
Feb 22 06:51:56.616: INFO: stderr: ""
Feb 22 06:51:56.616: INFO: stdout: ""
Feb 22 06:51:56.616: INFO: update-demo-nautilus-dzx9s is created but not running
Feb 22 06:52:01.619: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7219'
Feb 22 06:52:01.883: INFO: stderr: ""
Feb 22 06:52:01.883: INFO: stdout: "update-demo-nautilus-dzx9s update-demo-nautilus-nhr9b "
Feb 22 06:52:01.884: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods update-demo-nautilus-dzx9s -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7219'
Feb 22 06:52:02.083: INFO: stderr: ""
Feb 22 06:52:02.083: INFO: stdout: ""
Feb 22 06:52:02.083: INFO: update-demo-nautilus-dzx9s is created but not running
Feb 22 06:52:07.084: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7219'
Feb 22 06:52:07.382: INFO: stderr: ""
Feb 22 06:52:07.382: INFO: stdout: "update-demo-nautilus-dzx9s update-demo-nautilus-nhr9b "
Feb 22 06:52:07.382: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods update-demo-nautilus-dzx9s -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7219'
Feb 22 06:52:07.628: INFO: stderr: ""
Feb 22 06:52:07.628: INFO: stdout: ""
Feb 22 06:52:07.628: INFO: update-demo-nautilus-dzx9s is created but not running
Feb 22 06:52:12.629: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7219'
Feb 22 06:52:12.780: INFO: stderr: ""
Feb 22 06:52:12.780: INFO: stdout: "update-demo-nautilus-dzx9s update-demo-nautilus-nhr9b "
Feb 22 06:52:12.780: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods update-demo-nautilus-dzx9s -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7219'
Feb 22 06:52:12.962: INFO: stderr: ""
Feb 22 06:52:12.962: INFO: stdout: "true"
Feb 22 06:52:12.963: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods update-demo-nautilus-dzx9s -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7219'
Feb 22 06:52:13.222: INFO: stderr: ""
Feb 22 06:52:13.222: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 22 06:52:13.222: INFO: validating pod update-demo-nautilus-dzx9s
Feb 22 06:52:13.299: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 22 06:52:13.300: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 22 06:52:13.300: INFO: update-demo-nautilus-dzx9s is verified up and running
Feb 22 06:52:13.301: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods update-demo-nautilus-nhr9b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7219'
Feb 22 06:52:13.537: INFO: stderr: ""
Feb 22 06:52:13.537: INFO: stdout: "true"
Feb 22 06:52:13.537: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods update-demo-nautilus-nhr9b -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7219'
Feb 22 06:52:13.787: INFO: stderr: ""
Feb 22 06:52:13.787: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 22 06:52:13.787: INFO: validating pod update-demo-nautilus-nhr9b
Feb 22 06:52:13.871: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 22 06:52:13.871: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 22 06:52:13.871: INFO: update-demo-nautilus-nhr9b is verified up and running
STEP: using delete to clean up resources
Feb 22 06:52:13.871: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config delete --grace-period=0 --force -f - --namespace=kubectl-7219'
Feb 22 06:52:14.105: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 22 06:52:14.105: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Feb 22 06:52:14.106: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get rc,svc -l name=update-demo --no-headers --namespace=kubectl-7219'
Feb 22 06:52:14.409: INFO: stderr: "No resources found in kubectl-7219 namespace.\n"
Feb 22 06:52:14.409: INFO: stdout: ""
Feb 22 06:52:14.409: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods -l name=update-demo --namespace=kubectl-7219 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 22 06:52:14.707: INFO: stderr: ""
Feb 22 06:52:14.707: INFO: stdout: "update-demo-nautilus-dzx9s\nupdate-demo-nautilus-nhr9b\n"
Feb 22 06:52:15.208: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get rc,svc -l name=update-demo --no-headers --namespace=kubectl-7219'
Feb 22 06:52:15.458: INFO: stderr: "No resources found in kubectl-7219 namespace.\n"
Feb 22 06:52:15.458: INFO: stdout: ""
Feb 22 06:52:15.458: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods -l name=update-demo --namespace=kubectl-7219 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 22 06:52:15.805: INFO: stderr: ""
Feb 22 06:52:15.805: INFO: stdout: "update-demo-nautilus-dzx9s\nupdate-demo-nautilus-nhr9b\n"
Feb 22 06:52:16.208: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get rc,svc -l name=update-demo --no-headers --namespace=kubectl-7219'
Feb 22 06:52:16.445: INFO: stderr: "No resources found in kubectl-7219 namespace.\n"
Feb 22 06:52:16.445: INFO: stdout: ""
Feb 22 06:52:16.445: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pods -l name=update-demo --namespace=kubectl-7219 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 22 06:52:16.655: INFO: stderr: ""
Feb 22 06:52:16.655: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:52:16.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7219" for this suite.

â€¢ [SLOW TEST:40.354 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:269
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should create and stop a replication controller  [Conformance]","total":270,"completed":205,"skipped":3672,"failed":0}
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:52:16.704: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5610
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-upd-e07c1b1a-3bde-4fa9-bb34-13ff15e179c3
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:52:51.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5610" for this suite.

â€¢ [SLOW TEST:34.609 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:36
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]","total":270,"completed":206,"skipped":3672,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should patch a secret [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:52:51.317: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-2327
STEP: Waiting for a default service account to be provisioned in namespace
[It] should patch a secret [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a secret
STEP: listing secrets in all namespaces to ensure that there are more than zero
STEP: patching the secret
STEP: deleting the secret using a LabelSelector
STEP: listing secrets in all namespaces, searching for label name and value in patch
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:52:51.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2327" for this suite.
â€¢{"msg":"PASSED [sig-api-machinery] Secrets should patch a secret [Conformance]","total":270,"completed":207,"skipped":3691,"failed":0}
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:52:51.876: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-1174
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-map-291bb7e4-cde8-483f-b577-c462d3b91609
STEP: Creating a pod to test consume secrets
Feb 22 06:52:52.228: INFO: Waiting up to 5m0s for pod "pod-secrets-f9a1f413-51ca-4a05-a0d7-c2e02052181e" in namespace "secrets-1174" to be "Succeeded or Failed"
Feb 22 06:52:52.248: INFO: Pod "pod-secrets-f9a1f413-51ca-4a05-a0d7-c2e02052181e": Phase="Pending", Reason="", readiness=false. Elapsed: 20.012651ms
Feb 22 06:52:54.255: INFO: Pod "pod-secrets-f9a1f413-51ca-4a05-a0d7-c2e02052181e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027333706s
Feb 22 06:52:56.269: INFO: Pod "pod-secrets-f9a1f413-51ca-4a05-a0d7-c2e02052181e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.04067898s
Feb 22 06:52:58.310: INFO: Pod "pod-secrets-f9a1f413-51ca-4a05-a0d7-c2e02052181e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.081667973s
Feb 22 06:53:00.327: INFO: Pod "pod-secrets-f9a1f413-51ca-4a05-a0d7-c2e02052181e": Phase="Pending", Reason="", readiness=false. Elapsed: 8.099228426s
Feb 22 06:53:02.345: INFO: Pod "pod-secrets-f9a1f413-51ca-4a05-a0d7-c2e02052181e": Phase="Pending", Reason="", readiness=false. Elapsed: 10.116673174s
Feb 22 06:53:04.356: INFO: Pod "pod-secrets-f9a1f413-51ca-4a05-a0d7-c2e02052181e": Phase="Pending", Reason="", readiness=false. Elapsed: 12.12825512s
Feb 22 06:53:06.367: INFO: Pod "pod-secrets-f9a1f413-51ca-4a05-a0d7-c2e02052181e": Phase="Pending", Reason="", readiness=false. Elapsed: 14.138730325s
Feb 22 06:53:08.421: INFO: Pod "pod-secrets-f9a1f413-51ca-4a05-a0d7-c2e02052181e": Phase="Pending", Reason="", readiness=false. Elapsed: 16.192996316s
Feb 22 06:53:10.431: INFO: Pod "pod-secrets-f9a1f413-51ca-4a05-a0d7-c2e02052181e": Phase="Pending", Reason="", readiness=false. Elapsed: 18.202598304s
Feb 22 06:53:12.444: INFO: Pod "pod-secrets-f9a1f413-51ca-4a05-a0d7-c2e02052181e": Phase="Pending", Reason="", readiness=false. Elapsed: 20.215768309s
Feb 22 06:53:14.465: INFO: Pod "pod-secrets-f9a1f413-51ca-4a05-a0d7-c2e02052181e": Phase="Pending", Reason="", readiness=false. Elapsed: 22.236856403s
Feb 22 06:53:16.481: INFO: Pod "pod-secrets-f9a1f413-51ca-4a05-a0d7-c2e02052181e": Phase="Pending", Reason="", readiness=false. Elapsed: 24.252923476s
Feb 22 06:53:18.498: INFO: Pod "pod-secrets-f9a1f413-51ca-4a05-a0d7-c2e02052181e": Phase="Pending", Reason="", readiness=false. Elapsed: 26.269897254s
Feb 22 06:53:20.511: INFO: Pod "pod-secrets-f9a1f413-51ca-4a05-a0d7-c2e02052181e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 28.283243638s
STEP: Saw pod success
Feb 22 06:53:20.511: INFO: Pod "pod-secrets-f9a1f413-51ca-4a05-a0d7-c2e02052181e" satisfied condition "Succeeded or Failed"
Feb 22 06:53:20.526: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com pod pod-secrets-f9a1f413-51ca-4a05-a0d7-c2e02052181e container secret-volume-test: <nil>
STEP: delete the pod
Feb 22 06:53:27.775: INFO: Waiting for pod pod-secrets-f9a1f413-51ca-4a05-a0d7-c2e02052181e to disappear
Feb 22 06:53:27.796: INFO: Pod pod-secrets-f9a1f413-51ca-4a05-a0d7-c2e02052181e still exists
Feb 22 06:53:29.796: INFO: Waiting for pod pod-secrets-f9a1f413-51ca-4a05-a0d7-c2e02052181e to disappear
Feb 22 06:53:29.804: INFO: Pod pod-secrets-f9a1f413-51ca-4a05-a0d7-c2e02052181e still exists
Feb 22 06:53:31.797: INFO: Waiting for pod pod-secrets-f9a1f413-51ca-4a05-a0d7-c2e02052181e to disappear
Feb 22 06:53:31.806: INFO: Pod pod-secrets-f9a1f413-51ca-4a05-a0d7-c2e02052181e still exists
Feb 22 06:53:33.796: INFO: Waiting for pod pod-secrets-f9a1f413-51ca-4a05-a0d7-c2e02052181e to disappear
Feb 22 06:53:33.809: INFO: Pod pod-secrets-f9a1f413-51ca-4a05-a0d7-c2e02052181e no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:53:33.810: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1174" for this suite.

â€¢ [SLOW TEST:42.028 seconds]
[sig-storage] Secrets
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:36
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","total":270,"completed":208,"skipped":3692,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:53:33.906: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9581
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-map-faaefd6d-a0cc-4d1c-bf57-43a607b58466
STEP: Creating a pod to test consume configMaps
Feb 22 06:53:34.250: INFO: Waiting up to 5m0s for pod "pod-configmaps-164b380d-437c-4696-8037-8dab062ff9f5" in namespace "configmap-9581" to be "Succeeded or Failed"
Feb 22 06:53:34.264: INFO: Pod "pod-configmaps-164b380d-437c-4696-8037-8dab062ff9f5": Phase="Pending", Reason="", readiness=false. Elapsed: 14.440464ms
Feb 22 06:53:36.275: INFO: Pod "pod-configmaps-164b380d-437c-4696-8037-8dab062ff9f5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024745487s
Feb 22 06:53:38.286: INFO: Pod "pod-configmaps-164b380d-437c-4696-8037-8dab062ff9f5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.0359143s
Feb 22 06:53:40.303: INFO: Pod "pod-configmaps-164b380d-437c-4696-8037-8dab062ff9f5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.053267802s
Feb 22 06:53:42.310: INFO: Pod "pod-configmaps-164b380d-437c-4696-8037-8dab062ff9f5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.059903259s
Feb 22 06:53:44.316: INFO: Pod "pod-configmaps-164b380d-437c-4696-8037-8dab062ff9f5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.066095304s
Feb 22 06:53:46.331: INFO: Pod "pod-configmaps-164b380d-437c-4696-8037-8dab062ff9f5": Phase="Pending", Reason="", readiness=false. Elapsed: 12.081470485s
Feb 22 06:53:48.341: INFO: Pod "pod-configmaps-164b380d-437c-4696-8037-8dab062ff9f5": Phase="Pending", Reason="", readiness=false. Elapsed: 14.091381517s
Feb 22 06:53:50.364: INFO: Pod "pod-configmaps-164b380d-437c-4696-8037-8dab062ff9f5": Phase="Pending", Reason="", readiness=false. Elapsed: 16.114337126s
Feb 22 06:53:52.374: INFO: Pod "pod-configmaps-164b380d-437c-4696-8037-8dab062ff9f5": Phase="Pending", Reason="", readiness=false. Elapsed: 18.123691324s
Feb 22 06:53:54.381: INFO: Pod "pod-configmaps-164b380d-437c-4696-8037-8dab062ff9f5": Phase="Pending", Reason="", readiness=false. Elapsed: 20.130549972s
Feb 22 06:53:56.390: INFO: Pod "pod-configmaps-164b380d-437c-4696-8037-8dab062ff9f5": Phase="Pending", Reason="", readiness=false. Elapsed: 22.140001249s
Feb 22 06:53:58.402: INFO: Pod "pod-configmaps-164b380d-437c-4696-8037-8dab062ff9f5": Phase="Pending", Reason="", readiness=false. Elapsed: 24.151750535s
Feb 22 06:54:00.410: INFO: Pod "pod-configmaps-164b380d-437c-4696-8037-8dab062ff9f5": Phase="Pending", Reason="", readiness=false. Elapsed: 26.160253509s
Feb 22 06:54:02.424: INFO: Pod "pod-configmaps-164b380d-437c-4696-8037-8dab062ff9f5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 28.173621572s
STEP: Saw pod success
Feb 22 06:54:02.424: INFO: Pod "pod-configmaps-164b380d-437c-4696-8037-8dab062ff9f5" satisfied condition "Succeeded or Failed"
Feb 22 06:54:02.451: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com pod pod-configmaps-164b380d-437c-4696-8037-8dab062ff9f5 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 22 06:54:09.123: INFO: Waiting for pod pod-configmaps-164b380d-437c-4696-8037-8dab062ff9f5 to disappear
Feb 22 06:54:09.151: INFO: Pod pod-configmaps-164b380d-437c-4696-8037-8dab062ff9f5 still exists
Feb 22 06:54:11.152: INFO: Waiting for pod pod-configmaps-164b380d-437c-4696-8037-8dab062ff9f5 to disappear
Feb 22 06:54:11.161: INFO: Pod pod-configmaps-164b380d-437c-4696-8037-8dab062ff9f5 still exists
Feb 22 06:54:13.152: INFO: Waiting for pod pod-configmaps-164b380d-437c-4696-8037-8dab062ff9f5 to disappear
Feb 22 06:54:13.162: INFO: Pod pod-configmaps-164b380d-437c-4696-8037-8dab062ff9f5 still exists
Feb 22 06:54:15.152: INFO: Waiting for pod pod-configmaps-164b380d-437c-4696-8037-8dab062ff9f5 to disappear
Feb 22 06:54:15.164: INFO: Pod pod-configmaps-164b380d-437c-4696-8037-8dab062ff9f5 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:54:15.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9581" for this suite.

â€¢ [SLOW TEST:41.303 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:36
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","total":270,"completed":209,"skipped":3719,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:54:15.213: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-7540
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating service multi-endpoint-test in namespace services-7540
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7540 to expose endpoints map[]
Feb 22 06:54:15.651: INFO: Get endpoints failed (48.433505ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Feb 22 06:54:16.658: INFO: successfully validated that service multi-endpoint-test in namespace services-7540 exposes endpoints map[] (1.055336724s elapsed)
STEP: Creating pod pod1 in namespace services-7540
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7540 to expose endpoints map[pod1:[100]]
Feb 22 06:54:20.795: INFO: Unexpected endpoints: found map[], expected map[pod1:[100]] (4.115012369s elapsed, will retry)
Feb 22 06:54:25.915: INFO: Unexpected endpoints: found map[], expected map[pod1:[100]] (9.235298044s elapsed, will retry)
Feb 22 06:54:31.035: INFO: Unexpected endpoints: found map[], expected map[pod1:[100]] (14.354377826s elapsed, will retry)
Feb 22 06:54:36.111: INFO: Unexpected endpoints: found map[], expected map[pod1:[100]] (19.431140029s elapsed, will retry)
Feb 22 06:54:41.197: INFO: Unexpected endpoints: found map[], expected map[pod1:[100]] (24.516448765s elapsed, will retry)
Feb 22 06:54:46.347: INFO: successfully validated that service multi-endpoint-test in namespace services-7540 exposes endpoints map[pod1:[100]] (29.666350885s elapsed)
STEP: Creating pod pod2 in namespace services-7540
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7540 to expose endpoints map[pod1:[100] pod2:[101]]
Feb 22 06:54:50.527: INFO: Unexpected endpoints: found map[78f0cdf1-a1ef-4dbf-b808-a7426afba6e2:[100]], expected map[pod1:[100] pod2:[101]] (4.128073799s elapsed, will retry)
Feb 22 06:54:55.630: INFO: Unexpected endpoints: found map[78f0cdf1-a1ef-4dbf-b808-a7426afba6e2:[100]], expected map[pod1:[100] pod2:[101]] (9.230484411s elapsed, will retry)
Feb 22 06:55:00.819: INFO: Unexpected endpoints: found map[78f0cdf1-a1ef-4dbf-b808-a7426afba6e2:[100]], expected map[pod1:[100] pod2:[101]] (14.419673729s elapsed, will retry)
Feb 22 06:55:05.983: INFO: Unexpected endpoints: found map[78f0cdf1-a1ef-4dbf-b808-a7426afba6e2:[100]], expected map[pod1:[100] pod2:[101]] (19.583379316s elapsed, will retry)
Feb 22 06:55:11.310: INFO: Unexpected endpoints: found map[78f0cdf1-a1ef-4dbf-b808-a7426afba6e2:[100]], expected map[pod1:[100] pod2:[101]] (24.910955277s elapsed, will retry)
Feb 22 06:55:12.330: INFO: successfully validated that service multi-endpoint-test in namespace services-7540 exposes endpoints map[pod1:[100] pod2:[101]] (25.930355601s elapsed)
STEP: Deleting pod pod1 in namespace services-7540
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7540 to expose endpoints map[pod2:[101]]
Feb 22 06:55:12.455: INFO: successfully validated that service multi-endpoint-test in namespace services-7540 exposes endpoints map[pod2:[101]] (44.51716ms elapsed)
STEP: Deleting pod pod2 in namespace services-7540
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7540 to expose endpoints map[]
Feb 22 06:55:13.706: INFO: successfully validated that service multi-endpoint-test in namespace services-7540 exposes endpoints map[] (1.105427163s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:55:13.973: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7540" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702

â€¢ [SLOW TEST:58.830 seconds]
[sig-network] Services
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Services should serve multiport endpoints from pods  [Conformance]","total":270,"completed":210,"skipped":3739,"failed":0}
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:55:14.044: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-504
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating the pod
Feb 22 06:55:43.193: INFO: Successfully updated pod "labelsupdate83f77e75-a4ae-4d34-b411-9de74157b448"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:55:45.284: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-504" for this suite.

â€¢ [SLOW TEST:31.413 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:36
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]","total":270,"completed":211,"skipped":3744,"failed":0}
SSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:55:45.491: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-8609
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a service nodeport-service with the type=NodePort in namespace services-8609
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-8609
STEP: creating replication controller externalsvc in namespace services-8609
STEP: changing the NodePort service to type=ExternalName
Feb 22 06:56:25.447: INFO: Creating new exec pod
Feb 22 06:56:49.556: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=services-8609 execpodqtrww -- /bin/sh -x -c nslookup nodeport-service'
Feb 22 06:56:50.646: INFO: stderr: "+ nslookup nodeport-service\n"
Feb 22 06:56:50.646: INFO: stdout: "Server:\t\t172.24.0.10\nAddress:\t172.24.0.10#53\n\nnodeport-service.services-8609.svc.cluster.local\tcanonical name = externalsvc.services-8609.svc.cluster.local.\nName:\texternalsvc.services-8609.svc.cluster.local\nAddress: 172.24.1.245\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-8609, will wait for the garbage collector to delete the pods
Feb 22 06:56:50.722: INFO: Deleting ReplicationController externalsvc took: 19.152052ms
Feb 22 06:56:52.623: INFO: Terminating ReplicationController externalsvc pods took: 1.900878128s
Feb 22 06:57:13.378: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:57:13.683: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8609" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702

â€¢ [SLOW TEST:88.252 seconds]
[sig-network] Services
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]","total":270,"completed":212,"skipped":3754,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:57:13.754: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5524
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating secret secrets-5524/secret-test-5ef97f77-ade3-4d6b-90d7-9819bde9471a
STEP: Creating a pod to test consume secrets
Feb 22 06:57:14.087: INFO: Waiting up to 5m0s for pod "pod-configmaps-db33a7c1-2813-469c-8f22-5e6a3b70732b" in namespace "secrets-5524" to be "Succeeded or Failed"
Feb 22 06:57:14.096: INFO: Pod "pod-configmaps-db33a7c1-2813-469c-8f22-5e6a3b70732b": Phase="Pending", Reason="", readiness=false. Elapsed: 9.050135ms
Feb 22 06:57:16.116: INFO: Pod "pod-configmaps-db33a7c1-2813-469c-8f22-5e6a3b70732b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028474804s
Feb 22 06:57:18.132: INFO: Pod "pod-configmaps-db33a7c1-2813-469c-8f22-5e6a3b70732b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.04448366s
Feb 22 06:57:20.174: INFO: Pod "pod-configmaps-db33a7c1-2813-469c-8f22-5e6a3b70732b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.086584042s
Feb 22 06:57:22.986: INFO: Pod "pod-configmaps-db33a7c1-2813-469c-8f22-5e6a3b70732b": Phase="Pending", Reason="", readiness=false. Elapsed: 8.898738257s
Feb 22 06:57:25.075: INFO: Pod "pod-configmaps-db33a7c1-2813-469c-8f22-5e6a3b70732b": Phase="Pending", Reason="", readiness=false. Elapsed: 10.987518052s
Feb 22 06:57:27.089: INFO: Pod "pod-configmaps-db33a7c1-2813-469c-8f22-5e6a3b70732b": Phase="Pending", Reason="", readiness=false. Elapsed: 13.001334991s
Feb 22 06:57:29.170: INFO: Pod "pod-configmaps-db33a7c1-2813-469c-8f22-5e6a3b70732b": Phase="Pending", Reason="", readiness=false. Elapsed: 15.082382561s
Feb 22 06:57:31.177: INFO: Pod "pod-configmaps-db33a7c1-2813-469c-8f22-5e6a3b70732b": Phase="Pending", Reason="", readiness=false. Elapsed: 17.090167985s
Feb 22 06:57:33.188: INFO: Pod "pod-configmaps-db33a7c1-2813-469c-8f22-5e6a3b70732b": Phase="Pending", Reason="", readiness=false. Elapsed: 19.10076097s
Feb 22 06:57:35.197: INFO: Pod "pod-configmaps-db33a7c1-2813-469c-8f22-5e6a3b70732b": Phase="Pending", Reason="", readiness=false. Elapsed: 21.110029208s
Feb 22 06:57:37.208: INFO: Pod "pod-configmaps-db33a7c1-2813-469c-8f22-5e6a3b70732b": Phase="Pending", Reason="", readiness=false. Elapsed: 23.120598619s
Feb 22 06:57:39.215: INFO: Pod "pod-configmaps-db33a7c1-2813-469c-8f22-5e6a3b70732b": Phase="Pending", Reason="", readiness=false. Elapsed: 25.128079144s
Feb 22 06:57:41.229: INFO: Pod "pod-configmaps-db33a7c1-2813-469c-8f22-5e6a3b70732b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 27.142084828s
STEP: Saw pod success
Feb 22 06:57:41.230: INFO: Pod "pod-configmaps-db33a7c1-2813-469c-8f22-5e6a3b70732b" satisfied condition "Succeeded or Failed"
Feb 22 06:57:41.240: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com pod pod-configmaps-db33a7c1-2813-469c-8f22-5e6a3b70732b container env-test: <nil>
STEP: delete the pod
Feb 22 06:57:47.355: INFO: Waiting for pod pod-configmaps-db33a7c1-2813-469c-8f22-5e6a3b70732b to disappear
Feb 22 06:57:47.372: INFO: Pod pod-configmaps-db33a7c1-2813-469c-8f22-5e6a3b70732b still exists
Feb 22 06:57:49.373: INFO: Waiting for pod pod-configmaps-db33a7c1-2813-469c-8f22-5e6a3b70732b to disappear
Feb 22 06:57:49.408: INFO: Pod pod-configmaps-db33a7c1-2813-469c-8f22-5e6a3b70732b still exists
Feb 22 06:57:51.373: INFO: Waiting for pod pod-configmaps-db33a7c1-2813-469c-8f22-5e6a3b70732b to disappear
Feb 22 06:57:51.387: INFO: Pod pod-configmaps-db33a7c1-2813-469c-8f22-5e6a3b70732b still exists
Feb 22 06:57:53.373: INFO: Waiting for pod pod-configmaps-db33a7c1-2813-469c-8f22-5e6a3b70732b to disappear
Feb 22 06:57:53.396: INFO: Pod pod-configmaps-db33a7c1-2813-469c-8f22-5e6a3b70732b still exists
Feb 22 06:57:55.373: INFO: Waiting for pod pod-configmaps-db33a7c1-2813-469c-8f22-5e6a3b70732b to disappear
Feb 22 06:57:55.539: INFO: Pod pod-configmaps-db33a7c1-2813-469c-8f22-5e6a3b70732b still exists
Feb 22 06:57:57.373: INFO: Waiting for pod pod-configmaps-db33a7c1-2813-469c-8f22-5e6a3b70732b to disappear
Feb 22 06:57:57.385: INFO: Pod pod-configmaps-db33a7c1-2813-469c-8f22-5e6a3b70732b no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:57:57.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5524" for this suite.

â€¢ [SLOW TEST:43.734 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:35
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Secrets should be consumable via the environment [NodeConformance] [Conformance]","total":270,"completed":213,"skipped":3776,"failed":0}
SSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:57:57.519: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-7080
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:157
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:57:58.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7080" for this suite.
â€¢{"msg":"PASSED [k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]","total":270,"completed":214,"skipped":3786,"failed":0}
SSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:57:58.095: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-546
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name s-test-opt-del-1a15db41-4af8-4ea2-b1be-4da46e0eb2c9
STEP: Creating secret with name s-test-opt-upd-60fd6b2f-5b7c-49ad-9faf-02b6f76d4097
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-1a15db41-4af8-4ea2-b1be-4da46e0eb2c9
STEP: Updating secret s-test-opt-upd-60fd6b2f-5b7c-49ad-9faf-02b6f76d4097
STEP: Creating secret with name s-test-opt-create-18318943-bc02-4f55-820d-e4be1921f43f
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 06:59:18.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-546" for this suite.

â€¢ [SLOW TEST:80.200 seconds]
[sig-storage] Secrets
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:36
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]","total":270,"completed":215,"skipped":3792,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 06:59:18.304: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7034
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name cm-test-opt-del-8f99f8a3-7a0b-4fd0-a3b9-cf8224c7a5f9
STEP: Creating configMap with name cm-test-opt-upd-f7221e08-11e6-4150-bbd3-ad50e74f8256
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-8f99f8a3-7a0b-4fd0-a3b9-cf8224c7a5f9
STEP: Updating configmap cm-test-opt-upd-f7221e08-11e6-4150-bbd3-ad50e74f8256
STEP: Creating configMap with name cm-test-opt-create-3ba27e03-aacb-45dc-8052-465f21a73a34
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 07:00:40.650: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7034" for this suite.

â€¢ [SLOW TEST:82.401 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:36
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]","total":270,"completed":216,"skipped":3802,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with privileged 
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 07:00:40.706: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-9453
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:41
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Feb 22 07:00:41.060: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-259a1758-a781-4f35-b597-091e17c164af" in namespace "security-context-test-9453" to be "Succeeded or Failed"
Feb 22 07:00:41.075: INFO: Pod "busybox-privileged-false-259a1758-a781-4f35-b597-091e17c164af": Phase="Pending", Reason="", readiness=false. Elapsed: 14.509315ms
Feb 22 07:00:43.083: INFO: Pod "busybox-privileged-false-259a1758-a781-4f35-b597-091e17c164af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02317331s
Feb 22 07:00:45.092: INFO: Pod "busybox-privileged-false-259a1758-a781-4f35-b597-091e17c164af": Phase="Pending", Reason="", readiness=false. Elapsed: 4.031470289s
Feb 22 07:00:47.149: INFO: Pod "busybox-privileged-false-259a1758-a781-4f35-b597-091e17c164af": Phase="Pending", Reason="", readiness=false. Elapsed: 6.089047591s
Feb 22 07:00:49.170: INFO: Pod "busybox-privileged-false-259a1758-a781-4f35-b597-091e17c164af": Phase="Pending", Reason="", readiness=false. Elapsed: 8.109473592s
Feb 22 07:00:51.208: INFO: Pod "busybox-privileged-false-259a1758-a781-4f35-b597-091e17c164af": Phase="Pending", Reason="", readiness=false. Elapsed: 10.147825602s
Feb 22 07:00:53.237: INFO: Pod "busybox-privileged-false-259a1758-a781-4f35-b597-091e17c164af": Phase="Pending", Reason="", readiness=false. Elapsed: 12.176880805s
Feb 22 07:00:55.256: INFO: Pod "busybox-privileged-false-259a1758-a781-4f35-b597-091e17c164af": Phase="Pending", Reason="", readiness=false. Elapsed: 14.195945089s
Feb 22 07:00:57.276: INFO: Pod "busybox-privileged-false-259a1758-a781-4f35-b597-091e17c164af": Phase="Pending", Reason="", readiness=false. Elapsed: 16.216103001s
Feb 22 07:00:59.284: INFO: Pod "busybox-privileged-false-259a1758-a781-4f35-b597-091e17c164af": Phase="Pending", Reason="", readiness=false. Elapsed: 18.224148777s
Feb 22 07:01:01.290: INFO: Pod "busybox-privileged-false-259a1758-a781-4f35-b597-091e17c164af": Phase="Pending", Reason="", readiness=false. Elapsed: 20.230273671s
Feb 22 07:01:03.501: INFO: Pod "busybox-privileged-false-259a1758-a781-4f35-b597-091e17c164af": Phase="Pending", Reason="", readiness=false. Elapsed: 22.441325672s
Feb 22 07:01:05.537: INFO: Pod "busybox-privileged-false-259a1758-a781-4f35-b597-091e17c164af": Phase="Pending", Reason="", readiness=false. Elapsed: 24.477019923s
Feb 22 07:01:07.549: INFO: Pod "busybox-privileged-false-259a1758-a781-4f35-b597-091e17c164af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.488405712s
Feb 22 07:01:07.549: INFO: Pod "busybox-privileged-false-259a1758-a781-4f35-b597-091e17c164af" satisfied condition "Succeeded or Failed"
Feb 22 07:01:07.623: INFO: Got logs for pod "busybox-privileged-false-259a1758-a781-4f35-b597-091e17c164af": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 07:01:07.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-9453" for this suite.

â€¢ [SLOW TEST:26.966 seconds]
[k8s.io] Security Context
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  When creating a pod with privileged
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:227
    should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]","total":270,"completed":217,"skipped":3820,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 07:01:07.674: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8401
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-ab0df7ab-00c0-4815-bebb-e2cd5d7ca2b1
STEP: Creating a pod to test consume secrets
Feb 22 07:01:08.028: INFO: Waiting up to 5m0s for pod "pod-secrets-fd35cc4e-2b5f-4d25-ac56-00cc1f6ed986" in namespace "secrets-8401" to be "Succeeded or Failed"
Feb 22 07:01:08.039: INFO: Pod "pod-secrets-fd35cc4e-2b5f-4d25-ac56-00cc1f6ed986": Phase="Pending", Reason="", readiness=false. Elapsed: 10.795006ms
Feb 22 07:01:10.053: INFO: Pod "pod-secrets-fd35cc4e-2b5f-4d25-ac56-00cc1f6ed986": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025212957s
Feb 22 07:01:12.076: INFO: Pod "pod-secrets-fd35cc4e-2b5f-4d25-ac56-00cc1f6ed986": Phase="Pending", Reason="", readiness=false. Elapsed: 4.048435099s
Feb 22 07:01:14.092: INFO: Pod "pod-secrets-fd35cc4e-2b5f-4d25-ac56-00cc1f6ed986": Phase="Pending", Reason="", readiness=false. Elapsed: 6.064224288s
Feb 22 07:01:16.109: INFO: Pod "pod-secrets-fd35cc4e-2b5f-4d25-ac56-00cc1f6ed986": Phase="Pending", Reason="", readiness=false. Elapsed: 8.0810347s
Feb 22 07:01:18.144: INFO: Pod "pod-secrets-fd35cc4e-2b5f-4d25-ac56-00cc1f6ed986": Phase="Pending", Reason="", readiness=false. Elapsed: 10.11595135s
Feb 22 07:01:20.155: INFO: Pod "pod-secrets-fd35cc4e-2b5f-4d25-ac56-00cc1f6ed986": Phase="Pending", Reason="", readiness=false. Elapsed: 12.12730334s
Feb 22 07:01:22.194: INFO: Pod "pod-secrets-fd35cc4e-2b5f-4d25-ac56-00cc1f6ed986": Phase="Pending", Reason="", readiness=false. Elapsed: 14.166049791s
Feb 22 07:01:24.206: INFO: Pod "pod-secrets-fd35cc4e-2b5f-4d25-ac56-00cc1f6ed986": Phase="Pending", Reason="", readiness=false. Elapsed: 16.178271551s
Feb 22 07:01:26.213: INFO: Pod "pod-secrets-fd35cc4e-2b5f-4d25-ac56-00cc1f6ed986": Phase="Pending", Reason="", readiness=false. Elapsed: 18.18467153s
Feb 22 07:01:28.218: INFO: Pod "pod-secrets-fd35cc4e-2b5f-4d25-ac56-00cc1f6ed986": Phase="Pending", Reason="", readiness=false. Elapsed: 20.189745551s
Feb 22 07:01:30.229: INFO: Pod "pod-secrets-fd35cc4e-2b5f-4d25-ac56-00cc1f6ed986": Phase="Pending", Reason="", readiness=false. Elapsed: 22.200845521s
Feb 22 07:01:32.244: INFO: Pod "pod-secrets-fd35cc4e-2b5f-4d25-ac56-00cc1f6ed986": Phase="Pending", Reason="", readiness=false. Elapsed: 24.215756123s
Feb 22 07:01:34.256: INFO: Pod "pod-secrets-fd35cc4e-2b5f-4d25-ac56-00cc1f6ed986": Phase="Pending", Reason="", readiness=false. Elapsed: 26.22773236s
Feb 22 07:01:36.269: INFO: Pod "pod-secrets-fd35cc4e-2b5f-4d25-ac56-00cc1f6ed986": Phase="Pending", Reason="", readiness=false. Elapsed: 28.240947048s
Feb 22 07:01:38.279: INFO: Pod "pod-secrets-fd35cc4e-2b5f-4d25-ac56-00cc1f6ed986": Phase="Succeeded", Reason="", readiness=false. Elapsed: 30.250831092s
STEP: Saw pod success
Feb 22 07:01:38.279: INFO: Pod "pod-secrets-fd35cc4e-2b5f-4d25-ac56-00cc1f6ed986" satisfied condition "Succeeded or Failed"
Feb 22 07:01:38.287: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com pod pod-secrets-fd35cc4e-2b5f-4d25-ac56-00cc1f6ed986 container secret-volume-test: <nil>
STEP: delete the pod
Feb 22 07:01:38.375: INFO: Waiting for pod pod-secrets-fd35cc4e-2b5f-4d25-ac56-00cc1f6ed986 to disappear
Feb 22 07:01:38.400: INFO: Pod pod-secrets-fd35cc4e-2b5f-4d25-ac56-00cc1f6ed986 still exists
Feb 22 07:01:40.400: INFO: Waiting for pod pod-secrets-fd35cc4e-2b5f-4d25-ac56-00cc1f6ed986 to disappear
Feb 22 07:01:40.410: INFO: Pod pod-secrets-fd35cc4e-2b5f-4d25-ac56-00cc1f6ed986 still exists
Feb 22 07:01:42.401: INFO: Waiting for pod pod-secrets-fd35cc4e-2b5f-4d25-ac56-00cc1f6ed986 to disappear
Feb 22 07:01:42.415: INFO: Pod pod-secrets-fd35cc4e-2b5f-4d25-ac56-00cc1f6ed986 still exists
Feb 22 07:01:44.401: INFO: Waiting for pod pod-secrets-fd35cc4e-2b5f-4d25-ac56-00cc1f6ed986 to disappear
Feb 22 07:01:44.437: INFO: Pod pod-secrets-fd35cc4e-2b5f-4d25-ac56-00cc1f6ed986 still exists
Feb 22 07:01:46.401: INFO: Waiting for pod pod-secrets-fd35cc4e-2b5f-4d25-ac56-00cc1f6ed986 to disappear
Feb 22 07:01:46.445: INFO: Pod pod-secrets-fd35cc4e-2b5f-4d25-ac56-00cc1f6ed986 still exists
Feb 22 07:01:48.448: INFO: Waiting for pod pod-secrets-fd35cc4e-2b5f-4d25-ac56-00cc1f6ed986 to disappear
Feb 22 07:01:48.464: INFO: Pod pod-secrets-fd35cc4e-2b5f-4d25-ac56-00cc1f6ed986 still exists
Feb 22 07:01:50.401: INFO: Waiting for pod pod-secrets-fd35cc4e-2b5f-4d25-ac56-00cc1f6ed986 to disappear
Feb 22 07:01:50.410: INFO: Pod pod-secrets-fd35cc4e-2b5f-4d25-ac56-00cc1f6ed986 still exists
Feb 22 07:01:52.400: INFO: Waiting for pod pod-secrets-fd35cc4e-2b5f-4d25-ac56-00cc1f6ed986 to disappear
Feb 22 07:01:52.410: INFO: Pod pod-secrets-fd35cc4e-2b5f-4d25-ac56-00cc1f6ed986 still exists
Feb 22 07:01:54.401: INFO: Waiting for pod pod-secrets-fd35cc4e-2b5f-4d25-ac56-00cc1f6ed986 to disappear
Feb 22 07:01:54.412: INFO: Pod pod-secrets-fd35cc4e-2b5f-4d25-ac56-00cc1f6ed986 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 07:01:54.412: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8401" for this suite.

â€¢ [SLOW TEST:46.791 seconds]
[sig-storage] Secrets
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:36
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","total":270,"completed":218,"skipped":3846,"failed":0}
SSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 07:01:54.466: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-5103
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod pod-subpath-test-configmap-vbd7
STEP: Creating a pod to test atomic-volume-subpath
Feb 22 07:01:54.860: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-vbd7" in namespace "subpath-5103" to be "Succeeded or Failed"
Feb 22 07:01:54.879: INFO: Pod "pod-subpath-test-configmap-vbd7": Phase="Pending", Reason="", readiness=false. Elapsed: 18.233779ms
Feb 22 07:01:56.889: INFO: Pod "pod-subpath-test-configmap-vbd7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02842167s
Feb 22 07:01:58.917: INFO: Pod "pod-subpath-test-configmap-vbd7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.056181348s
Feb 22 07:02:00.968: INFO: Pod "pod-subpath-test-configmap-vbd7": Phase="Pending", Reason="", readiness=false. Elapsed: 6.1080098s
Feb 22 07:02:02.983: INFO: Pod "pod-subpath-test-configmap-vbd7": Phase="Pending", Reason="", readiness=false. Elapsed: 8.123113562s
Feb 22 07:02:04.991: INFO: Pod "pod-subpath-test-configmap-vbd7": Phase="Pending", Reason="", readiness=false. Elapsed: 10.130244167s
Feb 22 07:02:07.002: INFO: Pod "pod-subpath-test-configmap-vbd7": Phase="Pending", Reason="", readiness=false. Elapsed: 12.141633809s
Feb 22 07:02:09.008: INFO: Pod "pod-subpath-test-configmap-vbd7": Phase="Pending", Reason="", readiness=false. Elapsed: 14.147628346s
Feb 22 07:02:11.019: INFO: Pod "pod-subpath-test-configmap-vbd7": Phase="Pending", Reason="", readiness=false. Elapsed: 16.15875822s
Feb 22 07:02:13.031: INFO: Pod "pod-subpath-test-configmap-vbd7": Phase="Pending", Reason="", readiness=false. Elapsed: 18.170744423s
Feb 22 07:02:15.037: INFO: Pod "pod-subpath-test-configmap-vbd7": Phase="Pending", Reason="", readiness=false. Elapsed: 20.176605679s
Feb 22 07:02:17.044: INFO: Pod "pod-subpath-test-configmap-vbd7": Phase="Pending", Reason="", readiness=false. Elapsed: 22.183455045s
Feb 22 07:02:19.051: INFO: Pod "pod-subpath-test-configmap-vbd7": Phase="Running", Reason="", readiness=true. Elapsed: 24.191021478s
Feb 22 07:02:21.059: INFO: Pod "pod-subpath-test-configmap-vbd7": Phase="Running", Reason="", readiness=true. Elapsed: 26.199170428s
Feb 22 07:02:23.065: INFO: Pod "pod-subpath-test-configmap-vbd7": Phase="Running", Reason="", readiness=true. Elapsed: 28.204659411s
Feb 22 07:02:25.072: INFO: Pod "pod-subpath-test-configmap-vbd7": Phase="Running", Reason="", readiness=true. Elapsed: 30.211494857s
Feb 22 07:02:27.081: INFO: Pod "pod-subpath-test-configmap-vbd7": Phase="Running", Reason="", readiness=true. Elapsed: 32.220232472s
Feb 22 07:02:29.090: INFO: Pod "pod-subpath-test-configmap-vbd7": Phase="Running", Reason="", readiness=true. Elapsed: 34.229598323s
Feb 22 07:02:31.097: INFO: Pod "pod-subpath-test-configmap-vbd7": Phase="Running", Reason="", readiness=true. Elapsed: 36.236296875s
Feb 22 07:02:33.107: INFO: Pod "pod-subpath-test-configmap-vbd7": Phase="Running", Reason="", readiness=true. Elapsed: 38.247108113s
Feb 22 07:02:35.117: INFO: Pod "pod-subpath-test-configmap-vbd7": Phase="Running", Reason="", readiness=true. Elapsed: 40.256497722s
Feb 22 07:02:37.137: INFO: Pod "pod-subpath-test-configmap-vbd7": Phase="Running", Reason="", readiness=true. Elapsed: 42.276382424s
Feb 22 07:02:39.144: INFO: Pod "pod-subpath-test-configmap-vbd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 44.283571334s
STEP: Saw pod success
Feb 22 07:02:39.144: INFO: Pod "pod-subpath-test-configmap-vbd7" satisfied condition "Succeeded or Failed"
Feb 22 07:02:39.156: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com pod pod-subpath-test-configmap-vbd7 container test-container-subpath-configmap-vbd7: <nil>
STEP: delete the pod
Feb 22 07:02:45.049: INFO: Waiting for pod pod-subpath-test-configmap-vbd7 to disappear
Feb 22 07:02:45.073: INFO: Pod pod-subpath-test-configmap-vbd7 still exists
Feb 22 07:02:47.073: INFO: Waiting for pod pod-subpath-test-configmap-vbd7 to disappear
Feb 22 07:02:47.087: INFO: Pod pod-subpath-test-configmap-vbd7 still exists
Feb 22 07:02:49.074: INFO: Waiting for pod pod-subpath-test-configmap-vbd7 to disappear
Feb 22 07:02:49.090: INFO: Pod pod-subpath-test-configmap-vbd7 still exists
Feb 22 07:02:51.073: INFO: Waiting for pod pod-subpath-test-configmap-vbd7 to disappear
Feb 22 07:02:51.157: INFO: Pod pod-subpath-test-configmap-vbd7 still exists
Feb 22 07:02:53.074: INFO: Waiting for pod pod-subpath-test-configmap-vbd7 to disappear
Feb 22 07:02:53.090: INFO: Pod pod-subpath-test-configmap-vbd7 still exists
Feb 22 07:02:55.074: INFO: Waiting for pod pod-subpath-test-configmap-vbd7 to disappear
Feb 22 07:02:55.089: INFO: Pod pod-subpath-test-configmap-vbd7 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-vbd7
Feb 22 07:02:55.089: INFO: Deleting pod "pod-subpath-test-configmap-vbd7" in namespace "subpath-5103"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 07:02:55.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5103" for this suite.

â€¢ [SLOW TEST:60.684 seconds]
[sig-storage] Subpath
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [LinuxOnly] [Conformance]","total":270,"completed":219,"skipped":3852,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 07:02:55.169: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-9301
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 07:03:00.352: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-9301" for this suite.

â€¢ [SLOW TEST:5.253 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]","total":270,"completed":220,"skipped":3892,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 07:03:00.422: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-3995
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:82
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 07:03:24.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3995" for this suite.

â€¢ [SLOW TEST:24.464 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:79
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]","total":270,"completed":221,"skipped":3916,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 07:03:24.887: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1923
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Feb 22 07:03:25.289: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3d442aba-12d5-4282-b9ab-89db0832ba97" in namespace "downward-api-1923" to be "Succeeded or Failed"
Feb 22 07:03:25.298: INFO: Pod "downwardapi-volume-3d442aba-12d5-4282-b9ab-89db0832ba97": Phase="Pending", Reason="", readiness=false. Elapsed: 8.511752ms
Feb 22 07:03:27.308: INFO: Pod "downwardapi-volume-3d442aba-12d5-4282-b9ab-89db0832ba97": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018205206s
Feb 22 07:03:29.315: INFO: Pod "downwardapi-volume-3d442aba-12d5-4282-b9ab-89db0832ba97": Phase="Pending", Reason="", readiness=false. Elapsed: 4.025879545s
Feb 22 07:03:31.322: INFO: Pod "downwardapi-volume-3d442aba-12d5-4282-b9ab-89db0832ba97": Phase="Pending", Reason="", readiness=false. Elapsed: 6.032474714s
Feb 22 07:03:33.328: INFO: Pod "downwardapi-volume-3d442aba-12d5-4282-b9ab-89db0832ba97": Phase="Pending", Reason="", readiness=false. Elapsed: 8.039050338s
Feb 22 07:03:35.335: INFO: Pod "downwardapi-volume-3d442aba-12d5-4282-b9ab-89db0832ba97": Phase="Pending", Reason="", readiness=false. Elapsed: 10.04555027s
Feb 22 07:03:37.376: INFO: Pod "downwardapi-volume-3d442aba-12d5-4282-b9ab-89db0832ba97": Phase="Pending", Reason="", readiness=false. Elapsed: 12.086241264s
Feb 22 07:03:39.384: INFO: Pod "downwardapi-volume-3d442aba-12d5-4282-b9ab-89db0832ba97": Phase="Pending", Reason="", readiness=false. Elapsed: 14.094736662s
Feb 22 07:03:41.396: INFO: Pod "downwardapi-volume-3d442aba-12d5-4282-b9ab-89db0832ba97": Phase="Pending", Reason="", readiness=false. Elapsed: 16.106917205s
Feb 22 07:03:43.406: INFO: Pod "downwardapi-volume-3d442aba-12d5-4282-b9ab-89db0832ba97": Phase="Pending", Reason="", readiness=false. Elapsed: 18.116385198s
Feb 22 07:03:45.418: INFO: Pod "downwardapi-volume-3d442aba-12d5-4282-b9ab-89db0832ba97": Phase="Pending", Reason="", readiness=false. Elapsed: 20.12847815s
Feb 22 07:03:47.466: INFO: Pod "downwardapi-volume-3d442aba-12d5-4282-b9ab-89db0832ba97": Phase="Pending", Reason="", readiness=false. Elapsed: 22.176904297s
Feb 22 07:03:49.487: INFO: Pod "downwardapi-volume-3d442aba-12d5-4282-b9ab-89db0832ba97": Phase="Pending", Reason="", readiness=false. Elapsed: 24.197250128s
Feb 22 07:03:51.497: INFO: Pod "downwardapi-volume-3d442aba-12d5-4282-b9ab-89db0832ba97": Phase="Pending", Reason="", readiness=false. Elapsed: 26.207903869s
Feb 22 07:03:53.510: INFO: Pod "downwardapi-volume-3d442aba-12d5-4282-b9ab-89db0832ba97": Phase="Pending", Reason="", readiness=false. Elapsed: 28.220921376s
Feb 22 07:03:55.531: INFO: Pod "downwardapi-volume-3d442aba-12d5-4282-b9ab-89db0832ba97": Phase="Succeeded", Reason="", readiness=false. Elapsed: 30.241962273s
STEP: Saw pod success
Feb 22 07:03:55.532: INFO: Pod "downwardapi-volume-3d442aba-12d5-4282-b9ab-89db0832ba97" satisfied condition "Succeeded or Failed"
Feb 22 07:03:55.548: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com pod downwardapi-volume-3d442aba-12d5-4282-b9ab-89db0832ba97 container client-container: <nil>
STEP: delete the pod
Feb 22 07:04:02.805: INFO: Waiting for pod downwardapi-volume-3d442aba-12d5-4282-b9ab-89db0832ba97 to disappear
Feb 22 07:04:02.893: INFO: Pod downwardapi-volume-3d442aba-12d5-4282-b9ab-89db0832ba97 still exists
Feb 22 07:04:04.895: INFO: Waiting for pod downwardapi-volume-3d442aba-12d5-4282-b9ab-89db0832ba97 to disappear
Feb 22 07:04:04.975: INFO: Pod downwardapi-volume-3d442aba-12d5-4282-b9ab-89db0832ba97 still exists
Feb 22 07:04:06.895: INFO: Waiting for pod downwardapi-volume-3d442aba-12d5-4282-b9ab-89db0832ba97 to disappear
Feb 22 07:04:06.908: INFO: Pod downwardapi-volume-3d442aba-12d5-4282-b9ab-89db0832ba97 still exists
Feb 22 07:04:08.895: INFO: Waiting for pod downwardapi-volume-3d442aba-12d5-4282-b9ab-89db0832ba97 to disappear
Feb 22 07:04:08.940: INFO: Pod downwardapi-volume-3d442aba-12d5-4282-b9ab-89db0832ba97 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 07:04:08.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1923" for this suite.

â€¢ [SLOW TEST:44.124 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:37
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","total":270,"completed":222,"skipped":3928,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 07:04:09.055: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-6811
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 07:04:35.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6811" for this suite.

â€¢ [SLOW TEST:26.733 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:137
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox Pod with hostAliases should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]","total":270,"completed":223,"skipped":3943,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 07:04:35.878: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-2257
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 07:04:43.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2257" for this suite.

â€¢ [SLOW TEST:7.404 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]","total":270,"completed":224,"skipped":4024,"failed":0}
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 07:04:43.289: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8043
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Feb 22 07:04:43.626: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d8ca69fd-7aba-4068-959b-81590385ea4b" in namespace "downward-api-8043" to be "Succeeded or Failed"
Feb 22 07:04:43.634: INFO: Pod "downwardapi-volume-d8ca69fd-7aba-4068-959b-81590385ea4b": Phase="Pending", Reason="", readiness=false. Elapsed: 8.379212ms
Feb 22 07:04:45.656: INFO: Pod "downwardapi-volume-d8ca69fd-7aba-4068-959b-81590385ea4b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029979149s
Feb 22 07:04:47.673: INFO: Pod "downwardapi-volume-d8ca69fd-7aba-4068-959b-81590385ea4b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.047123331s
Feb 22 07:04:49.684: INFO: Pod "downwardapi-volume-d8ca69fd-7aba-4068-959b-81590385ea4b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.058319853s
Feb 22 07:04:51.693: INFO: Pod "downwardapi-volume-d8ca69fd-7aba-4068-959b-81590385ea4b": Phase="Pending", Reason="", readiness=false. Elapsed: 8.067227761s
Feb 22 07:04:53.706: INFO: Pod "downwardapi-volume-d8ca69fd-7aba-4068-959b-81590385ea4b": Phase="Pending", Reason="", readiness=false. Elapsed: 10.079460375s
Feb 22 07:04:55.716: INFO: Pod "downwardapi-volume-d8ca69fd-7aba-4068-959b-81590385ea4b": Phase="Pending", Reason="", readiness=false. Elapsed: 12.09019651s
Feb 22 07:04:57.723: INFO: Pod "downwardapi-volume-d8ca69fd-7aba-4068-959b-81590385ea4b": Phase="Pending", Reason="", readiness=false. Elapsed: 14.096899334s
Feb 22 07:04:59.825: INFO: Pod "downwardapi-volume-d8ca69fd-7aba-4068-959b-81590385ea4b": Phase="Pending", Reason="", readiness=false. Elapsed: 16.199127343s
Feb 22 07:05:01.835: INFO: Pod "downwardapi-volume-d8ca69fd-7aba-4068-959b-81590385ea4b": Phase="Pending", Reason="", readiness=false. Elapsed: 18.209018449s
Feb 22 07:05:03.847: INFO: Pod "downwardapi-volume-d8ca69fd-7aba-4068-959b-81590385ea4b": Phase="Pending", Reason="", readiness=false. Elapsed: 20.221324309s
Feb 22 07:05:05.881: INFO: Pod "downwardapi-volume-d8ca69fd-7aba-4068-959b-81590385ea4b": Phase="Pending", Reason="", readiness=false. Elapsed: 22.255119818s
Feb 22 07:05:07.886: INFO: Pod "downwardapi-volume-d8ca69fd-7aba-4068-959b-81590385ea4b": Phase="Pending", Reason="", readiness=false. Elapsed: 24.260057066s
Feb 22 07:05:09.895: INFO: Pod "downwardapi-volume-d8ca69fd-7aba-4068-959b-81590385ea4b": Phase="Pending", Reason="", readiness=false. Elapsed: 26.268711604s
Feb 22 07:05:11.905: INFO: Pod "downwardapi-volume-d8ca69fd-7aba-4068-959b-81590385ea4b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 28.278730807s
STEP: Saw pod success
Feb 22 07:05:11.905: INFO: Pod "downwardapi-volume-d8ca69fd-7aba-4068-959b-81590385ea4b" satisfied condition "Succeeded or Failed"
Feb 22 07:05:11.918: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com pod downwardapi-volume-d8ca69fd-7aba-4068-959b-81590385ea4b container client-container: <nil>
STEP: delete the pod
Feb 22 07:05:12.017: INFO: Waiting for pod downwardapi-volume-d8ca69fd-7aba-4068-959b-81590385ea4b to disappear
Feb 22 07:05:12.041: INFO: Pod downwardapi-volume-d8ca69fd-7aba-4068-959b-81590385ea4b still exists
Feb 22 07:05:14.042: INFO: Waiting for pod downwardapi-volume-d8ca69fd-7aba-4068-959b-81590385ea4b to disappear
Feb 22 07:05:14.062: INFO: Pod downwardapi-volume-d8ca69fd-7aba-4068-959b-81590385ea4b still exists
Feb 22 07:05:16.042: INFO: Waiting for pod downwardapi-volume-d8ca69fd-7aba-4068-959b-81590385ea4b to disappear
Feb 22 07:05:16.065: INFO: Pod downwardapi-volume-d8ca69fd-7aba-4068-959b-81590385ea4b still exists
Feb 22 07:05:18.042: INFO: Waiting for pod downwardapi-volume-d8ca69fd-7aba-4068-959b-81590385ea4b to disappear
Feb 22 07:05:18.060: INFO: Pod downwardapi-volume-d8ca69fd-7aba-4068-959b-81590385ea4b still exists
Feb 22 07:05:20.042: INFO: Waiting for pod downwardapi-volume-d8ca69fd-7aba-4068-959b-81590385ea4b to disappear
Feb 22 07:05:20.076: INFO: Pod downwardapi-volume-d8ca69fd-7aba-4068-959b-81590385ea4b still exists
Feb 22 07:05:22.041: INFO: Waiting for pod downwardapi-volume-d8ca69fd-7aba-4068-959b-81590385ea4b to disappear
Feb 22 07:05:22.049: INFO: Pod downwardapi-volume-d8ca69fd-7aba-4068-959b-81590385ea4b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 07:05:22.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8043" for this suite.

â€¢ [SLOW TEST:38.817 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:37
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","total":270,"completed":225,"skipped":4024,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 07:05:22.110: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2169
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-f6f176cf-0a4e-4a52-aacf-e128c57e81b6
STEP: Creating a pod to test consume configMaps
Feb 22 07:05:22.893: INFO: Waiting up to 5m0s for pod "pod-configmaps-baf260d1-a9de-4957-8db8-4c2c40fd3cc1" in namespace "configmap-2169" to be "Succeeded or Failed"
Feb 22 07:05:22.908: INFO: Pod "pod-configmaps-baf260d1-a9de-4957-8db8-4c2c40fd3cc1": Phase="Pending", Reason="", readiness=false. Elapsed: 14.317876ms
Feb 22 07:05:24.923: INFO: Pod "pod-configmaps-baf260d1-a9de-4957-8db8-4c2c40fd3cc1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029630349s
Feb 22 07:05:26.950: INFO: Pod "pod-configmaps-baf260d1-a9de-4957-8db8-4c2c40fd3cc1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.055757847s
Feb 22 07:05:29.160: INFO: Pod "pod-configmaps-baf260d1-a9de-4957-8db8-4c2c40fd3cc1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.265781729s
Feb 22 07:05:31.232: INFO: Pod "pod-configmaps-baf260d1-a9de-4957-8db8-4c2c40fd3cc1": Phase="Pending", Reason="", readiness=false. Elapsed: 8.337909344s
Feb 22 07:05:33.244: INFO: Pod "pod-configmaps-baf260d1-a9de-4957-8db8-4c2c40fd3cc1": Phase="Pending", Reason="", readiness=false. Elapsed: 10.350377389s
Feb 22 07:05:35.273: INFO: Pod "pod-configmaps-baf260d1-a9de-4957-8db8-4c2c40fd3cc1": Phase="Pending", Reason="", readiness=false. Elapsed: 12.379170709s
Feb 22 07:05:37.293: INFO: Pod "pod-configmaps-baf260d1-a9de-4957-8db8-4c2c40fd3cc1": Phase="Pending", Reason="", readiness=false. Elapsed: 14.398796179s
Feb 22 07:05:39.303: INFO: Pod "pod-configmaps-baf260d1-a9de-4957-8db8-4c2c40fd3cc1": Phase="Pending", Reason="", readiness=false. Elapsed: 16.409192028s
Feb 22 07:05:41.311: INFO: Pod "pod-configmaps-baf260d1-a9de-4957-8db8-4c2c40fd3cc1": Phase="Pending", Reason="", readiness=false. Elapsed: 18.416780312s
Feb 22 07:05:43.323: INFO: Pod "pod-configmaps-baf260d1-a9de-4957-8db8-4c2c40fd3cc1": Phase="Pending", Reason="", readiness=false. Elapsed: 20.429591052s
Feb 22 07:05:45.351: INFO: Pod "pod-configmaps-baf260d1-a9de-4957-8db8-4c2c40fd3cc1": Phase="Pending", Reason="", readiness=false. Elapsed: 22.45684208s
Feb 22 07:05:47.356: INFO: Pod "pod-configmaps-baf260d1-a9de-4957-8db8-4c2c40fd3cc1": Phase="Pending", Reason="", readiness=false. Elapsed: 24.46270142s
Feb 22 07:05:49.364: INFO: Pod "pod-configmaps-baf260d1-a9de-4957-8db8-4c2c40fd3cc1": Phase="Pending", Reason="", readiness=false. Elapsed: 26.470038013s
Feb 22 07:05:51.371: INFO: Pod "pod-configmaps-baf260d1-a9de-4957-8db8-4c2c40fd3cc1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 28.477428536s
STEP: Saw pod success
Feb 22 07:05:51.371: INFO: Pod "pod-configmaps-baf260d1-a9de-4957-8db8-4c2c40fd3cc1" satisfied condition "Succeeded or Failed"
Feb 22 07:05:51.383: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com pod pod-configmaps-baf260d1-a9de-4957-8db8-4c2c40fd3cc1 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 22 07:05:51.458: INFO: Waiting for pod pod-configmaps-baf260d1-a9de-4957-8db8-4c2c40fd3cc1 to disappear
Feb 22 07:05:51.478: INFO: Pod pod-configmaps-baf260d1-a9de-4957-8db8-4c2c40fd3cc1 still exists
Feb 22 07:05:53.479: INFO: Waiting for pod pod-configmaps-baf260d1-a9de-4957-8db8-4c2c40fd3cc1 to disappear
Feb 22 07:05:53.489: INFO: Pod pod-configmaps-baf260d1-a9de-4957-8db8-4c2c40fd3cc1 still exists
Feb 22 07:05:55.479: INFO: Waiting for pod pod-configmaps-baf260d1-a9de-4957-8db8-4c2c40fd3cc1 to disappear
Feb 22 07:05:55.487: INFO: Pod pod-configmaps-baf260d1-a9de-4957-8db8-4c2c40fd3cc1 still exists
Feb 22 07:05:57.478: INFO: Waiting for pod pod-configmaps-baf260d1-a9de-4957-8db8-4c2c40fd3cc1 to disappear
Feb 22 07:05:57.491: INFO: Pod pod-configmaps-baf260d1-a9de-4957-8db8-4c2c40fd3cc1 still exists
Feb 22 07:05:59.478: INFO: Waiting for pod pod-configmaps-baf260d1-a9de-4957-8db8-4c2c40fd3cc1 to disappear
Feb 22 07:05:59.488: INFO: Pod pod-configmaps-baf260d1-a9de-4957-8db8-4c2c40fd3cc1 still exists
Feb 22 07:06:01.479: INFO: Waiting for pod pod-configmaps-baf260d1-a9de-4957-8db8-4c2c40fd3cc1 to disappear
Feb 22 07:06:01.496: INFO: Pod pod-configmaps-baf260d1-a9de-4957-8db8-4c2c40fd3cc1 still exists
Feb 22 07:06:03.479: INFO: Waiting for pod pod-configmaps-baf260d1-a9de-4957-8db8-4c2c40fd3cc1 to disappear
Feb 22 07:06:03.510: INFO: Pod pod-configmaps-baf260d1-a9de-4957-8db8-4c2c40fd3cc1 still exists
Feb 22 07:06:05.478: INFO: Waiting for pod pod-configmaps-baf260d1-a9de-4957-8db8-4c2c40fd3cc1 to disappear
Feb 22 07:06:05.489: INFO: Pod pod-configmaps-baf260d1-a9de-4957-8db8-4c2c40fd3cc1 still exists
Feb 22 07:06:07.479: INFO: Waiting for pod pod-configmaps-baf260d1-a9de-4957-8db8-4c2c40fd3cc1 to disappear
Feb 22 07:06:07.491: INFO: Pod pod-configmaps-baf260d1-a9de-4957-8db8-4c2c40fd3cc1 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 07:06:07.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2169" for this suite.

â€¢ [SLOW TEST:45.440 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:36
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]","total":270,"completed":226,"skipped":4032,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 07:06:07.580: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1846
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Feb 22 07:06:07.963: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e36be0e1-bfaa-42a1-8086-1e77afe1770e" in namespace "downward-api-1846" to be "Succeeded or Failed"
Feb 22 07:06:07.980: INFO: Pod "downwardapi-volume-e36be0e1-bfaa-42a1-8086-1e77afe1770e": Phase="Pending", Reason="", readiness=false. Elapsed: 17.78308ms
Feb 22 07:06:09.992: INFO: Pod "downwardapi-volume-e36be0e1-bfaa-42a1-8086-1e77afe1770e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029015886s
Feb 22 07:06:12.004: INFO: Pod "downwardapi-volume-e36be0e1-bfaa-42a1-8086-1e77afe1770e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.041063759s
Feb 22 07:06:14.016: INFO: Pod "downwardapi-volume-e36be0e1-bfaa-42a1-8086-1e77afe1770e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.053146629s
Feb 22 07:06:16.026: INFO: Pod "downwardapi-volume-e36be0e1-bfaa-42a1-8086-1e77afe1770e": Phase="Pending", Reason="", readiness=false. Elapsed: 8.063409629s
Feb 22 07:06:18.053: INFO: Pod "downwardapi-volume-e36be0e1-bfaa-42a1-8086-1e77afe1770e": Phase="Pending", Reason="", readiness=false. Elapsed: 10.089882196s
Feb 22 07:06:20.064: INFO: Pod "downwardapi-volume-e36be0e1-bfaa-42a1-8086-1e77afe1770e": Phase="Pending", Reason="", readiness=false. Elapsed: 12.100929703s
Feb 22 07:06:22.073: INFO: Pod "downwardapi-volume-e36be0e1-bfaa-42a1-8086-1e77afe1770e": Phase="Pending", Reason="", readiness=false. Elapsed: 14.110699053s
Feb 22 07:06:24.323: INFO: Pod "downwardapi-volume-e36be0e1-bfaa-42a1-8086-1e77afe1770e": Phase="Pending", Reason="", readiness=false. Elapsed: 16.360804938s
Feb 22 07:06:26.359: INFO: Pod "downwardapi-volume-e36be0e1-bfaa-42a1-8086-1e77afe1770e": Phase="Pending", Reason="", readiness=false. Elapsed: 18.395921243s
Feb 22 07:06:28.413: INFO: Pod "downwardapi-volume-e36be0e1-bfaa-42a1-8086-1e77afe1770e": Phase="Pending", Reason="", readiness=false. Elapsed: 20.45055162s
Feb 22 07:06:30.426: INFO: Pod "downwardapi-volume-e36be0e1-bfaa-42a1-8086-1e77afe1770e": Phase="Pending", Reason="", readiness=false. Elapsed: 22.463642147s
Feb 22 07:06:32.437: INFO: Pod "downwardapi-volume-e36be0e1-bfaa-42a1-8086-1e77afe1770e": Phase="Pending", Reason="", readiness=false. Elapsed: 24.474027362s
Feb 22 07:06:34.450: INFO: Pod "downwardapi-volume-e36be0e1-bfaa-42a1-8086-1e77afe1770e": Phase="Pending", Reason="", readiness=false. Elapsed: 26.487846953s
Feb 22 07:06:36.463: INFO: Pod "downwardapi-volume-e36be0e1-bfaa-42a1-8086-1e77afe1770e": Phase="Pending", Reason="", readiness=false. Elapsed: 28.50039793s
Feb 22 07:06:38.471: INFO: Pod "downwardapi-volume-e36be0e1-bfaa-42a1-8086-1e77afe1770e": Phase="Pending", Reason="", readiness=false. Elapsed: 30.508188975s
Feb 22 07:06:40.501: INFO: Pod "downwardapi-volume-e36be0e1-bfaa-42a1-8086-1e77afe1770e": Phase="Pending", Reason="", readiness=false. Elapsed: 32.537905651s
Feb 22 07:06:42.513: INFO: Pod "downwardapi-volume-e36be0e1-bfaa-42a1-8086-1e77afe1770e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 34.550783503s
STEP: Saw pod success
Feb 22 07:06:42.514: INFO: Pod "downwardapi-volume-e36be0e1-bfaa-42a1-8086-1e77afe1770e" satisfied condition "Succeeded or Failed"
Feb 22 07:06:42.526: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com pod downwardapi-volume-e36be0e1-bfaa-42a1-8086-1e77afe1770e container client-container: <nil>
STEP: delete the pod
Feb 22 07:06:50.528: INFO: Waiting for pod downwardapi-volume-e36be0e1-bfaa-42a1-8086-1e77afe1770e to disappear
Feb 22 07:06:50.619: INFO: Pod downwardapi-volume-e36be0e1-bfaa-42a1-8086-1e77afe1770e still exists
Feb 22 07:06:52.619: INFO: Waiting for pod downwardapi-volume-e36be0e1-bfaa-42a1-8086-1e77afe1770e to disappear
Feb 22 07:06:52.628: INFO: Pod downwardapi-volume-e36be0e1-bfaa-42a1-8086-1e77afe1770e still exists
Feb 22 07:06:54.620: INFO: Waiting for pod downwardapi-volume-e36be0e1-bfaa-42a1-8086-1e77afe1770e to disappear
Feb 22 07:06:54.636: INFO: Pod downwardapi-volume-e36be0e1-bfaa-42a1-8086-1e77afe1770e still exists
Feb 22 07:06:56.620: INFO: Waiting for pod downwardapi-volume-e36be0e1-bfaa-42a1-8086-1e77afe1770e to disappear
Feb 22 07:06:56.629: INFO: Pod downwardapi-volume-e36be0e1-bfaa-42a1-8086-1e77afe1770e no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 07:06:56.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1846" for this suite.

â€¢ [SLOW TEST:49.127 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:37
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","total":270,"completed":227,"skipped":4050,"failed":0}
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 07:06:56.713: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7724
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Feb 22 07:06:57.251: INFO: Waiting up to 5m0s for pod "downwardapi-volume-13238277-969b-430c-b876-6dcb75150397" in namespace "projected-7724" to be "Succeeded or Failed"
Feb 22 07:06:57.267: INFO: Pod "downwardapi-volume-13238277-969b-430c-b876-6dcb75150397": Phase="Pending", Reason="", readiness=false. Elapsed: 15.401391ms
Feb 22 07:06:59.281: INFO: Pod "downwardapi-volume-13238277-969b-430c-b876-6dcb75150397": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029447429s
Feb 22 07:07:01.294: INFO: Pod "downwardapi-volume-13238277-969b-430c-b876-6dcb75150397": Phase="Pending", Reason="", readiness=false. Elapsed: 4.042979965s
Feb 22 07:07:03.308: INFO: Pod "downwardapi-volume-13238277-969b-430c-b876-6dcb75150397": Phase="Pending", Reason="", readiness=false. Elapsed: 6.056035642s
Feb 22 07:07:05.319: INFO: Pod "downwardapi-volume-13238277-969b-430c-b876-6dcb75150397": Phase="Pending", Reason="", readiness=false. Elapsed: 8.067186312s
Feb 22 07:07:07.327: INFO: Pod "downwardapi-volume-13238277-969b-430c-b876-6dcb75150397": Phase="Pending", Reason="", readiness=false. Elapsed: 10.075849319s
Feb 22 07:07:09.337: INFO: Pod "downwardapi-volume-13238277-969b-430c-b876-6dcb75150397": Phase="Pending", Reason="", readiness=false. Elapsed: 12.085129585s
Feb 22 07:07:11.354: INFO: Pod "downwardapi-volume-13238277-969b-430c-b876-6dcb75150397": Phase="Pending", Reason="", readiness=false. Elapsed: 14.102447918s
Feb 22 07:07:13.369: INFO: Pod "downwardapi-volume-13238277-969b-430c-b876-6dcb75150397": Phase="Pending", Reason="", readiness=false. Elapsed: 16.117661925s
Feb 22 07:07:15.377: INFO: Pod "downwardapi-volume-13238277-969b-430c-b876-6dcb75150397": Phase="Pending", Reason="", readiness=false. Elapsed: 18.125924259s
Feb 22 07:07:17.386: INFO: Pod "downwardapi-volume-13238277-969b-430c-b876-6dcb75150397": Phase="Pending", Reason="", readiness=false. Elapsed: 20.134263313s
Feb 22 07:07:19.394: INFO: Pod "downwardapi-volume-13238277-969b-430c-b876-6dcb75150397": Phase="Pending", Reason="", readiness=false. Elapsed: 22.142776064s
Feb 22 07:07:21.401: INFO: Pod "downwardapi-volume-13238277-969b-430c-b876-6dcb75150397": Phase="Pending", Reason="", readiness=false. Elapsed: 24.149639063s
Feb 22 07:07:23.425: INFO: Pod "downwardapi-volume-13238277-969b-430c-b876-6dcb75150397": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.173392223s
STEP: Saw pod success
Feb 22 07:07:23.425: INFO: Pod "downwardapi-volume-13238277-969b-430c-b876-6dcb75150397" satisfied condition "Succeeded or Failed"
Feb 22 07:07:23.442: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com pod downwardapi-volume-13238277-969b-430c-b876-6dcb75150397 container client-container: <nil>
STEP: delete the pod
Feb 22 07:07:29.963: INFO: Waiting for pod downwardapi-volume-13238277-969b-430c-b876-6dcb75150397 to disappear
Feb 22 07:07:30.011: INFO: Pod downwardapi-volume-13238277-969b-430c-b876-6dcb75150397 still exists
Feb 22 07:07:32.011: INFO: Waiting for pod downwardapi-volume-13238277-969b-430c-b876-6dcb75150397 to disappear
Feb 22 07:07:32.027: INFO: Pod downwardapi-volume-13238277-969b-430c-b876-6dcb75150397 still exists
Feb 22 07:07:34.011: INFO: Waiting for pod downwardapi-volume-13238277-969b-430c-b876-6dcb75150397 to disappear
Feb 22 07:07:34.018: INFO: Pod downwardapi-volume-13238277-969b-430c-b876-6dcb75150397 still exists
Feb 22 07:07:36.011: INFO: Waiting for pod downwardapi-volume-13238277-969b-430c-b876-6dcb75150397 to disappear
Feb 22 07:07:36.019: INFO: Pod downwardapi-volume-13238277-969b-430c-b876-6dcb75150397 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 07:07:36.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7724" for this suite.

â€¢ [SLOW TEST:39.342 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:36
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","total":270,"completed":228,"skipped":4051,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 07:07:36.066: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7818
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-37421638-4ad4-4b6a-a203-7dbc1e966ea1
STEP: Creating a pod to test consume configMaps
Feb 22 07:07:36.424: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-daf1fe4d-7f87-4c24-9262-9226e12b1506" in namespace "projected-7818" to be "Succeeded or Failed"
Feb 22 07:07:36.437: INFO: Pod "pod-projected-configmaps-daf1fe4d-7f87-4c24-9262-9226e12b1506": Phase="Pending", Reason="", readiness=false. Elapsed: 13.220552ms
Feb 22 07:07:38.448: INFO: Pod "pod-projected-configmaps-daf1fe4d-7f87-4c24-9262-9226e12b1506": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024823347s
Feb 22 07:07:40.456: INFO: Pod "pod-projected-configmaps-daf1fe4d-7f87-4c24-9262-9226e12b1506": Phase="Pending", Reason="", readiness=false. Elapsed: 4.0318911s
Feb 22 07:07:42.466: INFO: Pod "pod-projected-configmaps-daf1fe4d-7f87-4c24-9262-9226e12b1506": Phase="Pending", Reason="", readiness=false. Elapsed: 6.04193432s
Feb 22 07:07:44.475: INFO: Pod "pod-projected-configmaps-daf1fe4d-7f87-4c24-9262-9226e12b1506": Phase="Pending", Reason="", readiness=false. Elapsed: 8.05146921s
Feb 22 07:07:46.482: INFO: Pod "pod-projected-configmaps-daf1fe4d-7f87-4c24-9262-9226e12b1506": Phase="Pending", Reason="", readiness=false. Elapsed: 10.058384238s
Feb 22 07:07:48.489: INFO: Pod "pod-projected-configmaps-daf1fe4d-7f87-4c24-9262-9226e12b1506": Phase="Pending", Reason="", readiness=false. Elapsed: 12.065019894s
Feb 22 07:07:50.496: INFO: Pod "pod-projected-configmaps-daf1fe4d-7f87-4c24-9262-9226e12b1506": Phase="Pending", Reason="", readiness=false. Elapsed: 14.072802833s
Feb 22 07:07:52.504: INFO: Pod "pod-projected-configmaps-daf1fe4d-7f87-4c24-9262-9226e12b1506": Phase="Pending", Reason="", readiness=false. Elapsed: 16.080183833s
Feb 22 07:07:54.513: INFO: Pod "pod-projected-configmaps-daf1fe4d-7f87-4c24-9262-9226e12b1506": Phase="Pending", Reason="", readiness=false. Elapsed: 18.089820241s
Feb 22 07:07:56.543: INFO: Pod "pod-projected-configmaps-daf1fe4d-7f87-4c24-9262-9226e12b1506": Phase="Pending", Reason="", readiness=false. Elapsed: 20.119773721s
Feb 22 07:07:58.549: INFO: Pod "pod-projected-configmaps-daf1fe4d-7f87-4c24-9262-9226e12b1506": Phase="Pending", Reason="", readiness=false. Elapsed: 22.125834339s
Feb 22 07:08:00.562: INFO: Pod "pod-projected-configmaps-daf1fe4d-7f87-4c24-9262-9226e12b1506": Phase="Pending", Reason="", readiness=false. Elapsed: 24.138159018s
Feb 22 07:08:02.573: INFO: Pod "pod-projected-configmaps-daf1fe4d-7f87-4c24-9262-9226e12b1506": Phase="Pending", Reason="", readiness=false. Elapsed: 26.149628268s
Feb 22 07:08:04.589: INFO: Pod "pod-projected-configmaps-daf1fe4d-7f87-4c24-9262-9226e12b1506": Phase="Succeeded", Reason="", readiness=false. Elapsed: 28.165618505s
STEP: Saw pod success
Feb 22 07:08:04.589: INFO: Pod "pod-projected-configmaps-daf1fe4d-7f87-4c24-9262-9226e12b1506" satisfied condition "Succeeded or Failed"
Feb 22 07:08:04.609: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com pod pod-projected-configmaps-daf1fe4d-7f87-4c24-9262-9226e12b1506 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 22 07:08:10.776: INFO: Waiting for pod pod-projected-configmaps-daf1fe4d-7f87-4c24-9262-9226e12b1506 to disappear
Feb 22 07:08:10.798: INFO: Pod pod-projected-configmaps-daf1fe4d-7f87-4c24-9262-9226e12b1506 still exists
Feb 22 07:08:12.799: INFO: Waiting for pod pod-projected-configmaps-daf1fe4d-7f87-4c24-9262-9226e12b1506 to disappear
Feb 22 07:08:12.808: INFO: Pod pod-projected-configmaps-daf1fe4d-7f87-4c24-9262-9226e12b1506 still exists
Feb 22 07:08:14.799: INFO: Waiting for pod pod-projected-configmaps-daf1fe4d-7f87-4c24-9262-9226e12b1506 to disappear
Feb 22 07:08:14.822: INFO: Pod pod-projected-configmaps-daf1fe4d-7f87-4c24-9262-9226e12b1506 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 07:08:14.822: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7818" for this suite.

â€¢ [SLOW TEST:38.804 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:36
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":270,"completed":229,"skipped":4098,"failed":0}
S
------------------------------
[sig-cli] Kubectl client Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 07:08:14.871: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-559
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Kubectl run pod
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1418
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: running the image mirror.gcr.io/library/httpd:2.4.38-alpine
Feb 22 07:08:15.135: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config run e2e-test-httpd-pod --restart=Never --image=mirror.gcr.io/library/httpd:2.4.38-alpine --namespace=kubectl-559'
Feb 22 07:08:15.641: INFO: stderr: ""
Feb 22 07:08:15.641: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created
[AfterEach] Kubectl run pod
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1423
Feb 22 07:08:15.650: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config delete pods e2e-test-httpd-pod --namespace=kubectl-559'
Feb 22 07:08:15.988: INFO: stderr: ""
Feb 22 07:08:15.988: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 07:08:15.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-559" for this suite.
â€¢{"msg":"PASSED [sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never  [Conformance]","total":270,"completed":230,"skipped":4099,"failed":0}
SSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 07:08:16.045: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-5085
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-5085
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a new StatefulSet
Feb 22 07:08:16.442: INFO: Found 0 stateful pods, waiting for 3
Feb 22 07:08:26.456: INFO: Found 1 stateful pods, waiting for 3
Feb 22 07:08:36.455: INFO: Found 1 stateful pods, waiting for 3
Feb 22 07:08:46.452: INFO: Found 1 stateful pods, waiting for 3
Feb 22 07:08:56.454: INFO: Found 2 stateful pods, waiting for 3
Feb 22 07:09:06.451: INFO: Found 2 stateful pods, waiting for 3
Feb 22 07:09:16.453: INFO: Found 2 stateful pods, waiting for 3
Feb 22 07:09:26.454: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 22 07:09:26.454: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 22 07:09:26.454: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Feb 22 07:09:36.505: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 22 07:09:36.506: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 22 07:09:36.513: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Feb 22 07:09:46.459: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 22 07:09:46.459: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 22 07:09:46.459: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from mirror.gcr.io/library/httpd:2.4.38-alpine to mirror.gcr.io/library/httpd:2.4.39-alpine
Feb 22 07:09:46.593: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Feb 22 07:09:57.014: INFO: Updating stateful set ss2
Feb 22 07:09:57.356: INFO: Waiting for Pod statefulset-5085/ss2-2 to have revision ss2-6dc56fb9cb update revision ss2-6969d67667
Feb 22 07:10:07.389: INFO: Waiting for Pod statefulset-5085/ss2-2 to have revision ss2-6dc56fb9cb update revision ss2-6969d67667
STEP: Restoring Pods to the correct revision when they are deleted
Feb 22 07:10:17.707: INFO: Found 2 stateful pods, waiting for 3
Feb 22 07:10:27.719: INFO: Found 2 stateful pods, waiting for 3
Feb 22 07:10:37.722: INFO: Found 2 stateful pods, waiting for 3
Feb 22 07:10:48.195: INFO: Found 2 stateful pods, waiting for 3
Feb 22 07:10:57.731: INFO: Found 2 stateful pods, waiting for 3
Feb 22 07:11:07.726: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 22 07:11:07.727: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 22 07:11:07.728: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Feb 22 07:11:17.723: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 22 07:11:17.723: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 22 07:11:17.723: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Feb 22 07:11:27.725: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 22 07:11:27.725: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 22 07:11:27.725: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Feb 22 07:11:38.066: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 22 07:11:38.066: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 22 07:11:38.066: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Feb 22 07:11:47.757: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 22 07:11:47.757: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 22 07:11:47.757: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Feb 22 07:11:57.811: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 22 07:11:57.817: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 22 07:11:57.817: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Feb 22 07:12:07.770: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 22 07:12:07.771: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 22 07:12:07.772: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Feb 22 07:12:07.889: INFO: Updating stateful set ss2
Feb 22 07:12:08.024: INFO: Waiting for Pod statefulset-5085/ss2-1 to have revision ss2-6dc56fb9cb update revision ss2-6969d67667
Feb 22 07:12:18.045: INFO: Waiting for Pod statefulset-5085/ss2-1 to have revision ss2-6dc56fb9cb update revision ss2-6969d67667
Feb 22 07:12:28.097: INFO: Updating stateful set ss2
Feb 22 07:12:28.149: INFO: Waiting for StatefulSet statefulset-5085/ss2 to complete update
Feb 22 07:12:28.150: INFO: Waiting for Pod statefulset-5085/ss2-0 to have revision ss2-6dc56fb9cb update revision ss2-6969d67667
Feb 22 07:12:38.186: INFO: Waiting for StatefulSet statefulset-5085/ss2 to complete update
Feb 22 07:12:38.186: INFO: Waiting for Pod statefulset-5085/ss2-0 to have revision ss2-6dc56fb9cb update revision ss2-6969d67667
Feb 22 07:12:48.244: INFO: Waiting for StatefulSet statefulset-5085/ss2 to complete update
Feb 22 07:12:48.244: INFO: Waiting for Pod statefulset-5085/ss2-0 to have revision ss2-6dc56fb9cb update revision ss2-6969d67667
Feb 22 07:12:58.170: INFO: Waiting for StatefulSet statefulset-5085/ss2 to complete update
Feb 22 07:12:58.171: INFO: Waiting for Pod statefulset-5085/ss2-0 to have revision ss2-6dc56fb9cb update revision ss2-6969d67667
Feb 22 07:13:08.184: INFO: Waiting for StatefulSet statefulset-5085/ss2 to complete update
Feb 22 07:13:08.184: INFO: Waiting for Pod statefulset-5085/ss2-0 to have revision ss2-6dc56fb9cb update revision ss2-6969d67667
Feb 22 07:13:18.179: INFO: Waiting for StatefulSet statefulset-5085/ss2 to complete update
Feb 22 07:13:28.216: INFO: Waiting for StatefulSet statefulset-5085/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Feb 22 07:13:38.199: INFO: Deleting all statefulset in ns statefulset-5085
Feb 22 07:13:38.224: INFO: Scaling statefulset ss2 to 0
Feb 22 07:14:18.300: INFO: Waiting for statefulset status.replicas updated to 0
Feb 22 07:14:18.308: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 07:14:18.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5085" for this suite.

â€¢ [SLOW TEST:362.569 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]","total":270,"completed":231,"skipped":4102,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 07:14:18.624: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-9831
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test substitution in container's args
Feb 22 07:14:19.200: INFO: Waiting up to 5m0s for pod "var-expansion-51943867-4405-4af8-82ef-07bf00601ed8" in namespace "var-expansion-9831" to be "Succeeded or Failed"
Feb 22 07:14:19.236: INFO: Pod "var-expansion-51943867-4405-4af8-82ef-07bf00601ed8": Phase="Pending", Reason="", readiness=false. Elapsed: 36.313206ms
Feb 22 07:14:21.252: INFO: Pod "var-expansion-51943867-4405-4af8-82ef-07bf00601ed8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051906289s
Feb 22 07:14:23.260: INFO: Pod "var-expansion-51943867-4405-4af8-82ef-07bf00601ed8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.059877167s
Feb 22 07:14:25.273: INFO: Pod "var-expansion-51943867-4405-4af8-82ef-07bf00601ed8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.073026003s
Feb 22 07:14:27.285: INFO: Pod "var-expansion-51943867-4405-4af8-82ef-07bf00601ed8": Phase="Pending", Reason="", readiness=false. Elapsed: 8.085537937s
Feb 22 07:14:29.295: INFO: Pod "var-expansion-51943867-4405-4af8-82ef-07bf00601ed8": Phase="Pending", Reason="", readiness=false. Elapsed: 10.095591517s
Feb 22 07:14:31.304: INFO: Pod "var-expansion-51943867-4405-4af8-82ef-07bf00601ed8": Phase="Pending", Reason="", readiness=false. Elapsed: 12.104411979s
Feb 22 07:14:33.314: INFO: Pod "var-expansion-51943867-4405-4af8-82ef-07bf00601ed8": Phase="Pending", Reason="", readiness=false. Elapsed: 14.114172967s
Feb 22 07:14:35.322: INFO: Pod "var-expansion-51943867-4405-4af8-82ef-07bf00601ed8": Phase="Pending", Reason="", readiness=false. Elapsed: 16.122670781s
Feb 22 07:14:37.351: INFO: Pod "var-expansion-51943867-4405-4af8-82ef-07bf00601ed8": Phase="Pending", Reason="", readiness=false. Elapsed: 18.151550495s
Feb 22 07:14:39.360: INFO: Pod "var-expansion-51943867-4405-4af8-82ef-07bf00601ed8": Phase="Pending", Reason="", readiness=false. Elapsed: 20.160468552s
Feb 22 07:14:41.369: INFO: Pod "var-expansion-51943867-4405-4af8-82ef-07bf00601ed8": Phase="Pending", Reason="", readiness=false. Elapsed: 22.169230556s
Feb 22 07:14:43.380: INFO: Pod "var-expansion-51943867-4405-4af8-82ef-07bf00601ed8": Phase="Pending", Reason="", readiness=false. Elapsed: 24.180219266s
Feb 22 07:14:45.388: INFO: Pod "var-expansion-51943867-4405-4af8-82ef-07bf00601ed8": Phase="Pending", Reason="", readiness=false. Elapsed: 26.188501289s
Feb 22 07:14:47.402: INFO: Pod "var-expansion-51943867-4405-4af8-82ef-07bf00601ed8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 28.20213213s
STEP: Saw pod success
Feb 22 07:14:47.402: INFO: Pod "var-expansion-51943867-4405-4af8-82ef-07bf00601ed8" satisfied condition "Succeeded or Failed"
Feb 22 07:14:47.424: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com pod var-expansion-51943867-4405-4af8-82ef-07bf00601ed8 container dapi-container: <nil>
STEP: delete the pod
Feb 22 07:14:47.509: INFO: Waiting for pod var-expansion-51943867-4405-4af8-82ef-07bf00601ed8 to disappear
Feb 22 07:14:47.538: INFO: Pod var-expansion-51943867-4405-4af8-82ef-07bf00601ed8 still exists
Feb 22 07:14:49.539: INFO: Waiting for pod var-expansion-51943867-4405-4af8-82ef-07bf00601ed8 to disappear
Feb 22 07:14:49.548: INFO: Pod var-expansion-51943867-4405-4af8-82ef-07bf00601ed8 still exists
Feb 22 07:14:51.539: INFO: Waiting for pod var-expansion-51943867-4405-4af8-82ef-07bf00601ed8 to disappear
Feb 22 07:14:51.562: INFO: Pod var-expansion-51943867-4405-4af8-82ef-07bf00601ed8 still exists
Feb 22 07:14:53.541: INFO: Waiting for pod var-expansion-51943867-4405-4af8-82ef-07bf00601ed8 to disappear
Feb 22 07:14:53.692: INFO: Pod var-expansion-51943867-4405-4af8-82ef-07bf00601ed8 still exists
Feb 22 07:14:55.539: INFO: Waiting for pod var-expansion-51943867-4405-4af8-82ef-07bf00601ed8 to disappear
Feb 22 07:14:55.553: INFO: Pod var-expansion-51943867-4405-4af8-82ef-07bf00601ed8 still exists
Feb 22 07:14:57.539: INFO: Waiting for pod var-expansion-51943867-4405-4af8-82ef-07bf00601ed8 to disappear
Feb 22 07:14:57.572: INFO: Pod var-expansion-51943867-4405-4af8-82ef-07bf00601ed8 still exists
Feb 22 07:14:59.539: INFO: Waiting for pod var-expansion-51943867-4405-4af8-82ef-07bf00601ed8 to disappear
Feb 22 07:14:59.551: INFO: Pod var-expansion-51943867-4405-4af8-82ef-07bf00601ed8 still exists
Feb 22 07:15:01.539: INFO: Waiting for pod var-expansion-51943867-4405-4af8-82ef-07bf00601ed8 to disappear
Feb 22 07:15:01.569: INFO: Pod var-expansion-51943867-4405-4af8-82ef-07bf00601ed8 still exists
Feb 22 07:15:03.539: INFO: Waiting for pod var-expansion-51943867-4405-4af8-82ef-07bf00601ed8 to disappear
Feb 22 07:15:03.588: INFO: Pod var-expansion-51943867-4405-4af8-82ef-07bf00601ed8 still exists
Feb 22 07:15:05.539: INFO: Waiting for pod var-expansion-51943867-4405-4af8-82ef-07bf00601ed8 to disappear
Feb 22 07:15:05.553: INFO: Pod var-expansion-51943867-4405-4af8-82ef-07bf00601ed8 still exists
Feb 22 07:15:07.539: INFO: Waiting for pod var-expansion-51943867-4405-4af8-82ef-07bf00601ed8 to disappear
Feb 22 07:15:07.560: INFO: Pod var-expansion-51943867-4405-4af8-82ef-07bf00601ed8 still exists
Feb 22 07:15:09.542: INFO: Waiting for pod var-expansion-51943867-4405-4af8-82ef-07bf00601ed8 to disappear
Feb 22 07:15:09.606: INFO: Pod var-expansion-51943867-4405-4af8-82ef-07bf00601ed8 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 07:15:09.611: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-9831" for this suite.

â€¢ [SLOW TEST:51.244 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]","total":270,"completed":232,"skipped":4123,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 07:15:09.915: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-4301
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Feb 22 07:15:10.997: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:11.001: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:11.002: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:11.015: INFO: Number of nodes with available pods: 0
Feb 22 07:15:11.015: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 07:15:12.040: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:12.041: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:12.041: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:12.076: INFO: Number of nodes with available pods: 0
Feb 22 07:15:12.076: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 07:15:13.076: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:13.077: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:13.077: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:13.112: INFO: Number of nodes with available pods: 0
Feb 22 07:15:13.112: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 07:15:14.091: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:14.091: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:14.092: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:14.122: INFO: Number of nodes with available pods: 0
Feb 22 07:15:14.122: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 07:15:15.048: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:15.048: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:15.048: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:15.072: INFO: Number of nodes with available pods: 0
Feb 22 07:15:15.072: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 07:15:16.078: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:16.079: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:16.079: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:16.106: INFO: Number of nodes with available pods: 0
Feb 22 07:15:16.106: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 07:15:17.065: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:17.066: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:17.066: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:17.101: INFO: Number of nodes with available pods: 0
Feb 22 07:15:17.101: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 07:15:18.066: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:18.068: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:18.072: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:18.092: INFO: Number of nodes with available pods: 0
Feb 22 07:15:18.092: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 07:15:19.065: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:19.065: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:19.065: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:19.084: INFO: Number of nodes with available pods: 0
Feb 22 07:15:19.084: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 07:15:20.061: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:20.062: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:20.062: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:20.078: INFO: Number of nodes with available pods: 0
Feb 22 07:15:20.078: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 07:15:21.104: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:21.105: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:21.105: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:21.155: INFO: Number of nodes with available pods: 0
Feb 22 07:15:21.156: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 07:15:22.040: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:22.041: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:22.041: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:22.059: INFO: Number of nodes with available pods: 0
Feb 22 07:15:22.059: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 07:15:23.052: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:23.053: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:23.053: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:23.309: INFO: Number of nodes with available pods: 0
Feb 22 07:15:23.309: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 07:15:24.120: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:24.120: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:24.120: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:24.194: INFO: Number of nodes with available pods: 0
Feb 22 07:15:24.194: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 07:15:25.031: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:25.031: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:25.031: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:25.045: INFO: Number of nodes with available pods: 0
Feb 22 07:15:25.045: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 07:15:26.041: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:26.042: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:26.042: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:26.055: INFO: Number of nodes with available pods: 0
Feb 22 07:15:26.055: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 07:15:27.030: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:27.031: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:27.031: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:27.042: INFO: Number of nodes with available pods: 0
Feb 22 07:15:27.042: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 07:15:28.032: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:28.032: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:28.033: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:28.054: INFO: Number of nodes with available pods: 0
Feb 22 07:15:28.054: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 07:15:29.054: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:29.056: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:29.057: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:29.082: INFO: Number of nodes with available pods: 0
Feb 22 07:15:29.082: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 07:15:30.039: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:30.039: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:30.040: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:30.060: INFO: Number of nodes with available pods: 0
Feb 22 07:15:30.061: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 07:15:31.037: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:31.038: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:31.038: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:31.058: INFO: Number of nodes with available pods: 0
Feb 22 07:15:31.058: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 07:15:32.033: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:32.034: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:32.034: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:32.049: INFO: Number of nodes with available pods: 0
Feb 22 07:15:32.049: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 07:15:33.028: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:33.028: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:33.029: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:33.040: INFO: Number of nodes with available pods: 0
Feb 22 07:15:33.040: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 07:15:34.032: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:34.033: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:34.033: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:34.050: INFO: Number of nodes with available pods: 0
Feb 22 07:15:34.050: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 07:15:35.468: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:35.477: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:35.478: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:36.774: INFO: Number of nodes with available pods: 0
Feb 22 07:15:36.782: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 07:15:37.458: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:37.459: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:37.464: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:37.869: INFO: Number of nodes with available pods: 0
Feb 22 07:15:37.869: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 07:15:38.150: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:38.151: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:38.152: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:38.192: INFO: Number of nodes with available pods: 0
Feb 22 07:15:38.192: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 07:15:39.050: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:39.050: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:39.051: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:39.122: INFO: Number of nodes with available pods: 0
Feb 22 07:15:39.122: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 07:15:40.031: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:40.032: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:40.032: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:40.066: INFO: Number of nodes with available pods: 1
Feb 22 07:15:40.066: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 07:15:41.064: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:41.065: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:41.065: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:41.079: INFO: Number of nodes with available pods: 1
Feb 22 07:15:41.079: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 07:15:42.055: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:42.055: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:42.055: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:42.085: INFO: Number of nodes with available pods: 1
Feb 22 07:15:42.085: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 07:15:43.040: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:43.040: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:43.040: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:43.074: INFO: Number of nodes with available pods: 1
Feb 22 07:15:43.074: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 07:15:44.055: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:44.060: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:44.061: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:44.103: INFO: Number of nodes with available pods: 3
Feb 22 07:15:44.103: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Feb 22 07:15:44.228: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:44.228: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:44.228: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:44.304: INFO: Number of nodes with available pods: 2
Feb 22 07:15:44.305: INFO: Node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com is running more than one daemon pod
Feb 22 07:15:45.328: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:45.330: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:45.331: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:45.345: INFO: Number of nodes with available pods: 2
Feb 22 07:15:45.345: INFO: Node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com is running more than one daemon pod
Feb 22 07:15:46.323: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:46.323: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:46.324: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:46.351: INFO: Number of nodes with available pods: 2
Feb 22 07:15:46.351: INFO: Node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com is running more than one daemon pod
Feb 22 07:15:47.320: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:47.320: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:47.321: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:47.337: INFO: Number of nodes with available pods: 2
Feb 22 07:15:47.337: INFO: Node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com is running more than one daemon pod
Feb 22 07:15:48.352: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:48.353: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:48.353: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:48.405: INFO: Number of nodes with available pods: 2
Feb 22 07:15:48.405: INFO: Node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com is running more than one daemon pod
Feb 22 07:15:49.326: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:49.326: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:49.326: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:49.338: INFO: Number of nodes with available pods: 2
Feb 22 07:15:49.338: INFO: Node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com is running more than one daemon pod
Feb 22 07:15:50.341: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:50.341: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:50.341: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:50.367: INFO: Number of nodes with available pods: 2
Feb 22 07:15:50.367: INFO: Node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com is running more than one daemon pod
Feb 22 07:15:51.332: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:51.333: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:51.333: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:51.349: INFO: Number of nodes with available pods: 2
Feb 22 07:15:51.349: INFO: Node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com is running more than one daemon pod
Feb 22 07:15:52.321: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:52.321: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:52.321: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:52.332: INFO: Number of nodes with available pods: 2
Feb 22 07:15:52.332: INFO: Node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com is running more than one daemon pod
Feb 22 07:15:53.326: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:53.326: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:53.327: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:53.353: INFO: Number of nodes with available pods: 2
Feb 22 07:15:53.353: INFO: Node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com is running more than one daemon pod
Feb 22 07:15:54.327: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:54.328: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:54.328: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:54.342: INFO: Number of nodes with available pods: 2
Feb 22 07:15:54.342: INFO: Node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com is running more than one daemon pod
Feb 22 07:15:55.316: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:55.316: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:55.316: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:55.337: INFO: Number of nodes with available pods: 2
Feb 22 07:15:55.337: INFO: Node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com is running more than one daemon pod
Feb 22 07:15:56.317: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:56.318: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:56.318: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:56.346: INFO: Number of nodes with available pods: 2
Feb 22 07:15:56.347: INFO: Node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com is running more than one daemon pod
Feb 22 07:15:57.334: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:57.335: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:57.335: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:57.345: INFO: Number of nodes with available pods: 2
Feb 22 07:15:57.345: INFO: Node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com is running more than one daemon pod
Feb 22 07:15:58.325: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:58.327: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:58.328: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:58.347: INFO: Number of nodes with available pods: 2
Feb 22 07:15:58.347: INFO: Node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com is running more than one daemon pod
Feb 22 07:15:59.329: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:59.329: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:59.329: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:15:59.339: INFO: Number of nodes with available pods: 2
Feb 22 07:15:59.339: INFO: Node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com is running more than one daemon pod
Feb 22 07:16:00.340: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:00.340: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:00.340: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:00.357: INFO: Number of nodes with available pods: 2
Feb 22 07:16:00.357: INFO: Node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com is running more than one daemon pod
Feb 22 07:16:01.356: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:01.356: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:01.357: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:01.395: INFO: Number of nodes with available pods: 2
Feb 22 07:16:01.395: INFO: Node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com is running more than one daemon pod
Feb 22 07:16:02.364: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:02.365: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:02.365: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:02.393: INFO: Number of nodes with available pods: 2
Feb 22 07:16:02.393: INFO: Node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com is running more than one daemon pod
Feb 22 07:16:03.348: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:03.348: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:03.348: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:03.389: INFO: Number of nodes with available pods: 2
Feb 22 07:16:03.389: INFO: Node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com is running more than one daemon pod
Feb 22 07:16:04.369: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:04.370: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:04.370: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:04.393: INFO: Number of nodes with available pods: 2
Feb 22 07:16:04.393: INFO: Node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com is running more than one daemon pod
Feb 22 07:16:05.322: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:05.322: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:05.322: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:05.339: INFO: Number of nodes with available pods: 2
Feb 22 07:16:05.340: INFO: Node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com is running more than one daemon pod
Feb 22 07:16:06.325: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:06.325: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:06.326: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:06.339: INFO: Number of nodes with available pods: 2
Feb 22 07:16:06.339: INFO: Node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com is running more than one daemon pod
Feb 22 07:16:07.322: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:07.322: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:07.323: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:07.334: INFO: Number of nodes with available pods: 2
Feb 22 07:16:07.334: INFO: Node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com is running more than one daemon pod
Feb 22 07:16:08.326: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:08.327: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:08.329: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:08.339: INFO: Number of nodes with available pods: 2
Feb 22 07:16:08.339: INFO: Node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com is running more than one daemon pod
Feb 22 07:16:09.318: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:09.319: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:09.319: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:09.334: INFO: Number of nodes with available pods: 2
Feb 22 07:16:09.334: INFO: Node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com is running more than one daemon pod
Feb 22 07:16:10.318: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:10.318: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:10.318: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:10.328: INFO: Number of nodes with available pods: 2
Feb 22 07:16:10.328: INFO: Node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com is running more than one daemon pod
Feb 22 07:16:11.319: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:11.319: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:11.319: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:11.328: INFO: Number of nodes with available pods: 2
Feb 22 07:16:11.328: INFO: Node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com is running more than one daemon pod
Feb 22 07:16:12.317: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:12.318: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:12.318: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:12.329: INFO: Number of nodes with available pods: 2
Feb 22 07:16:12.329: INFO: Node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com is running more than one daemon pod
Feb 22 07:16:13.314: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:13.314: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:13.315: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:13.322: INFO: Number of nodes with available pods: 2
Feb 22 07:16:13.322: INFO: Node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com is running more than one daemon pod
Feb 22 07:16:14.317: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:14.318: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:14.318: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:14.330: INFO: Number of nodes with available pods: 2
Feb 22 07:16:14.330: INFO: Node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com is running more than one daemon pod
Feb 22 07:16:15.321: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:15.321: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:15.321: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:15.330: INFO: Number of nodes with available pods: 2
Feb 22 07:16:15.330: INFO: Node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com is running more than one daemon pod
Feb 22 07:16:16.320: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:16.320: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:16.320: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:16.331: INFO: Number of nodes with available pods: 2
Feb 22 07:16:16.331: INFO: Node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com is running more than one daemon pod
Feb 22 07:16:17.316: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:17.317: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:17.318: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:17.331: INFO: Number of nodes with available pods: 2
Feb 22 07:16:17.331: INFO: Node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com is running more than one daemon pod
Feb 22 07:16:18.340: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:18.340: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:18.340: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:18.363: INFO: Number of nodes with available pods: 2
Feb 22 07:16:18.363: INFO: Node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com is running more than one daemon pod
Feb 22 07:16:19.326: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:19.326: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:19.326: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:19.339: INFO: Number of nodes with available pods: 2
Feb 22 07:16:19.339: INFO: Node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com is running more than one daemon pod
Feb 22 07:16:20.338: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:20.338: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:20.338: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:20.375: INFO: Number of nodes with available pods: 2
Feb 22 07:16:20.376: INFO: Node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com is running more than one daemon pod
Feb 22 07:16:21.321: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:21.321: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:21.321: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:21.341: INFO: Number of nodes with available pods: 2
Feb 22 07:16:21.341: INFO: Node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com is running more than one daemon pod
Feb 22 07:16:22.342: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:22.342: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:22.343: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:22.355: INFO: Number of nodes with available pods: 2
Feb 22 07:16:22.355: INFO: Node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com is running more than one daemon pod
Feb 22 07:16:23.320: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:23.320: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:23.320: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:23.329: INFO: Number of nodes with available pods: 2
Feb 22 07:16:23.329: INFO: Node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com is running more than one daemon pod
Feb 22 07:16:24.318: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:24.318: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:24.319: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:24.332: INFO: Number of nodes with available pods: 2
Feb 22 07:16:24.332: INFO: Node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com is running more than one daemon pod
Feb 22 07:16:25.322: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:25.322: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:25.322: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:25.331: INFO: Number of nodes with available pods: 2
Feb 22 07:16:25.331: INFO: Node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com is running more than one daemon pod
Feb 22 07:16:26.315: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:26.315: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:26.315: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:26.327: INFO: Number of nodes with available pods: 2
Feb 22 07:16:26.327: INFO: Node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com is running more than one daemon pod
Feb 22 07:16:27.368: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:27.369: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:27.369: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:16:27.428: INFO: Number of nodes with available pods: 3
Feb 22 07:16:27.428: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4301, will wait for the garbage collector to delete the pods
Feb 22 07:16:27.543: INFO: Deleting DaemonSet.extensions daemon-set took: 32.344024ms
Feb 22 07:16:29.444: INFO: Terminating DaemonSet.extensions daemon-set pods took: 1.900655394s
Feb 22 07:16:47.697: INFO: Number of nodes with available pods: 0
Feb 22 07:16:47.702: INFO: Number of running nodes: 0, number of available pods: 0
Feb 22 07:16:47.726: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-4301/daemonsets","resourceVersion":"178919"},"items":null}

Feb 22 07:16:47.746: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-4301/pods","resourceVersion":"178919"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 07:16:47.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4301" for this suite.

â€¢ [SLOW TEST:98.339 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]","total":270,"completed":233,"skipped":4144,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 07:16:48.259: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7177
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Feb 22 07:16:49.018: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cf6d67f2-e04f-45e7-b669-7229d12026a6" in namespace "projected-7177" to be "Succeeded or Failed"
Feb 22 07:16:49.068: INFO: Pod "downwardapi-volume-cf6d67f2-e04f-45e7-b669-7229d12026a6": Phase="Pending", Reason="", readiness=false. Elapsed: 50.100814ms
Feb 22 07:16:51.219: INFO: Pod "downwardapi-volume-cf6d67f2-e04f-45e7-b669-7229d12026a6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.201199364s
Feb 22 07:16:53.234: INFO: Pod "downwardapi-volume-cf6d67f2-e04f-45e7-b669-7229d12026a6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.216298459s
Feb 22 07:16:55.256: INFO: Pod "downwardapi-volume-cf6d67f2-e04f-45e7-b669-7229d12026a6": Phase="Pending", Reason="", readiness=false. Elapsed: 6.238098855s
Feb 22 07:16:57.265: INFO: Pod "downwardapi-volume-cf6d67f2-e04f-45e7-b669-7229d12026a6": Phase="Pending", Reason="", readiness=false. Elapsed: 8.247232826s
Feb 22 07:16:59.280: INFO: Pod "downwardapi-volume-cf6d67f2-e04f-45e7-b669-7229d12026a6": Phase="Pending", Reason="", readiness=false. Elapsed: 10.261792093s
Feb 22 07:17:01.299: INFO: Pod "downwardapi-volume-cf6d67f2-e04f-45e7-b669-7229d12026a6": Phase="Pending", Reason="", readiness=false. Elapsed: 12.280657539s
Feb 22 07:17:03.319: INFO: Pod "downwardapi-volume-cf6d67f2-e04f-45e7-b669-7229d12026a6": Phase="Pending", Reason="", readiness=false. Elapsed: 14.300489913s
Feb 22 07:17:05.336: INFO: Pod "downwardapi-volume-cf6d67f2-e04f-45e7-b669-7229d12026a6": Phase="Pending", Reason="", readiness=false. Elapsed: 16.318360114s
Feb 22 07:17:07.343: INFO: Pod "downwardapi-volume-cf6d67f2-e04f-45e7-b669-7229d12026a6": Phase="Pending", Reason="", readiness=false. Elapsed: 18.325436377s
Feb 22 07:17:09.353: INFO: Pod "downwardapi-volume-cf6d67f2-e04f-45e7-b669-7229d12026a6": Phase="Pending", Reason="", readiness=false. Elapsed: 20.335118619s
Feb 22 07:17:11.364: INFO: Pod "downwardapi-volume-cf6d67f2-e04f-45e7-b669-7229d12026a6": Phase="Pending", Reason="", readiness=false. Elapsed: 22.345709975s
Feb 22 07:17:13.372: INFO: Pod "downwardapi-volume-cf6d67f2-e04f-45e7-b669-7229d12026a6": Phase="Pending", Reason="", readiness=false. Elapsed: 24.353484581s
Feb 22 07:17:15.378: INFO: Pod "downwardapi-volume-cf6d67f2-e04f-45e7-b669-7229d12026a6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.360303469s
STEP: Saw pod success
Feb 22 07:17:15.378: INFO: Pod "downwardapi-volume-cf6d67f2-e04f-45e7-b669-7229d12026a6" satisfied condition "Succeeded or Failed"
Feb 22 07:17:15.389: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com pod downwardapi-volume-cf6d67f2-e04f-45e7-b669-7229d12026a6 container client-container: <nil>
STEP: delete the pod
Feb 22 07:17:15.471: INFO: Waiting for pod downwardapi-volume-cf6d67f2-e04f-45e7-b669-7229d12026a6 to disappear
Feb 22 07:17:15.495: INFO: Pod downwardapi-volume-cf6d67f2-e04f-45e7-b669-7229d12026a6 still exists
Feb 22 07:17:17.496: INFO: Waiting for pod downwardapi-volume-cf6d67f2-e04f-45e7-b669-7229d12026a6 to disappear
Feb 22 07:17:17.505: INFO: Pod downwardapi-volume-cf6d67f2-e04f-45e7-b669-7229d12026a6 still exists
Feb 22 07:17:19.496: INFO: Waiting for pod downwardapi-volume-cf6d67f2-e04f-45e7-b669-7229d12026a6 to disappear
Feb 22 07:17:19.511: INFO: Pod downwardapi-volume-cf6d67f2-e04f-45e7-b669-7229d12026a6 still exists
Feb 22 07:17:21.496: INFO: Waiting for pod downwardapi-volume-cf6d67f2-e04f-45e7-b669-7229d12026a6 to disappear
Feb 22 07:17:21.510: INFO: Pod downwardapi-volume-cf6d67f2-e04f-45e7-b669-7229d12026a6 still exists
Feb 22 07:17:23.496: INFO: Waiting for pod downwardapi-volume-cf6d67f2-e04f-45e7-b669-7229d12026a6 to disappear
Feb 22 07:17:23.513: INFO: Pod downwardapi-volume-cf6d67f2-e04f-45e7-b669-7229d12026a6 still exists
Feb 22 07:17:25.496: INFO: Waiting for pod downwardapi-volume-cf6d67f2-e04f-45e7-b669-7229d12026a6 to disappear
Feb 22 07:17:25.515: INFO: Pod downwardapi-volume-cf6d67f2-e04f-45e7-b669-7229d12026a6 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 07:17:25.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7177" for this suite.

â€¢ [SLOW TEST:37.310 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:36
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","total":270,"completed":234,"skipped":4152,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 07:17:25.599: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7678
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-947d41f6-39ad-4c12-bfe3-cee9ef8b64d4
STEP: Creating a pod to test consume secrets
Feb 22 07:17:26.074: INFO: Waiting up to 5m0s for pod "pod-secrets-21ddeff8-a195-4d98-aa8e-201a06c7253a" in namespace "secrets-7678" to be "Succeeded or Failed"
Feb 22 07:17:26.085: INFO: Pod "pod-secrets-21ddeff8-a195-4d98-aa8e-201a06c7253a": Phase="Pending", Reason="", readiness=false. Elapsed: 10.736712ms
Feb 22 07:17:28.098: INFO: Pod "pod-secrets-21ddeff8-a195-4d98-aa8e-201a06c7253a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023596262s
Feb 22 07:17:30.108: INFO: Pod "pod-secrets-21ddeff8-a195-4d98-aa8e-201a06c7253a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.033966565s
Feb 22 07:17:32.126: INFO: Pod "pod-secrets-21ddeff8-a195-4d98-aa8e-201a06c7253a": Phase="Pending", Reason="", readiness=false. Elapsed: 6.051390719s
Feb 22 07:17:34.133: INFO: Pod "pod-secrets-21ddeff8-a195-4d98-aa8e-201a06c7253a": Phase="Pending", Reason="", readiness=false. Elapsed: 8.058854417s
Feb 22 07:17:36.145: INFO: Pod "pod-secrets-21ddeff8-a195-4d98-aa8e-201a06c7253a": Phase="Pending", Reason="", readiness=false. Elapsed: 10.070695787s
Feb 22 07:17:38.153: INFO: Pod "pod-secrets-21ddeff8-a195-4d98-aa8e-201a06c7253a": Phase="Pending", Reason="", readiness=false. Elapsed: 12.078854191s
Feb 22 07:17:40.162: INFO: Pod "pod-secrets-21ddeff8-a195-4d98-aa8e-201a06c7253a": Phase="Pending", Reason="", readiness=false. Elapsed: 14.087333689s
Feb 22 07:17:42.170: INFO: Pod "pod-secrets-21ddeff8-a195-4d98-aa8e-201a06c7253a": Phase="Pending", Reason="", readiness=false. Elapsed: 16.095813919s
Feb 22 07:17:44.182: INFO: Pod "pod-secrets-21ddeff8-a195-4d98-aa8e-201a06c7253a": Phase="Pending", Reason="", readiness=false. Elapsed: 18.107681889s
Feb 22 07:17:46.193: INFO: Pod "pod-secrets-21ddeff8-a195-4d98-aa8e-201a06c7253a": Phase="Pending", Reason="", readiness=false. Elapsed: 20.118211274s
Feb 22 07:17:48.205: INFO: Pod "pod-secrets-21ddeff8-a195-4d98-aa8e-201a06c7253a": Phase="Pending", Reason="", readiness=false. Elapsed: 22.130465243s
Feb 22 07:17:50.212: INFO: Pod "pod-secrets-21ddeff8-a195-4d98-aa8e-201a06c7253a": Phase="Pending", Reason="", readiness=false. Elapsed: 24.138136913s
Feb 22 07:17:52.741: INFO: Pod "pod-secrets-21ddeff8-a195-4d98-aa8e-201a06c7253a": Phase="Pending", Reason="", readiness=false. Elapsed: 26.667069211s
Feb 22 07:17:54.753: INFO: Pod "pod-secrets-21ddeff8-a195-4d98-aa8e-201a06c7253a": Phase="Pending", Reason="", readiness=false. Elapsed: 28.678829049s
Feb 22 07:17:56.766: INFO: Pod "pod-secrets-21ddeff8-a195-4d98-aa8e-201a06c7253a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 30.691883072s
STEP: Saw pod success
Feb 22 07:17:56.766: INFO: Pod "pod-secrets-21ddeff8-a195-4d98-aa8e-201a06c7253a" satisfied condition "Succeeded or Failed"
Feb 22 07:17:56.795: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com pod pod-secrets-21ddeff8-a195-4d98-aa8e-201a06c7253a container secret-volume-test: <nil>
STEP: delete the pod
Feb 22 07:18:02.611: INFO: Waiting for pod pod-secrets-21ddeff8-a195-4d98-aa8e-201a06c7253a to disappear
Feb 22 07:18:02.654: INFO: Pod pod-secrets-21ddeff8-a195-4d98-aa8e-201a06c7253a still exists
Feb 22 07:18:04.655: INFO: Waiting for pod pod-secrets-21ddeff8-a195-4d98-aa8e-201a06c7253a to disappear
Feb 22 07:18:04.665: INFO: Pod pod-secrets-21ddeff8-a195-4d98-aa8e-201a06c7253a still exists
Feb 22 07:18:06.655: INFO: Waiting for pod pod-secrets-21ddeff8-a195-4d98-aa8e-201a06c7253a to disappear
Feb 22 07:18:06.664: INFO: Pod pod-secrets-21ddeff8-a195-4d98-aa8e-201a06c7253a still exists
Feb 22 07:18:08.655: INFO: Waiting for pod pod-secrets-21ddeff8-a195-4d98-aa8e-201a06c7253a to disappear
Feb 22 07:18:08.665: INFO: Pod pod-secrets-21ddeff8-a195-4d98-aa8e-201a06c7253a still exists
Feb 22 07:18:10.655: INFO: Waiting for pod pod-secrets-21ddeff8-a195-4d98-aa8e-201a06c7253a to disappear
Feb 22 07:18:10.668: INFO: Pod pod-secrets-21ddeff8-a195-4d98-aa8e-201a06c7253a still exists
Feb 22 07:18:12.655: INFO: Waiting for pod pod-secrets-21ddeff8-a195-4d98-aa8e-201a06c7253a to disappear
Feb 22 07:18:12.662: INFO: Pod pod-secrets-21ddeff8-a195-4d98-aa8e-201a06c7253a still exists
Feb 22 07:18:14.655: INFO: Waiting for pod pod-secrets-21ddeff8-a195-4d98-aa8e-201a06c7253a to disappear
Feb 22 07:18:14.667: INFO: Pod pod-secrets-21ddeff8-a195-4d98-aa8e-201a06c7253a still exists
Feb 22 07:18:16.655: INFO: Waiting for pod pod-secrets-21ddeff8-a195-4d98-aa8e-201a06c7253a to disappear
Feb 22 07:18:16.661: INFO: Pod pod-secrets-21ddeff8-a195-4d98-aa8e-201a06c7253a still exists
Feb 22 07:18:18.655: INFO: Waiting for pod pod-secrets-21ddeff8-a195-4d98-aa8e-201a06c7253a to disappear
Feb 22 07:18:18.669: INFO: Pod pod-secrets-21ddeff8-a195-4d98-aa8e-201a06c7253a no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 07:18:18.670: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7678" for this suite.

â€¢ [SLOW TEST:53.104 seconds]
[sig-storage] Secrets
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:36
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","total":270,"completed":235,"skipped":4197,"failed":0}
SSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 07:18:18.707: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1426
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: starting the proxy server
Feb 22 07:18:19.051: INFO: Asynchronously running '/usr/bin/kubectl kubectl --kubeconfig=/root/.kube/config proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 07:18:19.419: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1426" for this suite.
â€¢{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support proxy with --port 0  [Conformance]","total":270,"completed":236,"skipped":4201,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 07:18:19.510: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in events-763
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Feb 22 07:18:47.914: INFO: &Pod{ObjectMeta:{send-events-d5329a05-2061-492d-831e-f8d30ce3f810  events-763 /api/v1/namespaces/events-763/pods/send-events-d5329a05-2061-492d-831e-f8d30ce3f810 f667d634-9ad7-4e0b-857d-fbd8cb4d6645 180251 0 2021-02-22 07:18:19 +0000 UTC <nil> <nil> map[name:foo time:804870626] map[attachment_id:b0519df5-3f44-4031-bbf2-3fa54c22da44 kubernetes.io/psp:e2e-test-privileged-psp mac:04:50:56:00:28:12 vlan:None vmware-system-ephemeral-disk-uuid:6000C29b-45eb-af57-4062-45bb80dc48d5 vmware-system-image-references:{"p":"agnhost-4c5d323a799f707178acf281f8da2d9a581ad331-v2020"} vmware-system-vm-moid:vm-855:6b180790-afb7-40a7-b1c1-16f00c9b6783 vmware-system-vm-uuid:502f632a-ea42-b0bc-4801-f5765767cfe1] [] [lifecycle-controller/system.vmware.com]  [{e2e.test Update v1 2021-02-22 07:18:19 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 116 105 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 112 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 114 103 115 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 114 116 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 99 111 110 116 97 105 110 101 114 80 111 114 116 92 34 58 56 48 44 92 34 112 114 111 116 111 99 111 108 92 34 58 92 34 84 67 80 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 99 111 110 116 97 105 110 101 114 80 111 114 116 34 58 123 125 44 34 102 58 112 114 111 116 111 99 111 108 34 58 123 125 125 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {image-controller Update v1 2021-02-22 07:18:20 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 105 109 97 103 101 45 114 101 102 101 114 101 110 99 101 115 34 58 123 125 125 125 125],}} {nsx-ncp-75bf644549-ps9h2 Update v1 2021-02-22 07:18:30 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 97 116 116 97 99 104 109 101 110 116 95 105 100 34 58 123 125 44 34 102 58 109 97 99 34 58 123 125 44 34 102 58 118 108 97 110 34 58 123 125 125 125 125],}} {scheduler-extender Update v1 2021-02-22 07:18:37 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 101 112 104 101 109 101 114 97 108 45 100 105 115 107 45 117 117 105 100 34 58 123 125 44 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 118 109 45 109 111 105 100 34 58 123 125 44 34 102 58 118 109 119 97 114 101 45 115 121 115 116 101 109 45 118 109 45 117 117 105 100 34 58 123 125 125 44 34 102 58 102 105 110 97 108 105 122 101 114 115 34 58 123 34 46 34 58 123 125 44 34 118 58 92 34 108 105 102 101 99 121 99 108 101 45 99 111 110 116 114 111 108 108 101 114 47 115 121 115 116 101 109 46 118 109 119 97 114 101 46 99 111 109 92 34 34 58 123 125 125 125 125],}} {spherelet Update v1 2021-02-22 07:18:46 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 112 92 34 125 34 58 123 34 102 58 101 110 118 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 95 52 52 51 95 84 67 80 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 95 52 52 51 95 84 67 80 95 65 68 68 82 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 95 52 52 51 95 84 67 80 95 80 79 82 84 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 80 79 82 84 95 52 52 51 95 84 67 80 95 80 82 79 84 79 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 83 69 82 86 73 67 69 95 72 79 83 84 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 83 69 82 86 73 67 69 95 80 79 82 84 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 44 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 75 85 66 69 82 78 69 84 69 83 95 83 69 82 86 73 67 69 95 80 79 82 84 95 72 84 84 80 83 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 118 97 108 117 101 34 58 123 125 125 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 55 50 46 50 54 46 49 46 50 50 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ff9kw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ff9kw,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:p,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,Command:[],Args:[serve-hostname],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ff9kw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:sc2-rdops-vm05-dhcp-174-51.eng.vmware.com,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 07:18:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 07:18:47 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 07:18:47 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2021-02-22 07:18:47 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.192.174.51,PodIP:172.26.1.226,StartTime:2021-02-22 07:18:45 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:p,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2021-02-22 07:18:46 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,ImageID:agnhost-4c5d323a799f707178acf281f8da2d9a581ad331-v2020,ContainerID:845097dc-cdc6-463d-a059-ff968218cc02,Started:nil,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.26.1.226,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

STEP: checking for scheduler event about the pod
Feb 22 07:18:49.969: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Feb 22 07:18:52.041: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 07:18:52.118: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-763" for this suite.

â€¢ [SLOW TEST:32.808 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] [sig-node] Events should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]","total":270,"completed":237,"skipped":4218,"failed":0}
SSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 07:18:52.321: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3095
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name projected-secret-test-ceaafbf3-c4df-412a-8113-24a94aac928b
STEP: Creating a pod to test consume secrets
Feb 22 07:18:52.889: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ffd6ef8e-0f58-4f65-beb3-7f9656686b32" in namespace "projected-3095" to be "Succeeded or Failed"
Feb 22 07:18:52.921: INFO: Pod "pod-projected-secrets-ffd6ef8e-0f58-4f65-beb3-7f9656686b32": Phase="Pending", Reason="", readiness=false. Elapsed: 31.995857ms
Feb 22 07:18:54.930: INFO: Pod "pod-projected-secrets-ffd6ef8e-0f58-4f65-beb3-7f9656686b32": Phase="Pending", Reason="", readiness=false. Elapsed: 2.04165204s
Feb 22 07:18:56.947: INFO: Pod "pod-projected-secrets-ffd6ef8e-0f58-4f65-beb3-7f9656686b32": Phase="Pending", Reason="", readiness=false. Elapsed: 4.058794742s
Feb 22 07:18:58.967: INFO: Pod "pod-projected-secrets-ffd6ef8e-0f58-4f65-beb3-7f9656686b32": Phase="Pending", Reason="", readiness=false. Elapsed: 6.078695614s
Feb 22 07:19:01.422: INFO: Pod "pod-projected-secrets-ffd6ef8e-0f58-4f65-beb3-7f9656686b32": Phase="Pending", Reason="", readiness=false. Elapsed: 8.5333444s
Feb 22 07:19:03.460: INFO: Pod "pod-projected-secrets-ffd6ef8e-0f58-4f65-beb3-7f9656686b32": Phase="Pending", Reason="", readiness=false. Elapsed: 10.571616539s
Feb 22 07:19:05.470: INFO: Pod "pod-projected-secrets-ffd6ef8e-0f58-4f65-beb3-7f9656686b32": Phase="Pending", Reason="", readiness=false. Elapsed: 12.581696374s
Feb 22 07:19:07.482: INFO: Pod "pod-projected-secrets-ffd6ef8e-0f58-4f65-beb3-7f9656686b32": Phase="Pending", Reason="", readiness=false. Elapsed: 14.593263218s
Feb 22 07:19:09.506: INFO: Pod "pod-projected-secrets-ffd6ef8e-0f58-4f65-beb3-7f9656686b32": Phase="Pending", Reason="", readiness=false. Elapsed: 16.617540919s
Feb 22 07:19:11.529: INFO: Pod "pod-projected-secrets-ffd6ef8e-0f58-4f65-beb3-7f9656686b32": Phase="Pending", Reason="", readiness=false. Elapsed: 18.640650629s
Feb 22 07:19:13.545: INFO: Pod "pod-projected-secrets-ffd6ef8e-0f58-4f65-beb3-7f9656686b32": Phase="Pending", Reason="", readiness=false. Elapsed: 20.656732945s
Feb 22 07:19:15.556: INFO: Pod "pod-projected-secrets-ffd6ef8e-0f58-4f65-beb3-7f9656686b32": Phase="Pending", Reason="", readiness=false. Elapsed: 22.667038701s
Feb 22 07:19:17.570: INFO: Pod "pod-projected-secrets-ffd6ef8e-0f58-4f65-beb3-7f9656686b32": Phase="Pending", Reason="", readiness=false. Elapsed: 24.681544598s
Feb 22 07:19:19.579: INFO: Pod "pod-projected-secrets-ffd6ef8e-0f58-4f65-beb3-7f9656686b32": Phase="Pending", Reason="", readiness=false. Elapsed: 26.690757953s
Feb 22 07:19:21.587: INFO: Pod "pod-projected-secrets-ffd6ef8e-0f58-4f65-beb3-7f9656686b32": Phase="Pending", Reason="", readiness=false. Elapsed: 28.698260203s
Feb 22 07:19:23.603: INFO: Pod "pod-projected-secrets-ffd6ef8e-0f58-4f65-beb3-7f9656686b32": Phase="Succeeded", Reason="", readiness=false. Elapsed: 30.714219199s
STEP: Saw pod success
Feb 22 07:19:23.604: INFO: Pod "pod-projected-secrets-ffd6ef8e-0f58-4f65-beb3-7f9656686b32" satisfied condition "Succeeded or Failed"
Feb 22 07:19:23.619: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com pod pod-projected-secrets-ffd6ef8e-0f58-4f65-beb3-7f9656686b32 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 22 07:19:23.723: INFO: Waiting for pod pod-projected-secrets-ffd6ef8e-0f58-4f65-beb3-7f9656686b32 to disappear
Feb 22 07:19:23.754: INFO: Pod pod-projected-secrets-ffd6ef8e-0f58-4f65-beb3-7f9656686b32 still exists
Feb 22 07:19:25.754: INFO: Waiting for pod pod-projected-secrets-ffd6ef8e-0f58-4f65-beb3-7f9656686b32 to disappear
Feb 22 07:19:25.764: INFO: Pod pod-projected-secrets-ffd6ef8e-0f58-4f65-beb3-7f9656686b32 still exists
Feb 22 07:19:27.754: INFO: Waiting for pod pod-projected-secrets-ffd6ef8e-0f58-4f65-beb3-7f9656686b32 to disappear
Feb 22 07:19:27.763: INFO: Pod pod-projected-secrets-ffd6ef8e-0f58-4f65-beb3-7f9656686b32 still exists
Feb 22 07:19:29.754: INFO: Waiting for pod pod-projected-secrets-ffd6ef8e-0f58-4f65-beb3-7f9656686b32 to disappear
Feb 22 07:19:29.767: INFO: Pod pod-projected-secrets-ffd6ef8e-0f58-4f65-beb3-7f9656686b32 still exists
Feb 22 07:19:31.754: INFO: Waiting for pod pod-projected-secrets-ffd6ef8e-0f58-4f65-beb3-7f9656686b32 to disappear
Feb 22 07:19:31.763: INFO: Pod pod-projected-secrets-ffd6ef8e-0f58-4f65-beb3-7f9656686b32 still exists
Feb 22 07:19:33.754: INFO: Waiting for pod pod-projected-secrets-ffd6ef8e-0f58-4f65-beb3-7f9656686b32 to disappear
Feb 22 07:19:33.763: INFO: Pod pod-projected-secrets-ffd6ef8e-0f58-4f65-beb3-7f9656686b32 still exists
Feb 22 07:19:35.754: INFO: Waiting for pod pod-projected-secrets-ffd6ef8e-0f58-4f65-beb3-7f9656686b32 to disappear
Feb 22 07:19:35.766: INFO: Pod pod-projected-secrets-ffd6ef8e-0f58-4f65-beb3-7f9656686b32 still exists
Feb 22 07:19:37.754: INFO: Waiting for pod pod-projected-secrets-ffd6ef8e-0f58-4f65-beb3-7f9656686b32 to disappear
Feb 22 07:19:37.762: INFO: Pod pod-projected-secrets-ffd6ef8e-0f58-4f65-beb3-7f9656686b32 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 07:19:37.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3095" for this suite.

â€¢ [SLOW TEST:45.532 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]","total":270,"completed":238,"skipped":4225,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] version v1
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 07:19:37.886: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-2692
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Feb 22 07:19:38.479: INFO: /api/v1/nodes/sc2-rdops-vm05-dhcp-174-51.eng.vmware.com/proxy/logs/: no body (200; 23.784979ms)
Feb 22 07:19:38.519: INFO: /api/v1/nodes/sc2-rdops-vm05-dhcp-174-51.eng.vmware.com/proxy/logs/: no body (200; 39.296894ms)
Feb 22 07:19:38.549: INFO: /api/v1/nodes/sc2-rdops-vm05-dhcp-174-51.eng.vmware.com/proxy/logs/: no body (200; 30.414092ms)
Feb 22 07:19:38.560: INFO: /api/v1/nodes/sc2-rdops-vm05-dhcp-174-51.eng.vmware.com/proxy/logs/: no body (200; 11.056337ms)
Feb 22 07:19:38.591: INFO: /api/v1/nodes/sc2-rdops-vm05-dhcp-174-51.eng.vmware.com/proxy/logs/: no body (200; 30.334283ms)
Feb 22 07:19:38.613: INFO: /api/v1/nodes/sc2-rdops-vm05-dhcp-174-51.eng.vmware.com/proxy/logs/: no body (200; 22.292595ms)
Feb 22 07:19:38.645: INFO: /api/v1/nodes/sc2-rdops-vm05-dhcp-174-51.eng.vmware.com/proxy/logs/: no body (200; 31.713853ms)
Feb 22 07:19:38.655: INFO: /api/v1/nodes/sc2-rdops-vm05-dhcp-174-51.eng.vmware.com/proxy/logs/: no body (200; 9.956515ms)
Feb 22 07:19:38.664: INFO: /api/v1/nodes/sc2-rdops-vm05-dhcp-174-51.eng.vmware.com/proxy/logs/: no body (200; 8.773249ms)
Feb 22 07:19:38.694: INFO: /api/v1/nodes/sc2-rdops-vm05-dhcp-174-51.eng.vmware.com/proxy/logs/: no body (200; 30.142826ms)
Feb 22 07:19:38.708: INFO: /api/v1/nodes/sc2-rdops-vm05-dhcp-174-51.eng.vmware.com/proxy/logs/: no body (200; 13.796939ms)
Feb 22 07:19:38.728: INFO: /api/v1/nodes/sc2-rdops-vm05-dhcp-174-51.eng.vmware.com/proxy/logs/: no body (200; 20.093225ms)
Feb 22 07:19:38.750: INFO: /api/v1/nodes/sc2-rdops-vm05-dhcp-174-51.eng.vmware.com/proxy/logs/: no body (200; 21.348763ms)
Feb 22 07:19:38.769: INFO: /api/v1/nodes/sc2-rdops-vm05-dhcp-174-51.eng.vmware.com/proxy/logs/: no body (200; 19.314868ms)
Feb 22 07:19:38.794: INFO: /api/v1/nodes/sc2-rdops-vm05-dhcp-174-51.eng.vmware.com/proxy/logs/: no body (200; 24.813677ms)
Feb 22 07:19:38.816: INFO: /api/v1/nodes/sc2-rdops-vm05-dhcp-174-51.eng.vmware.com/proxy/logs/: no body (200; 22.235675ms)
Feb 22 07:19:38.852: INFO: /api/v1/nodes/sc2-rdops-vm05-dhcp-174-51.eng.vmware.com/proxy/logs/: no body (200; 35.224432ms)
Feb 22 07:19:38.871: INFO: /api/v1/nodes/sc2-rdops-vm05-dhcp-174-51.eng.vmware.com/proxy/logs/: no body (200; 18.833427ms)
Feb 22 07:19:38.891: INFO: /api/v1/nodes/sc2-rdops-vm05-dhcp-174-51.eng.vmware.com/proxy/logs/: no body (200; 20.485622ms)
Feb 22 07:19:38.917: INFO: /api/v1/nodes/sc2-rdops-vm05-dhcp-174-51.eng.vmware.com/proxy/logs/: no body (200; 25.659754ms)
[AfterEach] version v1
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 07:19:38.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-2692" for this suite.
â€¢{"msg":"PASSED [sig-network] Proxy version v1 should proxy logs on node using proxy subresource  [Conformance]","total":270,"completed":239,"skipped":4241,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 07:19:39.040: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9269
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0666 on node default medium
Feb 22 07:19:39.631: INFO: Waiting up to 5m0s for pod "pod-105840c0-e4eb-4cec-a7fd-e55a36d4368c" in namespace "emptydir-9269" to be "Succeeded or Failed"
Feb 22 07:19:39.731: INFO: Pod "pod-105840c0-e4eb-4cec-a7fd-e55a36d4368c": Phase="Pending", Reason="", readiness=false. Elapsed: 100.029932ms
Feb 22 07:19:41.745: INFO: Pod "pod-105840c0-e4eb-4cec-a7fd-e55a36d4368c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.113887315s
Feb 22 07:19:43.760: INFO: Pod "pod-105840c0-e4eb-4cec-a7fd-e55a36d4368c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.12890242s
Feb 22 07:19:45.776: INFO: Pod "pod-105840c0-e4eb-4cec-a7fd-e55a36d4368c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.145653189s
Feb 22 07:19:47.802: INFO: Pod "pod-105840c0-e4eb-4cec-a7fd-e55a36d4368c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.171551423s
Feb 22 07:19:49.954: INFO: Pod "pod-105840c0-e4eb-4cec-a7fd-e55a36d4368c": Phase="Pending", Reason="", readiness=false. Elapsed: 10.322866689s
Feb 22 07:19:51.976: INFO: Pod "pod-105840c0-e4eb-4cec-a7fd-e55a36d4368c": Phase="Pending", Reason="", readiness=false. Elapsed: 12.345417587s
Feb 22 07:19:53.986: INFO: Pod "pod-105840c0-e4eb-4cec-a7fd-e55a36d4368c": Phase="Pending", Reason="", readiness=false. Elapsed: 14.355667983s
Feb 22 07:19:56.045: INFO: Pod "pod-105840c0-e4eb-4cec-a7fd-e55a36d4368c": Phase="Pending", Reason="", readiness=false. Elapsed: 16.414334864s
Feb 22 07:19:58.055: INFO: Pod "pod-105840c0-e4eb-4cec-a7fd-e55a36d4368c": Phase="Pending", Reason="", readiness=false. Elapsed: 18.42433993s
Feb 22 07:20:00.067: INFO: Pod "pod-105840c0-e4eb-4cec-a7fd-e55a36d4368c": Phase="Pending", Reason="", readiness=false. Elapsed: 20.435919488s
Feb 22 07:20:02.085: INFO: Pod "pod-105840c0-e4eb-4cec-a7fd-e55a36d4368c": Phase="Pending", Reason="", readiness=false. Elapsed: 22.454166174s
Feb 22 07:20:04.119: INFO: Pod "pod-105840c0-e4eb-4cec-a7fd-e55a36d4368c": Phase="Pending", Reason="", readiness=false. Elapsed: 24.487891518s
Feb 22 07:20:06.762: INFO: Pod "pod-105840c0-e4eb-4cec-a7fd-e55a36d4368c": Phase="Pending", Reason="", readiness=false. Elapsed: 27.131751251s
Feb 22 07:20:08.774: INFO: Pod "pod-105840c0-e4eb-4cec-a7fd-e55a36d4368c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 29.142988945s
STEP: Saw pod success
Feb 22 07:20:08.774: INFO: Pod "pod-105840c0-e4eb-4cec-a7fd-e55a36d4368c" satisfied condition "Succeeded or Failed"
Feb 22 07:20:08.786: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com pod pod-105840c0-e4eb-4cec-a7fd-e55a36d4368c container test-container: <nil>
STEP: delete the pod
Feb 22 07:20:08.902: INFO: Waiting for pod pod-105840c0-e4eb-4cec-a7fd-e55a36d4368c to disappear
Feb 22 07:20:08.932: INFO: Pod pod-105840c0-e4eb-4cec-a7fd-e55a36d4368c still exists
Feb 22 07:20:10.932: INFO: Waiting for pod pod-105840c0-e4eb-4cec-a7fd-e55a36d4368c to disappear
Feb 22 07:20:10.944: INFO: Pod pod-105840c0-e4eb-4cec-a7fd-e55a36d4368c still exists
Feb 22 07:20:12.932: INFO: Waiting for pod pod-105840c0-e4eb-4cec-a7fd-e55a36d4368c to disappear
Feb 22 07:20:12.945: INFO: Pod pod-105840c0-e4eb-4cec-a7fd-e55a36d4368c still exists
Feb 22 07:20:14.932: INFO: Waiting for pod pod-105840c0-e4eb-4cec-a7fd-e55a36d4368c to disappear
Feb 22 07:20:14.943: INFO: Pod pod-105840c0-e4eb-4cec-a7fd-e55a36d4368c still exists
Feb 22 07:20:16.932: INFO: Waiting for pod pod-105840c0-e4eb-4cec-a7fd-e55a36d4368c to disappear
Feb 22 07:20:16.942: INFO: Pod pod-105840c0-e4eb-4cec-a7fd-e55a36d4368c still exists
Feb 22 07:20:18.932: INFO: Waiting for pod pod-105840c0-e4eb-4cec-a7fd-e55a36d4368c to disappear
Feb 22 07:20:18.990: INFO: Pod pod-105840c0-e4eb-4cec-a7fd-e55a36d4368c still exists
Feb 22 07:20:20.933: INFO: Waiting for pod pod-105840c0-e4eb-4cec-a7fd-e55a36d4368c to disappear
Feb 22 07:20:20.945: INFO: Pod pod-105840c0-e4eb-4cec-a7fd-e55a36d4368c still exists
Feb 22 07:20:22.932: INFO: Waiting for pod pod-105840c0-e4eb-4cec-a7fd-e55a36d4368c to disappear
Feb 22 07:20:22.979: INFO: Pod pod-105840c0-e4eb-4cec-a7fd-e55a36d4368c still exists
Feb 22 07:20:24.932: INFO: Waiting for pod pod-105840c0-e4eb-4cec-a7fd-e55a36d4368c to disappear
Feb 22 07:20:24.940: INFO: Pod pod-105840c0-e4eb-4cec-a7fd-e55a36d4368c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 07:20:24.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9269" for this suite.

â€¢ [SLOW TEST:45.966 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:42
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","total":270,"completed":240,"skipped":4252,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 07:20:25.097: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-6350
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Pod that fits quota
STEP: Ensuring ResourceQuota status captures the pod usage
STEP: Not allowing a pod to be created that exceeds remaining quota
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources)
STEP: Ensuring a pod cannot update its resource requirements
STEP: Ensuring attempts to update pod resource requirements did not change quota usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 07:20:38.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6350" for this suite.

â€¢ [SLOW TEST:13.919 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]","total":270,"completed":241,"skipped":4307,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 07:20:39.062: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-5650
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation
Feb 22 07:20:39.605: INFO: >>> kubeConfig: /root/.kube/config
Feb 22 07:20:53.976: INFO: >>> kubeConfig: /root/.kube/config
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 07:21:45.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5650" for this suite.

â€¢ [SLOW TEST:66.749 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]","total":270,"completed":242,"skipped":4331,"failed":0}
[sig-network] DNS 
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 07:21:45.811: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-4446
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-4446.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-4446.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4446.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-4446.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-4446.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4446.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 22 07:22:20.716: INFO: DNS probes using dns-4446/dns-test-42da01b3-5059-4e8f-85b9-9f9bd2b99fec succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 07:22:20.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4446" for this suite.

â€¢ [SLOW TEST:35.143 seconds]
[sig-network] DNS
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Hostname [LinuxOnly] [Conformance]","total":270,"completed":243,"skipped":4331,"failed":0}
SSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 07:22:20.957: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-563
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod busybox-b99c707f-9892-4147-926b-4e8a262fea32 in namespace container-probe-563
Feb 22 07:22:59.326: INFO: Started pod busybox-b99c707f-9892-4147-926b-4e8a262fea32 in namespace container-probe-563
STEP: checking the pod's current state and verifying that restartCount is present
Feb 22 07:22:59.336: INFO: Initial restart count of pod busybox-b99c707f-9892-4147-926b-4e8a262fea32 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 07:26:59.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-563" for this suite.

â€¢ [SLOW TEST:278.948 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container should *not* be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","total":270,"completed":244,"skipped":4342,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] NoExecuteTaintManager Multiple Pods [Serial] 
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 07:26:59.929: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename taint-multiple-pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in taint-multiple-pods-8794
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/taints.go:345
Feb 22 07:27:00.278: INFO: Waiting up to 1m0s for all nodes to be ready
Feb 22 07:28:00.943: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Feb 22 07:28:00.962: INFO: Starting informer...
STEP: Starting pods...
Feb 22 07:28:01.324: INFO: Pod1 is running on sc2-rdops-vm05-dhcp-174-51.eng.vmware.com. Tainting Node
Feb 22 07:28:33.913: INFO: Pod2 is running on sc2-rdops-vm05-dhcp-174-51.eng.vmware.com. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting for Pod1 and Pod2 to be deleted
Feb 22 07:28:58.040: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Feb 22 07:29:18.257: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
[AfterEach] [k8s.io] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 07:29:18.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-8794" for this suite.

â€¢ [SLOW TEST:138.659 seconds]
[k8s.io] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] [sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]","total":270,"completed":245,"skipped":4368,"failed":0}
SSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 07:29:18.611: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-1855
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-fee2f061-32f0-4765-959f-a16012d20ef1
STEP: Creating a pod to test consume secrets
Feb 22 07:29:19.106: INFO: Waiting up to 5m0s for pod "pod-secrets-e265cd63-baa6-4246-81d3-c22f7b3d8c08" in namespace "secrets-1855" to be "Succeeded or Failed"
Feb 22 07:29:19.128: INFO: Pod "pod-secrets-e265cd63-baa6-4246-81d3-c22f7b3d8c08": Phase="Pending", Reason="", readiness=false. Elapsed: 21.626391ms
Feb 22 07:29:21.137: INFO: Pod "pod-secrets-e265cd63-baa6-4246-81d3-c22f7b3d8c08": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030626317s
Feb 22 07:29:23.148: INFO: Pod "pod-secrets-e265cd63-baa6-4246-81d3-c22f7b3d8c08": Phase="Pending", Reason="", readiness=false. Elapsed: 4.042269419s
Feb 22 07:29:25.163: INFO: Pod "pod-secrets-e265cd63-baa6-4246-81d3-c22f7b3d8c08": Phase="Pending", Reason="", readiness=false. Elapsed: 6.056684506s
Feb 22 07:29:27.172: INFO: Pod "pod-secrets-e265cd63-baa6-4246-81d3-c22f7b3d8c08": Phase="Pending", Reason="", readiness=false. Elapsed: 8.066476237s
Feb 22 07:29:29.189: INFO: Pod "pod-secrets-e265cd63-baa6-4246-81d3-c22f7b3d8c08": Phase="Pending", Reason="", readiness=false. Elapsed: 10.082551477s
Feb 22 07:29:31.202: INFO: Pod "pod-secrets-e265cd63-baa6-4246-81d3-c22f7b3d8c08": Phase="Pending", Reason="", readiness=false. Elapsed: 12.096050487s
Feb 22 07:29:33.210: INFO: Pod "pod-secrets-e265cd63-baa6-4246-81d3-c22f7b3d8c08": Phase="Pending", Reason="", readiness=false. Elapsed: 14.103941976s
Feb 22 07:29:35.219: INFO: Pod "pod-secrets-e265cd63-baa6-4246-81d3-c22f7b3d8c08": Phase="Pending", Reason="", readiness=false. Elapsed: 16.112812967s
Feb 22 07:29:37.226: INFO: Pod "pod-secrets-e265cd63-baa6-4246-81d3-c22f7b3d8c08": Phase="Pending", Reason="", readiness=false. Elapsed: 18.120279274s
Feb 22 07:29:39.235: INFO: Pod "pod-secrets-e265cd63-baa6-4246-81d3-c22f7b3d8c08": Phase="Pending", Reason="", readiness=false. Elapsed: 20.129374495s
Feb 22 07:29:41.245: INFO: Pod "pod-secrets-e265cd63-baa6-4246-81d3-c22f7b3d8c08": Phase="Pending", Reason="", readiness=false. Elapsed: 22.139491977s
Feb 22 07:29:43.263: INFO: Pod "pod-secrets-e265cd63-baa6-4246-81d3-c22f7b3d8c08": Phase="Pending", Reason="", readiness=false. Elapsed: 24.156602806s
Feb 22 07:29:45.271: INFO: Pod "pod-secrets-e265cd63-baa6-4246-81d3-c22f7b3d8c08": Phase="Pending", Reason="", readiness=false. Elapsed: 26.165285779s
Feb 22 07:29:47.283: INFO: Pod "pod-secrets-e265cd63-baa6-4246-81d3-c22f7b3d8c08": Phase="Pending", Reason="", readiness=false. Elapsed: 28.176722575s
Feb 22 07:29:49.308: INFO: Pod "pod-secrets-e265cd63-baa6-4246-81d3-c22f7b3d8c08": Phase="Succeeded", Reason="", readiness=false. Elapsed: 30.201596355s
STEP: Saw pod success
Feb 22 07:29:49.308: INFO: Pod "pod-secrets-e265cd63-baa6-4246-81d3-c22f7b3d8c08" satisfied condition "Succeeded or Failed"
Feb 22 07:29:49.321: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com pod pod-secrets-e265cd63-baa6-4246-81d3-c22f7b3d8c08 container secret-env-test: <nil>
STEP: delete the pod
Feb 22 07:29:49.513: INFO: Waiting for pod pod-secrets-e265cd63-baa6-4246-81d3-c22f7b3d8c08 to disappear
Feb 22 07:29:49.557: INFO: Pod pod-secrets-e265cd63-baa6-4246-81d3-c22f7b3d8c08 still exists
Feb 22 07:29:51.557: INFO: Waiting for pod pod-secrets-e265cd63-baa6-4246-81d3-c22f7b3d8c08 to disappear
Feb 22 07:29:51.567: INFO: Pod pod-secrets-e265cd63-baa6-4246-81d3-c22f7b3d8c08 still exists
Feb 22 07:29:53.557: INFO: Waiting for pod pod-secrets-e265cd63-baa6-4246-81d3-c22f7b3d8c08 to disappear
Feb 22 07:29:53.567: INFO: Pod pod-secrets-e265cd63-baa6-4246-81d3-c22f7b3d8c08 still exists
Feb 22 07:29:55.557: INFO: Waiting for pod pod-secrets-e265cd63-baa6-4246-81d3-c22f7b3d8c08 to disappear
Feb 22 07:29:55.576: INFO: Pod pod-secrets-e265cd63-baa6-4246-81d3-c22f7b3d8c08 still exists
Feb 22 07:29:57.557: INFO: Waiting for pod pod-secrets-e265cd63-baa6-4246-81d3-c22f7b3d8c08 to disappear
Feb 22 07:29:57.582: INFO: Pod pod-secrets-e265cd63-baa6-4246-81d3-c22f7b3d8c08 still exists
Feb 22 07:29:59.557: INFO: Waiting for pod pod-secrets-e265cd63-baa6-4246-81d3-c22f7b3d8c08 to disappear
Feb 22 07:29:59.568: INFO: Pod pod-secrets-e265cd63-baa6-4246-81d3-c22f7b3d8c08 still exists
Feb 22 07:30:01.560: INFO: Waiting for pod pod-secrets-e265cd63-baa6-4246-81d3-c22f7b3d8c08 to disappear
Feb 22 07:30:01.593: INFO: Pod pod-secrets-e265cd63-baa6-4246-81d3-c22f7b3d8c08 still exists
Feb 22 07:30:03.557: INFO: Waiting for pod pod-secrets-e265cd63-baa6-4246-81d3-c22f7b3d8c08 to disappear
Feb 22 07:30:03.566: INFO: Pod pod-secrets-e265cd63-baa6-4246-81d3-c22f7b3d8c08 still exists
Feb 22 07:30:05.557: INFO: Waiting for pod pod-secrets-e265cd63-baa6-4246-81d3-c22f7b3d8c08 to disappear
Feb 22 07:30:05.575: INFO: Pod pod-secrets-e265cd63-baa6-4246-81d3-c22f7b3d8c08 still exists
Feb 22 07:30:07.557: INFO: Waiting for pod pod-secrets-e265cd63-baa6-4246-81d3-c22f7b3d8c08 to disappear
Feb 22 07:30:07.577: INFO: Pod pod-secrets-e265cd63-baa6-4246-81d3-c22f7b3d8c08 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 07:30:07.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1855" for this suite.

â€¢ [SLOW TEST:49.025 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:35
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]","total":270,"completed":246,"skipped":4378,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Lease 
  lease API should be available [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Lease
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 07:30:07.637: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename lease-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in lease-test-3863
STEP: Waiting for a default service account to be provisioned in namespace
[It] lease API should be available [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Lease
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 07:30:09.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "lease-test-3863" for this suite.
â€¢{"msg":"PASSED [k8s.io] Lease lease API should be available [Conformance]","total":270,"completed":247,"skipped":4415,"failed":0}
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 07:30:09.234: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1119
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0666 on tmpfs
Feb 22 07:30:09.774: INFO: Waiting up to 5m0s for pod "pod-e562edd5-4824-49ba-aae6-e71b7859d343" in namespace "emptydir-1119" to be "Succeeded or Failed"
Feb 22 07:30:09.809: INFO: Pod "pod-e562edd5-4824-49ba-aae6-e71b7859d343": Phase="Pending", Reason="", readiness=false. Elapsed: 35.032509ms
Feb 22 07:30:11.849: INFO: Pod "pod-e562edd5-4824-49ba-aae6-e71b7859d343": Phase="Pending", Reason="", readiness=false. Elapsed: 2.074346611s
Feb 22 07:30:13.862: INFO: Pod "pod-e562edd5-4824-49ba-aae6-e71b7859d343": Phase="Pending", Reason="", readiness=false. Elapsed: 4.087165694s
Feb 22 07:30:15.902: INFO: Pod "pod-e562edd5-4824-49ba-aae6-e71b7859d343": Phase="Pending", Reason="", readiness=false. Elapsed: 6.127798721s
Feb 22 07:30:17.925: INFO: Pod "pod-e562edd5-4824-49ba-aae6-e71b7859d343": Phase="Pending", Reason="", readiness=false. Elapsed: 8.150096104s
Feb 22 07:30:19.941: INFO: Pod "pod-e562edd5-4824-49ba-aae6-e71b7859d343": Phase="Pending", Reason="", readiness=false. Elapsed: 10.166570053s
Feb 22 07:30:21.952: INFO: Pod "pod-e562edd5-4824-49ba-aae6-e71b7859d343": Phase="Pending", Reason="", readiness=false. Elapsed: 12.177663728s
Feb 22 07:30:23.959: INFO: Pod "pod-e562edd5-4824-49ba-aae6-e71b7859d343": Phase="Pending", Reason="", readiness=false. Elapsed: 14.184505564s
Feb 22 07:30:25.967: INFO: Pod "pod-e562edd5-4824-49ba-aae6-e71b7859d343": Phase="Pending", Reason="", readiness=false. Elapsed: 16.192875008s
Feb 22 07:30:27.975: INFO: Pod "pod-e562edd5-4824-49ba-aae6-e71b7859d343": Phase="Pending", Reason="", readiness=false. Elapsed: 18.200120771s
Feb 22 07:30:29.985: INFO: Pod "pod-e562edd5-4824-49ba-aae6-e71b7859d343": Phase="Pending", Reason="", readiness=false. Elapsed: 20.210573964s
Feb 22 07:30:31.997: INFO: Pod "pod-e562edd5-4824-49ba-aae6-e71b7859d343": Phase="Pending", Reason="", readiness=false. Elapsed: 22.222768202s
Feb 22 07:30:34.358: INFO: Pod "pod-e562edd5-4824-49ba-aae6-e71b7859d343": Phase="Pending", Reason="", readiness=false. Elapsed: 24.583296702s
Feb 22 07:30:36.383: INFO: Pod "pod-e562edd5-4824-49ba-aae6-e71b7859d343": Phase="Pending", Reason="", readiness=false. Elapsed: 26.608300747s
Feb 22 07:30:38.394: INFO: Pod "pod-e562edd5-4824-49ba-aae6-e71b7859d343": Phase="Pending", Reason="", readiness=false. Elapsed: 28.619263411s
Feb 22 07:30:40.433: INFO: Pod "pod-e562edd5-4824-49ba-aae6-e71b7859d343": Phase="Succeeded", Reason="", readiness=false. Elapsed: 30.658721053s
STEP: Saw pod success
Feb 22 07:30:40.434: INFO: Pod "pod-e562edd5-4824-49ba-aae6-e71b7859d343" satisfied condition "Succeeded or Failed"
Feb 22 07:30:40.455: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com pod pod-e562edd5-4824-49ba-aae6-e71b7859d343 container test-container: <nil>
STEP: delete the pod
Feb 22 07:30:46.633: INFO: Waiting for pod pod-e562edd5-4824-49ba-aae6-e71b7859d343 to disappear
Feb 22 07:30:46.644: INFO: Pod pod-e562edd5-4824-49ba-aae6-e71b7859d343 still exists
Feb 22 07:30:48.644: INFO: Waiting for pod pod-e562edd5-4824-49ba-aae6-e71b7859d343 to disappear
Feb 22 07:30:48.661: INFO: Pod pod-e562edd5-4824-49ba-aae6-e71b7859d343 still exists
Feb 22 07:30:50.644: INFO: Waiting for pod pod-e562edd5-4824-49ba-aae6-e71b7859d343 to disappear
Feb 22 07:30:50.652: INFO: Pod pod-e562edd5-4824-49ba-aae6-e71b7859d343 still exists
Feb 22 07:30:52.644: INFO: Waiting for pod pod-e562edd5-4824-49ba-aae6-e71b7859d343 to disappear
Feb 22 07:30:52.654: INFO: Pod pod-e562edd5-4824-49ba-aae6-e71b7859d343 still exists
Feb 22 07:30:54.644: INFO: Waiting for pod pod-e562edd5-4824-49ba-aae6-e71b7859d343 to disappear
Feb 22 07:30:54.653: INFO: Pod pod-e562edd5-4824-49ba-aae6-e71b7859d343 still exists
Feb 22 07:30:56.644: INFO: Waiting for pod pod-e562edd5-4824-49ba-aae6-e71b7859d343 to disappear
Feb 22 07:30:56.652: INFO: Pod pod-e562edd5-4824-49ba-aae6-e71b7859d343 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 07:30:56.654: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1119" for this suite.

â€¢ [SLOW TEST:47.499 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:42
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":270,"completed":248,"skipped":4417,"failed":0}
SSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 07:30:56.745: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-2119
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a ResourceQuota with best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a best-effort pod
STEP: Ensuring resource quota with best effort scope captures the pod usage
STEP: Ensuring resource quota with not best effort ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a not best-effort pod
STEP: Ensuring resource quota with not best effort scope captures the pod usage
STEP: Ensuring resource quota with best effort scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 07:31:13.482: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2119" for this suite.

â€¢ [SLOW TEST:16.781 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]","total":270,"completed":249,"skipped":4421,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 07:31:13.532: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5962
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0644 on tmpfs
Feb 22 07:31:13.984: INFO: Waiting up to 5m0s for pod "pod-4f9351b9-7fd9-4128-bc75-b72124622406" in namespace "emptydir-5962" to be "Succeeded or Failed"
Feb 22 07:31:14.004: INFO: Pod "pod-4f9351b9-7fd9-4128-bc75-b72124622406": Phase="Pending", Reason="", readiness=false. Elapsed: 19.470531ms
Feb 22 07:31:16.012: INFO: Pod "pod-4f9351b9-7fd9-4128-bc75-b72124622406": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02738866s
Feb 22 07:31:18.027: INFO: Pod "pod-4f9351b9-7fd9-4128-bc75-b72124622406": Phase="Pending", Reason="", readiness=false. Elapsed: 4.041959242s
Feb 22 07:31:20.056: INFO: Pod "pod-4f9351b9-7fd9-4128-bc75-b72124622406": Phase="Pending", Reason="", readiness=false. Elapsed: 6.071442171s
Feb 22 07:31:22.077: INFO: Pod "pod-4f9351b9-7fd9-4128-bc75-b72124622406": Phase="Pending", Reason="", readiness=false. Elapsed: 8.092242423s
Feb 22 07:31:24.128: INFO: Pod "pod-4f9351b9-7fd9-4128-bc75-b72124622406": Phase="Pending", Reason="", readiness=false. Elapsed: 10.143643151s
Feb 22 07:31:26.136: INFO: Pod "pod-4f9351b9-7fd9-4128-bc75-b72124622406": Phase="Pending", Reason="", readiness=false. Elapsed: 12.150948971s
Feb 22 07:31:28.210: INFO: Pod "pod-4f9351b9-7fd9-4128-bc75-b72124622406": Phase="Pending", Reason="", readiness=false. Elapsed: 14.225447185s
Feb 22 07:31:30.217: INFO: Pod "pod-4f9351b9-7fd9-4128-bc75-b72124622406": Phase="Pending", Reason="", readiness=false. Elapsed: 16.232160948s
Feb 22 07:31:32.224: INFO: Pod "pod-4f9351b9-7fd9-4128-bc75-b72124622406": Phase="Pending", Reason="", readiness=false. Elapsed: 18.239786309s
Feb 22 07:31:34.237: INFO: Pod "pod-4f9351b9-7fd9-4128-bc75-b72124622406": Phase="Pending", Reason="", readiness=false. Elapsed: 20.252361979s
Feb 22 07:31:36.249: INFO: Pod "pod-4f9351b9-7fd9-4128-bc75-b72124622406": Phase="Pending", Reason="", readiness=false. Elapsed: 22.264194801s
Feb 22 07:31:38.262: INFO: Pod "pod-4f9351b9-7fd9-4128-bc75-b72124622406": Phase="Pending", Reason="", readiness=false. Elapsed: 24.277171054s
Feb 22 07:31:40.272: INFO: Pod "pod-4f9351b9-7fd9-4128-bc75-b72124622406": Phase="Pending", Reason="", readiness=false. Elapsed: 26.287186762s
Feb 22 07:31:42.284: INFO: Pod "pod-4f9351b9-7fd9-4128-bc75-b72124622406": Phase="Pending", Reason="", readiness=false. Elapsed: 28.299035184s
Feb 22 07:31:44.293: INFO: Pod "pod-4f9351b9-7fd9-4128-bc75-b72124622406": Phase="Pending", Reason="", readiness=false. Elapsed: 30.308683979s
Feb 22 07:31:46.301: INFO: Pod "pod-4f9351b9-7fd9-4128-bc75-b72124622406": Phase="Pending", Reason="", readiness=false. Elapsed: 32.316498425s
Feb 22 07:31:48.313: INFO: Pod "pod-4f9351b9-7fd9-4128-bc75-b72124622406": Phase="Pending", Reason="", readiness=false. Elapsed: 34.328676728s
Feb 22 07:31:50.325: INFO: Pod "pod-4f9351b9-7fd9-4128-bc75-b72124622406": Phase="Succeeded", Reason="", readiness=false. Elapsed: 36.340208579s
STEP: Saw pod success
Feb 22 07:31:50.325: INFO: Pod "pod-4f9351b9-7fd9-4128-bc75-b72124622406" satisfied condition "Succeeded or Failed"
Feb 22 07:31:50.334: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com pod pod-4f9351b9-7fd9-4128-bc75-b72124622406 container test-container: <nil>
STEP: delete the pod
Feb 22 07:31:50.409: INFO: Waiting for pod pod-4f9351b9-7fd9-4128-bc75-b72124622406 to disappear
Feb 22 07:31:50.465: INFO: Pod pod-4f9351b9-7fd9-4128-bc75-b72124622406 still exists
Feb 22 07:31:52.466: INFO: Waiting for pod pod-4f9351b9-7fd9-4128-bc75-b72124622406 to disappear
Feb 22 07:31:52.473: INFO: Pod pod-4f9351b9-7fd9-4128-bc75-b72124622406 still exists
Feb 22 07:31:54.466: INFO: Waiting for pod pod-4f9351b9-7fd9-4128-bc75-b72124622406 to disappear
Feb 22 07:31:54.473: INFO: Pod pod-4f9351b9-7fd9-4128-bc75-b72124622406 still exists
Feb 22 07:31:56.466: INFO: Waiting for pod pod-4f9351b9-7fd9-4128-bc75-b72124622406 to disappear
Feb 22 07:31:56.478: INFO: Pod pod-4f9351b9-7fd9-4128-bc75-b72124622406 still exists
Feb 22 07:31:58.466: INFO: Waiting for pod pod-4f9351b9-7fd9-4128-bc75-b72124622406 to disappear
Feb 22 07:31:58.478: INFO: Pod pod-4f9351b9-7fd9-4128-bc75-b72124622406 still exists
Feb 22 07:32:00.466: INFO: Waiting for pod pod-4f9351b9-7fd9-4128-bc75-b72124622406 to disappear
Feb 22 07:32:00.478: INFO: Pod pod-4f9351b9-7fd9-4128-bc75-b72124622406 still exists
Feb 22 07:32:02.466: INFO: Waiting for pod pod-4f9351b9-7fd9-4128-bc75-b72124622406 to disappear
Feb 22 07:32:02.474: INFO: Pod pod-4f9351b9-7fd9-4128-bc75-b72124622406 still exists
Feb 22 07:32:04.466: INFO: Waiting for pod pod-4f9351b9-7fd9-4128-bc75-b72124622406 to disappear
Feb 22 07:32:04.479: INFO: Pod pod-4f9351b9-7fd9-4128-bc75-b72124622406 still exists
Feb 22 07:32:06.466: INFO: Waiting for pod pod-4f9351b9-7fd9-4128-bc75-b72124622406 to disappear
Feb 22 07:32:06.478: INFO: Pod pod-4f9351b9-7fd9-4128-bc75-b72124622406 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 07:32:06.478: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5962" for this suite.

â€¢ [SLOW TEST:53.051 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:42
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":270,"completed":250,"skipped":4431,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 07:32:06.585: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-1533
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:74
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Feb 22 07:32:07.153: INFO: Creating deployment "test-recreate-deployment"
Feb 22 07:32:07.228: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Feb 22 07:32:07.357: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Feb 22 07:32:09.557: INFO: Waiting deployment "test-recreate-deployment" to complete
Feb 22 07:32:09.578: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749575927, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749575927, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749575927, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749575927, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-74d98b5f7c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 07:32:11.588: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749575927, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749575927, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749575927, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749575927, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-74d98b5f7c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 07:32:13.599: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749575927, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749575927, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749575927, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749575927, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-74d98b5f7c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 07:32:15.586: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749575927, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749575927, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749575927, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749575927, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-74d98b5f7c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 07:32:17.592: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749575927, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749575927, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749575927, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749575927, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-74d98b5f7c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 07:32:19.586: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749575927, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749575927, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749575927, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749575927, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-74d98b5f7c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 07:32:21.590: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749575927, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749575927, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749575927, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749575927, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-74d98b5f7c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 07:32:23.599: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749575927, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749575927, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749575927, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749575927, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-74d98b5f7c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 07:32:25.587: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749575927, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749575927, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749575927, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749575927, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-74d98b5f7c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 07:32:27.595: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749575927, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749575927, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749575927, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749575927, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-74d98b5f7c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 07:32:29.592: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749575927, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749575927, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749575927, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749575927, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-74d98b5f7c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 07:32:31.587: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749575927, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749575927, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749575927, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749575927, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-74d98b5f7c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 07:32:33.588: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749575927, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749575927, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749575927, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749575927, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-74d98b5f7c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 07:32:35.589: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Feb 22 07:32:35.621: INFO: Updating deployment test-recreate-deployment
Feb 22 07:32:35.623: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
Feb 22 07:32:46.966: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-1533 /apis/apps/v1/namespaces/deployment-1533/deployments/test-recreate-deployment 7696c0fe-ed44-4548-8d1d-77b21d5947aa 188981 2 2021-02-22 07:32:07 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2021-02-22 07:32:35 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 112 114 111 103 114 101 115 115 68 101 97 100 108 105 110 101 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 118 105 115 105 111 110 72 105 115 116 111 114 121 76 105 109 105 116 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 116 114 97 116 101 103 121 34 58 123 34 102 58 116 121 112 101 34 58 123 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2021-02-22 07:32:46 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 65 118 97 105 108 97 98 108 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 80 114 111 103 114 101 115 115 105 110 103 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 110 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 112 100 97 116 101 100 82 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] []  []} {[] [] [{httpd mirror.gcr.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc005e431a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2021-02-22 07:32:35 +0000 UTC,LastTransitionTime:2021-02-22 07:32:35 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-68b89786cb" is progressing.,LastUpdateTime:2021-02-22 07:32:46 +0000 UTC,LastTransitionTime:2021-02-22 07:32:07 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Feb 22 07:32:46.985: INFO: New ReplicaSet "test-recreate-deployment-68b89786cb" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-68b89786cb  deployment-1533 /apis/apps/v1/namespaces/deployment-1533/replicasets/test-recreate-deployment-68b89786cb 67f935ca-073d-4084-862f-d19b2479afbe 188979 1 2021-02-22 07:32:46 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68b89786cb] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 7696c0fe-ed44-4548-8d1d-77b21d5947aa 0xc005e43607 0xc005e43608}] []  [{kube-controller-manager Update apps/v1 2021-02-22 07:32:46 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 55 54 57 54 99 48 102 101 45 101 100 52 52 45 52 53 52 56 45 56 100 49 100 45 55 55 98 50 49 100 53 57 52 55 97 97 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 68b89786cb,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68b89786cb] map[] [] []  []} {[] [] [{httpd mirror.gcr.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc005e43688 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Feb 22 07:32:46.985: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Feb 22 07:32:46.986: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-74d98b5f7c  deployment-1533 /apis/apps/v1/namespaces/deployment-1533/replicasets/test-recreate-deployment-74d98b5f7c 3a4870ab-d489-400c-a0af-ad758c3e8425 188873 2 2021-02-22 07:32:07 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:74d98b5f7c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 7696c0fe-ed44-4548-8d1d-77b21d5947aa 0xc005e436f7 0xc005e436f8}] []  [{kube-controller-manager Update apps/v1 2021-02-22 07:32:35 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 55 54 57 54 99 48 102 101 45 101 100 52 52 45 52 53 52 56 45 56 100 49 100 45 55 55 98 50 49 100 53 57 52 55 97 97 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 74d98b5f7c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:74d98b5f7c] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc005e43788 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Feb 22 07:32:46.999: INFO: Pod "test-recreate-deployment-68b89786cb-rk2m4" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-68b89786cb-rk2m4 test-recreate-deployment-68b89786cb- deployment-1533 /api/v1/namespaces/deployment-1533/pods/test-recreate-deployment-68b89786cb-rk2m4 f633c623-e64b-4ab8-8dfd-1c67b62ca611 188975 0 2021-02-22 07:32:46 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68b89786cb] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-recreate-deployment-68b89786cb 67f935ca-073d-4084-862f-d19b2479afbe 0xc005e43c87 0xc005e43c88}] []  [{kube-controller-manager Update v1 2021-02-22 07:32:46 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 54 55 102 57 51 53 99 97 45 48 55 51 100 45 52 48 56 52 45 56 54 50 102 45 100 49 57 98 50 52 55 57 97 102 98 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-76pfp,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-76pfp,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:mirror.gcr.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-76pfp,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 07:32:47.004: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1533" for this suite.

â€¢ [SLOW TEST:40.613 seconds]
[sig-apps] Deployment
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]","total":270,"completed":251,"skipped":4449,"failed":0}
SSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 07:32:47.219: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7333
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Kubectl replace
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1454
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: running the image mirror.gcr.io/library/httpd:2.4.38-alpine
Feb 22 07:32:47.599: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config run e2e-test-httpd-pod --image=mirror.gcr.io/library/httpd:2.4.38-alpine --labels=run=e2e-test-httpd-pod --namespace=kubectl-7333'
Feb 22 07:32:47.990: INFO: stderr: ""
Feb 22 07:32:47.990: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running
STEP: verifying the pod e2e-test-httpd-pod was created
Feb 22 07:33:23.047: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config get pod e2e-test-httpd-pod --namespace=kubectl-7333 -o json'
Feb 22 07:33:23.445: INFO: stderr: ""
Feb 22 07:33:23.446: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"attachment_id\": \"7bc05291-4637-4937-8f78-e5ba7dda58e9\",\n            \"kubernetes.io/psp\": \"e2e-test-privileged-psp\",\n            \"mac\": \"04:50:56:00:28:1f\",\n            \"vlan\": \"None\",\n            \"vmware-system-ephemeral-disk-uuid\": \"6000C29f-b5c5-d286-a1ae-98815de59137\",\n            \"vmware-system-image-references\": \"{\\\"e2e-test-httpd-pod\\\":\\\"httpd-d22d0e2cfeeaa0c1d2773814f5199d564ac0eae2-v79459\\\"}\",\n            \"vmware-system-vm-moid\": \"vm-888:6b180790-afb7-40a7-b1c1-16f00c9b6783\",\n            \"vmware-system-vm-uuid\": \"502f003b-3e2c-941c-b0a3-03cfb7042b04\"\n        },\n        \"creationTimestamp\": \"2021-02-22T07:32:47Z\",\n        \"finalizers\": [\n            \"lifecycle-controller/system.vmware.com\"\n        ],\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"managedFields\": [\n            {\n                \"apiVersion\": \"v1\",\n                \"fieldsType\": \"FieldsV1\",\n                \"fieldsV1\": {\n                    \"f:metadata\": {\n                        \"f:labels\": {\n                            \".\": {},\n                            \"f:run\": {}\n                        }\n                    },\n                    \"f:spec\": {\n                        \"f:containers\": {\n                            \"k:{\\\"name\\\":\\\"e2e-test-httpd-pod\\\"}\": {\n                                \".\": {},\n                                \"f:image\": {},\n                                \"f:imagePullPolicy\": {},\n                                \"f:name\": {},\n                                \"f:resources\": {},\n                                \"f:terminationMessagePath\": {},\n                                \"f:terminationMessagePolicy\": {}\n                            }\n                        },\n                        \"f:dnsPolicy\": {},\n                        \"f:enableServiceLinks\": {},\n                        \"f:restartPolicy\": {},\n                        \"f:schedulerName\": {},\n                        \"f:securityContext\": {},\n                        \"f:terminationGracePeriodSeconds\": {}\n                    }\n                },\n                \"manager\": \"kubectl\",\n                \"operation\": \"Update\",\n                \"time\": \"2021-02-22T07:32:47Z\"\n            },\n            {\n                \"apiVersion\": \"v1\",\n                \"fieldsType\": \"FieldsV1\",\n                \"fieldsV1\": {\n                    \"f:metadata\": {\n                        \"f:annotations\": {\n                            \"f:vmware-system-image-references\": {}\n                        }\n                    }\n                },\n                \"manager\": \"image-controller\",\n                \"operation\": \"Update\",\n                \"time\": \"2021-02-22T07:32:48Z\"\n            },\n            {\n                \"apiVersion\": \"v1\",\n                \"fieldsType\": \"FieldsV1\",\n                \"fieldsV1\": {\n                    \"f:metadata\": {\n                        \"f:annotations\": {\n                            \"f:attachment_id\": {},\n                            \"f:mac\": {},\n                            \"f:vlan\": {}\n                        }\n                    }\n                },\n                \"manager\": \"nsx-ncp-75bf644549-ps9h2\",\n                \"operation\": \"Update\",\n                \"time\": \"2021-02-22T07:32:54Z\"\n            },\n            {\n                \"apiVersion\": \"v1\",\n                \"fieldsType\": \"FieldsV1\",\n                \"fieldsV1\": {\n                    \"f:metadata\": {\n                        \"f:annotations\": {\n                            \"f:vmware-system-ephemeral-disk-uuid\": {},\n                            \"f:vmware-system-vm-moid\": {},\n                            \"f:vmware-system-vm-uuid\": {}\n                        },\n                        \"f:finalizers\": {\n                            \".\": {},\n                            \"v:\\\"lifecycle-controller/system.vmware.com\\\"\": {}\n                        }\n                    }\n                },\n                \"manager\": \"scheduler-extender\",\n                \"operation\": \"Update\",\n                \"time\": \"2021-02-22T07:33:09Z\"\n            },\n            {\n                \"apiVersion\": \"v1\",\n                \"fieldsType\": \"FieldsV1\",\n                \"fieldsV1\": {\n                    \"f:spec\": {\n                        \"f:containers\": {\n                            \"k:{\\\"name\\\":\\\"e2e-test-httpd-pod\\\"}\": {\n                                \"f:env\": {\n                                    \".\": {},\n                                    \"k:{\\\"name\\\":\\\"KUBERNETES_PORT\\\"}\": {\n                                        \".\": {},\n                                        \"f:name\": {},\n                                        \"f:value\": {}\n                                    },\n                                    \"k:{\\\"name\\\":\\\"KUBERNETES_PORT_443_TCP\\\"}\": {\n                                        \".\": {},\n                                        \"f:name\": {},\n                                        \"f:value\": {}\n                                    },\n                                    \"k:{\\\"name\\\":\\\"KUBERNETES_PORT_443_TCP_ADDR\\\"}\": {\n                                        \".\": {},\n                                        \"f:name\": {},\n                                        \"f:value\": {}\n                                    },\n                                    \"k:{\\\"name\\\":\\\"KUBERNETES_PORT_443_TCP_PORT\\\"}\": {\n                                        \".\": {},\n                                        \"f:name\": {},\n                                        \"f:value\": {}\n                                    },\n                                    \"k:{\\\"name\\\":\\\"KUBERNETES_PORT_443_TCP_PROTO\\\"}\": {\n                                        \".\": {},\n                                        \"f:name\": {},\n                                        \"f:value\": {}\n                                    },\n                                    \"k:{\\\"name\\\":\\\"KUBERNETES_SERVICE_HOST\\\"}\": {\n                                        \".\": {},\n                                        \"f:name\": {},\n                                        \"f:value\": {}\n                                    },\n                                    \"k:{\\\"name\\\":\\\"KUBERNETES_SERVICE_PORT\\\"}\": {\n                                        \".\": {},\n                                        \"f:name\": {},\n                                        \"f:value\": {}\n                                    },\n                                    \"k:{\\\"name\\\":\\\"KUBERNETES_SERVICE_PORT_HTTPS\\\"}\": {\n                                        \".\": {},\n                                        \"f:name\": {},\n                                        \"f:value\": {}\n                                    }\n                                }\n                            }\n                        }\n                    },\n                    \"f:status\": {\n                        \"f:conditions\": {\n                            \"k:{\\\"type\\\":\\\"ContainersReady\\\"}\": {\n                                \".\": {},\n                                \"f:lastProbeTime\": {},\n                                \"f:lastTransitionTime\": {},\n                                \"f:status\": {},\n                                \"f:type\": {}\n                            },\n                            \"k:{\\\"type\\\":\\\"Initialized\\\"}\": {\n                                \".\": {},\n                                \"f:lastProbeTime\": {},\n                                \"f:lastTransitionTime\": {},\n                                \"f:status\": {},\n                                \"f:type\": {}\n                            },\n                            \"k:{\\\"type\\\":\\\"Ready\\\"}\": {\n                                \".\": {},\n                                \"f:lastProbeTime\": {},\n                                \"f:lastTransitionTime\": {},\n                                \"f:status\": {},\n                                \"f:type\": {}\n                            }\n                        },\n                        \"f:containerStatuses\": {},\n                        \"f:hostIP\": {},\n                        \"f:phase\": {},\n                        \"f:podIP\": {},\n                        \"f:podIPs\": {\n                            \".\": {},\n                            \"k:{\\\"ip\\\":\\\"172.26.1.194\\\"}\": {\n                                \".\": {},\n                                \"f:ip\": {}\n                            }\n                        },\n                        \"f:startTime\": {}\n                    }\n                },\n                \"manager\": \"spherelet\",\n                \"operation\": \"Update\",\n                \"time\": \"2021-02-22T07:33:19Z\"\n            }\n        ],\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-7333\",\n        \"resourceVersion\": \"189383\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-7333/pods/e2e-test-httpd-pod\",\n        \"uid\": \"95d9af82-e86e-4f6e-aeda-62629fa2dd49\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"mirror.gcr.io/library/httpd:2.4.38-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-8xknj\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"sc2-rdops-vm05-dhcp-174-51.eng.vmware.com\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-8xknj\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-8xknj\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2021-02-22T07:32:48Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2021-02-22T07:33:19Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2021-02-22T07:33:19Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2021-02-22T07:33:19Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"7e80fad4-1054-42fa-ad70-c27a4dc84569\",\n                \"image\": \"mirror.gcr.io/library/httpd:2.4.38-alpine\",\n                \"imageID\": \"httpd-d22d0e2cfeeaa0c1d2773814f5199d564ac0eae2-v79459\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2021-02-22T07:33:17Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.192.174.51\",\n        \"phase\": \"Running\",\n        \"podIP\": \"172.26.1.194\",\n        \"podIPs\": [\n            {\n                \"ip\": \"172.26.1.194\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2021-02-22T07:33:16Z\"\n    }\n}\n"
STEP: replace the image in the pod
Feb 22 07:33:23.460: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config replace -f - --namespace=kubectl-7333'
Feb 22 07:33:25.378: INFO: stderr: ""
Feb 22 07:33:25.378: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image mirror.gcr.io/library/busybox:1.29
[AfterEach] Kubectl replace
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1459
Feb 22 07:33:25.422: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config delete pods e2e-test-httpd-pod --namespace=kubectl-7333'
Feb 22 07:33:38.245: INFO: stderr: ""
Feb 22 07:33:38.245: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 07:33:38.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7333" for this suite.

â€¢ [SLOW TEST:51.165 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl replace
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1450
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl replace should update a single-container pod's image  [Conformance]","total":270,"completed":252,"skipped":4454,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 07:33:38.388: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-2748
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2748.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2748.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 22 07:34:15.283: INFO: DNS probes using dns-2748/dns-test-df25aac2-9849-4aa1-89b4-8b84628d5dc6 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 07:34:15.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2748" for this suite.

â€¢ [SLOW TEST:37.019 seconds]
[sig-network] DNS
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for the cluster  [Conformance]","total":270,"completed":253,"skipped":4466,"failed":0}
SSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 07:34:15.412: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-5717
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-5717
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating stateful set ss in namespace statefulset-5717
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-5717
Feb 22 07:34:15.905: INFO: Found 0 stateful pods, waiting for 1
Feb 22 07:34:25.915: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
Feb 22 07:34:35.956: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
Feb 22 07:34:45.940: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Feb 22 07:34:45.953: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb 22 07:34:46.344: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb 22 07:34:46.344: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb 22 07:34:46.344: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb 22 07:34:46.358: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Feb 22 07:34:56.477: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 22 07:34:56.482: INFO: Waiting for statefulset status.replicas updated to 0
Feb 22 07:34:58.367: INFO: POD   NODE                                       PHASE    GRACE  CONDITIONS
Feb 22 07:34:58.367: INFO: ss-0  sc2-rdops-vm05-dhcp-174-51.eng.vmware.com  Running         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:34:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:34:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {Initialized True 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:34:45 +0000 UTC  } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:34:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]}]
Feb 22 07:34:58.368: INFO: 
Feb 22 07:34:58.368: INFO: StatefulSet ss has not reached scale 3, at 1
Feb 22 07:34:59.477: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.732670987s
Feb 22 07:35:00.502: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.623010187s
Feb 22 07:35:01.527: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.598925269s
Feb 22 07:35:02.552: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.57340794s
Feb 22 07:35:03.583: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.547329271s
Feb 22 07:35:04.608: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.517543805s
Feb 22 07:35:05.635: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.489751411s
Feb 22 07:35:06.653: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.465502794s
Feb 22 07:35:07.666: INFO: Verifying statefulset ss doesn't scale past 3 for another 447.488407ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-5717
Feb 22 07:35:08.686: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 22 07:35:09.831: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Feb 22 07:35:09.831: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb 22 07:35:09.831: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Feb 22 07:35:09.831: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 22 07:35:10.437: INFO: rc: 1
Feb 22 07:35:10.438: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
error: unable to upgrade connection: requested pod ss-1 not found

error:
exit status 1
Feb 22 07:35:20.470: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 22 07:35:20.834: INFO: rc: 1
Feb 22 07:35:20.834: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
error: unable to upgrade connection: requested pod ss-1 not found

error:
exit status 1
Feb 22 07:35:30.835: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 22 07:35:31.383: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Feb 22 07:35:31.383: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb 22 07:35:31.383: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Feb 22 07:35:31.383: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 22 07:35:31.790: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Feb 22 07:35:31.791: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb 22 07:35:31.791: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Feb 22 07:35:31.803: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 22 07:35:31.804: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 22 07:35:31.804: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Feb 22 07:35:31.823: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb 22 07:35:32.447: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb 22 07:35:32.447: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb 22 07:35:32.447: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb 22 07:35:32.447: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb 22 07:35:32.979: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb 22 07:35:32.979: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb 22 07:35:32.979: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb 22 07:35:32.979: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb 22 07:35:33.520: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb 22 07:35:33.520: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb 22 07:35:33.520: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb 22 07:35:33.520: INFO: Waiting for statefulset status.replicas updated to 0
Feb 22 07:35:33.539: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Feb 22 07:35:43.563: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 22 07:35:43.564: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Feb 22 07:35:43.564: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Feb 22 07:35:43.646: INFO: POD   NODE                                       PHASE    GRACE  CONDITIONS
Feb 22 07:35:43.646: INFO: ss-0  sc2-rdops-vm05-dhcp-174-51.eng.vmware.com  Running         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:34:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {Initialized True 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:34:45 +0000 UTC  } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]}]
Feb 22 07:35:43.646: INFO: ss-1  sc2-rdops-vm05-dhcp-174-51.eng.vmware.com  Running         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:34:59 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:26 +0000 UTC  } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {Ready False 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]}]
Feb 22 07:35:43.646: INFO: ss-2  sc2-rdops-vm05-dhcp-174-51.eng.vmware.com  Running         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:34:59 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:26 +0000 UTC  } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {Ready False 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]}]
Feb 22 07:35:43.646: INFO: 
Feb 22 07:35:43.646: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 22 07:35:44.665: INFO: POD   NODE                                       PHASE    GRACE  CONDITIONS
Feb 22 07:35:44.665: INFO: ss-0  sc2-rdops-vm05-dhcp-174-51.eng.vmware.com  Running  30s    [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:34:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {Initialized True 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:34:45 +0000 UTC  } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]}]
Feb 22 07:35:44.666: INFO: ss-1  sc2-rdops-vm05-dhcp-174-51.eng.vmware.com  Running  30s    [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:34:59 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:26 +0000 UTC  } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {Ready False 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]}]
Feb 22 07:35:44.667: INFO: ss-2  sc2-rdops-vm05-dhcp-174-51.eng.vmware.com  Running  30s    [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:34:59 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:26 +0000 UTC  } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {Ready False 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]}]
Feb 22 07:35:44.669: INFO: 
Feb 22 07:35:44.669: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 22 07:35:45.684: INFO: POD   NODE                                       PHASE    GRACE  CONDITIONS
Feb 22 07:35:45.684: INFO: ss-0  sc2-rdops-vm05-dhcp-174-51.eng.vmware.com  Running  30s    [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:34:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {Initialized True 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:34:45 +0000 UTC  } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]}]
Feb 22 07:35:45.684: INFO: ss-1  sc2-rdops-vm05-dhcp-174-51.eng.vmware.com  Running  30s    [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:34:59 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:26 +0000 UTC  } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {Ready False 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]}]
Feb 22 07:35:45.685: INFO: ss-2  sc2-rdops-vm05-dhcp-174-51.eng.vmware.com  Running  30s    [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:34:59 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:26 +0000 UTC  } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {Ready False 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]}]
Feb 22 07:35:45.685: INFO: 
Feb 22 07:35:45.685: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 22 07:35:46.718: INFO: POD   NODE                                       PHASE    GRACE  CONDITIONS
Feb 22 07:35:46.718: INFO: ss-0  sc2-rdops-vm05-dhcp-174-51.eng.vmware.com  Running  30s    [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:34:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {Initialized True 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:34:45 +0000 UTC  } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]}]
Feb 22 07:35:46.718: INFO: ss-1  sc2-rdops-vm05-dhcp-174-51.eng.vmware.com  Running  30s    [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:34:59 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:26 +0000 UTC  } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {Ready False 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]}]
Feb 22 07:35:46.718: INFO: ss-2  sc2-rdops-vm05-dhcp-174-51.eng.vmware.com  Running  0s     [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:34:59 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:26 +0000 UTC  } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {Ready False 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]}]
Feb 22 07:35:46.719: INFO: 
Feb 22 07:35:46.719: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 22 07:35:47.736: INFO: POD   NODE                                       PHASE    GRACE  CONDITIONS
Feb 22 07:35:47.736: INFO: ss-0  sc2-rdops-vm05-dhcp-174-51.eng.vmware.com  Running  0s     [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:34:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {Initialized True 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:34:45 +0000 UTC  } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]}]
Feb 22 07:35:47.736: INFO: ss-1  sc2-rdops-vm05-dhcp-174-51.eng.vmware.com  Running  0s     [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:34:59 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:26 +0000 UTC  } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {Ready False 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]}]
Feb 22 07:35:47.736: INFO: ss-2  sc2-rdops-vm05-dhcp-174-51.eng.vmware.com  Running  0s     [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:34:59 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:26 +0000 UTC  } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {Ready False 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]}]
Feb 22 07:35:47.736: INFO: 
Feb 22 07:35:47.736: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 22 07:35:48.756: INFO: POD   NODE                                       PHASE    GRACE  CONDITIONS
Feb 22 07:35:48.757: INFO: ss-0  sc2-rdops-vm05-dhcp-174-51.eng.vmware.com  Running  0s     [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:34:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {Initialized True 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:34:45 +0000 UTC  } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]}]
Feb 22 07:35:48.757: INFO: ss-1  sc2-rdops-vm05-dhcp-174-51.eng.vmware.com  Running  0s     [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:34:59 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:26 +0000 UTC  } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {Ready False 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]}]
Feb 22 07:35:48.757: INFO: ss-2  sc2-rdops-vm05-dhcp-174-51.eng.vmware.com  Running  0s     [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:34:59 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:26 +0000 UTC  } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {Ready False 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]}]
Feb 22 07:35:48.757: INFO: 
Feb 22 07:35:48.758: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 22 07:35:49.773: INFO: POD   NODE                                       PHASE    GRACE  CONDITIONS
Feb 22 07:35:49.773: INFO: ss-0  sc2-rdops-vm05-dhcp-174-51.eng.vmware.com  Running  0s     [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:34:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {Initialized True 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:34:45 +0000 UTC  } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]}]
Feb 22 07:35:49.774: INFO: ss-1  sc2-rdops-vm05-dhcp-174-51.eng.vmware.com  Running  0s     [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:34:59 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:26 +0000 UTC  } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {Ready False 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]}]
Feb 22 07:35:49.774: INFO: ss-2  sc2-rdops-vm05-dhcp-174-51.eng.vmware.com  Running  0s     [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:34:59 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:26 +0000 UTC  } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {Ready False 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]}]
Feb 22 07:35:49.775: INFO: 
Feb 22 07:35:49.776: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 22 07:35:50.786: INFO: POD   NODE                                       PHASE    GRACE  CONDITIONS
Feb 22 07:35:50.786: INFO: ss-0  sc2-rdops-vm05-dhcp-174-51.eng.vmware.com  Running  0s     [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:34:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {Initialized True 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:34:45 +0000 UTC  } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]}]
Feb 22 07:35:50.786: INFO: ss-1  sc2-rdops-vm05-dhcp-174-51.eng.vmware.com  Running  0s     [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:34:59 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:26 +0000 UTC  } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {Ready False 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]}]
Feb 22 07:35:50.786: INFO: ss-2  sc2-rdops-vm05-dhcp-174-51.eng.vmware.com  Running  0s     [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:34:59 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:26 +0000 UTC  } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {Ready False 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]}]
Feb 22 07:35:50.786: INFO: 
Feb 22 07:35:50.786: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 22 07:35:51.800: INFO: POD   NODE                                       PHASE    GRACE  CONDITIONS
Feb 22 07:35:51.800: INFO: ss-0  sc2-rdops-vm05-dhcp-174-51.eng.vmware.com  Running  0s     [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:34:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {Initialized True 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:34:45 +0000 UTC  } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]}]
Feb 22 07:35:51.800: INFO: ss-1  sc2-rdops-vm05-dhcp-174-51.eng.vmware.com  Running  0s     [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:34:59 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:26 +0000 UTC  } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {Ready False 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]}]
Feb 22 07:35:51.800: INFO: ss-2  sc2-rdops-vm05-dhcp-174-51.eng.vmware.com  Running  0s     [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:34:59 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:26 +0000 UTC  } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {Ready False 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]}]
Feb 22 07:35:51.800: INFO: 
Feb 22 07:35:51.800: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 22 07:35:52.816: INFO: POD   NODE                                       PHASE    GRACE  CONDITIONS
Feb 22 07:35:52.817: INFO: ss-0  sc2-rdops-vm05-dhcp-174-51.eng.vmware.com  Running  0s     [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:34:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {Initialized True 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:34:45 +0000 UTC  } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]}]
Feb 22 07:35:52.818: INFO: ss-1  sc2-rdops-vm05-dhcp-174-51.eng.vmware.com  Running  0s     [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:34:59 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:26 +0000 UTC  } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {Ready False 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]}]
Feb 22 07:35:52.818: INFO: ss-2  sc2-rdops-vm05-dhcp-174-51.eng.vmware.com  Running  0s     [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:34:59 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:26 +0000 UTC  } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {Ready False 0001-01-01 00:00:00 +0000 UTC 2021-02-22 07:35:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]}]
Feb 22 07:35:52.818: INFO: 
Feb 22 07:35:52.818: INFO: StatefulSet ss has not reached scale 0, at 3
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-5717
Feb 22 07:35:53.836: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 22 07:35:54.081: INFO: rc: 1
Feb 22 07:35:54.081: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
error: unable to upgrade connection: requested pod ss-0 not found

error:
exit status 1
Feb 22 07:36:04.082: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 22 07:36:04.221: INFO: rc: 1
Feb 22 07:36:04.222: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Feb 22 07:36:14.222: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 22 07:36:14.413: INFO: rc: 1
Feb 22 07:36:14.413: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Feb 22 07:36:24.419: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 22 07:36:24.891: INFO: rc: 1
Feb 22 07:36:24.893: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Feb 22 07:36:34.894: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 22 07:36:35.043: INFO: rc: 1
Feb 22 07:36:35.043: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Feb 22 07:36:45.044: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 22 07:36:45.222: INFO: rc: 1
Feb 22 07:36:45.222: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Feb 22 07:36:55.223: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 22 07:36:55.434: INFO: rc: 1
Feb 22 07:36:55.434: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Feb 22 07:37:05.435: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 22 07:37:05.635: INFO: rc: 1
Feb 22 07:37:05.635: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Feb 22 07:37:15.639: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 22 07:37:15.879: INFO: rc: 1
Feb 22 07:37:15.879: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Feb 22 07:37:25.880: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 22 07:37:26.191: INFO: rc: 1
Feb 22 07:37:26.191: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Feb 22 07:37:36.192: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 22 07:37:36.382: INFO: rc: 1
Feb 22 07:37:36.382: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Feb 22 07:37:46.382: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 22 07:37:46.577: INFO: rc: 1
Feb 22 07:37:46.577: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Feb 22 07:37:56.578: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 22 07:37:56.720: INFO: rc: 1
Feb 22 07:37:56.721: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Feb 22 07:38:06.722: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 22 07:38:07.014: INFO: rc: 1
Feb 22 07:38:07.015: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Feb 22 07:38:17.015: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 22 07:38:17.235: INFO: rc: 1
Feb 22 07:38:17.235: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Feb 22 07:38:27.236: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 22 07:38:27.403: INFO: rc: 1
Feb 22 07:38:27.403: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Feb 22 07:38:37.404: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 22 07:38:37.554: INFO: rc: 1
Feb 22 07:38:37.554: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Feb 22 07:38:47.554: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 22 07:38:47.692: INFO: rc: 1
Feb 22 07:38:47.692: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Feb 22 07:38:57.694: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 22 07:38:57.869: INFO: rc: 1
Feb 22 07:38:57.869: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Feb 22 07:39:07.870: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 22 07:39:08.083: INFO: rc: 1
Feb 22 07:39:08.083: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Feb 22 07:39:18.084: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 22 07:39:18.280: INFO: rc: 1
Feb 22 07:39:18.280: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Feb 22 07:39:28.280: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 22 07:39:28.573: INFO: rc: 1
Feb 22 07:39:28.574: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Feb 22 07:39:38.574: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 22 07:39:38.914: INFO: rc: 1
Feb 22 07:39:38.914: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Feb 22 07:39:48.914: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 22 07:39:49.121: INFO: rc: 1
Feb 22 07:39:49.121: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Feb 22 07:39:59.121: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 22 07:39:59.289: INFO: rc: 1
Feb 22 07:39:59.289: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Feb 22 07:40:09.289: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 22 07:40:09.620: INFO: rc: 1
Feb 22 07:40:09.620: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Feb 22 07:40:19.621: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 22 07:40:19.954: INFO: rc: 1
Feb 22 07:40:19.954: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Feb 22 07:40:29.954: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 22 07:40:30.152: INFO: rc: 1
Feb 22 07:40:30.152: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Feb 22 07:40:40.152: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 22 07:40:40.347: INFO: rc: 1
Feb 22 07:40:40.347: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Feb 22 07:40:50.347: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 22 07:40:50.672: INFO: rc: 1
Feb 22 07:40:50.672: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Feb 22 07:41:00.672: INFO: Running '/usr/bin/kubectl --kubeconfig=/root/.kube/config exec --namespace=statefulset-5717 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 22 07:41:01.036: INFO: rc: 1
Feb 22 07:41:01.036: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: 
Feb 22 07:41:01.036: INFO: Scaling statefulset ss to 0
Feb 22 07:41:01.092: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Feb 22 07:41:01.108: INFO: Deleting all statefulset in ns statefulset-5717
Feb 22 07:41:01.129: INFO: Scaling statefulset ss to 0
Feb 22 07:41:01.169: INFO: Waiting for statefulset status.replicas updated to 0
Feb 22 07:41:01.178: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 07:41:01.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5717" for this suite.

â€¢ [SLOW TEST:405.977 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]","total":270,"completed":254,"skipped":4472,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 07:41:01.461: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4127
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Feb 22 07:41:01.943: INFO: Waiting up to 5m0s for pod "downwardapi-volume-59746b44-d178-4db9-a38b-8e9bb54fc06f" in namespace "downward-api-4127" to be "Succeeded or Failed"
Feb 22 07:41:01.952: INFO: Pod "downwardapi-volume-59746b44-d178-4db9-a38b-8e9bb54fc06f": Phase="Pending", Reason="", readiness=false. Elapsed: 9.245747ms
Feb 22 07:41:03.975: INFO: Pod "downwardapi-volume-59746b44-d178-4db9-a38b-8e9bb54fc06f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032336557s
Feb 22 07:41:06.016: INFO: Pod "downwardapi-volume-59746b44-d178-4db9-a38b-8e9bb54fc06f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.072793719s
Feb 22 07:41:08.079: INFO: Pod "downwardapi-volume-59746b44-d178-4db9-a38b-8e9bb54fc06f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.135412838s
Feb 22 07:41:10.097: INFO: Pod "downwardapi-volume-59746b44-d178-4db9-a38b-8e9bb54fc06f": Phase="Pending", Reason="", readiness=false. Elapsed: 8.153655353s
Feb 22 07:41:12.165: INFO: Pod "downwardapi-volume-59746b44-d178-4db9-a38b-8e9bb54fc06f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.221754676s
Feb 22 07:41:14.194: INFO: Pod "downwardapi-volume-59746b44-d178-4db9-a38b-8e9bb54fc06f": Phase="Pending", Reason="", readiness=false. Elapsed: 12.250919164s
Feb 22 07:41:16.205: INFO: Pod "downwardapi-volume-59746b44-d178-4db9-a38b-8e9bb54fc06f": Phase="Pending", Reason="", readiness=false. Elapsed: 14.261956838s
Feb 22 07:41:18.211: INFO: Pod "downwardapi-volume-59746b44-d178-4db9-a38b-8e9bb54fc06f": Phase="Pending", Reason="", readiness=false. Elapsed: 16.268181253s
Feb 22 07:41:20.218: INFO: Pod "downwardapi-volume-59746b44-d178-4db9-a38b-8e9bb54fc06f": Phase="Pending", Reason="", readiness=false. Elapsed: 18.274707967s
Feb 22 07:41:22.225: INFO: Pod "downwardapi-volume-59746b44-d178-4db9-a38b-8e9bb54fc06f": Phase="Pending", Reason="", readiness=false. Elapsed: 20.281827239s
Feb 22 07:41:24.238: INFO: Pod "downwardapi-volume-59746b44-d178-4db9-a38b-8e9bb54fc06f": Phase="Pending", Reason="", readiness=false. Elapsed: 22.295244292s
Feb 22 07:41:26.248: INFO: Pod "downwardapi-volume-59746b44-d178-4db9-a38b-8e9bb54fc06f": Phase="Pending", Reason="", readiness=false. Elapsed: 24.304815263s
Feb 22 07:41:28.255: INFO: Pod "downwardapi-volume-59746b44-d178-4db9-a38b-8e9bb54fc06f": Phase="Pending", Reason="", readiness=false. Elapsed: 26.311566291s
Feb 22 07:41:30.262: INFO: Pod "downwardapi-volume-59746b44-d178-4db9-a38b-8e9bb54fc06f": Phase="Pending", Reason="", readiness=false. Elapsed: 28.3189109s
Feb 22 07:41:32.289: INFO: Pod "downwardapi-volume-59746b44-d178-4db9-a38b-8e9bb54fc06f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 30.345448171s
STEP: Saw pod success
Feb 22 07:41:32.289: INFO: Pod "downwardapi-volume-59746b44-d178-4db9-a38b-8e9bb54fc06f" satisfied condition "Succeeded or Failed"
Feb 22 07:41:32.300: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com pod downwardapi-volume-59746b44-d178-4db9-a38b-8e9bb54fc06f container client-container: <nil>
STEP: delete the pod
Feb 22 07:41:32.383: INFO: Waiting for pod downwardapi-volume-59746b44-d178-4db9-a38b-8e9bb54fc06f to disappear
Feb 22 07:41:32.404: INFO: Pod downwardapi-volume-59746b44-d178-4db9-a38b-8e9bb54fc06f still exists
Feb 22 07:41:34.404: INFO: Waiting for pod downwardapi-volume-59746b44-d178-4db9-a38b-8e9bb54fc06f to disappear
Feb 22 07:41:34.465: INFO: Pod downwardapi-volume-59746b44-d178-4db9-a38b-8e9bb54fc06f still exists
Feb 22 07:41:36.404: INFO: Waiting for pod downwardapi-volume-59746b44-d178-4db9-a38b-8e9bb54fc06f to disappear
Feb 22 07:41:36.412: INFO: Pod downwardapi-volume-59746b44-d178-4db9-a38b-8e9bb54fc06f still exists
Feb 22 07:41:38.404: INFO: Waiting for pod downwardapi-volume-59746b44-d178-4db9-a38b-8e9bb54fc06f to disappear
Feb 22 07:41:38.426: INFO: Pod downwardapi-volume-59746b44-d178-4db9-a38b-8e9bb54fc06f still exists
Feb 22 07:41:40.404: INFO: Waiting for pod downwardapi-volume-59746b44-d178-4db9-a38b-8e9bb54fc06f to disappear
Feb 22 07:41:40.414: INFO: Pod downwardapi-volume-59746b44-d178-4db9-a38b-8e9bb54fc06f still exists
Feb 22 07:41:42.404: INFO: Waiting for pod downwardapi-volume-59746b44-d178-4db9-a38b-8e9bb54fc06f to disappear
Feb 22 07:41:42.422: INFO: Pod downwardapi-volume-59746b44-d178-4db9-a38b-8e9bb54fc06f still exists
Feb 22 07:41:44.404: INFO: Waiting for pod downwardapi-volume-59746b44-d178-4db9-a38b-8e9bb54fc06f to disappear
Feb 22 07:41:44.414: INFO: Pod downwardapi-volume-59746b44-d178-4db9-a38b-8e9bb54fc06f still exists
Feb 22 07:41:46.404: INFO: Waiting for pod downwardapi-volume-59746b44-d178-4db9-a38b-8e9bb54fc06f to disappear
Feb 22 07:41:46.414: INFO: Pod downwardapi-volume-59746b44-d178-4db9-a38b-8e9bb54fc06f still exists
Feb 22 07:41:48.404: INFO: Waiting for pod downwardapi-volume-59746b44-d178-4db9-a38b-8e9bb54fc06f to disappear
Feb 22 07:41:48.417: INFO: Pod downwardapi-volume-59746b44-d178-4db9-a38b-8e9bb54fc06f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 07:41:48.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4127" for this suite.

â€¢ [SLOW TEST:47.013 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:37
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","total":270,"completed":255,"skipped":4527,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 07:41:48.475: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-2297
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Feb 22 07:41:49.206: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-2297 /api/v1/namespaces/watch-2297/configmaps/e2e-watch-test-resource-version 5475ec0d-5fb5-4bbe-892a-0a08ef928c75 194569 0 2021-02-22 07:41:49 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  [{e2e.test Update v1 2021-02-22 07:41:49 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Feb 22 07:41:49.210: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-2297 /api/v1/namespaces/watch-2297/configmaps/e2e-watch-test-resource-version 5475ec0d-5fb5-4bbe-892a-0a08ef928c75 194570 0 2021-02-22 07:41:49 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  [{e2e.test Update v1 2021-02-22 07:41:49 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 07:41:49.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2297" for this suite.
â€¢{"msg":"PASSED [sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]","total":270,"completed":256,"skipped":4539,"failed":0}
S
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 07:41:49.286: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6381
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name projected-secret-test-1e688131-223d-49ac-af86-cd84e0bf8057
STEP: Creating a pod to test consume secrets
Feb 22 07:41:49.708: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-3f9ce4d1-09ca-4b73-bebe-a1abff2688d2" in namespace "projected-6381" to be "Succeeded or Failed"
Feb 22 07:41:49.743: INFO: Pod "pod-projected-secrets-3f9ce4d1-09ca-4b73-bebe-a1abff2688d2": Phase="Pending", Reason="", readiness=false. Elapsed: 34.65216ms
Feb 22 07:41:51.754: INFO: Pod "pod-projected-secrets-3f9ce4d1-09ca-4b73-bebe-a1abff2688d2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.045770281s
Feb 22 07:41:53.764: INFO: Pod "pod-projected-secrets-3f9ce4d1-09ca-4b73-bebe-a1abff2688d2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.055554296s
Feb 22 07:41:55.785: INFO: Pod "pod-projected-secrets-3f9ce4d1-09ca-4b73-bebe-a1abff2688d2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.076059579s
Feb 22 07:41:58.664: INFO: Pod "pod-projected-secrets-3f9ce4d1-09ca-4b73-bebe-a1abff2688d2": Phase="Pending", Reason="", readiness=false. Elapsed: 8.95537806s
Feb 22 07:42:00.867: INFO: Pod "pod-projected-secrets-3f9ce4d1-09ca-4b73-bebe-a1abff2688d2": Phase="Pending", Reason="", readiness=false. Elapsed: 11.158733945s
Feb 22 07:42:03.062: INFO: Pod "pod-projected-secrets-3f9ce4d1-09ca-4b73-bebe-a1abff2688d2": Phase="Pending", Reason="", readiness=false. Elapsed: 13.353108806s
Feb 22 07:42:05.393: INFO: Pod "pod-projected-secrets-3f9ce4d1-09ca-4b73-bebe-a1abff2688d2": Phase="Pending", Reason="", readiness=false. Elapsed: 15.684344413s
Feb 22 07:42:07.431: INFO: Pod "pod-projected-secrets-3f9ce4d1-09ca-4b73-bebe-a1abff2688d2": Phase="Pending", Reason="", readiness=false. Elapsed: 17.722768679s
Feb 22 07:42:09.446: INFO: Pod "pod-projected-secrets-3f9ce4d1-09ca-4b73-bebe-a1abff2688d2": Phase="Pending", Reason="", readiness=false. Elapsed: 19.737725501s
Feb 22 07:42:11.487: INFO: Pod "pod-projected-secrets-3f9ce4d1-09ca-4b73-bebe-a1abff2688d2": Phase="Pending", Reason="", readiness=false. Elapsed: 21.778332441s
Feb 22 07:42:13.551: INFO: Pod "pod-projected-secrets-3f9ce4d1-09ca-4b73-bebe-a1abff2688d2": Phase="Pending", Reason="", readiness=false. Elapsed: 23.842769633s
Feb 22 07:42:15.573: INFO: Pod "pod-projected-secrets-3f9ce4d1-09ca-4b73-bebe-a1abff2688d2": Phase="Pending", Reason="", readiness=false. Elapsed: 25.864350612s
Feb 22 07:42:17.584: INFO: Pod "pod-projected-secrets-3f9ce4d1-09ca-4b73-bebe-a1abff2688d2": Phase="Pending", Reason="", readiness=false. Elapsed: 27.875678113s
Feb 22 07:42:19.599: INFO: Pod "pod-projected-secrets-3f9ce4d1-09ca-4b73-bebe-a1abff2688d2": Phase="Pending", Reason="", readiness=false. Elapsed: 29.890836982s
Feb 22 07:42:21.615: INFO: Pod "pod-projected-secrets-3f9ce4d1-09ca-4b73-bebe-a1abff2688d2": Phase="Pending", Reason="", readiness=false. Elapsed: 31.906092922s
Feb 22 07:42:23.655: INFO: Pod "pod-projected-secrets-3f9ce4d1-09ca-4b73-bebe-a1abff2688d2": Phase="Pending", Reason="", readiness=false. Elapsed: 33.946741757s
Feb 22 07:42:25.665: INFO: Pod "pod-projected-secrets-3f9ce4d1-09ca-4b73-bebe-a1abff2688d2": Phase="Pending", Reason="", readiness=false. Elapsed: 35.956309417s
Feb 22 07:42:27.682: INFO: Pod "pod-projected-secrets-3f9ce4d1-09ca-4b73-bebe-a1abff2688d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 37.973310891s
STEP: Saw pod success
Feb 22 07:42:27.682: INFO: Pod "pod-projected-secrets-3f9ce4d1-09ca-4b73-bebe-a1abff2688d2" satisfied condition "Succeeded or Failed"
Feb 22 07:42:27.698: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com pod pod-projected-secrets-3f9ce4d1-09ca-4b73-bebe-a1abff2688d2 container secret-volume-test: <nil>
STEP: delete the pod
Feb 22 07:42:27.814: INFO: Waiting for pod pod-projected-secrets-3f9ce4d1-09ca-4b73-bebe-a1abff2688d2 to disappear
Feb 22 07:42:27.831: INFO: Pod pod-projected-secrets-3f9ce4d1-09ca-4b73-bebe-a1abff2688d2 still exists
Feb 22 07:42:29.832: INFO: Waiting for pod pod-projected-secrets-3f9ce4d1-09ca-4b73-bebe-a1abff2688d2 to disappear
Feb 22 07:42:29.866: INFO: Pod pod-projected-secrets-3f9ce4d1-09ca-4b73-bebe-a1abff2688d2 still exists
Feb 22 07:42:31.831: INFO: Waiting for pod pod-projected-secrets-3f9ce4d1-09ca-4b73-bebe-a1abff2688d2 to disappear
Feb 22 07:42:31.854: INFO: Pod pod-projected-secrets-3f9ce4d1-09ca-4b73-bebe-a1abff2688d2 still exists
Feb 22 07:42:33.832: INFO: Waiting for pod pod-projected-secrets-3f9ce4d1-09ca-4b73-bebe-a1abff2688d2 to disappear
Feb 22 07:42:33.840: INFO: Pod pod-projected-secrets-3f9ce4d1-09ca-4b73-bebe-a1abff2688d2 still exists
Feb 22 07:42:35.832: INFO: Waiting for pod pod-projected-secrets-3f9ce4d1-09ca-4b73-bebe-a1abff2688d2 to disappear
Feb 22 07:42:35.853: INFO: Pod pod-projected-secrets-3f9ce4d1-09ca-4b73-bebe-a1abff2688d2 still exists
Feb 22 07:42:37.832: INFO: Waiting for pod pod-projected-secrets-3f9ce4d1-09ca-4b73-bebe-a1abff2688d2 to disappear
Feb 22 07:42:37.842: INFO: Pod pod-projected-secrets-3f9ce4d1-09ca-4b73-bebe-a1abff2688d2 still exists
Feb 22 07:42:39.832: INFO: Waiting for pod pod-projected-secrets-3f9ce4d1-09ca-4b73-bebe-a1abff2688d2 to disappear
Feb 22 07:42:39.840: INFO: Pod pod-projected-secrets-3f9ce4d1-09ca-4b73-bebe-a1abff2688d2 still exists
Feb 22 07:42:41.832: INFO: Waiting for pod pod-projected-secrets-3f9ce4d1-09ca-4b73-bebe-a1abff2688d2 to disappear
Feb 22 07:42:41.846: INFO: Pod pod-projected-secrets-3f9ce4d1-09ca-4b73-bebe-a1abff2688d2 still exists
Feb 22 07:42:43.832: INFO: Waiting for pod pod-projected-secrets-3f9ce4d1-09ca-4b73-bebe-a1abff2688d2 to disappear
Feb 22 07:42:43.841: INFO: Pod pod-projected-secrets-3f9ce4d1-09ca-4b73-bebe-a1abff2688d2 still exists
Feb 22 07:42:45.832: INFO: Waiting for pod pod-projected-secrets-3f9ce4d1-09ca-4b73-bebe-a1abff2688d2 to disappear
Feb 22 07:42:45.905: INFO: Pod pod-projected-secrets-3f9ce4d1-09ca-4b73-bebe-a1abff2688d2 still exists
Feb 22 07:42:47.832: INFO: Waiting for pod pod-projected-secrets-3f9ce4d1-09ca-4b73-bebe-a1abff2688d2 to disappear
Feb 22 07:42:47.838: INFO: Pod pod-projected-secrets-3f9ce4d1-09ca-4b73-bebe-a1abff2688d2 still exists
Feb 22 07:42:49.832: INFO: Waiting for pod pod-projected-secrets-3f9ce4d1-09ca-4b73-bebe-a1abff2688d2 to disappear
Feb 22 07:42:49.843: INFO: Pod pod-projected-secrets-3f9ce4d1-09ca-4b73-bebe-a1abff2688d2 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 07:42:49.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6381" for this suite.

â€¢ [SLOW TEST:60.612 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","total":270,"completed":257,"skipped":4540,"failed":0}
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate configmap [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 07:42:49.902: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-90
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 22 07:42:50.831: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Feb 22 07:42:52.867: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749576570, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749576570, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749576571, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749576570, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 07:42:54.875: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749576570, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749576570, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749576571, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749576570, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 07:42:56.876: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749576570, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749576570, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749576571, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749576570, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 07:42:58.873: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749576570, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749576570, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749576571, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749576570, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 07:43:00.881: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749576570, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749576570, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749576571, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749576570, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 07:43:02.878: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749576570, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749576570, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749576571, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749576570, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 07:43:04.880: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749576570, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749576570, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749576571, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749576570, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 07:43:06.904: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749576570, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749576570, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749576571, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749576570, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 07:43:08.876: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749576570, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749576570, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749576571, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749576570, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 07:43:10.878: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749576570, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749576570, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749576571, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749576570, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 07:43:12.878: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749576570, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749576570, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749576571, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749576570, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 07:43:14.881: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749576570, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749576570, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749576571, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749576570, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 07:43:16.876: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749576570, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749576570, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749576571, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749576570, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 07:43:18.880: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749576570, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749576570, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749576571, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749576570, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 22 07:43:20.876: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749576570, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749576570, loc:(*time.Location)(0x7b501e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63749576571, loc:(*time.Location)(0x7b501e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63749576570, loc:(*time.Location)(0x7b501e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 22 07:43:23.951: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API
STEP: create a configmap that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 07:43:24.189: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-90" for this suite.
STEP: Destroying namespace "webhook-90-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

â€¢ [SLOW TEST:34.705 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]","total":270,"completed":258,"skipped":4541,"failed":0}
SS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 07:43:24.607: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7517
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward api env vars
Feb 22 07:43:25.079: INFO: Waiting up to 5m0s for pod "downward-api-d9ac5bad-1bbd-4620-b21a-3fec736d67ed" in namespace "downward-api-7517" to be "Succeeded or Failed"
Feb 22 07:43:25.099: INFO: Pod "downward-api-d9ac5bad-1bbd-4620-b21a-3fec736d67ed": Phase="Pending", Reason="", readiness=false. Elapsed: 19.567052ms
Feb 22 07:43:27.111: INFO: Pod "downward-api-d9ac5bad-1bbd-4620-b21a-3fec736d67ed": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031384089s
Feb 22 07:43:29.124: INFO: Pod "downward-api-d9ac5bad-1bbd-4620-b21a-3fec736d67ed": Phase="Pending", Reason="", readiness=false. Elapsed: 4.044255395s
Feb 22 07:43:31.165: INFO: Pod "downward-api-d9ac5bad-1bbd-4620-b21a-3fec736d67ed": Phase="Pending", Reason="", readiness=false. Elapsed: 6.085180675s
Feb 22 07:43:33.181: INFO: Pod "downward-api-d9ac5bad-1bbd-4620-b21a-3fec736d67ed": Phase="Pending", Reason="", readiness=false. Elapsed: 8.101528943s
Feb 22 07:43:35.190: INFO: Pod "downward-api-d9ac5bad-1bbd-4620-b21a-3fec736d67ed": Phase="Pending", Reason="", readiness=false. Elapsed: 10.110458159s
Feb 22 07:43:37.198: INFO: Pod "downward-api-d9ac5bad-1bbd-4620-b21a-3fec736d67ed": Phase="Pending", Reason="", readiness=false. Elapsed: 12.11877129s
Feb 22 07:43:39.206: INFO: Pod "downward-api-d9ac5bad-1bbd-4620-b21a-3fec736d67ed": Phase="Pending", Reason="", readiness=false. Elapsed: 14.126775521s
Feb 22 07:43:41.217: INFO: Pod "downward-api-d9ac5bad-1bbd-4620-b21a-3fec736d67ed": Phase="Pending", Reason="", readiness=false. Elapsed: 16.13702903s
Feb 22 07:43:43.231: INFO: Pod "downward-api-d9ac5bad-1bbd-4620-b21a-3fec736d67ed": Phase="Pending", Reason="", readiness=false. Elapsed: 18.151847731s
Feb 22 07:43:45.239: INFO: Pod "downward-api-d9ac5bad-1bbd-4620-b21a-3fec736d67ed": Phase="Pending", Reason="", readiness=false. Elapsed: 20.159377983s
Feb 22 07:43:47.245: INFO: Pod "downward-api-d9ac5bad-1bbd-4620-b21a-3fec736d67ed": Phase="Pending", Reason="", readiness=false. Elapsed: 22.165208457s
Feb 22 07:43:49.277: INFO: Pod "downward-api-d9ac5bad-1bbd-4620-b21a-3fec736d67ed": Phase="Pending", Reason="", readiness=false. Elapsed: 24.197313456s
Feb 22 07:43:51.288: INFO: Pod "downward-api-d9ac5bad-1bbd-4620-b21a-3fec736d67ed": Phase="Pending", Reason="", readiness=false. Elapsed: 26.207968346s
Feb 22 07:43:53.295: INFO: Pod "downward-api-d9ac5bad-1bbd-4620-b21a-3fec736d67ed": Phase="Pending", Reason="", readiness=false. Elapsed: 28.215244191s
Feb 22 07:43:55.306: INFO: Pod "downward-api-d9ac5bad-1bbd-4620-b21a-3fec736d67ed": Phase="Pending", Reason="", readiness=false. Elapsed: 30.226347939s
Feb 22 07:43:57.320: INFO: Pod "downward-api-d9ac5bad-1bbd-4620-b21a-3fec736d67ed": Phase="Succeeded", Reason="", readiness=false. Elapsed: 32.240753273s
STEP: Saw pod success
Feb 22 07:43:57.321: INFO: Pod "downward-api-d9ac5bad-1bbd-4620-b21a-3fec736d67ed" satisfied condition "Succeeded or Failed"
Feb 22 07:43:57.329: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com pod downward-api-d9ac5bad-1bbd-4620-b21a-3fec736d67ed container dapi-container: <nil>
STEP: delete the pod
Feb 22 07:43:57.415: INFO: Waiting for pod downward-api-d9ac5bad-1bbd-4620-b21a-3fec736d67ed to disappear
Feb 22 07:43:57.433: INFO: Pod downward-api-d9ac5bad-1bbd-4620-b21a-3fec736d67ed still exists
Feb 22 07:43:59.434: INFO: Waiting for pod downward-api-d9ac5bad-1bbd-4620-b21a-3fec736d67ed to disappear
Feb 22 07:43:59.452: INFO: Pod downward-api-d9ac5bad-1bbd-4620-b21a-3fec736d67ed still exists
Feb 22 07:44:01.434: INFO: Waiting for pod downward-api-d9ac5bad-1bbd-4620-b21a-3fec736d67ed to disappear
Feb 22 07:44:01.445: INFO: Pod downward-api-d9ac5bad-1bbd-4620-b21a-3fec736d67ed still exists
Feb 22 07:44:03.434: INFO: Waiting for pod downward-api-d9ac5bad-1bbd-4620-b21a-3fec736d67ed to disappear
Feb 22 07:44:03.449: INFO: Pod downward-api-d9ac5bad-1bbd-4620-b21a-3fec736d67ed still exists
Feb 22 07:44:05.433: INFO: Waiting for pod downward-api-d9ac5bad-1bbd-4620-b21a-3fec736d67ed to disappear
Feb 22 07:44:05.444: INFO: Pod downward-api-d9ac5bad-1bbd-4620-b21a-3fec736d67ed still exists
Feb 22 07:44:07.433: INFO: Waiting for pod downward-api-d9ac5bad-1bbd-4620-b21a-3fec736d67ed to disappear
Feb 22 07:44:07.454: INFO: Pod downward-api-d9ac5bad-1bbd-4620-b21a-3fec736d67ed still exists
Feb 22 07:44:09.434: INFO: Waiting for pod downward-api-d9ac5bad-1bbd-4620-b21a-3fec736d67ed to disappear
Feb 22 07:44:09.446: INFO: Pod downward-api-d9ac5bad-1bbd-4620-b21a-3fec736d67ed still exists
Feb 22 07:44:11.434: INFO: Waiting for pod downward-api-d9ac5bad-1bbd-4620-b21a-3fec736d67ed to disappear
Feb 22 07:44:11.446: INFO: Pod downward-api-d9ac5bad-1bbd-4620-b21a-3fec736d67ed still exists
Feb 22 07:44:13.438: INFO: Waiting for pod downward-api-d9ac5bad-1bbd-4620-b21a-3fec736d67ed to disappear
Feb 22 07:44:13.456: INFO: Pod downward-api-d9ac5bad-1bbd-4620-b21a-3fec736d67ed still exists
Feb 22 07:44:15.433: INFO: Waiting for pod downward-api-d9ac5bad-1bbd-4620-b21a-3fec736d67ed to disappear
Feb 22 07:44:15.442: INFO: Pod downward-api-d9ac5bad-1bbd-4620-b21a-3fec736d67ed still exists
Feb 22 07:44:17.434: INFO: Waiting for pod downward-api-d9ac5bad-1bbd-4620-b21a-3fec736d67ed to disappear
Feb 22 07:44:17.457: INFO: Pod downward-api-d9ac5bad-1bbd-4620-b21a-3fec736d67ed still exists
Feb 22 07:44:19.434: INFO: Waiting for pod downward-api-d9ac5bad-1bbd-4620-b21a-3fec736d67ed to disappear
Feb 22 07:44:19.442: INFO: Pod downward-api-d9ac5bad-1bbd-4620-b21a-3fec736d67ed no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 07:44:19.443: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7517" for this suite.

â€¢ [SLOW TEST:54.884 seconds]
[sig-node] Downward API
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:34
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]","total":270,"completed":259,"skipped":4543,"failed":0}
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 07:44:19.492: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-9578
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Feb 22 07:44:59.997: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 07:44:59.998: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9578" for this suite.

â€¢ [SLOW TEST:40.582 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance]","total":270,"completed":260,"skipped":4549,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 07:45:00.078: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-3117
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
Feb 22 07:45:06.603: INFO: 10 pods remaining
Feb 22 07:45:06.603: INFO: 10 pods has nil DeletionTimestamp
Feb 22 07:45:06.603: INFO: 
Feb 22 07:45:07.927: INFO: 3 pods remaining
Feb 22 07:45:07.927: INFO: 0 pods has nil DeletionTimestamp
Feb 22 07:45:07.927: INFO: 
STEP: Gathering metrics
Feb 22 07:45:08.644: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 07:45:08.645: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3117" for this suite.

â€¢ [SLOW TEST:8.826 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]","total":270,"completed":261,"skipped":4560,"failed":0}
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] version v1
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 07:45:08.904: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-3437
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-6wsnt in namespace proxy-3437
Feb 22 07:46:09.006: INFO: setup took 59.497731236s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Feb 22 07:46:09.146: INFO: (0) /api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:460/proxy/: tls baz (200; 121.203268ms)
Feb 22 07:46:09.152: INFO: (0) /api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:160/proxy/: foo (200; 126.812687ms)
Feb 22 07:46:09.154: INFO: (0) /api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:162/proxy/: bar (200; 126.058678ms)
Feb 22 07:46:09.171: INFO: (0) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:162/proxy/: bar (200; 147.919229ms)
Feb 22 07:46:09.176: INFO: (0) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:160/proxy/: foo (200; 146.865539ms)
Feb 22 07:46:09.183: INFO: (0) /api/v1/namespaces/proxy-3437/services/http:proxy-service-6wsnt:portname1/proxy/: foo (200; 164.663548ms)
Feb 22 07:46:09.183: INFO: (0) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:1080/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:1080/proxy/rewriteme">test<... (200; 158.04847ms)
Feb 22 07:46:09.187: INFO: (0) /api/v1/namespaces/proxy-3437/services/https:proxy-service-6wsnt:tlsportname1/proxy/: tls baz (200; 158.860327ms)
Feb 22 07:46:09.187: INFO: (0) /api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:1080/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:1080/proxy/rewriteme">... (200; 158.451169ms)
Feb 22 07:46:09.190: INFO: (0) /api/v1/namespaces/proxy-3437/services/proxy-service-6wsnt:portname1/proxy/: foo (200; 176.439912ms)
Feb 22 07:46:09.195: INFO: (0) /api/v1/namespaces/proxy-3437/services/proxy-service-6wsnt:portname2/proxy/: bar (200; 175.76926ms)
Feb 22 07:46:09.199: INFO: (0) /api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:462/proxy/: tls qux (200; 181.520235ms)
Feb 22 07:46:09.199: INFO: (0) /api/v1/namespaces/proxy-3437/services/http:proxy-service-6wsnt:portname2/proxy/: bar (200; 169.859343ms)
Feb 22 07:46:09.200: INFO: (0) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd/proxy/rewriteme">test</a> (200; 180.215063ms)
Feb 22 07:46:09.201: INFO: (0) /api/v1/namespaces/proxy-3437/services/https:proxy-service-6wsnt:tlsportname2/proxy/: tls qux (200; 171.775734ms)
Feb 22 07:46:09.204: INFO: (0) /api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:443/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:443/proxy/tlsrewritem... (200; 179.398964ms)
Feb 22 07:46:09.246: INFO: (1) /api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:443/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:443/proxy/tlsrewritem... (200; 41.332556ms)
Feb 22 07:46:09.251: INFO: (1) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:162/proxy/: bar (200; 46.997148ms)
Feb 22 07:46:09.252: INFO: (1) /api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:460/proxy/: tls baz (200; 46.768802ms)
Feb 22 07:46:09.253: INFO: (1) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:1080/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:1080/proxy/rewriteme">test<... (200; 47.445705ms)
Feb 22 07:46:09.253: INFO: (1) /api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:162/proxy/: bar (200; 47.744307ms)
Feb 22 07:46:09.254: INFO: (1) /api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:462/proxy/: tls qux (200; 49.301336ms)
Feb 22 07:46:09.257: INFO: (1) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:160/proxy/: foo (200; 52.560177ms)
Feb 22 07:46:09.257: INFO: (1) /api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:1080/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:1080/proxy/rewriteme">... (200; 52.693754ms)
Feb 22 07:46:09.260: INFO: (1) /api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:160/proxy/: foo (200; 54.200201ms)
Feb 22 07:46:09.261: INFO: (1) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd/proxy/rewriteme">test</a> (200; 55.269285ms)
Feb 22 07:46:09.278: INFO: (1) /api/v1/namespaces/proxy-3437/services/https:proxy-service-6wsnt:tlsportname1/proxy/: tls baz (200; 73.834234ms)
Feb 22 07:46:09.280: INFO: (1) /api/v1/namespaces/proxy-3437/services/proxy-service-6wsnt:portname2/proxy/: bar (200; 74.423793ms)
Feb 22 07:46:09.350: INFO: (1) /api/v1/namespaces/proxy-3437/services/proxy-service-6wsnt:portname1/proxy/: foo (200; 144.142531ms)
Feb 22 07:46:09.352: INFO: (1) /api/v1/namespaces/proxy-3437/services/https:proxy-service-6wsnt:tlsportname2/proxy/: tls qux (200; 147.628339ms)
Feb 22 07:46:09.353: INFO: (1) /api/v1/namespaces/proxy-3437/services/http:proxy-service-6wsnt:portname2/proxy/: bar (200; 148.203599ms)
Feb 22 07:46:09.354: INFO: (1) /api/v1/namespaces/proxy-3437/services/http:proxy-service-6wsnt:portname1/proxy/: foo (200; 148.730307ms)
Feb 22 07:46:09.450: INFO: (2) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:162/proxy/: bar (200; 94.525053ms)
Feb 22 07:46:09.452: INFO: (2) /api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:462/proxy/: tls qux (200; 96.211922ms)
Feb 22 07:46:09.454: INFO: (2) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:1080/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:1080/proxy/rewriteme">test<... (200; 99.1278ms)
Feb 22 07:46:09.464: INFO: (2) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:160/proxy/: foo (200; 108.398539ms)
Feb 22 07:46:09.466: INFO: (2) /api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:460/proxy/: tls baz (200; 111.325936ms)
Feb 22 07:46:09.467: INFO: (2) /api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:1080/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:1080/proxy/rewriteme">... (200; 111.956931ms)
Feb 22 07:46:09.469: INFO: (2) /api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:443/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:443/proxy/tlsrewritem... (200; 113.026303ms)
Feb 22 07:46:09.472: INFO: (2) /api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:162/proxy/: bar (200; 116.826236ms)
Feb 22 07:46:09.490: INFO: (2) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd/proxy/rewriteme">test</a> (200; 135.857883ms)
Feb 22 07:46:09.493: INFO: (2) /api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:160/proxy/: foo (200; 138.30733ms)
Feb 22 07:46:09.540: INFO: (2) /api/v1/namespaces/proxy-3437/services/https:proxy-service-6wsnt:tlsportname1/proxy/: tls baz (200; 185.098732ms)
Feb 22 07:46:09.541: INFO: (2) /api/v1/namespaces/proxy-3437/services/proxy-service-6wsnt:portname1/proxy/: foo (200; 186.27034ms)
Feb 22 07:46:09.541: INFO: (2) /api/v1/namespaces/proxy-3437/services/http:proxy-service-6wsnt:portname1/proxy/: foo (200; 186.260817ms)
Feb 22 07:46:09.543: INFO: (2) /api/v1/namespaces/proxy-3437/services/https:proxy-service-6wsnt:tlsportname2/proxy/: tls qux (200; 187.204336ms)
Feb 22 07:46:09.544: INFO: (2) /api/v1/namespaces/proxy-3437/services/http:proxy-service-6wsnt:portname2/proxy/: bar (200; 189.140144ms)
Feb 22 07:46:09.544: INFO: (2) /api/v1/namespaces/proxy-3437/services/proxy-service-6wsnt:portname2/proxy/: bar (200; 189.234233ms)
Feb 22 07:46:09.570: INFO: (3) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd/proxy/rewriteme">test</a> (200; 25.75238ms)
Feb 22 07:46:09.575: INFO: (3) /api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:443/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:443/proxy/tlsrewritem... (200; 30.756737ms)
Feb 22 07:46:09.590: INFO: (3) /api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:1080/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:1080/proxy/rewriteme">... (200; 45.006604ms)
Feb 22 07:46:09.595: INFO: (3) /api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:162/proxy/: bar (200; 49.542779ms)
Feb 22 07:46:09.597: INFO: (3) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:160/proxy/: foo (200; 52.333488ms)
Feb 22 07:46:09.599: INFO: (3) /api/v1/namespaces/proxy-3437/services/proxy-service-6wsnt:portname2/proxy/: bar (200; 54.737312ms)
Feb 22 07:46:09.600: INFO: (3) /api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:462/proxy/: tls qux (200; 54.477849ms)
Feb 22 07:46:09.600: INFO: (3) /api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:160/proxy/: foo (200; 54.636737ms)
Feb 22 07:46:09.600: INFO: (3) /api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:460/proxy/: tls baz (200; 54.716015ms)
Feb 22 07:46:09.600: INFO: (3) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:162/proxy/: bar (200; 54.543958ms)
Feb 22 07:46:09.600: INFO: (3) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:1080/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:1080/proxy/rewriteme">test<... (200; 55.001374ms)
Feb 22 07:46:09.613: INFO: (3) /api/v1/namespaces/proxy-3437/services/https:proxy-service-6wsnt:tlsportname1/proxy/: tls baz (200; 68.459231ms)
Feb 22 07:46:09.614: INFO: (3) /api/v1/namespaces/proxy-3437/services/http:proxy-service-6wsnt:portname1/proxy/: foo (200; 69.473061ms)
Feb 22 07:46:09.616: INFO: (3) /api/v1/namespaces/proxy-3437/services/proxy-service-6wsnt:portname1/proxy/: foo (200; 71.446712ms)
Feb 22 07:46:09.616: INFO: (3) /api/v1/namespaces/proxy-3437/services/http:proxy-service-6wsnt:portname2/proxy/: bar (200; 71.372711ms)
Feb 22 07:46:09.618: INFO: (3) /api/v1/namespaces/proxy-3437/services/https:proxy-service-6wsnt:tlsportname2/proxy/: tls qux (200; 73.446582ms)
Feb 22 07:46:09.658: INFO: (4) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:1080/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:1080/proxy/rewriteme">test<... (200; 38.916681ms)
Feb 22 07:46:09.660: INFO: (4) /api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:162/proxy/: bar (200; 40.926968ms)
Feb 22 07:46:09.660: INFO: (4) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:162/proxy/: bar (200; 41.672598ms)
Feb 22 07:46:09.663: INFO: (4) /api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:460/proxy/: tls baz (200; 43.617634ms)
Feb 22 07:46:09.663: INFO: (4) /api/v1/namespaces/proxy-3437/services/https:proxy-service-6wsnt:tlsportname2/proxy/: tls qux (200; 43.502796ms)
Feb 22 07:46:09.663: INFO: (4) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:160/proxy/: foo (200; 43.826311ms)
Feb 22 07:46:09.663: INFO: (4) /api/v1/namespaces/proxy-3437/services/https:proxy-service-6wsnt:tlsportname1/proxy/: tls baz (200; 43.663811ms)
Feb 22 07:46:09.663: INFO: (4) /api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:1080/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:1080/proxy/rewriteme">... (200; 44.001175ms)
Feb 22 07:46:09.663: INFO: (4) /api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:160/proxy/: foo (200; 43.906374ms)
Feb 22 07:46:09.663: INFO: (4) /api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:443/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:443/proxy/tlsrewritem... (200; 43.538358ms)
Feb 22 07:46:09.663: INFO: (4) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd/proxy/rewriteme">test</a> (200; 44.084327ms)
Feb 22 07:46:09.665: INFO: (4) /api/v1/namespaces/proxy-3437/services/proxy-service-6wsnt:portname1/proxy/: foo (200; 46.722379ms)
Feb 22 07:46:09.665: INFO: (4) /api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:462/proxy/: tls qux (200; 46.057672ms)
Feb 22 07:46:09.665: INFO: (4) /api/v1/namespaces/proxy-3437/services/http:proxy-service-6wsnt:portname1/proxy/: foo (200; 46.56115ms)
Feb 22 07:46:09.680: INFO: (4) /api/v1/namespaces/proxy-3437/services/proxy-service-6wsnt:portname2/proxy/: bar (200; 61.586164ms)
Feb 22 07:46:09.682: INFO: (4) /api/v1/namespaces/proxy-3437/services/http:proxy-service-6wsnt:portname2/proxy/: bar (200; 62.738178ms)
Feb 22 07:46:09.723: INFO: (5) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd/proxy/rewriteme">test</a> (200; 40.752882ms)
Feb 22 07:46:09.727: INFO: (5) /api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:462/proxy/: tls qux (200; 42.12635ms)
Feb 22 07:46:09.728: INFO: (5) /api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:160/proxy/: foo (200; 44.379571ms)
Feb 22 07:46:09.734: INFO: (5) /api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:443/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:443/proxy/tlsrewritem... (200; 51.497903ms)
Feb 22 07:46:09.734: INFO: (5) /api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:162/proxy/: bar (200; 50.146064ms)
Feb 22 07:46:09.734: INFO: (5) /api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:1080/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:1080/proxy/rewriteme">... (200; 49.904268ms)
Feb 22 07:46:09.737: INFO: (5) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:160/proxy/: foo (200; 52.86023ms)
Feb 22 07:46:09.737: INFO: (5) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:1080/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:1080/proxy/rewriteme">test<... (200; 53.528036ms)
Feb 22 07:46:09.737: INFO: (5) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:162/proxy/: bar (200; 54.794345ms)
Feb 22 07:46:09.737: INFO: (5) /api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:460/proxy/: tls baz (200; 53.183129ms)
Feb 22 07:46:09.747: INFO: (5) /api/v1/namespaces/proxy-3437/services/http:proxy-service-6wsnt:portname1/proxy/: foo (200; 64.215104ms)
Feb 22 07:46:09.758: INFO: (5) /api/v1/namespaces/proxy-3437/services/https:proxy-service-6wsnt:tlsportname2/proxy/: tls qux (200; 73.375208ms)
Feb 22 07:46:09.758: INFO: (5) /api/v1/namespaces/proxy-3437/services/proxy-service-6wsnt:portname1/proxy/: foo (200; 73.801583ms)
Feb 22 07:46:09.758: INFO: (5) /api/v1/namespaces/proxy-3437/services/proxy-service-6wsnt:portname2/proxy/: bar (200; 75.391081ms)
Feb 22 07:46:09.759: INFO: (5) /api/v1/namespaces/proxy-3437/services/https:proxy-service-6wsnt:tlsportname1/proxy/: tls baz (200; 75.019827ms)
Feb 22 07:46:09.762: INFO: (5) /api/v1/namespaces/proxy-3437/services/http:proxy-service-6wsnt:portname2/proxy/: bar (200; 80.09192ms)
Feb 22 07:46:09.818: INFO: (6) /api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:1080/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:1080/proxy/rewriteme">... (200; 55.376862ms)
Feb 22 07:46:09.821: INFO: (6) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:1080/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:1080/proxy/rewriteme">test<... (200; 57.900973ms)
Feb 22 07:46:09.822: INFO: (6) /api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:460/proxy/: tls baz (200; 59.160887ms)
Feb 22 07:46:09.848: INFO: (6) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:160/proxy/: foo (200; 84.769712ms)
Feb 22 07:46:09.848: INFO: (6) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:162/proxy/: bar (200; 84.811263ms)
Feb 22 07:46:09.848: INFO: (6) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd/proxy/rewriteme">test</a> (200; 85.1012ms)
Feb 22 07:46:09.848: INFO: (6) /api/v1/namespaces/proxy-3437/services/http:proxy-service-6wsnt:portname2/proxy/: bar (200; 85.00589ms)
Feb 22 07:46:09.873: INFO: (6) /api/v1/namespaces/proxy-3437/services/https:proxy-service-6wsnt:tlsportname1/proxy/: tls baz (200; 110.684371ms)
Feb 22 07:46:09.875: INFO: (6) /api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:462/proxy/: tls qux (200; 112.955031ms)
Feb 22 07:46:09.876: INFO: (6) /api/v1/namespaces/proxy-3437/services/proxy-service-6wsnt:portname1/proxy/: foo (200; 113.484426ms)
Feb 22 07:46:09.878: INFO: (6) /api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:162/proxy/: bar (200; 114.661507ms)
Feb 22 07:46:09.879: INFO: (6) /api/v1/namespaces/proxy-3437/services/https:proxy-service-6wsnt:tlsportname2/proxy/: tls qux (200; 116.116103ms)
Feb 22 07:46:09.879: INFO: (6) /api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:443/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:443/proxy/tlsrewritem... (200; 116.249478ms)
Feb 22 07:46:09.882: INFO: (6) /api/v1/namespaces/proxy-3437/services/http:proxy-service-6wsnt:portname1/proxy/: foo (200; 118.467877ms)
Feb 22 07:46:09.884: INFO: (6) /api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:160/proxy/: foo (200; 121.569671ms)
Feb 22 07:46:09.913: INFO: (6) /api/v1/namespaces/proxy-3437/services/proxy-service-6wsnt:portname2/proxy/: bar (200; 150.376278ms)
Feb 22 07:46:10.004: INFO: (7) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd/proxy/rewriteme">test</a> (200; 90.578752ms)
Feb 22 07:46:10.007: INFO: (7) /api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:1080/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:1080/proxy/rewriteme">... (200; 93.433112ms)
Feb 22 07:46:10.008: INFO: (7) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:162/proxy/: bar (200; 94.38375ms)
Feb 22 07:46:10.008: INFO: (7) /api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:160/proxy/: foo (200; 94.779042ms)
Feb 22 07:46:10.009: INFO: (7) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:160/proxy/: foo (200; 95.282524ms)
Feb 22 07:46:10.011: INFO: (7) /api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:460/proxy/: tls baz (200; 97.177916ms)
Feb 22 07:46:10.013: INFO: (7) /api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:443/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:443/proxy/tlsrewritem... (200; 99.211381ms)
Feb 22 07:46:10.013: INFO: (7) /api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:462/proxy/: tls qux (200; 99.939764ms)
Feb 22 07:46:10.013: INFO: (7) /api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:162/proxy/: bar (200; 99.896845ms)
Feb 22 07:46:10.014: INFO: (7) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:1080/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:1080/proxy/rewriteme">test<... (200; 100.420376ms)
Feb 22 07:46:10.029: INFO: (7) /api/v1/namespaces/proxy-3437/services/https:proxy-service-6wsnt:tlsportname1/proxy/: tls baz (200; 114.951548ms)
Feb 22 07:46:10.046: INFO: (7) /api/v1/namespaces/proxy-3437/services/proxy-service-6wsnt:portname2/proxy/: bar (200; 132.805366ms)
Feb 22 07:46:10.048: INFO: (7) /api/v1/namespaces/proxy-3437/services/proxy-service-6wsnt:portname1/proxy/: foo (200; 134.81598ms)
Feb 22 07:46:10.055: INFO: (7) /api/v1/namespaces/proxy-3437/services/http:proxy-service-6wsnt:portname2/proxy/: bar (200; 141.383739ms)
Feb 22 07:46:10.062: INFO: (7) /api/v1/namespaces/proxy-3437/services/https:proxy-service-6wsnt:tlsportname2/proxy/: tls qux (200; 148.183654ms)
Feb 22 07:46:10.063: INFO: (7) /api/v1/namespaces/proxy-3437/services/http:proxy-service-6wsnt:portname1/proxy/: foo (200; 149.258572ms)
Feb 22 07:46:10.114: INFO: (8) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:160/proxy/: foo (200; 50.023215ms)
Feb 22 07:46:10.120: INFO: (8) /api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:160/proxy/: foo (200; 56.510343ms)
Feb 22 07:46:10.120: INFO: (8) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:1080/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:1080/proxy/rewriteme">test<... (200; 56.445926ms)
Feb 22 07:46:10.122: INFO: (8) /api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:162/proxy/: bar (200; 58.429399ms)
Feb 22 07:46:10.133: INFO: (8) /api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:460/proxy/: tls baz (200; 69.726239ms)
Feb 22 07:46:10.135: INFO: (8) /api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:443/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:443/proxy/tlsrewritem... (200; 71.766843ms)
Feb 22 07:46:10.149: INFO: (8) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd/proxy/rewriteme">test</a> (200; 85.435663ms)
Feb 22 07:46:10.150: INFO: (8) /api/v1/namespaces/proxy-3437/services/http:proxy-service-6wsnt:portname2/proxy/: bar (200; 85.427367ms)
Feb 22 07:46:10.151: INFO: (8) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:162/proxy/: bar (200; 86.02753ms)
Feb 22 07:46:10.153: INFO: (8) /api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:1080/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:1080/proxy/rewriteme">... (200; 88.748971ms)
Feb 22 07:46:10.153: INFO: (8) /api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:462/proxy/: tls qux (200; 88.732772ms)
Feb 22 07:46:10.159: INFO: (8) /api/v1/namespaces/proxy-3437/services/proxy-service-6wsnt:portname1/proxy/: foo (200; 95.122177ms)
Feb 22 07:46:10.168: INFO: (8) /api/v1/namespaces/proxy-3437/services/https:proxy-service-6wsnt:tlsportname2/proxy/: tls qux (200; 103.586239ms)
Feb 22 07:46:10.169: INFO: (8) /api/v1/namespaces/proxy-3437/services/http:proxy-service-6wsnt:portname1/proxy/: foo (200; 105.451047ms)
Feb 22 07:46:10.171: INFO: (8) /api/v1/namespaces/proxy-3437/services/https:proxy-service-6wsnt:tlsportname1/proxy/: tls baz (200; 107.325675ms)
Feb 22 07:46:10.174: INFO: (8) /api/v1/namespaces/proxy-3437/services/proxy-service-6wsnt:portname2/proxy/: bar (200; 109.873983ms)
Feb 22 07:46:10.211: INFO: (9) /api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:443/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:443/proxy/tlsrewritem... (200; 36.730674ms)
Feb 22 07:46:10.224: INFO: (9) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:160/proxy/: foo (200; 49.718583ms)
Feb 22 07:46:10.224: INFO: (9) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd/proxy/rewriteme">test</a> (200; 49.619412ms)
Feb 22 07:46:10.229: INFO: (9) /api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:1080/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:1080/proxy/rewriteme">... (200; 54.636684ms)
Feb 22 07:46:10.230: INFO: (9) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:1080/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:1080/proxy/rewriteme">test<... (200; 55.47379ms)
Feb 22 07:46:10.231: INFO: (9) /api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:462/proxy/: tls qux (200; 56.566284ms)
Feb 22 07:46:10.231: INFO: (9) /api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:460/proxy/: tls baz (200; 56.902131ms)
Feb 22 07:46:10.231: INFO: (9) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:162/proxy/: bar (200; 56.61454ms)
Feb 22 07:46:10.233: INFO: (9) /api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:162/proxy/: bar (200; 58.833042ms)
Feb 22 07:46:10.237: INFO: (9) /api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:160/proxy/: foo (200; 62.249364ms)
Feb 22 07:46:10.277: INFO: (9) /api/v1/namespaces/proxy-3437/services/proxy-service-6wsnt:portname1/proxy/: foo (200; 102.622135ms)
Feb 22 07:46:10.277: INFO: (9) /api/v1/namespaces/proxy-3437/services/http:proxy-service-6wsnt:portname1/proxy/: foo (200; 103.010277ms)
Feb 22 07:46:10.302: INFO: (9) /api/v1/namespaces/proxy-3437/services/https:proxy-service-6wsnt:tlsportname1/proxy/: tls baz (200; 127.855353ms)
Feb 22 07:46:10.302: INFO: (9) /api/v1/namespaces/proxy-3437/services/https:proxy-service-6wsnt:tlsportname2/proxy/: tls qux (200; 127.921032ms)
Feb 22 07:46:10.303: INFO: (9) /api/v1/namespaces/proxy-3437/services/http:proxy-service-6wsnt:portname2/proxy/: bar (200; 129.093907ms)
Feb 22 07:46:10.305: INFO: (9) /api/v1/namespaces/proxy-3437/services/proxy-service-6wsnt:portname2/proxy/: bar (200; 130.399708ms)
Feb 22 07:46:10.372: INFO: (10) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:160/proxy/: foo (200; 66.72985ms)
Feb 22 07:46:10.373: INFO: (10) /api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:1080/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:1080/proxy/rewriteme">... (200; 67.463716ms)
Feb 22 07:46:10.375: INFO: (10) /api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:443/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:443/proxy/tlsrewritem... (200; 69.671106ms)
Feb 22 07:46:10.375: INFO: (10) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd/proxy/rewriteme">test</a> (200; 69.510932ms)
Feb 22 07:46:10.376: INFO: (10) /api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:460/proxy/: tls baz (200; 70.501853ms)
Feb 22 07:46:10.388: INFO: (10) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:1080/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:1080/proxy/rewriteme">test<... (200; 83.560076ms)
Feb 22 07:46:10.390: INFO: (10) /api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:462/proxy/: tls qux (200; 84.258524ms)
Feb 22 07:46:10.393: INFO: (10) /api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:160/proxy/: foo (200; 88.055185ms)
Feb 22 07:46:10.412: INFO: (10) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:162/proxy/: bar (200; 106.132212ms)
Feb 22 07:46:10.426: INFO: (10) /api/v1/namespaces/proxy-3437/services/proxy-service-6wsnt:portname1/proxy/: foo (200; 119.987681ms)
Feb 22 07:46:10.427: INFO: (10) /api/v1/namespaces/proxy-3437/services/http:proxy-service-6wsnt:portname1/proxy/: foo (200; 121.437416ms)
Feb 22 07:46:10.429: INFO: (10) /api/v1/namespaces/proxy-3437/services/proxy-service-6wsnt:portname2/proxy/: bar (200; 123.014179ms)
Feb 22 07:46:10.433: INFO: (10) /api/v1/namespaces/proxy-3437/services/https:proxy-service-6wsnt:tlsportname1/proxy/: tls baz (200; 127.440958ms)
Feb 22 07:46:10.434: INFO: (10) /api/v1/namespaces/proxy-3437/services/http:proxy-service-6wsnt:portname2/proxy/: bar (200; 128.286867ms)
Feb 22 07:46:10.437: INFO: (10) /api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:162/proxy/: bar (200; 131.908362ms)
Feb 22 07:46:10.438: INFO: (10) /api/v1/namespaces/proxy-3437/services/https:proxy-service-6wsnt:tlsportname2/proxy/: tls qux (200; 131.891174ms)
Feb 22 07:46:10.497: INFO: (11) /api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:443/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:443/proxy/tlsrewritem... (200; 58.869245ms)
Feb 22 07:46:10.511: INFO: (11) /api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:1080/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:1080/proxy/rewriteme">... (200; 71.460751ms)
Feb 22 07:46:10.513: INFO: (11) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:1080/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:1080/proxy/rewriteme">test<... (200; 75.100802ms)
Feb 22 07:46:10.513: INFO: (11) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:160/proxy/: foo (200; 73.979161ms)
Feb 22 07:46:10.514: INFO: (11) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd/proxy/rewriteme">test</a> (200; 76.120446ms)
Feb 22 07:46:10.532: INFO: (11) /api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:460/proxy/: tls baz (200; 93.610859ms)
Feb 22 07:46:10.534: INFO: (11) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:162/proxy/: bar (200; 95.806995ms)
Feb 22 07:46:10.537: INFO: (11) /api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:160/proxy/: foo (200; 97.843386ms)
Feb 22 07:46:10.537: INFO: (11) /api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:162/proxy/: bar (200; 97.863639ms)
Feb 22 07:46:10.537: INFO: (11) /api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:462/proxy/: tls qux (200; 99.117102ms)
Feb 22 07:46:10.570: INFO: (11) /api/v1/namespaces/proxy-3437/services/https:proxy-service-6wsnt:tlsportname2/proxy/: tls qux (200; 130.432576ms)
Feb 22 07:46:10.575: INFO: (11) /api/v1/namespaces/proxy-3437/services/proxy-service-6wsnt:portname1/proxy/: foo (200; 136.954485ms)
Feb 22 07:46:10.589: INFO: (11) /api/v1/namespaces/proxy-3437/services/http:proxy-service-6wsnt:portname2/proxy/: bar (200; 149.375537ms)
Feb 22 07:46:10.592: INFO: (11) /api/v1/namespaces/proxy-3437/services/https:proxy-service-6wsnt:tlsportname1/proxy/: tls baz (200; 152.958716ms)
Feb 22 07:46:10.604: INFO: (11) /api/v1/namespaces/proxy-3437/services/http:proxy-service-6wsnt:portname1/proxy/: foo (200; 165.72238ms)
Feb 22 07:46:10.604: INFO: (11) /api/v1/namespaces/proxy-3437/services/proxy-service-6wsnt:portname2/proxy/: bar (200; 166.467317ms)
Feb 22 07:46:10.674: INFO: (12) /api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:462/proxy/: tls qux (200; 69.248586ms)
Feb 22 07:46:10.675: INFO: (12) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:162/proxy/: bar (200; 70.270463ms)
Feb 22 07:46:10.697: INFO: (12) /api/v1/namespaces/proxy-3437/services/http:proxy-service-6wsnt:portname1/proxy/: foo (200; 92.223114ms)
Feb 22 07:46:10.706: INFO: (12) /api/v1/namespaces/proxy-3437/services/https:proxy-service-6wsnt:tlsportname1/proxy/: tls baz (200; 101.27233ms)
Feb 22 07:46:10.708: INFO: (12) /api/v1/namespaces/proxy-3437/services/https:proxy-service-6wsnt:tlsportname2/proxy/: tls qux (200; 102.929988ms)
Feb 22 07:46:10.712: INFO: (12) /api/v1/namespaces/proxy-3437/services/proxy-service-6wsnt:portname1/proxy/: foo (200; 107.60569ms)
Feb 22 07:46:10.713: INFO: (12) /api/v1/namespaces/proxy-3437/services/proxy-service-6wsnt:portname2/proxy/: bar (200; 108.271012ms)
Feb 22 07:46:10.716: INFO: (12) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd/proxy/rewriteme">test</a> (200; 110.89306ms)
Feb 22 07:46:10.716: INFO: (12) /api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:460/proxy/: tls baz (200; 111.072712ms)
Feb 22 07:46:10.719: INFO: (12) /api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:160/proxy/: foo (200; 113.996342ms)
Feb 22 07:46:10.720: INFO: (12) /api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:162/proxy/: bar (200; 115.114678ms)
Feb 22 07:46:10.720: INFO: (12) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:1080/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:1080/proxy/rewriteme">test<... (200; 115.401924ms)
Feb 22 07:46:10.720: INFO: (12) /api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:443/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:443/proxy/tlsrewritem... (200; 115.430545ms)
Feb 22 07:46:10.724: INFO: (12) /api/v1/namespaces/proxy-3437/services/http:proxy-service-6wsnt:portname2/proxy/: bar (200; 118.86477ms)
Feb 22 07:46:10.725: INFO: (12) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:160/proxy/: foo (200; 120.502122ms)
Feb 22 07:46:10.726: INFO: (12) /api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:1080/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:1080/proxy/rewriteme">... (200; 121.345747ms)
Feb 22 07:46:10.771: INFO: (13) /api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:443/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:443/proxy/tlsrewritem... (200; 44.215003ms)
Feb 22 07:46:10.776: INFO: (13) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:162/proxy/: bar (200; 49.688904ms)
Feb 22 07:46:10.776: INFO: (13) /api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:462/proxy/: tls qux (200; 49.776269ms)
Feb 22 07:46:10.776: INFO: (13) /api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:162/proxy/: bar (200; 50.28385ms)
Feb 22 07:46:10.777: INFO: (13) /api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:460/proxy/: tls baz (200; 50.201346ms)
Feb 22 07:46:10.779: INFO: (13) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd/proxy/rewriteme">test</a> (200; 51.879867ms)
Feb 22 07:46:10.779: INFO: (13) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:1080/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:1080/proxy/rewriteme">test<... (200; 51.656291ms)
Feb 22 07:46:10.779: INFO: (13) /api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:160/proxy/: foo (200; 51.908858ms)
Feb 22 07:46:10.779: INFO: (13) /api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:1080/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:1080/proxy/rewriteme">... (200; 53.01727ms)
Feb 22 07:46:10.782: INFO: (13) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:160/proxy/: foo (200; 55.440882ms)
Feb 22 07:46:10.783: INFO: (13) /api/v1/namespaces/proxy-3437/services/http:proxy-service-6wsnt:portname2/proxy/: bar (200; 56.544105ms)
Feb 22 07:46:10.800: INFO: (13) /api/v1/namespaces/proxy-3437/services/https:proxy-service-6wsnt:tlsportname1/proxy/: tls baz (200; 73.065574ms)
Feb 22 07:46:10.801: INFO: (13) /api/v1/namespaces/proxy-3437/services/proxy-service-6wsnt:portname1/proxy/: foo (200; 74.511686ms)
Feb 22 07:46:10.801: INFO: (13) /api/v1/namespaces/proxy-3437/services/https:proxy-service-6wsnt:tlsportname2/proxy/: tls qux (200; 74.914649ms)
Feb 22 07:46:10.802: INFO: (13) /api/v1/namespaces/proxy-3437/services/http:proxy-service-6wsnt:portname1/proxy/: foo (200; 75.577093ms)
Feb 22 07:46:10.802: INFO: (13) /api/v1/namespaces/proxy-3437/services/proxy-service-6wsnt:portname2/proxy/: bar (200; 75.842945ms)
Feb 22 07:46:10.828: INFO: (14) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:162/proxy/: bar (200; 24.685578ms)
Feb 22 07:46:10.840: INFO: (14) /api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:460/proxy/: tls baz (200; 35.923629ms)
Feb 22 07:46:10.846: INFO: (14) /api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:1080/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:1080/proxy/rewriteme">... (200; 42.394681ms)
Feb 22 07:46:10.852: INFO: (14) /api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:162/proxy/: bar (200; 48.914677ms)
Feb 22 07:46:10.860: INFO: (14) /api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:443/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:443/proxy/tlsrewritem... (200; 56.398321ms)
Feb 22 07:46:10.860: INFO: (14) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:1080/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:1080/proxy/rewriteme">test<... (200; 56.796123ms)
Feb 22 07:46:10.861: INFO: (14) /api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:462/proxy/: tls qux (200; 58.103373ms)
Feb 22 07:46:10.861: INFO: (14) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:160/proxy/: foo (200; 58.494207ms)
Feb 22 07:46:10.861: INFO: (14) /api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:160/proxy/: foo (200; 57.576702ms)
Feb 22 07:46:10.861: INFO: (14) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd/proxy/rewriteme">test</a> (200; 57.743224ms)
Feb 22 07:46:10.900: INFO: (14) /api/v1/namespaces/proxy-3437/services/proxy-service-6wsnt:portname2/proxy/: bar (200; 96.137017ms)
Feb 22 07:46:10.905: INFO: (14) /api/v1/namespaces/proxy-3437/services/https:proxy-service-6wsnt:tlsportname1/proxy/: tls baz (200; 101.422943ms)
Feb 22 07:46:10.906: INFO: (14) /api/v1/namespaces/proxy-3437/services/https:proxy-service-6wsnt:tlsportname2/proxy/: tls qux (200; 102.866292ms)
Feb 22 07:46:10.906: INFO: (14) /api/v1/namespaces/proxy-3437/services/proxy-service-6wsnt:portname1/proxy/: foo (200; 102.282975ms)
Feb 22 07:46:10.914: INFO: (14) /api/v1/namespaces/proxy-3437/services/http:proxy-service-6wsnt:portname2/proxy/: bar (200; 110.971411ms)
Feb 22 07:46:10.916: INFO: (14) /api/v1/namespaces/proxy-3437/services/http:proxy-service-6wsnt:portname1/proxy/: foo (200; 111.827507ms)
Feb 22 07:46:10.991: INFO: (15) /api/v1/namespaces/proxy-3437/services/https:proxy-service-6wsnt:tlsportname2/proxy/: tls qux (200; 74.315718ms)
Feb 22 07:46:11.002: INFO: (15) /api/v1/namespaces/proxy-3437/services/proxy-service-6wsnt:portname2/proxy/: bar (200; 84.058337ms)
Feb 22 07:46:11.002: INFO: (15) /api/v1/namespaces/proxy-3437/services/http:proxy-service-6wsnt:portname1/proxy/: foo (200; 84.151998ms)
Feb 22 07:46:11.002: INFO: (15) /api/v1/namespaces/proxy-3437/services/https:proxy-service-6wsnt:tlsportname1/proxy/: tls baz (200; 86.233258ms)
Feb 22 07:46:11.004: INFO: (15) /api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:462/proxy/: tls qux (200; 86.997409ms)
Feb 22 07:46:11.005: INFO: (15) /api/v1/namespaces/proxy-3437/services/proxy-service-6wsnt:portname1/proxy/: foo (200; 87.872228ms)
Feb 22 07:46:11.005: INFO: (15) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd/proxy/rewriteme">test</a> (200; 87.491703ms)
Feb 22 07:46:11.005: INFO: (15) /api/v1/namespaces/proxy-3437/services/http:proxy-service-6wsnt:portname2/proxy/: bar (200; 89.022935ms)
Feb 22 07:46:11.006: INFO: (15) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:1080/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:1080/proxy/rewriteme">test<... (200; 90.272876ms)
Feb 22 07:46:11.010: INFO: (15) /api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:162/proxy/: bar (200; 92.781644ms)
Feb 22 07:46:11.010: INFO: (15) /api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:443/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:443/proxy/tlsrewritem... (200; 93.42994ms)
Feb 22 07:46:11.011: INFO: (15) /api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:460/proxy/: tls baz (200; 93.959022ms)
Feb 22 07:46:11.013: INFO: (15) /api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:160/proxy/: foo (200; 95.952373ms)
Feb 22 07:46:11.013: INFO: (15) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:160/proxy/: foo (200; 96.539836ms)
Feb 22 07:46:11.014: INFO: (15) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:162/proxy/: bar (200; 97.083242ms)
Feb 22 07:46:11.014: INFO: (15) /api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:1080/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:1080/proxy/rewriteme">... (200; 98.452853ms)
Feb 22 07:46:11.063: INFO: (16) /api/v1/namespaces/proxy-3437/services/https:proxy-service-6wsnt:tlsportname2/proxy/: tls qux (200; 47.462978ms)
Feb 22 07:46:11.067: INFO: (16) /api/v1/namespaces/proxy-3437/services/https:proxy-service-6wsnt:tlsportname1/proxy/: tls baz (200; 51.397071ms)
Feb 22 07:46:11.070: INFO: (16) /api/v1/namespaces/proxy-3437/services/proxy-service-6wsnt:portname1/proxy/: foo (200; 55.119354ms)
Feb 22 07:46:11.071: INFO: (16) /api/v1/namespaces/proxy-3437/services/proxy-service-6wsnt:portname2/proxy/: bar (200; 55.121158ms)
Feb 22 07:46:11.073: INFO: (16) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:162/proxy/: bar (200; 57.005427ms)
Feb 22 07:46:11.076: INFO: (16) /api/v1/namespaces/proxy-3437/services/http:proxy-service-6wsnt:portname2/proxy/: bar (200; 59.89887ms)
Feb 22 07:46:11.077: INFO: (16) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:160/proxy/: foo (200; 60.881173ms)
Feb 22 07:46:11.077: INFO: (16) /api/v1/namespaces/proxy-3437/services/http:proxy-service-6wsnt:portname1/proxy/: foo (200; 61.45106ms)
Feb 22 07:46:11.078: INFO: (16) /api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:462/proxy/: tls qux (200; 61.436158ms)
Feb 22 07:46:11.079: INFO: (16) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:1080/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:1080/proxy/rewriteme">test<... (200; 63.422964ms)
Feb 22 07:46:11.081: INFO: (16) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd/proxy/rewriteme">test</a> (200; 65.51297ms)
Feb 22 07:46:11.082: INFO: (16) /api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:1080/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:1080/proxy/rewriteme">... (200; 66.199875ms)
Feb 22 07:46:11.084: INFO: (16) /api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:460/proxy/: tls baz (200; 68.624435ms)
Feb 22 07:46:11.084: INFO: (16) /api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:160/proxy/: foo (200; 69.374305ms)
Feb 22 07:46:11.085: INFO: (16) /api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:162/proxy/: bar (200; 69.88549ms)
Feb 22 07:46:11.099: INFO: (16) /api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:443/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:443/proxy/tlsrewritem... (200; 84.794039ms)
Feb 22 07:46:11.133: INFO: (17) /api/v1/namespaces/proxy-3437/services/http:proxy-service-6wsnt:portname1/proxy/: foo (200; 33.251374ms)
Feb 22 07:46:11.136: INFO: (17) /api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:462/proxy/: tls qux (200; 36.241327ms)
Feb 22 07:46:11.136: INFO: (17) /api/v1/namespaces/proxy-3437/services/http:proxy-service-6wsnt:portname2/proxy/: bar (200; 35.360732ms)
Feb 22 07:46:11.137: INFO: (17) /api/v1/namespaces/proxy-3437/services/https:proxy-service-6wsnt:tlsportname2/proxy/: tls qux (200; 35.768891ms)
Feb 22 07:46:11.138: INFO: (17) /api/v1/namespaces/proxy-3437/services/proxy-service-6wsnt:portname2/proxy/: bar (200; 37.41697ms)
Feb 22 07:46:11.139: INFO: (17) /api/v1/namespaces/proxy-3437/services/proxy-service-6wsnt:portname1/proxy/: foo (200; 38.985335ms)
Feb 22 07:46:11.149: INFO: (17) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:162/proxy/: bar (200; 49.633166ms)
Feb 22 07:46:11.160: INFO: (17) /api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:162/proxy/: bar (200; 60.211813ms)
Feb 22 07:46:11.163: INFO: (17) /api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:160/proxy/: foo (200; 62.471444ms)
Feb 22 07:46:11.164: INFO: (17) /api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:1080/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:1080/proxy/rewriteme">... (200; 62.951505ms)
Feb 22 07:46:11.164: INFO: (17) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd/proxy/rewriteme">test</a> (200; 63.895994ms)
Feb 22 07:46:11.166: INFO: (17) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:1080/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:1080/proxy/rewriteme">test<... (200; 65.28152ms)
Feb 22 07:46:11.168: INFO: (17) /api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:443/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:443/proxy/tlsrewritem... (200; 67.948069ms)
Feb 22 07:46:11.169: INFO: (17) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:160/proxy/: foo (200; 68.798123ms)
Feb 22 07:46:11.180: INFO: (17) /api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:460/proxy/: tls baz (200; 79.719955ms)
Feb 22 07:46:11.193: INFO: (17) /api/v1/namespaces/proxy-3437/services/https:proxy-service-6wsnt:tlsportname1/proxy/: tls baz (200; 92.037389ms)
Feb 22 07:46:11.243: INFO: (18) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:1080/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:1080/proxy/rewriteme">test<... (200; 49.931468ms)
Feb 22 07:46:11.245: INFO: (18) /api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:1080/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:1080/proxy/rewriteme">... (200; 51.488ms)
Feb 22 07:46:11.245: INFO: (18) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:162/proxy/: bar (200; 51.549237ms)
Feb 22 07:46:11.245: INFO: (18) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:160/proxy/: foo (200; 51.990527ms)
Feb 22 07:46:11.246: INFO: (18) /api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:462/proxy/: tls qux (200; 52.739166ms)
Feb 22 07:46:11.246: INFO: (18) /api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:162/proxy/: bar (200; 53.313213ms)
Feb 22 07:46:11.247: INFO: (18) /api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:460/proxy/: tls baz (200; 53.933518ms)
Feb 22 07:46:11.253: INFO: (18) /api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:160/proxy/: foo (200; 59.894891ms)
Feb 22 07:46:11.255: INFO: (18) /api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:443/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:443/proxy/tlsrewritem... (200; 62.150484ms)
Feb 22 07:46:11.263: INFO: (18) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd/proxy/rewriteme">test</a> (200; 69.893996ms)
Feb 22 07:46:11.286: INFO: (18) /api/v1/namespaces/proxy-3437/services/http:proxy-service-6wsnt:portname1/proxy/: foo (200; 92.825647ms)
Feb 22 07:46:11.288: INFO: (18) /api/v1/namespaces/proxy-3437/services/https:proxy-service-6wsnt:tlsportname2/proxy/: tls qux (200; 94.750249ms)
Feb 22 07:46:11.290: INFO: (18) /api/v1/namespaces/proxy-3437/services/proxy-service-6wsnt:portname2/proxy/: bar (200; 96.913661ms)
Feb 22 07:46:11.290: INFO: (18) /api/v1/namespaces/proxy-3437/services/proxy-service-6wsnt:portname1/proxy/: foo (200; 97.060861ms)
Feb 22 07:46:11.293: INFO: (18) /api/v1/namespaces/proxy-3437/services/http:proxy-service-6wsnt:portname2/proxy/: bar (200; 99.534576ms)
Feb 22 07:46:11.294: INFO: (18) /api/v1/namespaces/proxy-3437/services/https:proxy-service-6wsnt:tlsportname1/proxy/: tls baz (200; 100.619419ms)
Feb 22 07:46:11.357: INFO: (19) /api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:162/proxy/: bar (200; 62.048075ms)
Feb 22 07:46:11.357: INFO: (19) /api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:460/proxy/: tls baz (200; 62.362296ms)
Feb 22 07:46:11.363: INFO: (19) /api/v1/namespaces/proxy-3437/services/https:proxy-service-6wsnt:tlsportname1/proxy/: tls baz (200; 68.436896ms)
Feb 22 07:46:11.363: INFO: (19) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:160/proxy/: foo (200; 68.599412ms)
Feb 22 07:46:11.363: INFO: (19) /api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:443/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:443/proxy/tlsrewritem... (200; 69.100823ms)
Feb 22 07:46:11.364: INFO: (19) /api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:1080/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:1080/proxy/rewriteme">... (200; 69.214485ms)
Feb 22 07:46:11.364: INFO: (19) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd/proxy/rewriteme">test</a> (200; 69.156559ms)
Feb 22 07:46:11.364: INFO: (19) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:162/proxy/: bar (200; 69.461218ms)
Feb 22 07:46:11.364: INFO: (19) /api/v1/namespaces/proxy-3437/services/http:proxy-service-6wsnt:portname2/proxy/: bar (200; 68.645045ms)
Feb 22 07:46:11.364: INFO: (19) /api/v1/namespaces/proxy-3437/pods/http:proxy-service-6wsnt-lc5wd:160/proxy/: foo (200; 69.322041ms)
Feb 22 07:46:11.364: INFO: (19) /api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:1080/proxy/: <a href="/api/v1/namespaces/proxy-3437/pods/proxy-service-6wsnt-lc5wd:1080/proxy/rewriteme">test<... (200; 69.329961ms)
Feb 22 07:46:11.364: INFO: (19) /api/v1/namespaces/proxy-3437/pods/https:proxy-service-6wsnt-lc5wd:462/proxy/: tls qux (200; 69.216274ms)
Feb 22 07:46:11.372: INFO: (19) /api/v1/namespaces/proxy-3437/services/https:proxy-service-6wsnt:tlsportname2/proxy/: tls qux (200; 77.80022ms)
Feb 22 07:46:11.373: INFO: (19) /api/v1/namespaces/proxy-3437/services/proxy-service-6wsnt:portname1/proxy/: foo (200; 78.34595ms)
Feb 22 07:46:11.376: INFO: (19) /api/v1/namespaces/proxy-3437/services/proxy-service-6wsnt:portname2/proxy/: bar (200; 81.36969ms)
Feb 22 07:46:11.380: INFO: (19) /api/v1/namespaces/proxy-3437/services/http:proxy-service-6wsnt:portname1/proxy/: foo (200; 85.14682ms)
STEP: deleting ReplicationController proxy-service-6wsnt in namespace proxy-3437, will wait for the garbage collector to delete the pods
Feb 22 07:46:11.510: INFO: Deleting ReplicationController proxy-service-6wsnt took: 41.881072ms
Feb 22 07:46:13.411: INFO: Terminating ReplicationController proxy-service-6wsnt pods took: 1.901018774s
[AfterEach] version v1
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 07:46:32.618: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-3437" for this suite.

â€¢ [SLOW TEST:83.839 seconds]
[sig-network] Proxy
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:59
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Proxy version v1 should proxy through a service and a pod  [Conformance]","total":270,"completed":262,"skipped":4560,"failed":0}
SSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 07:46:32.761: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-917
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: set up a multi version CRD
Feb 22 07:46:33.263: INFO: >>> kubeConfig: /root/.kube/config
STEP: rename a version
STEP: check the new version name is served
STEP: check the old version name is removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 07:47:33.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-917" for this suite.

â€¢ [SLOW TEST:60.342 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]","total":270,"completed":263,"skipped":4563,"failed":0}
SSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 07:47:33.104: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-8925
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Feb 22 07:47:33.536: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Feb 22 07:47:33.577: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:33.578: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:33.579: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:33.603: INFO: Number of nodes with available pods: 0
Feb 22 07:47:33.603: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 07:47:34.643: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:34.643: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:34.644: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:34.658: INFO: Number of nodes with available pods: 0
Feb 22 07:47:34.658: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 07:47:35.617: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:35.618: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:35.618: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:35.662: INFO: Number of nodes with available pods: 0
Feb 22 07:47:35.662: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 07:47:36.614: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:36.614: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:36.615: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:36.625: INFO: Number of nodes with available pods: 0
Feb 22 07:47:36.625: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 07:47:37.614: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:37.614: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:37.614: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:37.624: INFO: Number of nodes with available pods: 0
Feb 22 07:47:37.624: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 07:47:38.613: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:38.613: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:38.613: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:38.624: INFO: Number of nodes with available pods: 0
Feb 22 07:47:38.624: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 07:47:39.621: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:39.622: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:39.624: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:39.665: INFO: Number of nodes with available pods: 0
Feb 22 07:47:39.665: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 07:47:40.620: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:40.620: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:40.620: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:40.639: INFO: Number of nodes with available pods: 0
Feb 22 07:47:40.639: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 07:47:41.647: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:41.647: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:41.647: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:41.693: INFO: Number of nodes with available pods: 0
Feb 22 07:47:41.693: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 07:47:42.630: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:42.630: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:42.630: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:42.648: INFO: Number of nodes with available pods: 0
Feb 22 07:47:42.648: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 07:47:43.632: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:43.632: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:43.632: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:43.652: INFO: Number of nodes with available pods: 0
Feb 22 07:47:43.652: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 07:47:44.613: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:44.613: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:44.613: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:44.627: INFO: Number of nodes with available pods: 0
Feb 22 07:47:44.627: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 07:47:45.624: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:45.625: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:45.625: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:45.648: INFO: Number of nodes with available pods: 0
Feb 22 07:47:45.648: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 07:47:46.634: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:46.634: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:46.634: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:46.658: INFO: Number of nodes with available pods: 0
Feb 22 07:47:46.658: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 07:47:47.626: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:47.626: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:47.626: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:47.637: INFO: Number of nodes with available pods: 0
Feb 22 07:47:47.637: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 07:47:48.621: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:48.621: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:48.621: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:48.652: INFO: Number of nodes with available pods: 0
Feb 22 07:47:48.653: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 07:47:49.663: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:49.664: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:49.664: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:49.676: INFO: Number of nodes with available pods: 0
Feb 22 07:47:49.676: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 07:47:50.624: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:50.626: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:50.626: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:50.675: INFO: Number of nodes with available pods: 0
Feb 22 07:47:50.675: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 07:47:53.303: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:53.317: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:53.321: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:54.146: INFO: Number of nodes with available pods: 0
Feb 22 07:47:54.146: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 07:47:54.751: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:54.752: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:54.752: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:54.829: INFO: Number of nodes with available pods: 0
Feb 22 07:47:54.829: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 07:47:55.650: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:55.650: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:55.651: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:55.687: INFO: Number of nodes with available pods: 0
Feb 22 07:47:55.687: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 07:47:56.620: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:56.621: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:56.623: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:56.642: INFO: Number of nodes with available pods: 0
Feb 22 07:47:56.643: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 07:47:57.637: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:57.640: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:57.641: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:57.654: INFO: Number of nodes with available pods: 0
Feb 22 07:47:57.654: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 07:47:58.623: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:58.624: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:58.624: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:58.634: INFO: Number of nodes with available pods: 0
Feb 22 07:47:58.634: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 07:47:59.628: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:59.628: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:59.629: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:47:59.647: INFO: Number of nodes with available pods: 0
Feb 22 07:47:59.648: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 07:48:00.633: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:00.633: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:00.633: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:00.667: INFO: Number of nodes with available pods: 0
Feb 22 07:48:00.667: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 07:48:01.630: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:01.631: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:01.631: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:01.650: INFO: Number of nodes with available pods: 0
Feb 22 07:48:01.650: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 07:48:02.625: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:02.625: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:02.625: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:02.657: INFO: Number of nodes with available pods: 0
Feb 22 07:48:02.657: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 07:48:03.624: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:03.624: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:03.625: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:03.645: INFO: Number of nodes with available pods: 0
Feb 22 07:48:03.645: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 07:48:04.642: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:04.649: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:04.649: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:04.677: INFO: Number of nodes with available pods: 0
Feb 22 07:48:04.677: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 07:48:05.626: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:05.626: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:05.626: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:05.639: INFO: Number of nodes with available pods: 0
Feb 22 07:48:05.639: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 07:48:06.633: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:06.633: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:06.633: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:06.666: INFO: Number of nodes with available pods: 0
Feb 22 07:48:06.666: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 07:48:07.623: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:07.623: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:07.623: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:07.636: INFO: Number of nodes with available pods: 1
Feb 22 07:48:07.636: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 07:48:08.616: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:08.616: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:08.616: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:08.626: INFO: Number of nodes with available pods: 1
Feb 22 07:48:08.626: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 07:48:09.617: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:09.618: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:09.618: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:09.656: INFO: Number of nodes with available pods: 1
Feb 22 07:48:09.656: INFO: Node sc2-rdops-vm05-dhcp-163-39.eng.vmware.com is running more than one daemon pod
Feb 22 07:48:10.629: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:10.629: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:10.630: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:10.658: INFO: Number of nodes with available pods: 2
Feb 22 07:48:10.658: INFO: Node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com is running more than one daemon pod
Feb 22 07:48:11.618: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:11.618: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:11.618: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:11.639: INFO: Number of nodes with available pods: 2
Feb 22 07:48:11.639: INFO: Node sc2-rdops-vm05-dhcp-179-105.eng.vmware.com is running more than one daemon pod
Feb 22 07:48:12.671: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:12.671: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:12.671: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:12.691: INFO: Number of nodes with available pods: 3
Feb 22 07:48:12.691: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Feb 22 07:48:12.814: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:12.814: INFO: Wrong image for pod: daemon-set-mhtq6. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:12.814: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:12.843: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:12.844: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:12.844: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:13.865: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:13.865: INFO: Wrong image for pod: daemon-set-mhtq6. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:13.865: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:13.890: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:13.890: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:13.890: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:14.870: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:14.870: INFO: Wrong image for pod: daemon-set-mhtq6. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:14.870: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:14.892: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:14.893: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:14.893: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:15.865: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:15.866: INFO: Wrong image for pod: daemon-set-mhtq6. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:15.866: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:15.900: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:15.901: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:15.901: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:16.858: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:16.858: INFO: Wrong image for pod: daemon-set-mhtq6. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:16.858: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:16.878: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:16.879: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:16.879: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:17.891: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:17.891: INFO: Wrong image for pod: daemon-set-mhtq6. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:17.891: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:17.910: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:17.910: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:17.911: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:18.894: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:18.894: INFO: Wrong image for pod: daemon-set-mhtq6. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:18.894: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:18.913: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:18.914: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:18.914: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:19.861: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:19.861: INFO: Wrong image for pod: daemon-set-mhtq6. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:19.861: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:19.877: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:19.879: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:19.879: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:20.855: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:20.856: INFO: Wrong image for pod: daemon-set-mhtq6. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:20.856: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:20.870: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:20.870: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:20.870: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:21.856: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:21.856: INFO: Wrong image for pod: daemon-set-mhtq6. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:21.856: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:21.869: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:21.870: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:21.870: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:22.861: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:22.861: INFO: Wrong image for pod: daemon-set-mhtq6. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:22.861: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:22.874: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:22.875: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:22.875: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:23.857: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:23.857: INFO: Wrong image for pod: daemon-set-mhtq6. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:23.857: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:23.874: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:23.874: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:23.874: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:24.863: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:24.863: INFO: Wrong image for pod: daemon-set-mhtq6. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:24.863: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:24.877: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:24.877: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:24.877: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:25.864: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:25.864: INFO: Wrong image for pod: daemon-set-mhtq6. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:25.864: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:25.888: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:25.889: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:25.889: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:27.044: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:27.044: INFO: Wrong image for pod: daemon-set-mhtq6. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:27.044: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:27.199: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:27.200: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:27.200: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:27.861: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:27.861: INFO: Wrong image for pod: daemon-set-mhtq6. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:27.861: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:27.877: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:27.877: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:27.877: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:28.877: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:28.877: INFO: Wrong image for pod: daemon-set-mhtq6. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:28.877: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:28.901: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:28.902: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:28.902: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:29.859: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:29.859: INFO: Wrong image for pod: daemon-set-mhtq6. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:29.859: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:29.887: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:29.887: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:29.888: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:30.861: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:30.861: INFO: Wrong image for pod: daemon-set-mhtq6. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:30.861: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:30.888: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:30.890: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:30.890: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:31.877: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:31.877: INFO: Wrong image for pod: daemon-set-mhtq6. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:31.878: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:31.908: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:31.912: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:31.914: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:32.888: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:32.888: INFO: Pod daemon-set-s5q4p is not available
Feb 22 07:48:32.888: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:32.914: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:32.914: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:32.914: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:33.861: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:33.862: INFO: Pod daemon-set-s5q4p is not available
Feb 22 07:48:33.862: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:33.903: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:33.903: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:33.904: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:34.856: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:34.856: INFO: Pod daemon-set-s5q4p is not available
Feb 22 07:48:34.856: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:34.874: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:34.878: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:34.880: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:36.797: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:36.798: INFO: Pod daemon-set-s5q4p is not available
Feb 22 07:48:36.798: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:37.489: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:37.490: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:37.490: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:37.939: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:37.939: INFO: Pod daemon-set-s5q4p is not available
Feb 22 07:48:37.939: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:38.126: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:38.127: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:38.128: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:38.876: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:38.876: INFO: Pod daemon-set-s5q4p is not available
Feb 22 07:48:38.876: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:38.934: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:38.935: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:38.937: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:39.957: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:39.958: INFO: Pod daemon-set-s5q4p is not available
Feb 22 07:48:39.958: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:40.185: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:40.185: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:40.185: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:40.861: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:40.861: INFO: Pod daemon-set-s5q4p is not available
Feb 22 07:48:40.861: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:40.878: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:40.878: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:40.878: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:41.863: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:41.863: INFO: Pod daemon-set-s5q4p is not available
Feb 22 07:48:41.863: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:41.886: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:41.887: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:41.888: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:42.889: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:42.890: INFO: Pod daemon-set-s5q4p is not available
Feb 22 07:48:42.890: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:42.968: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:42.970: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:42.973: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:43.910: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:43.910: INFO: Pod daemon-set-s5q4p is not available
Feb 22 07:48:43.911: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:43.994: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:43.995: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:43.995: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:44.888: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:44.888: INFO: Pod daemon-set-s5q4p is not available
Feb 22 07:48:44.889: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:44.956: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:44.956: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:44.956: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:45.864: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:45.865: INFO: Pod daemon-set-s5q4p is not available
Feb 22 07:48:45.865: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:45.895: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:45.895: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:45.896: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:46.865: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:46.866: INFO: Pod daemon-set-s5q4p is not available
Feb 22 07:48:46.866: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:46.890: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:46.891: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:46.891: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:47.898: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:47.898: INFO: Pod daemon-set-s5q4p is not available
Feb 22 07:48:47.898: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:47.970: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:47.971: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:47.971: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:48.872: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:48.872: INFO: Pod daemon-set-s5q4p is not available
Feb 22 07:48:48.873: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:48.933: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:48.933: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:48.934: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:49.861: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:49.861: INFO: Pod daemon-set-s5q4p is not available
Feb 22 07:48:49.861: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:49.882: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:49.884: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:49.885: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:50.862: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:50.863: INFO: Pod daemon-set-s5q4p is not available
Feb 22 07:48:50.864: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:50.887: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:50.887: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:50.887: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:51.877: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:51.877: INFO: Pod daemon-set-s5q4p is not available
Feb 22 07:48:51.877: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:51.892: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:51.893: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:51.894: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:53.261: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:53.267: INFO: Pod daemon-set-s5q4p is not available
Feb 22 07:48:53.270: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:53.726: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:53.727: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:53.728: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:53.956: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:53.956: INFO: Pod daemon-set-s5q4p is not available
Feb 22 07:48:53.957: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:54.193: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:54.194: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:54.195: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:54.884: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:54.884: INFO: Pod daemon-set-s5q4p is not available
Feb 22 07:48:54.884: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:54.909: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:54.910: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:54.910: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:55.880: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:55.881: INFO: Pod daemon-set-s5q4p is not available
Feb 22 07:48:55.881: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:55.915: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:55.915: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:55.916: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:56.863: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:56.865: INFO: Pod daemon-set-s5q4p is not available
Feb 22 07:48:56.865: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:56.906: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:56.907: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:56.907: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:57.875: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:57.875: INFO: Pod daemon-set-s5q4p is not available
Feb 22 07:48:57.875: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:57.906: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:57.906: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:57.906: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:58.861: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:58.861: INFO: Pod daemon-set-s5q4p is not available
Feb 22 07:48:58.861: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:58.887: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:58.887: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:58.887: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:59.868: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:59.868: INFO: Pod daemon-set-s5q4p is not available
Feb 22 07:48:59.868: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:48:59.924: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:59.924: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:48:59.924: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:00.861: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:00.862: INFO: Pod daemon-set-s5q4p is not available
Feb 22 07:49:00.862: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:00.879: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:00.880: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:00.881: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:01.875: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:01.875: INFO: Pod daemon-set-s5q4p is not available
Feb 22 07:49:01.875: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:01.967: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:01.968: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:01.968: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:02.859: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:02.859: INFO: Pod daemon-set-s5q4p is not available
Feb 22 07:49:02.859: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:02.872: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:02.873: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:02.873: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:03.859: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:03.859: INFO: Pod daemon-set-s5q4p is not available
Feb 22 07:49:03.859: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:03.875: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:03.875: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:03.876: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:04.883: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:04.884: INFO: Pod daemon-set-s5q4p is not available
Feb 22 07:49:04.884: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:04.910: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:04.910: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:04.911: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:05.856: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:05.856: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:05.881: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:05.887: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:05.888: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:06.878: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:06.879: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:06.927: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:06.928: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:06.928: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:07.861: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:07.861: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:07.887: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:07.888: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:07.888: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:08.868: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:08.869: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:08.883: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:08.884: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:08.884: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:09.876: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:09.876: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:09.896: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:09.896: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:09.896: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:10.856: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:10.857: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:10.878: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:10.878: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:10.878: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:11.857: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:11.857: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:11.874: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:11.875: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:11.875: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:12.856: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:12.857: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:12.869: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:12.872: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:12.872: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:13.858: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:13.858: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:13.869: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:13.869: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:13.870: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:14.856: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:14.857: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:14.877: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:14.878: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:14.878: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:15.866: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:15.867: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:15.912: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:15.913: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:15.913: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:16.861: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:16.861: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:16.881: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:16.882: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:16.882: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:17.864: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:17.865: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:17.898: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:17.899: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:17.899: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:18.864: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:18.864: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:18.889: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:18.890: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:18.890: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:19.861: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:19.862: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:19.876: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:19.876: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:19.876: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:20.856: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:20.856: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:20.868: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:20.869: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:20.869: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:21.864: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:21.864: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:21.882: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:21.883: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:21.883: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:22.873: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:22.874: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:22.906: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:22.906: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:22.906: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:23.868: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:23.869: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:23.887: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:23.887: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:23.887: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:24.860: INFO: Wrong image for pod: daemon-set-ksflw. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:24.860: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:24.889: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:24.889: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:24.889: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:25.864: INFO: Pod daemon-set-r5p9q is not available
Feb 22 07:49:25.864: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:25.892: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:25.892: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:25.892: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:26.855: INFO: Pod daemon-set-r5p9q is not available
Feb 22 07:49:26.856: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:26.869: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:26.869: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:26.869: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:27.853: INFO: Pod daemon-set-r5p9q is not available
Feb 22 07:49:27.853: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:27.864: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:27.865: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:27.865: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:28.857: INFO: Pod daemon-set-r5p9q is not available
Feb 22 07:49:28.857: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:28.876: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:28.876: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:28.877: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:29.868: INFO: Pod daemon-set-r5p9q is not available
Feb 22 07:49:29.868: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:29.879: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:29.879: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:29.879: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:30.854: INFO: Pod daemon-set-r5p9q is not available
Feb 22 07:49:30.854: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:30.868: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:30.868: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:30.869: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:31.867: INFO: Pod daemon-set-r5p9q is not available
Feb 22 07:49:31.867: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:31.886: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:31.887: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:31.887: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:32.854: INFO: Pod daemon-set-r5p9q is not available
Feb 22 07:49:32.854: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:32.866: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:32.866: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:32.866: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:33.882: INFO: Pod daemon-set-r5p9q is not available
Feb 22 07:49:33.883: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:33.903: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:33.903: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:33.903: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:34.856: INFO: Pod daemon-set-r5p9q is not available
Feb 22 07:49:34.856: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:34.868: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:34.868: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:34.868: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:35.859: INFO: Pod daemon-set-r5p9q is not available
Feb 22 07:49:35.859: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:35.875: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:35.876: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:35.876: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:36.854: INFO: Pod daemon-set-r5p9q is not available
Feb 22 07:49:36.854: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:36.867: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:36.867: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:36.867: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:37.853: INFO: Pod daemon-set-r5p9q is not available
Feb 22 07:49:37.853: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:37.865: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:37.865: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:37.865: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:38.860: INFO: Pod daemon-set-r5p9q is not available
Feb 22 07:49:38.860: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:38.869: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:38.869: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:38.869: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:39.864: INFO: Pod daemon-set-r5p9q is not available
Feb 22 07:49:39.864: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:39.875: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:39.876: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:39.876: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:40.860: INFO: Pod daemon-set-r5p9q is not available
Feb 22 07:49:40.860: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:40.881: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:40.882: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:40.882: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:41.852: INFO: Pod daemon-set-r5p9q is not available
Feb 22 07:49:41.852: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:41.861: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:41.862: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:41.862: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:42.857: INFO: Pod daemon-set-r5p9q is not available
Feb 22 07:49:42.857: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:42.867: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:42.868: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:42.868: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:43.861: INFO: Pod daemon-set-r5p9q is not available
Feb 22 07:49:43.862: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:43.874: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:43.874: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:43.874: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:44.857: INFO: Pod daemon-set-r5p9q is not available
Feb 22 07:49:44.857: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:44.870: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:44.870: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:44.870: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:45.864: INFO: Pod daemon-set-r5p9q is not available
Feb 22 07:49:45.864: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:45.888: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:45.888: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:45.888: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:46.857: INFO: Pod daemon-set-r5p9q is not available
Feb 22 07:49:46.857: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:46.864: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:46.865: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:46.865: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:47.863: INFO: Pod daemon-set-r5p9q is not available
Feb 22 07:49:47.863: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:47.873: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:47.874: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:47.874: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:48.858: INFO: Pod daemon-set-r5p9q is not available
Feb 22 07:49:48.859: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:48.878: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:48.879: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:48.879: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:49.896: INFO: Pod daemon-set-r5p9q is not available
Feb 22 07:49:49.896: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:49.917: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:49.917: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:49.917: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:50.863: INFO: Pod daemon-set-r5p9q is not available
Feb 22 07:49:50.864: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:50.885: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:50.886: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:50.886: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:52.880: INFO: Pod daemon-set-r5p9q is not available
Feb 22 07:49:52.880: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:53.302: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:53.306: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:53.308: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:53.861: INFO: Pod daemon-set-r5p9q is not available
Feb 22 07:49:53.861: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:53.925: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:53.926: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:53.926: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:54.857: INFO: Pod daemon-set-r5p9q is not available
Feb 22 07:49:54.857: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:54.872: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:54.873: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:54.873: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:55.860: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:55.890: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:55.890: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:55.890: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:56.856: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:56.873: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:56.873: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:56.873: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:57.856: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:57.869: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:57.870: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:57.870: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:58.869: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:58.892: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:58.892: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:58.893: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:59.861: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:49:59.880: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:59.880: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:49:59.880: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:00.875: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:50:00.906: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:00.907: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:00.907: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:01.879: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:50:01.914: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:01.914: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:01.915: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:02.880: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:50:02.898: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:02.899: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:02.899: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:03.955: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:50:04.036: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:04.036: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:04.037: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:04.876: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:50:04.952: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:04.952: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:04.952: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:05.876: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:50:05.893: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:05.893: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:05.893: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:06.869: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:50:06.892: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:06.892: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:06.892: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:07.863: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:50:07.879: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:07.880: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:07.881: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:08.915: INFO: Wrong image for pod: daemon-set-sfqrj. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: mirror.gcr.io/library/httpd:2.4.38-alpine.
Feb 22 07:50:08.976: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:08.976: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:08.976: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:09.954: INFO: Pod daemon-set-q4v2g is not available
Feb 22 07:50:10.067: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:10.067: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:10.068: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Feb 22 07:50:10.118: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:10.119: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:10.119: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:10.142: INFO: Number of nodes with available pods: 2
Feb 22 07:50:10.142: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 07:50:11.246: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:11.246: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:11.246: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:11.340: INFO: Number of nodes with available pods: 2
Feb 22 07:50:11.340: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 07:50:12.164: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:12.164: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:12.164: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:12.181: INFO: Number of nodes with available pods: 2
Feb 22 07:50:12.181: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 07:50:13.164: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:13.164: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:13.165: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:13.186: INFO: Number of nodes with available pods: 2
Feb 22 07:50:13.186: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 07:50:14.153: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:14.154: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:14.154: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:14.179: INFO: Number of nodes with available pods: 2
Feb 22 07:50:14.179: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 07:50:15.162: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:15.165: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:15.165: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:15.177: INFO: Number of nodes with available pods: 2
Feb 22 07:50:15.178: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 07:50:16.156: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:16.157: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:16.158: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:16.171: INFO: Number of nodes with available pods: 2
Feb 22 07:50:16.171: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 07:50:17.161: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:17.162: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:17.162: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:17.172: INFO: Number of nodes with available pods: 2
Feb 22 07:50:17.175: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 07:50:18.174: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:18.174: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:18.174: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:18.190: INFO: Number of nodes with available pods: 2
Feb 22 07:50:18.190: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 07:50:19.162: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:19.163: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:19.163: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:19.218: INFO: Number of nodes with available pods: 2
Feb 22 07:50:19.218: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 07:50:20.170: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:20.171: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:20.172: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:20.199: INFO: Number of nodes with available pods: 2
Feb 22 07:50:20.204: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 07:50:21.153: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:21.153: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:21.154: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:21.164: INFO: Number of nodes with available pods: 2
Feb 22 07:50:21.164: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 07:50:22.165: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:22.166: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:22.166: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:22.186: INFO: Number of nodes with available pods: 2
Feb 22 07:50:22.187: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 07:50:23.154: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:23.154: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:23.155: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:23.163: INFO: Number of nodes with available pods: 2
Feb 22 07:50:23.163: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 07:50:24.177: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:24.178: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:24.178: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:24.195: INFO: Number of nodes with available pods: 2
Feb 22 07:50:24.195: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 07:50:25.160: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:25.160: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:25.160: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:25.186: INFO: Number of nodes with available pods: 2
Feb 22 07:50:25.186: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 07:50:26.169: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:26.169: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:26.170: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:26.183: INFO: Number of nodes with available pods: 2
Feb 22 07:50:26.186: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 07:50:27.153: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:27.153: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:27.156: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:27.170: INFO: Number of nodes with available pods: 2
Feb 22 07:50:27.170: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 07:50:28.183: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:28.184: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:28.184: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:28.218: INFO: Number of nodes with available pods: 2
Feb 22 07:50:28.218: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 07:50:29.190: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:29.190: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:29.190: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:29.201: INFO: Number of nodes with available pods: 2
Feb 22 07:50:29.201: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 07:50:30.165: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:30.165: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:30.166: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:30.183: INFO: Number of nodes with available pods: 2
Feb 22 07:50:30.183: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 07:50:31.155: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:31.155: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:31.155: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:31.180: INFO: Number of nodes with available pods: 2
Feb 22 07:50:31.180: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 07:50:32.153: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:32.153: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:32.153: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:32.166: INFO: Number of nodes with available pods: 2
Feb 22 07:50:32.166: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 07:50:33.152: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:33.152: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:33.152: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:33.163: INFO: Number of nodes with available pods: 2
Feb 22 07:50:33.163: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 07:50:34.151: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:34.151: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:34.151: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:34.159: INFO: Number of nodes with available pods: 2
Feb 22 07:50:34.160: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 07:50:35.158: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:35.158: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:35.158: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:35.190: INFO: Number of nodes with available pods: 2
Feb 22 07:50:35.190: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 07:50:36.155: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:36.155: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:36.155: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:36.176: INFO: Number of nodes with available pods: 2
Feb 22 07:50:36.176: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 07:50:37.153: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:37.153: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:37.153: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:37.164: INFO: Number of nodes with available pods: 2
Feb 22 07:50:37.164: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 07:50:38.154: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:38.155: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:38.155: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:38.162: INFO: Number of nodes with available pods: 2
Feb 22 07:50:38.163: INFO: Node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com is running more than one daemon pod
Feb 22 07:50:39.181: INFO: DaemonSet pods can't tolerate node 422f888355a48498536ab68056030072 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:39.181: INFO: DaemonSet pods can't tolerate node 422f8946e8dc4ac0fce204ff99712420 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:39.181: INFO: DaemonSet pods can't tolerate node 422fb028afb4424610166abf3cd69ee0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb 22 07:50:39.233: INFO: Number of nodes with available pods: 3
Feb 22 07:50:39.233: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8925, will wait for the garbage collector to delete the pods
Feb 22 07:50:39.503: INFO: Deleting DaemonSet.extensions daemon-set took: 46.12276ms
Feb 22 07:50:41.504: INFO: Terminating DaemonSet.extensions daemon-set pods took: 2.001243391s
Feb 22 07:51:01.536: INFO: Number of nodes with available pods: 0
Feb 22 07:51:01.537: INFO: Number of running nodes: 0, number of available pods: 0
Feb 22 07:51:01.549: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-8925/daemonsets","resourceVersion":"200577"},"items":null}

Feb 22 07:51:01.555: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-8925/pods","resourceVersion":"200577"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 07:51:01.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8925" for this suite.

â€¢ [SLOW TEST:208.675 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]","total":270,"completed":264,"skipped":4567,"failed":0}
SSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 07:51:01.797: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4669
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-map-1c5bb5ef-6fce-4ee9-b6f8-69f0b2443c93
STEP: Creating a pod to test consume configMaps
Feb 22 07:51:02.257: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b151088f-419e-406c-b358-ba7ce238dbf7" in namespace "projected-4669" to be "Succeeded or Failed"
Feb 22 07:51:02.265: INFO: Pod "pod-projected-configmaps-b151088f-419e-406c-b358-ba7ce238dbf7": Phase="Pending", Reason="", readiness=false. Elapsed: 8.752384ms
Feb 22 07:51:04.283: INFO: Pod "pod-projected-configmaps-b151088f-419e-406c-b358-ba7ce238dbf7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026633225s
Feb 22 07:51:06.296: INFO: Pod "pod-projected-configmaps-b151088f-419e-406c-b358-ba7ce238dbf7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.039785656s
Feb 22 07:51:08.314: INFO: Pod "pod-projected-configmaps-b151088f-419e-406c-b358-ba7ce238dbf7": Phase="Pending", Reason="", readiness=false. Elapsed: 6.057346747s
Feb 22 07:51:10.327: INFO: Pod "pod-projected-configmaps-b151088f-419e-406c-b358-ba7ce238dbf7": Phase="Pending", Reason="", readiness=false. Elapsed: 8.07064274s
Feb 22 07:51:12.335: INFO: Pod "pod-projected-configmaps-b151088f-419e-406c-b358-ba7ce238dbf7": Phase="Pending", Reason="", readiness=false. Elapsed: 10.078264461s
Feb 22 07:51:14.355: INFO: Pod "pod-projected-configmaps-b151088f-419e-406c-b358-ba7ce238dbf7": Phase="Pending", Reason="", readiness=false. Elapsed: 12.098355708s
Feb 22 07:51:16.368: INFO: Pod "pod-projected-configmaps-b151088f-419e-406c-b358-ba7ce238dbf7": Phase="Pending", Reason="", readiness=false. Elapsed: 14.110992347s
Feb 22 07:51:18.374: INFO: Pod "pod-projected-configmaps-b151088f-419e-406c-b358-ba7ce238dbf7": Phase="Pending", Reason="", readiness=false. Elapsed: 16.117820838s
Feb 22 07:51:20.397: INFO: Pod "pod-projected-configmaps-b151088f-419e-406c-b358-ba7ce238dbf7": Phase="Pending", Reason="", readiness=false. Elapsed: 18.140402021s
Feb 22 07:51:22.471: INFO: Pod "pod-projected-configmaps-b151088f-419e-406c-b358-ba7ce238dbf7": Phase="Pending", Reason="", readiness=false. Elapsed: 20.214644786s
Feb 22 07:51:24.530: INFO: Pod "pod-projected-configmaps-b151088f-419e-406c-b358-ba7ce238dbf7": Phase="Pending", Reason="", readiness=false. Elapsed: 22.27301305s
Feb 22 07:51:26.542: INFO: Pod "pod-projected-configmaps-b151088f-419e-406c-b358-ba7ce238dbf7": Phase="Pending", Reason="", readiness=false. Elapsed: 24.285767905s
Feb 22 07:51:28.550: INFO: Pod "pod-projected-configmaps-b151088f-419e-406c-b358-ba7ce238dbf7": Phase="Pending", Reason="", readiness=false. Elapsed: 26.293734625s
Feb 22 07:51:30.559: INFO: Pod "pod-projected-configmaps-b151088f-419e-406c-b358-ba7ce238dbf7": Phase="Pending", Reason="", readiness=false. Elapsed: 28.30282146s
Feb 22 07:51:32.570: INFO: Pod "pod-projected-configmaps-b151088f-419e-406c-b358-ba7ce238dbf7": Phase="Pending", Reason="", readiness=false. Elapsed: 30.313699542s
Feb 22 07:51:34.621: INFO: Pod "pod-projected-configmaps-b151088f-419e-406c-b358-ba7ce238dbf7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 32.364113242s
STEP: Saw pod success
Feb 22 07:51:34.621: INFO: Pod "pod-projected-configmaps-b151088f-419e-406c-b358-ba7ce238dbf7" satisfied condition "Succeeded or Failed"
Feb 22 07:51:34.646: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com pod pod-projected-configmaps-b151088f-419e-406c-b358-ba7ce238dbf7 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 22 07:51:41.759: INFO: Waiting for pod pod-projected-configmaps-b151088f-419e-406c-b358-ba7ce238dbf7 to disappear
Feb 22 07:51:41.796: INFO: Pod pod-projected-configmaps-b151088f-419e-406c-b358-ba7ce238dbf7 still exists
Feb 22 07:51:43.796: INFO: Waiting for pod pod-projected-configmaps-b151088f-419e-406c-b358-ba7ce238dbf7 to disappear
Feb 22 07:51:43.813: INFO: Pod pod-projected-configmaps-b151088f-419e-406c-b358-ba7ce238dbf7 still exists
Feb 22 07:51:45.796: INFO: Waiting for pod pod-projected-configmaps-b151088f-419e-406c-b358-ba7ce238dbf7 to disappear
Feb 22 07:51:45.806: INFO: Pod pod-projected-configmaps-b151088f-419e-406c-b358-ba7ce238dbf7 still exists
Feb 22 07:51:47.796: INFO: Waiting for pod pod-projected-configmaps-b151088f-419e-406c-b358-ba7ce238dbf7 to disappear
Feb 22 07:51:47.802: INFO: Pod pod-projected-configmaps-b151088f-419e-406c-b358-ba7ce238dbf7 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 07:51:47.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4669" for this suite.

â€¢ [SLOW TEST:46.075 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:36
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","total":270,"completed":265,"skipped":4574,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 07:51:47.890: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4228
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name cm-test-opt-del-c5438e88-958c-4885-8ee9-a207068dae0f
STEP: Creating configMap with name cm-test-opt-upd-43bce311-225f-48bc-8e1e-4edc9bc8ee6d
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-c5438e88-958c-4885-8ee9-a207068dae0f
STEP: Updating configmap cm-test-opt-upd-43bce311-225f-48bc-8e1e-4edc9bc8ee6d
STEP: Creating configMap with name cm-test-opt-create-fef46e70-bd3f-4ac7-8498-c7568ff4950f
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 07:53:18.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4228" for this suite.

â€¢ [SLOW TEST:90.611 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:36
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]","total":270,"completed":266,"skipped":4611,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 07:53:18.526: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-6441
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a ResourceQuota
STEP: Getting a ResourceQuota
STEP: Updating a ResourceQuota
STEP: Verifying a ResourceQuota was modified
STEP: Deleting a ResourceQuota
STEP: Verifying the deleted ResourceQuota
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 07:53:19.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6441" for this suite.
â€¢{"msg":"PASSED [sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]","total":270,"completed":267,"skipped":4637,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 07:53:19.510: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3792
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name projected-secret-test-map-c7ba4ff3-db79-4c0b-9b8c-92588de36444
STEP: Creating a pod to test consume secrets
Feb 22 07:53:20.196: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-11ff8813-9952-403d-9e5f-77dbc8703adf" in namespace "projected-3792" to be "Succeeded or Failed"
Feb 22 07:53:20.373: INFO: Pod "pod-projected-secrets-11ff8813-9952-403d-9e5f-77dbc8703adf": Phase="Pending", Reason="", readiness=false. Elapsed: 177.310028ms
Feb 22 07:53:22.383: INFO: Pod "pod-projected-secrets-11ff8813-9952-403d-9e5f-77dbc8703adf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.18710025s
Feb 22 07:53:24.477: INFO: Pod "pod-projected-secrets-11ff8813-9952-403d-9e5f-77dbc8703adf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.281066731s
Feb 22 07:53:26.503: INFO: Pod "pod-projected-secrets-11ff8813-9952-403d-9e5f-77dbc8703adf": Phase="Pending", Reason="", readiness=false. Elapsed: 6.307057025s
Feb 22 07:53:28.510: INFO: Pod "pod-projected-secrets-11ff8813-9952-403d-9e5f-77dbc8703adf": Phase="Pending", Reason="", readiness=false. Elapsed: 8.314538621s
Feb 22 07:53:30.554: INFO: Pod "pod-projected-secrets-11ff8813-9952-403d-9e5f-77dbc8703adf": Phase="Pending", Reason="", readiness=false. Elapsed: 10.357863801s
Feb 22 07:53:32.562: INFO: Pod "pod-projected-secrets-11ff8813-9952-403d-9e5f-77dbc8703adf": Phase="Pending", Reason="", readiness=false. Elapsed: 12.366418711s
Feb 22 07:53:34.576: INFO: Pod "pod-projected-secrets-11ff8813-9952-403d-9e5f-77dbc8703adf": Phase="Pending", Reason="", readiness=false. Elapsed: 14.379869591s
Feb 22 07:53:36.584: INFO: Pod "pod-projected-secrets-11ff8813-9952-403d-9e5f-77dbc8703adf": Phase="Pending", Reason="", readiness=false. Elapsed: 16.388596058s
Feb 22 07:53:38.593: INFO: Pod "pod-projected-secrets-11ff8813-9952-403d-9e5f-77dbc8703adf": Phase="Pending", Reason="", readiness=false. Elapsed: 18.397199149s
Feb 22 07:53:40.606: INFO: Pod "pod-projected-secrets-11ff8813-9952-403d-9e5f-77dbc8703adf": Phase="Pending", Reason="", readiness=false. Elapsed: 20.410219143s
Feb 22 07:53:42.622: INFO: Pod "pod-projected-secrets-11ff8813-9952-403d-9e5f-77dbc8703adf": Phase="Pending", Reason="", readiness=false. Elapsed: 22.426134062s
Feb 22 07:53:44.628: INFO: Pod "pod-projected-secrets-11ff8813-9952-403d-9e5f-77dbc8703adf": Phase="Pending", Reason="", readiness=false. Elapsed: 24.432465057s
Feb 22 07:53:46.637: INFO: Pod "pod-projected-secrets-11ff8813-9952-403d-9e5f-77dbc8703adf": Phase="Pending", Reason="", readiness=false. Elapsed: 26.440859046s
Feb 22 07:53:48.652: INFO: Pod "pod-projected-secrets-11ff8813-9952-403d-9e5f-77dbc8703adf": Phase="Pending", Reason="", readiness=false. Elapsed: 28.456380038s
Feb 22 07:53:50.668: INFO: Pod "pod-projected-secrets-11ff8813-9952-403d-9e5f-77dbc8703adf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 30.47170779s
STEP: Saw pod success
Feb 22 07:53:50.668: INFO: Pod "pod-projected-secrets-11ff8813-9952-403d-9e5f-77dbc8703adf" satisfied condition "Succeeded or Failed"
Feb 22 07:53:50.682: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com pod pod-projected-secrets-11ff8813-9952-403d-9e5f-77dbc8703adf container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 22 07:53:57.584: INFO: Waiting for pod pod-projected-secrets-11ff8813-9952-403d-9e5f-77dbc8703adf to disappear
Feb 22 07:53:57.602: INFO: Pod pod-projected-secrets-11ff8813-9952-403d-9e5f-77dbc8703adf still exists
Feb 22 07:53:59.603: INFO: Waiting for pod pod-projected-secrets-11ff8813-9952-403d-9e5f-77dbc8703adf to disappear
Feb 22 07:53:59.610: INFO: Pod pod-projected-secrets-11ff8813-9952-403d-9e5f-77dbc8703adf still exists
Feb 22 07:54:01.603: INFO: Waiting for pod pod-projected-secrets-11ff8813-9952-403d-9e5f-77dbc8703adf to disappear
Feb 22 07:54:01.621: INFO: Pod pod-projected-secrets-11ff8813-9952-403d-9e5f-77dbc8703adf still exists
Feb 22 07:54:03.603: INFO: Waiting for pod pod-projected-secrets-11ff8813-9952-403d-9e5f-77dbc8703adf to disappear
Feb 22 07:54:03.614: INFO: Pod pod-projected-secrets-11ff8813-9952-403d-9e5f-77dbc8703adf still exists
Feb 22 07:54:05.609: INFO: Waiting for pod pod-projected-secrets-11ff8813-9952-403d-9e5f-77dbc8703adf to disappear
Feb 22 07:54:06.561: INFO: Pod pod-projected-secrets-11ff8813-9952-403d-9e5f-77dbc8703adf still exists
Feb 22 07:54:07.603: INFO: Waiting for pod pod-projected-secrets-11ff8813-9952-403d-9e5f-77dbc8703adf to disappear
Feb 22 07:54:08.466: INFO: Pod pod-projected-secrets-11ff8813-9952-403d-9e5f-77dbc8703adf still exists
Feb 22 07:54:09.602: INFO: Waiting for pod pod-projected-secrets-11ff8813-9952-403d-9e5f-77dbc8703adf to disappear
Feb 22 07:54:10.545: INFO: Pod pod-projected-secrets-11ff8813-9952-403d-9e5f-77dbc8703adf no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 07:54:10.551: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3792" for this suite.

â€¢ [SLOW TEST:51.906 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":270,"completed":268,"skipped":4648,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 07:54:11.505: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-9771
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test override command
Feb 22 07:54:13.018: INFO: Waiting up to 5m0s for pod "client-containers-f28b181f-3e3f-41a6-bb0e-3e4026a85b06" in namespace "containers-9771" to be "Succeeded or Failed"
Feb 22 07:54:13.329: INFO: Pod "client-containers-f28b181f-3e3f-41a6-bb0e-3e4026a85b06": Phase="Pending", Reason="", readiness=false. Elapsed: 310.616901ms
Feb 22 07:54:15.386: INFO: Pod "client-containers-f28b181f-3e3f-41a6-bb0e-3e4026a85b06": Phase="Pending", Reason="", readiness=false. Elapsed: 2.367426131s
Feb 22 07:54:18.189: INFO: Pod "client-containers-f28b181f-3e3f-41a6-bb0e-3e4026a85b06": Phase="Pending", Reason="", readiness=false. Elapsed: 5.170877584s
Feb 22 07:54:20.955: INFO: Pod "client-containers-f28b181f-3e3f-41a6-bb0e-3e4026a85b06": Phase="Pending", Reason="", readiness=false. Elapsed: 7.936602572s
Feb 22 07:54:23.034: INFO: Pod "client-containers-f28b181f-3e3f-41a6-bb0e-3e4026a85b06": Phase="Pending", Reason="", readiness=false. Elapsed: 10.015457516s
Feb 22 07:54:25.062: INFO: Pod "client-containers-f28b181f-3e3f-41a6-bb0e-3e4026a85b06": Phase="Pending", Reason="", readiness=false. Elapsed: 12.044042851s
Feb 22 07:54:27.082: INFO: Pod "client-containers-f28b181f-3e3f-41a6-bb0e-3e4026a85b06": Phase="Pending", Reason="", readiness=false. Elapsed: 14.064144866s
Feb 22 07:54:29.094: INFO: Pod "client-containers-f28b181f-3e3f-41a6-bb0e-3e4026a85b06": Phase="Pending", Reason="", readiness=false. Elapsed: 16.075730223s
Feb 22 07:54:31.101: INFO: Pod "client-containers-f28b181f-3e3f-41a6-bb0e-3e4026a85b06": Phase="Pending", Reason="", readiness=false. Elapsed: 18.083200383s
Feb 22 07:54:33.111: INFO: Pod "client-containers-f28b181f-3e3f-41a6-bb0e-3e4026a85b06": Phase="Pending", Reason="", readiness=false. Elapsed: 20.092522372s
Feb 22 07:54:35.121: INFO: Pod "client-containers-f28b181f-3e3f-41a6-bb0e-3e4026a85b06": Phase="Pending", Reason="", readiness=false. Elapsed: 22.103222445s
Feb 22 07:54:37.142: INFO: Pod "client-containers-f28b181f-3e3f-41a6-bb0e-3e4026a85b06": Phase="Pending", Reason="", readiness=false. Elapsed: 24.124035171s
Feb 22 07:54:39.154: INFO: Pod "client-containers-f28b181f-3e3f-41a6-bb0e-3e4026a85b06": Phase="Pending", Reason="", readiness=false. Elapsed: 26.136242649s
Feb 22 07:54:41.170: INFO: Pod "client-containers-f28b181f-3e3f-41a6-bb0e-3e4026a85b06": Phase="Pending", Reason="", readiness=false. Elapsed: 28.151718028s
Feb 22 07:54:43.202: INFO: Pod "client-containers-f28b181f-3e3f-41a6-bb0e-3e4026a85b06": Phase="Pending", Reason="", readiness=false. Elapsed: 30.183407908s
Feb 22 07:54:45.211: INFO: Pod "client-containers-f28b181f-3e3f-41a6-bb0e-3e4026a85b06": Phase="Succeeded", Reason="", readiness=false. Elapsed: 32.193254739s
STEP: Saw pod success
Feb 22 07:54:45.212: INFO: Pod "client-containers-f28b181f-3e3f-41a6-bb0e-3e4026a85b06" satisfied condition "Succeeded or Failed"
Feb 22 07:54:45.241: INFO: Trying to get logs from node sc2-rdops-vm05-dhcp-174-51.eng.vmware.com pod client-containers-f28b181f-3e3f-41a6-bb0e-3e4026a85b06 container test-container: <nil>
STEP: delete the pod
Feb 22 07:54:45.322: INFO: Waiting for pod client-containers-f28b181f-3e3f-41a6-bb0e-3e4026a85b06 to disappear
Feb 22 07:54:45.354: INFO: Pod client-containers-f28b181f-3e3f-41a6-bb0e-3e4026a85b06 still exists
Feb 22 07:54:47.356: INFO: Waiting for pod client-containers-f28b181f-3e3f-41a6-bb0e-3e4026a85b06 to disappear
Feb 22 07:54:47.365: INFO: Pod client-containers-f28b181f-3e3f-41a6-bb0e-3e4026a85b06 still exists
Feb 22 07:54:49.356: INFO: Waiting for pod client-containers-f28b181f-3e3f-41a6-bb0e-3e4026a85b06 to disappear
Feb 22 07:54:49.375: INFO: Pod client-containers-f28b181f-3e3f-41a6-bb0e-3e4026a85b06 still exists
Feb 22 07:54:51.355: INFO: Waiting for pod client-containers-f28b181f-3e3f-41a6-bb0e-3e4026a85b06 to disappear
Feb 22 07:54:51.376: INFO: Pod client-containers-f28b181f-3e3f-41a6-bb0e-3e4026a85b06 still exists
Feb 22 07:54:53.356: INFO: Waiting for pod client-containers-f28b181f-3e3f-41a6-bb0e-3e4026a85b06 to disappear
Feb 22 07:54:53.371: INFO: Pod client-containers-f28b181f-3e3f-41a6-bb0e-3e4026a85b06 still exists
Feb 22 07:54:55.356: INFO: Waiting for pod client-containers-f28b181f-3e3f-41a6-bb0e-3e4026a85b06 to disappear
Feb 22 07:54:55.368: INFO: Pod client-containers-f28b181f-3e3f-41a6-bb0e-3e4026a85b06 still exists
Feb 22 07:54:57.355: INFO: Waiting for pod client-containers-f28b181f-3e3f-41a6-bb0e-3e4026a85b06 to disappear
Feb 22 07:54:57.365: INFO: Pod client-containers-f28b181f-3e3f-41a6-bb0e-3e4026a85b06 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 07:54:57.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-9771" for this suite.

â€¢ [SLOW TEST:45.920 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Docker Containers should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]","total":270,"completed":269,"skipped":4693,"failed":0}
SSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Feb 22 07:54:57.445: INFO: >>> kubeConfig: /root/.kube/config
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-8009
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Performing setup for networking test in namespace pod-network-test-8009
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 22 07:54:57.765: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Feb 22 07:54:57.917: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Feb 22 07:54:59.938: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Feb 22 07:55:01.947: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Feb 22 07:55:03.960: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Feb 22 07:55:05.942: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Feb 22 07:55:07.925: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Feb 22 07:55:09.942: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Feb 22 07:55:11.928: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Feb 22 07:55:13.926: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Feb 22 07:55:15.927: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Feb 22 07:55:17.929: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Feb 22 07:55:19.929: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Feb 22 07:55:21.927: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Feb 22 07:55:23.935: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Feb 22 07:55:25.953: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Feb 22 07:55:28.023: INFO: The status of Pod netserver-0 is Running (Ready = false)
Feb 22 07:55:29.962: INFO: The status of Pod netserver-0 is Running (Ready = false)
Feb 22 07:55:31.932: INFO: The status of Pod netserver-0 is Running (Ready = false)
Feb 22 07:55:33.942: INFO: The status of Pod netserver-0 is Running (Ready = false)
Feb 22 07:55:36.224: INFO: The status of Pod netserver-0 is Running (Ready = false)
Feb 22 07:55:37.929: INFO: The status of Pod netserver-0 is Running (Ready = false)
Feb 22 07:55:39.932: INFO: The status of Pod netserver-0 is Running (Ready = true)
Feb 22 07:55:39.957: INFO: The status of Pod netserver-1 is Running (Ready = true)
Feb 22 07:55:39.992: INFO: The status of Pod netserver-2 is Running (Ready = false)
Feb 22 07:55:42.015: INFO: The status of Pod netserver-2 is Running (Ready = false)
Feb 22 07:55:44.004: INFO: The status of Pod netserver-2 is Running (Ready = true)
STEP: Creating test pods
Feb 22 07:56:10.281: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.26.1.197:8080/dial?request=hostname&protocol=http&host=172.26.1.194&port=8080&tries=1'] Namespace:pod-network-test-8009 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 22 07:56:10.282: INFO: >>> kubeConfig: /root/.kube/config
Feb 22 07:56:10.900: INFO: Waiting for responses: map[]
Feb 22 07:56:10.907: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.26.1.197:8080/dial?request=hostname&protocol=http&host=172.26.1.195&port=8080&tries=1'] Namespace:pod-network-test-8009 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 22 07:56:10.908: INFO: >>> kubeConfig: /root/.kube/config
Feb 22 07:56:11.045: INFO: Waiting for responses: map[]
Feb 22 07:56:11.056: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.26.1.197:8080/dial?request=hostname&protocol=http&host=172.26.1.196&port=8080&tries=1'] Namespace:pod-network-test-8009 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 22 07:56:11.056: INFO: >>> kubeConfig: /root/.kube/config
Feb 22 07:56:11.193: INFO: Waiting for responses: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Feb 22 07:56:11.194: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-8009" for this suite.

â€¢ [SLOW TEST:73.803 seconds]
[sig-network] Networking
/workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:26
  Granular Checks: Pods
  /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:29
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.18.2-beta.0.14+a78cd082e8c913/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance]","total":270,"completed":270,"skipped":4698,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSFeb 22 07:56:11.252: INFO: Running AfterSuite actions on all nodes
Feb 22 07:56:11.253: INFO: Running AfterSuite actions on node 1
Feb 22 07:56:11.253: INFO: Dumping logs locally to: /root/e2e.results
Checking for custom logdump instances, if any
Sourcing kube-util.sh
Detecting project
/root/kubernetes/cluster/log-dump/../../cluster/../cluster/gce/util.sh: line 187: gcloud: command not found
Feb 22 07:56:11.488: INFO: Error running cluster/log-dump/log-dump.sh: exit status 127

JUnit report was created: /root/e2e.results/junit_01.xml
{"msg":"Test Suite completed","total":270,"completed":270,"skipped":4722,"failed":0}

Ran 270 of 4992 Specs in 14766.785 seconds
SUCCESS! -- 270 Passed | 0 Failed | 0 Pending | 4722 Skipped
PASS
